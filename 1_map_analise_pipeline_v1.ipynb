{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark> <b> > 1. </b> Mapeamento e analise do  Pipeline </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1_map_analise_pipeline_v0.ipynb </b> |  Atual notebook com as funçoes de mapeamento e analise do pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from urllib import response\n",
    "\n",
    "from outlook_msg import Message\n",
    "import extract_msg\n",
    "import zipfile\n",
    "from pyunpack import Archive\n",
    "import py7zr\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import PyPDF2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "import locale\n",
    "import time, copy\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import cv2\n",
    "import fitz  # Módulo PyMuPDF\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "# Modulos da solucao\n",
    "import modules.cronometro as cron\n",
    "import modules.utils as utl\n",
    "import modules.trata_pdf as tpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Token\n",
    "from spacy.language import Language\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "ner = nlp.remove_pipe('ner')\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Config - Mapeamento e Analise do pipeline\n",
    "\n",
    "# 1. XXX Path para planilha de processamento de batches\n",
    "conf_export_plan_path = 'processamentos/processamento_batches/df_conf_export_batch.xlsx'\n",
    "\n",
    "# 2. XXX  Tratando nome de carga do df_processamento\n",
    "map_analise_path = \"processamentos/mapeamento_analise\"\n",
    "\n",
    "# 3. XXX  prefixo de nome do arquivo de exportaçao\n",
    "df_root_pipe_file = \"df_root_\"\n",
    "\n",
    "# 4. XXX Tipos de documentos para extracao\n",
    "tipo_documento_path = \"config/tipo_documentos\"\n",
    "\n",
    "# 5. XXX Path para tipo de documento patterns\n",
    "tipo_documento_patterns_path = \"config/tipo_documentos/patterns\"\n",
    "\n",
    "\n",
    "# 5. Path para documentos para extracao\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento\"\n",
    "\n",
    "\n",
    "# Paths de trabalho para Raster_PDF\n",
    "raster_process_pdf_path = 'processamentos/temp/pdf'\n",
    "raster_process_txt_path = 'processamentos/temp/txt'\n",
    "\n",
    "\n",
    "# 6. XXX Nome do caminha para dict Tipo de documento\n",
    "config_tipo_doc_path = \"config/tipo_documentos/tipo_documento.json\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. IMPORTANTE - MUDOU - Path para gestao de imagens resized\n",
    "image_resized_path = \"processamentos/temp/images/processadas\"\n",
    "\n",
    "\n",
    "#### Config - E-mail\n",
    "# 1. Caminho do arquivo uma mensagem especifica\n",
    "msg_dir_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/11_emails'\n",
    "\n",
    "# 2. Path para arquivos atachados compactados\n",
    "msg_attachment_zip = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/13_attachments'\n",
    "\n",
    "\n",
    "#### Config - messages\n",
    "# 3. Caminho do arquivo uma mensagem especifica\n",
    "msg_outros_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/12_messages'\n",
    "\n",
    "# 4. Path para arquivos recebidos manualmente\n",
    "arquivos_recebidos_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/14_documentos_recebidos'\n",
    "\n",
    "\n",
    "# 6. Path para gestao de imagens resized\n",
    "image_resized_path = \"pipeline_extracao_documentos/6_geral_administacao/temp_docs/images/processadas\"\n",
    "\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ent_new(text, patterns):\n",
    "    #nlp = spacy.blank(\"pt\")\n",
    "    #ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = []\n",
    "    ents = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        span = doc.char_span(ent.start_char, ent.end_char, label=ent.label_)\n",
    "        ents.append(span)\n",
    "        \n",
    "    for token in doc:\n",
    "        start = token.idx\n",
    "        end = start + len(token)\n",
    "        tokens.append((token.text, start, end))\n",
    "        \n",
    "    return doc, tokens, ents\n",
    "\n",
    "\n",
    "# Funcoes para salvar e carregar entity ruler patterns\n",
    "\n",
    "def write_patterns_to_file(patterns, colors, filename):\n",
    "    data = {\"patterns\": patterns, \"colors\": colors}\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, ensure_ascii=True, indent=2)\n",
    "        \n",
    "\n",
    "        \n",
    "def load_patterns_and_colors(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        patterns = data[\"patterns\"]\n",
    "        colors = data[\"colors\"]\n",
    "    return patterns, colors \n",
    "\n",
    "\n",
    "\n",
    "def save_tipo_doc_to_file(dic, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dic, f) \n",
    "        \n",
    "        \n",
    "def load_dict_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes para Analise do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor = 'NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e'\n",
    "valor.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_documento_dict = {}\n",
    "\n",
    "tipo_documento_dict = {\n",
    "    'nfs_e': {\n",
    "            'descricao': 'nota fiscal de serviços eletrônica - nfs-e',\n",
    "            'matcher_pattern_path': path_matches_pattern_json,\n",
    "            'matcher_pattern_dict': matcher_pattern_dict,\n",
    "            'entity_ruler_pattern_path': entityruler_file_path,\n",
    "            'entity_ruler_colors': colors,\n",
    "            'entity_ruler_patterns': patterns,\n",
    "            'sample_content': \"\"\"27/07/2023, 15:12 Nota Fiscal de Serviços Eletrônica (NFSe) https://nfe.mesquita.rj.gov.br 1/1 PREFEITURA MUNICIPAL DE MESQUITA SECRETARIA MUNICIPAL DA FAZENDA NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Número da Nota: 20234 Competência: Julho/2023 Data e Hora da Emissão: 27/07/2023 15:11:00 Código Verificação: 4FDA9FBAE PRESTADOR DE SERVIÇOS CPF/CNPJ: 50.921.369/0001-05 Inscrição Municipal: 952538 Telefone: 2297268232.. Inscrição Estadual: Nome/Razão Social: MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA Nome de Fantasia: Endereço: RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesquita-RJ E-mail: LARA_VSORIA@HOTMAIL.COM TOMADOR DE SERVIÇOS CPF/CNPJ: 06.047.087/0033-16 | INSC:MUNICIPAL: RG: Telefone: Inscrição Estadual: Nome/Razão Social: REDE D'OR SAO LUIZ S.A. Endereço: OLINDA ELLIS N° 93 BAIRRO: CAMPO GRANDE CIDADE: RIO DE JANEIRO - RJ CEP: 23045160 E-mail: Não Informado DISCRIMINAÇÃO DOS SERVIÇOS Ref a Plantões de Janeiro, 36h no Setor de Radiologia - Médica: Lara Veiga Soria Catuladeira. VALOR TOTAL DA NOTA: R$ 4.280,16 CNAE - 8630502 - ATIVIDADE MÉDICA AMBULATORIAL COM RECURSOS PARA REALIZAÇÃO DE EXAMES COMPLEMENTARES Item da Lista de Serviços - 4.03 - HOSPITAIS, CLÍNICAS, LABORATÓRIOS, SANATÓRIOS, MANICÔMIOS, CASAS DE SAÚDE, PRONTOS-SOCORROS, AMBULATÓRIOS E CONGÊNERES. VALOR SERVIÇOS: R$ 4.280,16 VALOR DEDUÇÃO: R$ 0,00 DESC. INCOND: R$ 0,00 BASE DE CÁLCULO: R$ 4.280,16 ALÍQUOTA: 2,01% VALOR ISS: R$ 86,03 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 ____________________________________________________________________ VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR INSS: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR LÍQUIDO: R$ 4.280,16 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim ( 2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Mesquita - RJ LOCAL INCIDÊNCIA Mesquita - RJ Observação: LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 DE DEZEMBRO DE 2012. - PRESTADOR OPTANTE DO SIMPLES NACIONAL (ALÍQUOTA: 2,01 %) ESTA NFS-E FOI EMITIDA EM SUBSTITUIÇÃO À NFS-E 20231 Valor Aproximado dos Tributos Federais R$ 575,68 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 95,45 (Alíq IBPT 2,23 IBPT)\"\"\",\n",
    "            'official_name': 'Official Document Name',\n",
    "            'min_score_similarity_analise': 0.60,\n",
    "            'min_score_similarity_documento': 0.7\n",
    "    }\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_documento_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "novo_tipo_documento = {\n",
    "    'lista_nota': {\n",
    "            'descricao': 'Listagem de Notas Fiscais',\n",
    "            'matcher_pattern_path': path_matches_pattern_json,\n",
    "            'matcher_pattern_dict': matcher_pattern_dict,\n",
    "            'entity_ruler_pattern_path': entityruler_file_path,\n",
    "            'entity_ruler_colors': colors,\n",
    "            'entity_ruler_patterns': patterns,\n",
    "            'sample_content': \"\"\"02/08/23, 16:33 Nota Fiscal de Serviços Eletrônica (NFSe) Número da Nota: PREFEITURA MUNICIPAL DE MAGE ia Competência: SECRETARIA MUNICIPAL DA FAZENDA Agosto/2023 NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Data e Hora da Emissão: 02/08/2023 16:29:00 Código Verificação: OCDD6FB51 PRESTADOR DE SERVIÇOS CPF/CNPJ: Inscrição Municipal: Telefone: Inscrição Estadual: 33.462.862/0001-95 li: 4337 al Nome/Razão Social: SÃO MARCOS TERRAPLENAGEM E CONSTRUÇÃO LTDA. Nome de Fantasia: Endereço: RUA DAS MARGARIDAS ,578 ,SANTA DALILA - Magé-RJ E-mail: TOMADOR DE SERVIÇOS CPF/CNPJ: 29.115.474/0001-60 HINSC:MUNICIPAL: RG: | Telefone: Inscrição Estadual: Nome/Razão Social: MUNICÍPIO DE MACAE Endereço: ; PRESIDENTE FELICIANO SODRE Nº 534 PAÇO E-mail: NÃO INFORMADO MUNICIPAL BAIRRO: CENTRO CIDADE: MACAE ; - RJ CEP: 27913080 DISCRIMINAÇÃO DOS SERVIÇOS Serviço de Recomposição do Pavimento Asfáltico (Tapa Buraco), na cidade de Macaé/RJ, abrangendo Perímetro Urbano, Região Serrana, conf Boletim de Medição 08 — CO 022/2022 — Contrato 045/2022 - . Empenhos 501/2023 e 502/2023. M. Obra (10%)= R$ 104.468,45 Retenção p/ Prev. Social=R$ 11.491,53 Banco: ITAU Agência: 0726 C/Corrente: 35410-3 VALOR TOTAL DA NOTA: R$ 1.044.684,55 CNAE - 4313400 - OBRAS DE TERRAPLENAGEM . é o Item da Lista de Serviços - 7.02 - EXECUÇÃO, POR ADMINISTRAÇÃO, EMPREITADA OU SUBEMPREITADA, DE OBRAS DE CONSTRUÇÃO CIVIL, HIDRAULICA OU ELETRICA E DE OUTRAS OBRAS SEMELHANTES, INCLUSIVE SONDAGEM, PERFURAÇÃO DE POÇOS, ESCAVAÇÃO, DRENAG = [m]\\' vm La [=] VALOR SERVIÇOS: R$ 1.044.684,55 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 1.044.684,55 ALÍQUOTA: 2% VALOR ISS: R$ 0,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS R$ 0,00 eEd Era a e [=] Lt A =\" DADOS VALOR INSS: R$ 11.491,53 VALOR ISS RETIDO: R$ 20.893,69 RETENÇÕES: DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 1.012.299,33 COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Não ISSQN RETIDO Sim LOCAL. PRESTAÇÃO SERVIÇO Macaé - RJ LOCAL INCIDÊNCIA Macaé - RJ Observação: - ISS RETIDO PELO TOMADOR DE SERVIÇOS CNPJ: 29.115.474/0001-60 Valor Aproximado dos Tributos Federais R$ 136154,26 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 49906,36 (Alíq IBPT 4,93 IBPT) https://nfs-e.mage.rj.gov.br\"\"\",\n",
    "            'official_name': 'Official Document Name',\n",
    "            'min_score_similarity_analise': 0.45,\n",
    "            'min_score_similarity_documento': 0.6\n",
    "    }\n",
    "}\n",
    "\n",
    "tipo_documento_dict.update(novo_tipo_documento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Salvando o dict do tipo de documento para arquivo json\n",
    "save_tipo_doc_to_file(tipo_documento_dict, config_tipo_doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo de uso\n",
    "loaded_dict = load_dict_from_file('config.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Criar um dicionário para matchers patterns - nfs-e\n",
    "matcher_pattern_dict = {\n",
    "        \"numero_nota_pattern\": [\n",
    "            {\"LOWER\": \"número\"},\n",
    "            {\"LOWER\": \"da\"},\n",
    "            {\"LOWER\": \"nota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True}\n",
    "        ],\n",
    "        \"competencia_pattern\": [\n",
    "            {\"LOWER\": \"competência\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"?\"},\n",
    "            {\"ORTH\": {\"REGEX\": \"^[A-Z][a-z]+/[0-9]{4}$\"}}   \n",
    "        ],\n",
    "        \"data_hora_emissao_pattern\": [\n",
    "            {\"LOWER\": \"data\"},\n",
    "            {\"LOWER\": \"e\"},\n",
    "            {\"LOWER\": \"hora\"},\n",
    "            {\"LOWER\": \"da\"},\n",
    "            {\"LOWER\": \"emissão\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"SHAPE\": \"dd/dd/dddd\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"SHAPE\": \"dd:dd:dd\"}\n",
    "        ],\n",
    "        \"codigo_verificacao_pattern\": [\n",
    "            {\"LOWER\": \"código\"},\n",
    "            {\"LOWER\": \"verificação\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_ASCII\": True, \"LENGTH\": 9}\n",
    "        ],\n",
    "        \"valor_total_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"total\"},\n",
    "            {\"LOWER\": \"da\", \"OP\": \"?\"},\n",
    "            {\"LOWER\": \"nota\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_servicos_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"serviços\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_deducao_pattern\": [\n",
    "            {\"LOWER\": \"dedução\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_incondR_pattern\": [\n",
    "            {\"LOWER\": \"base\"},\n",
    "            {\"LOWER\": \"de\"},\n",
    "            {\"IS_SPACE\": True},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "        ],\n",
    "        \"valor_incond_patternP\": [\n",
    "            {\"LOWER\": \"desc\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "            {\"LOWER\": \"incond\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "        ],\n",
    "        \"valor_calculoR_pattern\": [\n",
    "            {\"LOWER\": \"cálculo\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_calculoP_pattern\": [\n",
    "            {\"LOWER\": \"base\"},\n",
    "            {\"LOWER\": \"de\"},\n",
    "            {\"LOWER\": \"cálculo\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_aliquota_pattern\": [\n",
    "            {\"LOWER\": \"alíquota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"d,dd\", \"OP\": \"?\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ],\n",
    "        \"valor_aliquota2_pattern\": [\n",
    "            {\"LOWER\": \"alíquota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"d\", \"OP\": \"?\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ],\n",
    "        \"valor_iss_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_issretido_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"LOWER\": \"retido\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_desccond_pattern\": [\n",
    "            {\"LOWER\": \"desc\"},\n",
    "            {\"ORTH\": \".\"},\n",
    "            {\"LOWER\": \"cond\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_pis_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"pis\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_cofins_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"cofins\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_ir_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"ir\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_inss_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"inss\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_csll_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"csll\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_outrasreten_pattern\": [\n",
    "            {\"LOWER\": \"outras\"},\n",
    "            {\"LOWER\": \"retenções\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_liquido_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"líquido\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"exigibilidade_iss_pattern\": [\n",
    "            {\"LOWER\": \"exigibilidade\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"LOWER\": {\"IN\": [\"exigivel\", \"não exigivel\"]}}\n",
    "        ],\n",
    "        \"padrao_regime_tributacao\": [\n",
    "            {\"LOWER\": \"regime\"},\n",
    "            {\"LOWER\": \"tributação\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"+\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"*\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": \"simples\", \"OP\": \"?\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"simples_nacional_nao_pattern\": [\n",
    "            {\"LOWER\": \"simples\"},\n",
    "            {\"LOWER\": \"nacional\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": \"não\"}\n",
    "        ],\n",
    "        \"simples_nacional_pattern\": [\n",
    "            {\"LOWER\": \"simples\"},\n",
    "            {\"LOWER\": \"nacional\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": \"sim\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \"(\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \"%\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \")\", \"OP\": \"?\"}\n",
    "        ],\n",
    "        \"issqn_retido_pattern\": [\n",
    "            {\"LOWER\": \"issqn\"},\n",
    "            {\"LOWER\": \"retido\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": {\"IN\": [\"sim\", \"não\"]}}\n",
    "        ],\n",
    "        \"local_prestacao_servico_pattern\": [\n",
    "            {\"LOWER\": \"local\"},\n",
    "            {\"ORTH\": \".\"},\n",
    "            {\"LOWER\": \"prestação\"},\n",
    "            {\"LOWER\": \"serviço\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"+\"},  # para lidar com múltiplos espaços\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"+\"},  # para a cidade\n",
    "            {\"ORTH\": \"-\", \"OP\": \"?\"},\n",
    "            {\"IS_UPPER\": True, \"LENGTH\": 2, \"OP\": \"?\"}  # para a sigla do estado\n",
    "        ],\n",
    "        \"local_incidencia_pattern\": [\n",
    "            {\"LOWER\": \"local\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "            {\"LOWER\": \"incidência\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"+\"},  # Nome da cidade\n",
    "            {\"ORTH\": \"-\", \"OP\": \"?\"},  # Hífen opcional\n",
    "            {\"SHAPE\": \"XX\", \"OP\": \"?\"}  # Sigla do estado\n",
    "        ],\n",
    "        \"valor_aliquota_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"+\"},\n",
    "            {\"ORTH\": \"\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity ruler patterns\n",
    "colors = {\n",
    "            \"secretaria\": \"linear-gradient(90deg, #2ADB5E, #1FA346)\", # Verde Degrade\n",
    "            \"tipo_documento\": \"linear-gradient(90deg, #09D6FF, #08A0D1)\", #Azul medio degrade\n",
    "            \"nome_prefeitura\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", # Roxo claro para lilaz - degrade bem bacana\n",
    "            \"nome_section\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\", #  lilaz - Degrade\n",
    "            \"nome_section\": \"#FFEA7F\", # Laranja claro\n",
    "            \"SAFRA\": \"#CCA10C\", # Terracota\n",
    "            \"SAFRA\": \"#AB9BFC\", # Roxo claro \n",
    "            \"CNPJ\": \"#7AECEC\", # Azul bem claro\n",
    "            \"NOME\": \"#EE8AF8\" # Rosa medio\n",
    "        }          \n",
    "\n",
    "patternsPrefeitura = [\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mesquita\"}], \"id\": \"PM_MESQUITA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mage\"}], \"id\": \"PM_MAGE\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsSection = [     \n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"número\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}, {\"ORTH\": \":\"}], \"id\": \"1. CABECALHO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"discriminação\"}, {\"LOWER\": \"dos\"}, {\"LOWER\": \"serviços\"}], \"id\": \"4. DESCRIMINACAO DOS SERVIÇOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"total\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}], \"id\": \"5. VALOR TOTAL\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"cnae\"}], \"id\": \"6. CNAE e Item da Lista de Serviços\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"serviços\"}], \"id\": \"7. VALORES E IMPOSTOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"dados\"}, {\"LOWER\": \"complementares\"}], \"id\": \"8. DADOS COMPLEMENTARES\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"outras\"}, {\"LOWER\": \"informações\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"criticas\"}], \"id\": \"9. OUTRAS INFORMAÇOES / CRITICAS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"observação\"}], \"id\": \"10. OBSERVACOES\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "patternsSecretarias = [{\"label\": \"secretaria\", \"pattern\": [{\"LOWER\": \"secretaria\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"fazenda\"},], \"id\": \"SECRETARIA\"}] \n",
    "\n",
    "\n",
    "patternsTipoDocumento = [\n",
    "                        {\"label\": \"tipo_documento\", \"pattern\": [{\"LOWER\": \"nota\"}, {\"LOWER\": \"fiscal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}, {\"LOWER\": \"eletrônica\"}, {\"LOWER\": \"-\"}, {\"LOWER\": \"nfs-e\"}], \"id\": \"NFS-e\"}\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsIdentificaEntidade = [\n",
    "                            {\"label\": \"CNPJ\", \"pattern\": [{\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}$\"}}], \"id\": \"cpf_cnpj_com_mascara\"}\n",
    "                            ]\n",
    "\n",
    "patternsCnpj = [\n",
    "    {\n",
    "        \"label\": \"CNPJ\",\n",
    "        \"pattern\": [\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/$\"}},\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{4}-\\d{2}$\"}}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "patterns = patternsPrefeitura + patternsSection + patternsSecretarias + patternsTipoDocumento + patternsIdentificaEntidade + patternsCnpj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Processo para salvar matcher pattern para json\n",
    "nome_matches_pattern_json = tipo_documento + \"_matcher_pattern.json\"\n",
    "path_matches_pattern_json = os.path.join(tipo_documento_patterns_path, nome_matches_pattern_json)\n",
    "with open(path_matches_pattern_json, \"w\") as f:\n",
    "    json.dump(matcher_pattern_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Processo para salvar entity ruler pattern para json\n",
    "nome_entityruler_pattern_json = tipo_documento + \"_entity_ruler_pattern.json\"\n",
    "entityruler_file_path = os.path.join(tipo_documento_patterns_path, nome_entityruler_pattern_json)\n",
    "\n",
    "write_patterns_to_file(patterns=patterns, colors=colors, filename=entityruler_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Rotina para carregar e atribuir ao matcher os patterns do disco\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# XXX Carregar matcher patterns do disco\n",
    "with open(\"config/tipo_documentos/patterns/nfs_e_matcher_pattern.json\", \"r\") as f:\n",
    "    loaded_patterns = json.load(f)\n",
    "    \n",
    "# Adicionar ao Matcher\n",
    "for label, pattern in loaded_patterns.items():\n",
    "    matcher.add(label, [pattern])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Carregar Entity Ruler patterns do disco\n",
    "patterns, colors = load_patterns_and_colors(\"config/tipo_documentos/patterns/nfs_e_entity_ruler_pattern.json\")\n",
    "\n",
    "\n",
    "# XXX Aplicar a funçao show_ent_new para exibir o resultado\n",
    "doc, tokens, ents = show_ent_new(texto_PDF, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Analisar os Matcher patterns do documento\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = tipo_documento_dict['sample_content']\n",
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.B Extracao de texto de todo o documento - RASTER PDF\t\n",
    "def extrai_texto_R_PDF(file_path, output_file, debug):    \n",
    "    \n",
    "    input_file = file_path\n",
    "\n",
    "    # 1. XXX Executar o comando OCRmyPDF\n",
    "    run_ocrmypdf(input_file, output_file)\n",
    "\n",
    "    # 2. XXX Executar o comando OCRmyPDF    \n",
    "    !pdftotext processamentos/temp/documento.pdf processamentos/temp/txt/documento.txt\n",
    "\n",
    "    # 3. XXX Ler o arquivo TXT\n",
    "    with open('processamentos/temp/txt/output.txt', 'r', encoding='utf-8') as arquivo:\n",
    "        texto_OCR_R = arquivo.read()\n",
    "        \n",
    "    texto_PDF_Raster = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\nFUNC extrai_texto_PDF_P: doc.:{original_file_name} | diretorio: {map_directory}  texto_PDF_Raster: \\n\\n{texto_PDF_Raster}\\n\\n')\n",
    "\n",
    "    return texto_PDF_Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento/Batch_23/MESQUITA_PDF_31282023_2258/159871/2023 -4.pdf\"\n",
    "document_unique_id = utl.generate_unique_id()\n",
    "nome_arquivo = os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRmyPDF completed successfully. Output saved to processamentos/temp/pdf/6bca0884-16ee-4e13-9d23-c20a6074924c.pdf.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"29/07/23, 15:50 Nota Fiscal de Serviços Eletrônica (NFSe) Número da Nota: PREFEITURA MUNICIPAL DE MAGE ia: Competência: SECRETARIA MUNICIPAL DA FAZENDA Julho/2023 NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Data e Hora da Emissão: 25/07/2023 15:40:00 Código Verificação: B16C73D79 PRESTADOR DE SERVIÇOS CPF/CNPJ: 33.462.862/0001-95 Inscrição Municipal: 4337 Telefone: Inscrição Estadual: nr: a Nome/Razão Social: SÃO MARCOS TERRAPLENAGEM E CONST RUÇÃO LTDA. Nome de Fantasia: Endereço: RUA DAS MARGARIDAS ,578 ,SANTA DALILA - Magé-RJ E-mail: TOMADOR DE SERVIÇOS CPF/CNPJ: 09.542.728/0001-10 INSC:MUNICIPAL: RG: | Inscrição Estadual: Telefone: Nome/Razão Social: CONSORCIO ZADAR - ENGETECNICA Endereço: RUA SENADOR DANTAS, 75 Nº 75 SALA 1903 BAIRRO: CENTRO CIDADE: RIO DE JANEIRO - RJ CEP: 20031914 E-mail: NÃO INFORMADO DISCRIMINAÇÃO DOS SERVIÇOS Serviço de Pavimentação Asfáltica. Linha Vermelha, conf Med 13/23. M.Obra (10%)=R$ 3.596,97 Retenção p/ Prev. Social = R$ 395,67 BANCO : ITAÚ AGÊNCIA: 0726 C/CORRENTE: 35410-3 VALOR TOTAL DA NOTA: R$ 35.969,70 CNAE - 4313400 - OBRAS DE TERRAPLENAGEM Item da Lista de Serviços - 7.02 - EXECUÇÃO, POR ADMINISTRAÇÃO, EMPREITADA OU SUBEMPREITADA, DE OBRAS DE CONSTRUÇÃO CIVIL, HIDRÁULICA OU ELÉTRICA E DE OUTRAS OBRAS SEMELHANTES, INCLUSI VE SONDAGEM, PERFURAÇÃO DE POÇOS, ESCAVAÇÃO, DRENAG E [2] Ti. 4 [m] ' ] RS: VALOR SERVIÇOS: R$ 35.969,70 VALOR . DEDUÇÃO: R$ 0,00 VALOR PIS: R$ 0,00 VALOR COFINS: VALOR IR: R$ 0,00 R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CÁLCULO: R$ 35.969,70 ALÍQUOTA: 2% VALOR INSS: R$ 395,67 VALOR CSLL: R$ 0,00 — VALORISS: R$ 0,00 VALOR ISS RETIDO: R$ 719,39 OUTRAS RETENÇÕES: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 34.854,64 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Não ISSQN RETIDO Sim LOCAL. PRESTAÇÃO SERVIÇO Macaé - RJ LOCAL INCIDÊNCIA Macaé - RJ Observação: - ISS RETIDO PELO TOMADOR DE SERVIÇOS CNPJ: 09.542.728/0001-10 ValorA proximado dos Tributos Federais R$ 4687,95 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 1718,33 (Alíq IBPT 4,93 IBPT) https://nfs-e.mage.rj.gov.br 1/1\""
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"pipeline_extracao_documentos/0_arquivos_teste_pipeline/pdf_raster/Mage/Techmuniz 0032 Sys Manager.pdf\"\n",
    "document_unique_id = utl.generate_unique_id()\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_PDF_Raster = extracao_texto_PDF_Raster(document_unique_id, file_path, debug)\n",
    "texto_PDF_Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_PDF_Raster, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_padrao = tipo_documento_dict.get('nfs_e', {}).get('sample_content', 'valor_padrao')\n",
    "texto_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1, tokens, ents = show_ent_new(texto_padrao, patterns=patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento/Batch_23/MESQUITA_PDF_31282023_2258/159871/2023 -4.pdf\"\n",
    "document_unique_id = utl.generate_unique_id()\n",
    "nome_arquivo = os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_min_documento = tipo_documento_dict.get('nfs_e', {}).get('min_score_similarity_documento', 'valor_padrao')\n",
    "score_min_documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_min_analise = tipo_documento_dict.get('nfs_e', {}).get('min_score_similarity_analise', 'valor_padrao')\n",
    "score_min_analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = texto_padrao\n",
    "doc2 = texto_PDF_Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de Similaridade: 0.7324063189820084\n",
      "\n",
      "Quase certeza que e NFS-e pois seu score e: 0.7324063189820084 e o score minimo documento e de: 0.7 - acao_sugerida: PREPROCESS_EXTRACT\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unica funcao que devera ser movida para junto das demais funcoes de dicionario\n",
    "def define_rotulo_acao(nome_arquivo):\n",
    "    \n",
    "    for palavra_chave, rotulo in mapeamento_palavras_chave.items():\n",
    "        if palavra_chave.lower() in nome_arquivo.lower():\n",
    "            break\n",
    "    else:\n",
    "        rotulo = 'prov_nota_fiscal' #\"sem_rotulo\"\n",
    "        palavra_chave = 'default'\n",
    "        acao_sugerida = sugestoes_acao.get(rotulo, 'None')\n",
    "        return palavra_chave, rotulo, acao_sugerida\n",
    "        # palavra_chave = 'None' #\"sem_palavra_chave\"\n",
    "        # acao_sugerida = 'None' #\"sem_acao_sugerida\"\n",
    "        \n",
    "        return palavra_chave, rotulo, acao_sugerida\n",
    "        #print(f'nome_arquivo: {nome_arquivo} | rotulo: {rotulo}')\n",
    "    if rotulo != 'None': #\"sem_rotulo\"\n",
    "        acao_sugerida = sugestoes_acao.get(rotulo, 'None') # \"Ação não definida\"\n",
    "        return palavra_chave, rotulo, acao_sugerida\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Dicionário para mapear palavras-chave a rótulos\n",
    "mapeamento_palavras_chave = {\n",
    "    \"relatorio\": \"prov_relatorio\",\n",
    "    \"listagem\": \"prov_listagem\",\n",
    "    \"NF\": \"prov_nota_fiscal\",\n",
    "    \"nf\": \"prov_nota_fiscal\",\n",
    "    \"relatorio\": \"prov_listagem\",\n",
    "    \"sintetico\": \"prov_listagem\",\n",
    "    \"livro\": \"prov_livro_registro\",\n",
    "    \"sintético\": \"prov_listagem\",\n",
    "    \"nota\": \"prov_nota_fiscal\",\n",
    "    \"zip\": \"doc_zip\",\n",
    "    \"rar\": \"doc_rar\",\n",
    "    \"valores\": \"prov_dinheiro\",\n",
    "}\n",
    "\n",
    "# Dicionário mapeando rótulos a ações sugeridas\n",
    "sugestoes_acao = {\n",
    "    \"prov_relatorio\": \"NO_PROCESS\",\n",
    "    \"prov_listagem\": \"NO_PROCESS\",\n",
    "    \"prov_nota_fiscal\": \"PROCESS\",\n",
    "    \"sem_rotulo\": \"MANUAL_REV\",\n",
    "    \"prov_livro_registro\": \"NO_PROCESS\",\n",
    "    \"doc_nao_pdf\": \"verificar\",\n",
    "    \"nao_pdf\": \"NO_PROCESS\",\n",
    "    \"doc_zip\": \"NO_PROCESS\",\n",
    "    \"pdf_mul_paginas\": \"SPLIT\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 2.Testando\n",
    "nome_arquivo = 'batatinha_quando_nasce.pdf' # 'pre-processamento'\n",
    "#palavra_chave, rotulo, acao_sugerida = define_rotulo_acao(nome_arquivo, debug)\n",
    "#print(f'nome_arquivo: {nome_arquivo:>55} | palavra_chave: {palavra_chave:>20} | rotulo: {rotulo:20} | acao_sugerida: {acao_sugerida:30}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark> <b> 3.0</b>  Mapeamento e Analise do pipeline </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. XXX apagar arquivos zone\n",
    "utl.apagar_zone(documentos_extracao_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOMENTE PARA TESTE DE FUNCAO\n",
    "#fake_parent_document_unique_id = 'f976c128-1f41-4551-bffd-fac687c1c8b2'\n",
    "\n",
    "# Busca proximo Batch caso nao esteja rodando email\n",
    "batch_name = utl.busca_proximo_batch(conf_export_plan_path)\n",
    "batch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.B XXX Funçao de criacao do PDF Pesquisavel\n",
    "def run_ocrmypdf(input_file, output_file):\n",
    "    command = [\n",
    "        'ocrmypdf',\n",
    "        '--language', 'por',\n",
    "        '--deskew',\n",
    "        '--force-ocr',\n",
    "        input_file,\n",
    "        output_file\n",
    "    ]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"OCRmyPDF completed successfully. Output saved to {output_file}.\")\n",
    "    else:\n",
    "        print(f\"OCRmyPDF failed with error: {result.stderr.decode('utf-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.A XXX Extracao de texto de todo o documento - PDF PESQUISAVEL\t\n",
    "def extracao_texto_PDF_P(i, document_unique_id, nome_arquivo, file_path, debug):    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text_P = page.get_text(\"text\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    texto_PDF = re.sub('\\s+', ' ', text_P).strip()  \n",
    "    if debug:\n",
    "        print(f'\\nFUNC analise_texto_PDF: doc.:{nome_arquivo}   texto_PDF_P: \\n\\n{texto_PDF}\\n\\n')\n",
    "\n",
    "    return texto_PDF_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.B XXX Extracao de texto de todo o documento - RASTER PDF\n",
    "def extracao_texto_Raster_P(i, document_unique_id, nome_arquivo, file_path, debug):    \n",
    "    \n",
    "    output_file = None\n",
    "    txt_document_file = None\n",
    "    \n",
    "    input_file = file_path\n",
    "    \n",
    "    #output_file = \"/home/dani-boy/extractNF/processamentos/temp/documento.pdf\"\n",
    "    output_file = os.path.join(raster_process_pdf_path, document_unique_id + '.pdf')\n",
    "\n",
    "    # 1. XXX Executar o comando OCRmyPDF\n",
    "    run_ocrmypdf(input_file, output_file)\n",
    "\n",
    "    txt_document_file = os.path.join(raster_process_txt_path, document_unique_id + '.txt')\n",
    "\n",
    "    txt_dir = os.path.dirname(txt_document_file)\n",
    "    if not os.path.exists(txt_dir):\n",
    "        os.makedirs(txt_dir)\n",
    "\n",
    "    # Execute o comando\n",
    "    subprocess.run([\"pdftotext\", output_file, txt_document_file])\n",
    "\n",
    "    # 3. XXX Ler o arquivo TXT\n",
    "    with open(txt_document_file, 'r', encoding='utf-8') as arquivo:\n",
    "        texto_OCR_R = arquivo.read()\n",
    "    texto_PDF_Raster = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "    \n",
    "    os.remove(output_file)\n",
    "    os.remove(txt_document_file)\n",
    "    \n",
    "    return texto_Raster_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. XXX Analise de silimaridade doc1 x doc2\n",
    "def analisa_similiaridade_doc(doc1, doc2):\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "\n",
    "    # Calculando Similaridade de Cosseno\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
    "\n",
    "    print(f\"Score de Similaridade: {similarity_scores[0][0]}\")\n",
    "    \n",
    "    return similarity_scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = analisa_similiaridade_doc(doc1, doc2)\n",
    "\n",
    "if score > score_min_documento:\n",
    "    acao_sugerida = 'PREPROCESS_EXTRACT'\n",
    "    print(f'\\nQuase certeza que e NFS-e pois seu score e: {score} e o score minimo documento e de: {score_min_documento} - acao_sugerida: {acao_sugerida}\\n')\n",
    "elif score > score_min_analise: \n",
    "    acao_sugerida = 'PREPROCESS_ANALISE'\n",
    "    print(f'\\nPode ser que se trate de um documento NFS-e pois seu score e: {score} e o score minimo e de analise e: {score_min_analise} - acao_sugerida: {acao_sugerida}\\n')   \n",
    "elif score < score_min_analise:\n",
    "    acao_sugerida = 'NO_PROCESS'\n",
    "    print(f'\\nE pouco provavel que seja NFSe pois seu score e de: {score} para um score minimo de: {score_min_analise} - acao_sugerida: {acao_sugerida}\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.XXX  Acao 1 - Ler todo o pipeline de documentos recebidos - ESSA E A UNICA FUNCAO QUE ITERA NO DIRETORIO\n",
    "def scan_pipeline_documentos(documentos_extracao_path, batch_name, fase, atividade, status, debug):\n",
    "    \n",
    "    doc_info = {}\n",
    "    resumo = {}\n",
    "    raw_document = []\n",
    "    \n",
    "    output_dir = os.path.join(documentos_extracao_path, batch_name)\n",
    "    i = 1\n",
    "    for root, dirs, files in os.walk(output_dir):\n",
    "        folder_name = os.path.basename(root)\n",
    "        #print(folder_name)\n",
    "        for file in files:\n",
    "            pdf_pesquisavel_map = None\n",
    "            document_unique_id = utl.generate_unique_id()\n",
    "            nome_arquivo = file\n",
    "            \n",
    "            palavra_chave, rotulo, acao_sugerida = define_rotulo_acao(nome_arquivo)\n",
    "            acao_executada = \"Analise\"\n",
    "            informations = ' '    \n",
    "            file_name = file.lower()    \n",
    "            file_path = os.path.join(root, file)\n",
    "            if file.lower().endswith('.zip') or file.lower().endswith('.rar') or file.lower().endswith('.7z'):\n",
    "                compressed_file_path = file_path\n",
    "                compressed_file_name = os.path.basename(compressed_file_path)\n",
    "                compressed_file_hash = utl.generate_file_hash(compressed_file_path)\n",
    "                compressed_file_unique_id = utl.generate_unique_id()\n",
    "                parent_document_unique_id = compressed_file_unique_id\n",
    "                level = 2\n",
    "            new_path_name = os.path.join(output_dir, file)\n",
    "            acao_sugerida = 'ARCHIEVE_EXTRACTION'\n",
    "            \n",
    "            if file.lower().endswith('.pdf'):\n",
    "                doc_one_page, nro_pgs = tpdf.analisa_nro_pages(file_path)\n",
    "                \n",
    "                one_page = doc_one_page\n",
    "                num_page = nro_pgs\n",
    "                if num_page > 1:\n",
    "                    acao_sugerida = 'SPLIT_PAGES'\n",
    "                else:\n",
    "                    texto_PDF = analise_texto_PDF(i, document_unique_id, nome_arquivo, file_path, debug)  \n",
    "                    level = 3\n",
    "                    if texto_PDF:\n",
    "                        pdf_pesquisavel_map = True\n",
    "                    else:\n",
    "                        pdf_pesquisavel_map = False  \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            \n",
    "            else:\n",
    "                one_page = False\n",
    "                    \n",
    "            # if doc_one_page:\n",
    "            #     one_page = doc_one_page\n",
    "            # else:\n",
    "            #     one_page = False    \n",
    "            #             rotulo = 'pdf_mul_paginas'\n",
    "            diretorio = os.path.basename(file_path)\n",
    "            if folder_name == batch_name:\n",
    "                folder_name = \"root_dir\"\n",
    "                \n",
    "            #print(f'nome_arquivo: {nome_arquivo:>55} | palavra_chave: {palavra_chave:>20} | rotulo: {rotulo:20} | acao_sugerida: {acao_sugerida:30}')    \n",
    "            \n",
    "            new_row = {\n",
    "                \"seq\": i,\n",
    "                \"date_time\": cron.timenow_pt_BR(),\n",
    "                \"batch\": batch_name,\n",
    "                \"fase_processo\": fase,\n",
    "                \"nome_atividade\": atividade,\n",
    "                \"status_documento\": status,\n",
    "                \"acao_executada\": acao_executada,\n",
    "                \"original_file_name\": file,\n",
    "                \"directory\": folder_name,\n",
    "                \"one_page\": one_page,\n",
    "                \"pages\": num_page,\n",
    "                \"palavra_chave\": palavra_chave,\n",
    "                \"document_tag\": rotulo,\n",
    "                \"action_item\": acao_sugerida,\n",
    "                \"level\": level,\n",
    "                \"pdf_pesquisavel\": pdf_pesquisavel_map,\n",
    "                \"document_unique_id\": document_unique_id,\n",
    "                \"parent_document_unique_id\": parent_document_unique_id,\n",
    "                \"file_hash\": utl.generate_file_hash(file_path),\n",
    "                \"file_path\": file_path,\n",
    "                \"informations\": informations,\n",
    "            }\n",
    "            raw_document.append(new_row)\n",
    "\n",
    "            \n",
    "            # print(f'seq: {i} | file: {file}'\n",
    "            i += 1\n",
    "    df_trans_pipe = pd.DataFrame(raw_document)\n",
    "      \n",
    "                \n",
    "    return df_trans_pipe, raw_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. XXX Crio o DF df_scan_pipe\n",
    "fase = 'analise' # 'pre-processamento'\n",
    "atividade = 'scan_analise'\n",
    "status = 'root_analise'\n",
    "\n",
    "documentos = []\n",
    "debug = False\n",
    "\n",
    "df_root_pipe, documentos = scan_pipeline_documentos(documentos_extracao_path, batch_name, fase, atividade, status, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Acertando o Index\n",
    "df_root_pipe.set_index('document_unique_id', inplace=True)\n",
    "df_root_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exportando o map_analise_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. XXX Definiçao do path para salvar o arquivo\n",
    "file_path_root_pipe = os.path.join(map_analise_path, df_root_pipe_file + batch_name + \".xlsx\")\n",
    "\n",
    "# 2. XXX Salvando o arquivo de df: df_root_pipe\n",
    "df_root_pipe.to_excel(file_path_root_pipe, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pesquisas e outros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atualizando o valor da coluna status_documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status(row):\n",
    "    if row['seq'] in sequencia:\n",
    "        row['status_documento'] = 'PREPROCESS_EXTRACT'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencia = [2, 8, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_pipe = df_root_pipe.apply(update_status, axis=1)\n",
    "df_root_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos chegar de forma mais rapida\n",
    "subset_df.loc[subset_df['status_documento'] == \"Template_encontrado\", 'pdf_pesquisavel'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Usando query para Filtrar Baseado em Condições Complexas\n",
    "subset_df_analise_pipe = df_analise_pipe.query('seq == 59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Salvando o DF (IMPORTANTE)\n",
    "df_analise_pipe.to_excel(\"df_mapeamento_e_analise2.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Criando uma nova coluna no DF\n",
    "df_analise_pipe.insert(loc=17, column='s_act', value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Usando query para Filtrar Baseado em Condições Complexas\n",
    "df_root_pipe.query('one_page == False & palavra_chave == \"sem_palavra_chave\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. XXX Retiro o indice do DF - Resetando o índice e mantendo o índice original como uma nova coluna\n",
    "df_analise_pipe.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# XXX Criando uma nova coluna no DF\n",
    "df_conferencia.insert(loc=50, column='original_file_name', value=df_conferencia['file_path'].apply(lambda x: os.path.basename(x)))\n",
    "\n",
    "df['coluna_cnae'] = df['coluna_cnae'].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# 4. XXX Usando loc para Filtrar Baseado em one_page == False\n",
    "df_pages_2_split = df_root_pipe[df_root_pipe['one_page'] == False]\n",
    "\n",
    "\n",
    "\n",
    "# 3. Usando query para Filtrar Baseado em Condições Complexas\n",
    "df_root_pipe.query('one_page == False & palavra_chave == \"sem_palavra_chave\"')\n",
    "\n",
    "\n",
    "# XXX Criando uma nova coluna no DF\n",
    "df_analise_pipe.insert(loc=17, column='s_act', value=None)\n",
    "\n",
    "\n",
    "# 4. Filtrando Linhas Baseadas em Valores em uma Lista\n",
    "\n",
    "valores = [11, 16, 30, 41]\n",
    "subset_df = df_scan_pipe[df_scan_pipe['seq'].isin(valores)]\n",
    "\n",
    "# 2. Usando iloc para Filtrar um Número Específico de Linhas\n",
    "subset_df = df_scan_pipe.iloc[:10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "registro_específico = df_scan_pipe.loc['e1f4b1af-30f3-45d2-85a7-1bb895bd5325']\n",
    "\n",
    "\n",
    "\n",
    "df_analise_pipe['pdf_pesquisavel'] = df_analise_pipe.apply(lambda row: row['coluna1'] * 2 if row['coluna2'] > 0 else row['coluna1'], axis=1)\n",
    "\n",
    "\n",
    "# Atualizei o DF baseado em condiçao de outra coluna\n",
    "df_analise_pipe['pdf_pesquisavel'] = df_analise_pipe.apply(lambda row: False if row['status_documento'] == \"Template_encontrado\" else row['pdf_pesquisavel'], axis=1)\n",
    "\n",
    "\n",
    "# Podemos chegar de forma mais rapida\n",
    "df_analise_pipe.loc[df_analise_pipe['status_documento'] == \"Template_encontrado\", 'pdf_pesquisavel'] = False\n",
    "\n",
    "\n",
    "# 8. XXX Concatenando os DataFrames\n",
    "df_analise_pipe = pd.concat([df_analise_pipe, df_docs_splitados], ignore_index=True)\n",
    "\n",
    "# 9. XXX Volto novamente o indice do DF\n",
    "df_analise_pipe.set_index('document_unique_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = None\n",
    "txt_document_file = None\n",
    "input_file = \"pipeline_extracao_documentos/0_arquivos_teste_pipeline/pdf_raster/Mage/nf_688___consor_zadar__engetecnica_enza_1_anotado.pdf\"\n",
    "document_unique_id = utl.generate_unique_id()\n",
    "#output_file = \"/home/dani-boy/extractNF/processamentos/temp/documento.pdf\"\n",
    "output_file = os.path.join(raster_process_pdf_path, document_unique_id + '.pdf')\n",
    "\n",
    "# 1. XXX Executar o comando OCRmyPDF\n",
    "run_ocrmypdf(input_file, output_file)\n",
    "\n",
    "txt_document_file = os.path.join(raster_process_txt_path, document_unique_id + '.txt')\n",
    "\n",
    "txt_dir = os.path.dirname(txt_document_file)\n",
    "if not os.path.exists(txt_dir):\n",
    "    os.makedirs(txt_dir)\n",
    "\n",
    "# Execute o comando\n",
    "subprocess.run([\"pdftotext\", output_file, txt_document_file])\n",
    "\n",
    "# 3. XXX Ler o arquivo TXT\n",
    "with open(txt_document_file, 'r', encoding='utf-8') as arquivo:\n",
    "    texto_OCR_R = arquivo.read()\n",
    "texto_PDF_Raster = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "texto_PDF_Raster\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
