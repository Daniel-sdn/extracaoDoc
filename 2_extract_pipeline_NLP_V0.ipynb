{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark> <b> > 2.0 </b> Pipeline de Extracao de dados de documentos - NLP </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2_extract_pipeline_NLP_V0.ipynb</b>    |     Atual notebook com as funçoes para processamento de documentos com soluçao NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules e config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from urllib import response\n",
    "\n",
    "from outlook_msg import Message\n",
    "import extract_msg\n",
    "import zipfile\n",
    "from pyunpack import Archive\n",
    "import py7zr\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import PyPDF2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "import locale\n",
    "import time, copy\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import cv2\n",
    "import fitz  # Módulo PyMuPDF\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Token\n",
    "from spacy.language import Language\n",
    "from difflib import SequenceMatcher # verificar\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "# Modulos da solucao\n",
    "# import modules.extrai_pdf_pesquisavel as Extc\n",
    "import modules.cronometro as cron\n",
    "import modules.nova_extracao_pdf_pesquisavel as novaextra \n",
    "import modules.trata_model as tmod\n",
    "import modules.trata_pdf as tpdf\n",
    "import modules.utils as utl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.remove_pipe('ner')\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.utf8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de documento em uso\n",
    "tipo_doc_work = 'nfs_e'\n",
    "\n",
    "# 1. XXX Path para planilha de processamento de batches\n",
    "conf_export_plan_path = 'processamentos/processamento_batches/df_conf_export_batch.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "# 2. XXX  Tratando nome de carga do df_processamento\n",
    "map_analise_path = \"processamentos/mapeamento_analise\"\n",
    "\n",
    "# 3. XXX  prefixo de nome do arquivo de exportaçao\n",
    "df_root_pipe_file = \"df_root_\"\n",
    "\n",
    "# 4. XXX Tipos de documentos para extracao\n",
    "tipo_documento_path = \"config/tipo_documentos\"\n",
    "\n",
    "# 5. XXX Path para tipo de documento patterns\n",
    "tipo_documento_patterns_path = \"config/tipo_documentos/patterns\"\n",
    "\n",
    "# 6. XXX Nome do caminha para dict Tipo de documento\n",
    "config_tipo_doc_path = \"config/tipo_documentos/tipo_documento.json\"\n",
    "\n",
    "# Paths de trabalho para Raster_PDF\n",
    "raster_process_pdf_path = 'processamentos/temp/pdf'\n",
    "raster_process_txt_path = 'processamentos/temp/txt'\n",
    "\n",
    "\n",
    "# 6. IMPORTANTE - MUDOU - Path para gestao de imagens resized\n",
    "image_resized_path = \"processamentos/temp/images/processadas\"\n",
    "\n",
    "\n",
    "#### Config - E-mail\n",
    "# 1. Caminho do arquivo uma mensagem especifica\n",
    "msg_dir_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/11_emails'\n",
    "\n",
    "# 2. Path para arquivos atachados compactados\n",
    "msg_attachment_zip = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/13_attachments'\n",
    "\n",
    "\n",
    "#### Config - messages\n",
    "# 3. Caminho do arquivo uma mensagem especifica\n",
    "msg_outros_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/12_messages'\n",
    "\n",
    "# 4. Path para arquivos recebidos manualmente\n",
    "arquivos_recebidos_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/14_documentos_recebidos'\n",
    "\n",
    "\n",
    "####Config Processamento Pipeline\n",
    "\n",
    "# 5. Path para documentos para extracao\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento\"\n",
    "\n",
    "\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"pipeline_extracao_documentos/5_documentos_processados/jsons\"\n",
    "\n",
    "# 7. Path para DFs e CSVs exportados\n",
    "export_path = \"pipeline_extracao_documentos/6_geral_administacao/exports\"\n",
    "\n",
    "# 8. Path para lixeira\n",
    "root_garbage_path = \"pipeline_extracao_documentos/0_lixeira\"\n",
    "\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "cnae_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets/CNAE_X_ITEM_SERVICO_PREFEITURAS.xlsx\"\n",
    "\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "#Modelo atual\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "# definindo localizadcao para pt_BR\n",
    "locale.setlocale(locale.LC_TIME, \"pt_BR.utf8\")\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     filename='config/log_ocorrencias.log',\n",
    "#     level=logging.INFO, \n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "#     datefmt='%d/%m/%Y %H:%M:%S'\n",
    "# )\n",
    "\n",
    "# logging.info(\"kernel reiniciado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>A.</b> Funcoes de Imagem </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX IMPORTANTE - ESTA E A FUNCAO PARA SER UTILIZADA: POIS CONVERTE PARA CINZA E RESIZE: (4134, 5846)\n",
    "def convert_resize_gray(original_file_name, file_path, image_resized_path):\n",
    "\n",
    "    name_image = utl.conv_filename_no_ext(original_file_name)\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(name_image)}.jpg')\n",
    "    pages = convert_from_path(file_path, 500, poppler_path=poppler_path)\n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((4134, 5846))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "    imagem_gray = resized_pages[0].convert('L')\n",
    "    imagem_gray.save(image_resized_name, 'JPEG')\n",
    "\n",
    "    return  imagem_gray, image_resized_name\n",
    "\n",
    "# XXX Pequenos mas poderosos\n",
    "def extract_text_PIL(image, coordinates):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    image_croped = image.crop((x0, y0, x1, y1))\n",
    "    texto_extraido = pytesseract.image_to_string(image_croped, lang='por', config='--psm 6')\n",
    "    return texto_extraido \n",
    "\n",
    "\n",
    "# 5. XXX Ajusta textoYYY\n",
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>B.</b> Funcoes de Frames </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funçao importante para buscar coordenadas do frame em funçao do contexto\n",
    "def get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo):\n",
    "    \n",
    "    row_frame = utl.filtrar_df(frames_nf_v4_df, model=model_map, context_mapping=context_mapping, type=tipo)\n",
    "    \n",
    "    # Verificando se row_frame não está vazio\n",
    "    if not row_frame.empty:\n",
    "        # Acessando a primeira linha do DataFrame filtrado e depois acessando as colunas\n",
    "        coodinates = [((row_frame.iloc[0]['x0_p'], row_frame.iloc[0]['y0_p'], row_frame.iloc[0]['x1_p'], row_frame.iloc[0]['y1_p']) if pdf_pesquisavel_map else (row_frame.iloc[0]['x0'], row_frame.iloc[0]['y0'], row_frame.iloc[0]['x1'], row_frame.iloc[0]['y1']))]\n",
    "    else:\n",
    "        # Retornando uma tupla de valores NaN se o DataFrame filtrado estiver vazio\n",
    "        coodinates = [(float('nan'), float('nan'), float('nan'), float('nan'))]\n",
    "    \n",
    "    return coodinates\n",
    "\n",
    "\n",
    "\n",
    "# XXXpara buscar melhor as coordendas dos FRAMES\n",
    "def get_coordinates_filter(pdf_pesquisavel_map, model, tipo, label, section):\n",
    "    \n",
    "    row_frame = utl.filtrar_df(frames_nf_v4_df, model=model, type=tipo, label=label, section_json=section)\n",
    "    \n",
    "    # Verificando se row_frame não está vazio\n",
    "    if not row_frame.empty:\n",
    "        # Acessando a primeira linha do DataFrame filtrado e depois acessando as colunas\n",
    "        coodinates = [((row_frame.iloc[0]['x0_p'], row_frame.iloc[0]['y0_p'], row_frame.iloc[0]['x1_p'], row_frame.iloc[0]['y1_p']) if pdf_pesquisavel_map else (row_frame.iloc[0]['x0'], row_frame.iloc[0]['y0'], row_frame.iloc[0]['x1'], row_frame.iloc[0]['y1']))]\n",
    "    else:\n",
    "        # Retornando uma tupla de valores NaN se o DataFrame filtrado estiver vazio\n",
    "        coodinates = [(float('nan'), float('nan'), float('nan'), float('nan'))]\n",
    "    \n",
    "    return coodinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>C.</b> Funcoes de Processamento e Extracao </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.A Dados iniciais - PDF PESQUISAVEL\t\n",
    "def pesquisa_prefeitura_pdf_pesquisavel(idx, row, row_info, map_directory, original_file_name, file_path, debug):    \n",
    "    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 4\n",
    "    x1 = 600\n",
    "    y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\ndentro da funçao: pesquisa_prefeitura_pdf_pesquisavel: doc.:{original_file_name} | diretorio: {map_directory}  text: \\n\\n{text}\\n\\n')\n",
    "    \n",
    "    if text:\n",
    "       page_number = 0\n",
    "       #print(page_number)\n",
    "    else:\n",
    "       page_number = 1\n",
    "       #print(page_number)\n",
    "    \n",
    "    pdf_document.close()\n",
    "   \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0. INFOMACOES INICIAIS - RASTER PDF\n",
    "def processar_dados_iniciais(idx, row, row_info, section, map_directory, original_file_name, file_path, debug):\n",
    "    \n",
    "    # lista_texto_extraido = []\n",
    "\n",
    "    nf_dados_doc = {}\n",
    "    nf_dados_doc['secao'] = section\n",
    "    pdf_pesquisavel = None\n",
    "    extracted_txt = pesquisa_prefeitura_pdf_pesquisavel(idx, row, row_info, map_directory, original_file_name, file_path, debug)\n",
    "    if debug:\n",
    "        print(f'\\n1. funcao: processar_dados_iniciais: doc.:{original_file_name} | diretorio: {map_directory} apos funcao: pesquisa_prefeitura_pdf_pesquisavel: extracted_txt:\\n{extracted_txt}\\n\\n')\n",
    "    \n",
    "    if extracted_txt:\n",
    "        pdf_pesquisavel = True\n",
    "        print(f'extracted_txt: {extracted_txt} - portanto pdf_pesquisavel: {pdf_pesquisavel} ')\n",
    "        \n",
    "    else:\n",
    "        pdf_pesquisavel = False\n",
    "        print(f'extracted_txt: {extracted_txt} - portanto pdf_pesquisavel: {pdf_pesquisavel} ') \n",
    "       \n",
    "       \n",
    "        # WTF\n",
    "        x0 = 220\n",
    "        y0 = 0\n",
    "        x1= 3858\n",
    "        y1 = 1572\n",
    "        \n",
    "        # usando novo processo que gera o arquivo \"on the fly\" imagem_gray (converte PDF para imagem de tamanho grande (4134, 5846) - torna-a cinza e a salva)\n",
    "        imagem_gray, image_resized_name = convert_resize_gray(original_file_name, file_path, image_resized_path)\n",
    "        extracted_txt = extract_text_PIL(imagem_gray, (x0, y0, x1, y1))\n",
    "        #print(f'extracted_txt: {extracted_txt}')\n",
    "        if debug:\n",
    "            print(f'\\n2. funcao: processar_dados_iniciaisdoc.:{original_file_name} | diretorio: {map_directory}  apos : extract_text_PIL: extracted_txt:\\n{extracted_txt}\\n\\n')\n",
    "    \n",
    "    nf_dados_doc['file_name'] = original_file_name    \n",
    "    nf_dados_doc['pdf_pesquisavel'] = pdf_pesquisavel \n",
    "    value = {}   \n",
    "    texto_tratado = texto_extraido(extracted_txt)\n",
    "    value = define_dados_iniciais(idx, row, row_info, texto_tratado, debug)\n",
    "    if debug:\n",
    "        print(f'\\n3. funcao: processar_dados_iniciais doc.:{original_file_name} | diretorio: {map_directory} | apos funcao: define_dados_iniciais() value \\n{value}\\n\\n')\n",
    "    if value:\n",
    "        nf_dados_doc.update(value)\n",
    "   \n",
    "\n",
    "\n",
    "    return nf_dados_doc\n",
    "\n",
    "\n",
    "# 1.B CABECALHO XXX Funcoes de extracao -cabecalho Raster\n",
    "def processar_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    data_box_conferencia = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    # Busco a imagem np do documento\n",
    "    image_np_row_info = row_info.get('image_np')\n",
    "    \n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "    data_box_valores['processo'] = context_mapping\n",
    "    data_box_valores['conf_cod'] = 0\n",
    "\n",
    "\n",
    "                     \n",
    "    \n",
    "    # busco coordenadas para o contexto\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "    #print(f'\\n2. Dentro func: section: {section} mapping_method: {mapping_method} | context_mapping: {context_mapping} | model_map: {model_map} | original_file_name: {original_file_name}\\n')\n",
    "   \n",
    "    # 2. usando a funcao de extracao de coordenadas por contexto    \n",
    "    coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    #print(f'x0: {x0} | y0: {y0} | x1: {x1} | y1: {y1}')\n",
    "    x0 = int(x0)\n",
    "    y0 = int(y0)\n",
    "    x1 = int(x1)\n",
    "    y1 = int(y1) \n",
    "    # 3. Cropo a imagem - novo modelo\n",
    "    cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "    data_box_conferencia[f'box_{context_mapping}'] = cropped_image_np\n",
    "    data_box_conferencia[f'coordinates_{context_mapping}'] = coordinates\n",
    "    # 4. Converto para PIL\n",
    "    cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "    # 6. Executo OCR\n",
    "    texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "    # 7. Trato o texto extraido = text_splited\n",
    "    text_splited = texto_extraido_cabecalho(texto_extraido)\n",
    "    if debug:\n",
    "        print()\n",
    "        plt.imshow(cropped_image_np)\n",
    "        plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "        plt.show()\n",
    "        print(f'\\ncoordinates {coordinates} - \\ntexto_extraido:\\n{text_splited}\\n')\n",
    "        \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "    \n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        try:\n",
    "            section = row_frame['section_json']\n",
    "            label = row_frame['label']\n",
    "            reference = row_frame['reference']\n",
    "            string_pesquisa = row_frame['marcador_inicio']  \n",
    "            keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "            texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "            data_box_valores[label] = texto\n",
    "            if debug:\n",
    "               print(f'\\nidx: {index_frame:> 3} | label: {label} |  string_pesquisa:{string_pesquisa} | dentro do try do raster PDF cabecalho - texto: \\n{texto}\\n\\n')\n",
    "        except Exception as e:\n",
    "            msg = (f\"{e}\")\n",
    "            data_box_conferencia[label] = msg\n",
    "    \n",
    "\n",
    "    # Verificações após o loop\n",
    "    for key, value in data_box_valores.items():\n",
    "        if key == 'numero_nota_fiscal' and value is None:\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "        \n",
    "        elif key == 'codigo_verificacao' and value != None:\n",
    "            codigo_verificacao_nf = value\n",
    "            tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "            data_box_valores['conf_cod'] = tam_codigo_verificacao\n",
    "            \n",
    "        \n",
    "        elif key != 'numero_nota_fiscal' and value is None:\n",
    "            logging.error(f\" {batch_name_row_info} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "            \n",
    "      # if value is None:\n",
    "        #     logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "\n",
    "    \n",
    "    return data_box_valores\n",
    "\n",
    "# 1.A CABECALHO - PDF PESQUISAVEL  \n",
    "def extrai_cabecalho_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, de_para_pm, model_map, f_0, f_1, original_file_name, file_path, debug):\n",
    "    \n",
    "    nf_data_cabecalho = {}\n",
    "    lista_erros = []\n",
    "    label = \"1_frame_dados_nf\"\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    nf_data_cabecalho['secao'] = section\n",
    "    nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "    nf_data_cabecalho['informations'] = information_row_info\n",
    "    nf_data_cabecalho['processo'] = 'mapeamento regex - PDF pesquisavel'\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\n\\n2. dentro da funçao extrai_cabecalho_PDF: batch_name: {batch_name_row_info}\\n\\n')\n",
    "    \n",
    "    pdf_document = fitz.open(file_path)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]    \n",
    "    tipo = \"frame\"\n",
    "\n",
    "    coordinates = get_coordinates_filter(pdf_pesquisavel_map=pdf_pesquisavel_map, model=model_map, tipo=tipo, label=label, section=section)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    y0 = y0 * f_0\n",
    "    y1 = y1 * f_1\n",
    "    \n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    if debug:\n",
    "        print(f'\\n3. x0: {x0}, y0: {y0}, x1: {x1}, y1: {y1} f_0: {f_0} f_1: {f_1} | text: \\n{text} \\n\\n')\n",
    "\n",
    "    try:\n",
    "        numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "        if numero_nota_match:\n",
    "            numero_nf = numero_nota_match.group(1)\n",
    "            nf_data_cabecalho['numero_nota_fiscal'] = numero_nf\n",
    "            #nf_data_cabecalho['informations'] = 'documento com numero de nota fiscal'\n",
    "            if debug:\n",
    "                print(f'\\nnr_nro_nf: {nr_nro_nf} - doc: {original_file_name}\\n')\n",
    "        else:\n",
    "            msg = (f\"Número da Nota não encontrado\")\n",
    "            nf_data_cabecalho['numero_nota_fiscal'] = None\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            nf_data_cabecalho['informations'] = information_row_info\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "    except Exception as e:\n",
    "        msg = (f\"doc: {original_file_name} | numero NF nao encontrado {e}\")\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = None\n",
    "        information_row_info = 'Número da Nota não encontrado'\n",
    "        nf_data_cabecalho['informations'] = information_row_info\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair codigo Verificacao\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        codigo_verificacao_nf = codigo_verificacao_match.group(1)\n",
    "        nf_data_cabecalho['codigo_verificacao'] =  codigo_verificacao_nf\n",
    "        tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "        nf_data_cabecalho['conf_cod'] = tam_codigo_verificacao\n",
    "        \n",
    "    \n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    return nf_data_cabecalho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark> <b>1.X</b> Funcoes NLP </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ent_new(text, patterns):\n",
    "    #nlp = spacy.blank(\"pt\")\n",
    "    #ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = []\n",
    "    ents = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        span = doc.char_span(ent.start_char, ent.end_char, label=ent.label_)\n",
    "        ents.append(span)\n",
    "        \n",
    "    for token in doc:\n",
    "        start = token.idx\n",
    "        end = start + len(token)\n",
    "        tokens.append((token.text, start, end))\n",
    "        \n",
    "    return doc, tokens, ents\n",
    "\n",
    "\n",
    "\n",
    "# chunk.text, chunk.start, chunk.end, chunk.root.head.lemma_, chunk.root.dep_, chunk.doc\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Funcoes para salvar e carregar entity ruler patterns\n",
    "def write_patterns_to_file(patterns, colors, filename):\n",
    "    data = {\"patterns\": patterns, \"colors\": colors}\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, ensure_ascii=True, indent=2)\n",
    "        \n",
    "\n",
    "# Funcao para carregar as cores e patterns do Entity ruler        \n",
    "def load_patterns_and_colors(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        patterns = data[\"patterns\"]\n",
    "        colors = data[\"colors\"]\n",
    "    return patterns, colors \n",
    "\n",
    "\n",
    "# Salva do tipo de documento em arquivo\n",
    "def save_tipo_doc_to_file(dic, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dic, f) \n",
    "        \n",
    "# carrega o tipo de documento do arquivo        \n",
    "def load_dict_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Salva o dict doc_content em arquivo\n",
    "def save_doc_content_to_file(doc_content):\n",
    "    file_doc_content_path = os.path.join(map_analise_path, 'doc_content_' + batch_name + \".json\")\n",
    "    with open(file_doc_content_path, 'w') as f:\n",
    "        json.dump(doc_content, f)\n",
    "        \n",
    "# Carrega o dict doc_content em arquivo\n",
    "def load_doc_content_from_file():\n",
    "    file_doc_content_path = os.path.join(map_analise_path, 'doc_content_' + batch_name + \".json\")\n",
    "    with open(file_doc_content_path, 'r') as f:\n",
    "        return json.load(f) \n",
    "\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocrmypdf(input_file, output_file):\n",
    "    command = [\n",
    "        'ocrmypdf',\n",
    "        '--language', 'por',\n",
    "        '--deskew',\n",
    "        input_file,\n",
    "        output_file\n",
    "    ]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"OCRmyPDF completed successfully. Output saved to {output_file}.\")\n",
    "    else:\n",
    "        print(f\"OCRmyPDF failed with error: {result.stderr.decode('utf-8')}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# Função para definir o atributo \"is_cnpj\"\n",
    "@Language.component(\"set_cnpj_attribute\")\n",
    "def set_cnpj_attribute(doc):\n",
    "    for i, token in enumerate(doc):\n",
    "        if i < len(doc) - 1:\n",
    "            next_token = doc[i + 1]\n",
    "            if token.shape_ == \"dd.ddd.ddd/\" and next_token.shape_ == \"dddd-dd\":\n",
    "                token._.is_cnpj = True\n",
    "                next_token._.is_cnpj = True\n",
    "            else:\n",
    "                token._.is_cnpj = False\n",
    "    return doc        \n",
    "\n",
    "\n",
    "# Registro do atributo 'is_cnpj'\n",
    "Token.set_extension('is_cnpj', force=True, default=False)\n",
    "\n",
    "\n",
    "# Função para aplicar o matcher\n",
    "@Language.component(\"apply_cnpj_matcher\")\n",
    "def apply_cnpj_matcher(doc):\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        for token in span:\n",
    "            token._.is_cnpj = True\n",
    "    return doc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dict de Tipo de documento, Patterns - Entity Ruler e Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><mark> <b>1.0</b> Carregando o dict de tipo de documento, os patterns para o Entity Ruler e o Matcher </mark></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Criar um dicionário para matchers patterns - nfs-e\n",
    "matcher_pattern_dict = {\n",
    "        \"numero_nota_fiscal\": [\n",
    "            {\"LOWER\": \"número\"},\n",
    "            {\"LOWER\": \"da\"},\n",
    "            {\"LOWER\": \"nota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True}\n",
    "        ],\n",
    "        \"competencia\": [\n",
    "            {\"LOWER\": \"competência\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"?\"},\n",
    "            {\"ORTH\": {\"REGEX\": \"^[A-Z][a-z]+/[0-9]{4}$\"}}   \n",
    "        ],\n",
    "        \"dt_hr_emissao\": [\n",
    "            {\"LOWER\": \"data\"},\n",
    "            {\"LOWER\": \"e\"},\n",
    "            {\"LOWER\": \"hora\"},\n",
    "            {\"LOWER\": \"da\"},\n",
    "            {\"LOWER\": \"emissão\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"SHAPE\": \"dd/dd/dddd\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"SHAPE\": \"dd:dd:dd\"}\n",
    "        ],\n",
    "        \"codigo_verificacao\": [\n",
    "            {\"LOWER\": \"código\"},\n",
    "            {\"LOWER\": \"verificação\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_ASCII\": True, \"LENGTH\": 9}\n",
    "        ],\n",
    "        \"valor_total_nota\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"total\"},\n",
    "            {\"LOWER\": \"da\", \"OP\": \"?\"},\n",
    "            {\"LOWER\": \"nota\", \"OP\": \"?\"},\n",
    "            {\"TEXT\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_servicos_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"serviços\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_deducao_pattern\": [\n",
    "            {\"LOWER\": \"dedução\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_incondR_pattern\": [\n",
    "            {\"LOWER\": \"base\"},\n",
    "            {\"LOWER\": \"de\"},\n",
    "            {\"IS_SPACE\": True},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "        ],\n",
    "        \"valor_incond_patternP\": [\n",
    "            {\"LOWER\": \"desc\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "            {\"LOWER\": \"incond\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "        ],\n",
    "        \"valor_calculoR_pattern\": [\n",
    "            {\"LOWER\": \"cálculo\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_calculoP_pattern\": [\n",
    "            {\"LOWER\": \"base\"},\n",
    "            {\"LOWER\": \"de\"},\n",
    "            {\"LOWER\": \"cálculo\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_aliquota_pattern\": [\n",
    "            {\"LOWER\": \"alíquota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"d,dd\", \"OP\": \"?\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ],\n",
    "        \"valor_aliquota2_pattern\": [\n",
    "            {\"LOWER\": \"alíquota\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"d\", \"OP\": \"?\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ],\n",
    "        \"valor_iss_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_issretido_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"LOWER\": \"retido\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_desccond_pattern\": [\n",
    "            {\"LOWER\": \"desc\"},\n",
    "            {\"ORTH\": \".\"},\n",
    "            {\"LOWER\": \"cond\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_pis_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"pis\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_cofins_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"cofins\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_ir_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"ir\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_inss_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"inss\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_csll_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"csll\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_outrasreten_pattern\": [\n",
    "            {\"LOWER\": \"outras\"},\n",
    "            {\"LOWER\": \"retenções\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"valor_liquido_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"líquido\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"SHAPE\": \"X$\"},\n",
    "            {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "            {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"exigibilidade_iss_pattern\": [\n",
    "            {\"LOWER\": \"exigibilidade\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"LOWER\": {\"IN\": [\"exigivel\", \"não exigivel\"]}}\n",
    "        ],\n",
    "        \"padrao_regime_tributacao\": [\n",
    "            {\"LOWER\": \"regime\"},\n",
    "            {\"LOWER\": \"tributação\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"+\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"*\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": \"simples\", \"OP\": \"?\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"*\"}\n",
    "        ],\n",
    "        \"simples_nacional_nao_pattern\": [\n",
    "            {\"LOWER\": \"simples\"},\n",
    "            {\"LOWER\": \"nacional\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": \"não\"}\n",
    "        ],\n",
    "        \"simples_nacional_pattern\": [\n",
    "            {\"LOWER\": \"simples\"},\n",
    "            {\"LOWER\": \"nacional\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": \"sim\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \"(\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \"%\", \"OP\": \"?\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \")\", \"OP\": \"?\"}\n",
    "        ],\n",
    "        \"issqn_retido_pattern\": [\n",
    "            {\"LOWER\": \"issqn\"},\n",
    "            {\"LOWER\": \"retido\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"LOWER\": {\"IN\": [\"sim\", \"não\"]}}\n",
    "        ],\n",
    "        \"local_prestacao_servico_pattern\": [\n",
    "            {\"LOWER\": \"local\"},\n",
    "            {\"ORTH\": \".\"},\n",
    "            {\"LOWER\": \"prestação\"},\n",
    "            {\"LOWER\": \"serviço\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"+\"},  # para lidar com múltiplos espaços\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"+\"},  # para a cidade\n",
    "            {\"ORTH\": \"-\", \"OP\": \"?\"},\n",
    "            {\"IS_UPPER\": True, \"LENGTH\": 2, \"OP\": \"?\"}  # para a sigla do estado\n",
    "        ],\n",
    "        \"local_incidencia_pattern\": [\n",
    "            {\"LOWER\": \"local\"},\n",
    "            {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "            {\"LOWER\": \"incidência\"},\n",
    "            {\"IS_ALPHA\": True, \"OP\": \"+\"},  # Nome da cidade\n",
    "            {\"ORTH\": \"-\", \"OP\": \"?\"},  # Hífen opcional\n",
    "            {\"SHAPE\": \"XX\", \"OP\": \"?\"}  # Sigla do estado\n",
    "        ],\n",
    "        \"valor_aliquota_pattern\": [\n",
    "            {\"LOWER\": \"valor\"},\n",
    "            {\"LOWER\": \"iss\"},\n",
    "            {\"ORTH\": \":\"},\n",
    "            {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"+\"},\n",
    "            {\"ORTH\": \"\", \"OP\": \"?\"},\n",
    "            {\"IS_DIGIT\": True, \"OP\": \"*\"},\n",
    "            {\"ORTH\": \"%\"}\n",
    "        ]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity ruler patterns\n",
    "colors = {\n",
    "            \"secretaria\": \"linear-gradient(90deg, #2ADB5E, #1FA346)\", # Verde Degrade\n",
    "            \"tipo_documento\": \"linear-gradient(90deg, #09D6FF, #08A0D1)\", #Azul medio degrade\n",
    "            \"nome_prefeitura\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", # Roxo claro para lilaz - degrade bem bacana\n",
    "            \"nome_section\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\", #  lilaz - Degrade\n",
    "            \"nome_section\": \"#FFEA7F\", # Laranja claro\n",
    "            \"SAFRA\": \"#CCA10C\", # Terracota\n",
    "            \"SAFRA\": \"#AB9BFC\", # Roxo claro \n",
    "            \"CNPJ\": \"#7AECEC\", # Azul bem claro\n",
    "            \"encerrador\": \"#EE8AF8\" # Rosa medio\n",
    "        }          \n",
    "\n",
    "patternsPrefeitura = [\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mesquita\"}], \"id\": \"PM_MESQUITA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mage\"}], \"id\": \"PM_MAGE\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsSection = [     \n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"número\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}, {\"ORTH\": \":\"}], \"id\": \"1. CABECALHO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"discriminação\"}, {\"LOWER\": \"dos\"}, {\"LOWER\": \"serviços\"}], \"id\": \"4. DESCRIMINACAO DOS SERVIÇOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"total\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}], \"id\": \"5. VALOR TOTAL\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"cnae\"}], \"id\": \"6. CNAE e Item da Lista de Serviços\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"serviços\"}], \"id\": \"7. VALORES E IMPOSTOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"dados\"}, {\"LOWER\": \"complementares\"}], \"id\": \"8. DADOS COMPLEMENTARES\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"outras\"}, {\"LOWER\": \"informações\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"criticas\"}], \"id\": \"9. OUTRAS INFORMAÇOES / CRITICAS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"observação\"},{\"ORTH\": \":\"}], \"id\": \"10. OBSERVACOES\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "patternsSecretarias = [{\"label\": \"secretaria\", \"pattern\": [{\"LOWER\": \"secretaria\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"fazenda\"},], \"id\": \"SECRETARIA\"}] \n",
    "\n",
    "\n",
    "patternsTipoDocumento = [\n",
    "                        {\"label\": \"tipo_documento\", \"pattern\": [{\"LOWER\": \"nota\"}, {\"LOWER\": \"fiscal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}, {\"LOWER\": \"eletrônica\"}, {\"LOWER\": \"-\"}, {\"LOWER\": \"nfs-e\"}], \"id\": \"NFS-e\"}\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsIdentificaEntidade = [\n",
    "                            {\"label\": \"CNPJ\", \"pattern\": [{\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}$\"}}], \"id\": \"cpf_cnpj_com_mascara\"}\n",
    "                            ]\n",
    "\n",
    "patternsEncerradores = [{\"label\": \"encerrador\", \"pattern\": [{\"LOWER\": \"https\"},{\"ORTH\": \":\"}], \"id\": \"encerrador\"},\n",
    "                        {\"label\": \"encerrador\", \"pattern\": [{\"LOWER\": \"https://nfs-e.mage.rj.gov.br\"}], \"id\": \"encerrador\"}\n",
    "                        ] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patternsCnpj = [\n",
    "    {\n",
    "        \"label\": \"CNPJ\",\n",
    "        \"pattern\": [\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/$\"}},\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{4}-\\d{2}$\"}}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "patterns = patternsPrefeitura + patternsSection + patternsSecretarias + patternsTipoDocumento + patternsIdentificaEntidade + patternsCnpj + patternsEncerradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://nfs-e.mage.rj.gov.br'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. XXX IMPORTANTE, carregar o dict de tipo de documento \n",
    "tipo_documento_dict = load_dict_from_file(config_tipo_doc_path)\n",
    "\n",
    "\n",
    "\n",
    "matcher_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('matcher_pattern_path', 'valor_padrao')\n",
    "entity_ruler_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('entity_ruler_pattern_path', 'valor_padrao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Rotina para carregar e atribuir ao matcher os patterns do disco\n",
    "matcher_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('matcher_pattern_path', 'valor_padrao')\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# XXX Carregar matcher patterns do disco\n",
    "with open(matcher_pattern_path, \"r\") as f:\n",
    "    loaded_patterns = json.load(f)\n",
    "    \n",
    "# Adicionar ao Matcher\n",
    "for label, pattern in loaded_patterns.items():\n",
    "    matcher.add(label, [pattern])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Carregar Entity Ruler patterns do disco\n",
    "entity_ruler_pattern_path = tipo_documento_dict.get(tipo_doc_work, {}).get('entity_ruler_pattern_path', 'valor_padrao')\n",
    "\n",
    "patterns, colors = load_patterns_and_colors(entity_ruler_pattern_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> <b>1.1</b> Salvando novos patterns de Entity Ruler e  Matcher  para disco </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Processo para salvar matcher pattern para json\n",
    "nome_matches_pattern_json = tipo_documento + \"_matcher_pattern.json\"\n",
    "path_matches_pattern_json = os.path.join(tipo_documento_patterns_path, nome_matches_pattern_json)\n",
    "with open(path_matches_pattern_json, \"w\") as f:\n",
    "    json.dump(matcher_pattern_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Processo para salvar entity ruler pattern para json\n",
    "nome_entityruler_pattern_json = tipo_documento + \"_entity_ruler_pattern.json\"\n",
    "entityruler_file_path = os.path.join(tipo_documento_patterns_path, nome_entityruler_pattern_json)\n",
    "\n",
    "write_patterns_to_file(patterns=patterns, colors=colors, filename=entityruler_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"set_cnpj_attribute\") # Adicione esta etapa se você quiser definir o atributo manualmente\n",
    "\n",
    "nlp.add_pipe(\"apply_cnpj_matcher\")  # Adicione esta etapa para aplicar o matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> <b>1.2</b> Criando novos patterns </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor = 'PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA'\n",
    "valor.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 - Processo de Extracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2.x</b> Templates e Dics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames_nf_v4_df: 2.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def define_dados_iniciais(idx, row, row_info, texto_tratado, debug):\n",
    "    \n",
    "    dados_iniciais_nf = {}\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    \n",
    "    dados_iniciais_nf['action_item'] = action_item_row_info\n",
    "    dados_iniciais_nf['informations'] = information_row_info\n",
    "    \n",
    "    print(f'\\nDentro da func define_dados_iniciais:  -action_item_row_info: {action_item_row_info}')\n",
    "   \n",
    "\n",
    "\n",
    "    prefeitura_encontrada = None\n",
    "    de_para_encontrado = None\n",
    "\n",
    "    # 7. ZZZ Dicionário para mapear Prefeitura com sua sigla\n",
    "    de_para_prefeitura = {\n",
    "        \"PREFEITURA DA CIDADE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA DA CIDADE DE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA MUNICIPAL DE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA\": \"PM_SPA\",\n",
    "        \"MUNICIPAL DE SAO PEDRO DA ALDEIA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA\\nALDEIA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE MESQUITA\": \"PM_MESQUITA\",\n",
    "        \"PREFEITURA MUNICIPAL DE DE MESQUITA\": \"PM_MESQUITA\",\n",
    "        # ... adicione \n",
    "    }\n",
    "    \n",
    "\n",
    "    templates = {\n",
    "        (\"PM_MAGE\", None): \"MAGE\",\n",
    "        (\"PM_SPA\", None): \"SPA\",\n",
    "        (\"PM_MESQUITA\", None): \"MESQUITA\",\n",
    "        (\"Pague agora com o seu Pix\", None): \"NAO_PROCESSAR\",\n",
    "        # ... adicione outras combinações aqui\n",
    "    }\n",
    "\n",
    "    cnpj_encontrado = None\n",
    "    # Verifique cada linha do texto\n",
    "    for linha in texto_tratado:\n",
    "        for pref in de_para_prefeitura.keys():\n",
    "            if pref in linha:\n",
    "                #print(linha)\n",
    "                prefeitura_encontrada = pref\n",
    "                dados_iniciais_nf['prefeitura'] = prefeitura_encontrada\n",
    "                if debug:\n",
    "                    print(f'\\n4.funcao: define_dados_iniciais(texto_tratado) - dentro do loop for de pesquisa prefeitura - prefeitura_encontrada: \\n{prefeitura_encontrada}\\n\\n')\n",
    "    # Saímos do loop, agora vamos verificar qual template usar\n",
    "    if prefeitura_encontrada:\n",
    "        de_para_pm = de_para_prefeitura.get(prefeitura_encontrada)\n",
    "        dados_iniciais_nf['de_para_pm'] = de_para_pm\n",
    "        if debug:\n",
    "            print(f'\\n5.funcao: define_dados_iniciais(texto_tratado) - if prefeitura_encontrada - de_para_pm \\n{de_para_pm}\\n\\n')\n",
    "        if not de_para_pm:\n",
    "            de_para_pm = de_para_prefeitura.get(prefeitura_encontrada, \"NAO_PROCESSAR\")\n",
    "            dados_iniciais_nf['de_para_pm'] = de_para_pm\n",
    "            #print(de_para_pm)\n",
    "    else:\n",
    "        de_para_pm = \"NAO_PROCESSAR\"\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        information_row_info = 'Nao identificado dados iniciais para o documento'\n",
    "        \n",
    "     \n",
    "        \n",
    "    # Verifique cada linha do texto\n",
    "    for linha in texto_tratado:\n",
    "        for de_para, cnpj in templates.keys():\n",
    "            if cnpj and cnpj in linha:\n",
    "                cnpj_encontrado = cnpj\n",
    "                dados_iniciais_nf['cnpj_encontrado'] = cnpj_encontrado\n",
    "                \n",
    "                \n",
    "    # Saímos do loop, agora vamos verificar qual template usar\n",
    "    if de_para_pm:\n",
    "        template_usar = templates.get((de_para_pm, cnpj_encontrado))\n",
    "        logging.info(f'usara template {template_usar} para: {cnpj_encontrado}')\n",
    "        # print(template_usar)\n",
    "        dados_iniciais_nf['model'] = template_usar\n",
    "        if not template_usar:\n",
    "            template_usar = templates.get((de_para_pm, None), \"TEMPLATE_NAO_ENCONTRADO\")\n",
    "            dados_iniciais_nf['model'] = 'NAO_ENC.' \n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'model nao encontrado'\n",
    "    else:\n",
    "        template_usar = \"TEMPLATE_NAO_ENCONTRADO\"\n",
    "        dados_iniciais_nf['model'] = 'NAO_ENC.'\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        information_row_info = 'model nao encontrado'\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #Confirmando se template existe em frames    \n",
    "    try:        \n",
    "        f_type = 'frame'\n",
    "        #template_usar = 'SAO_PEDRO_SUPERMIX'\n",
    "        result = filtrar_df(frames_nf_v4_df, type=f_type, de_para_pm=de_para_pm, model=template_usar)\n",
    "        model = result['model'].values[0]\n",
    "        if model:\n",
    "            template_oficial = model\n",
    "            if model == template_usar:\n",
    "                dados_iniciais_nf['model'] = template_oficial\n",
    "            else:    \n",
    "                template_usar = \"necessario cadastrar\"\n",
    "                dados_iniciais_nf['model'] = \"CADASTRAR\"\n",
    "                \n",
    "            dados_iniciais_nf['model'] = template_usar\n",
    "        else:\n",
    "            template_usar = \"necessario cadastrar\"\n",
    "            dados_iniciais_nf['model'] = \"CADASTRAR\"\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "       error_msg = (f\"Erro busca do template: {e}\") \n",
    "    \n",
    "    dados_iniciais_nf['action_item'] = action_item_row_info \n",
    "    dados_iniciais_nf['informations'] = information_row_info         \n",
    "        \n",
    "    return dados_iniciais_nf  \n",
    "\n",
    "\n",
    "\n",
    "nf_model_path = \"config/modelos/frames_nf_v11.xlsx\"\n",
    "\n",
    "#Le a planilha e cria do DF\n",
    "frames_nf_v4_df = pd.read_excel(nf_model_path)\n",
    "\n",
    "\n",
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'section']\n",
    "frames_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']\n",
    "\n",
    "ver = tmod.get_template_version(frames_nf_v4_df, 'MAGE')\n",
    "\n",
    "frames_nf_v4_df.head(5)\n",
    "\n",
    "print(f'frames_nf_v4_df: {ver}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>date_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>sigla_tipo</th>\n",
       "      <th>fase_processo</th>\n",
       "      <th>nome_atividade</th>\n",
       "      <th>status_documento</th>\n",
       "      <th>acao_executada</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>...</th>\n",
       "      <th>pdf_pesquisavel</th>\n",
       "      <th>score</th>\n",
       "      <th>palavra_chave</th>\n",
       "      <th>document_tag</th>\n",
       "      <th>action_item</th>\n",
       "      <th>level</th>\n",
       "      <th>parent_document_unique_id</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>file_path</th>\n",
       "      <th>informations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4433a03b-d30a-4c92-80fc-015912e1f357</th>\n",
       "      <td>1</td>\n",
       "      <td>('26/09/2023 16:16:39',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zip</td>\n",
       "      <td>doc_zip</td>\n",
       "      <td>ARCHIEVE_EXTRACTION</td>\n",
       "      <td>2</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>8d7038d712373364fa4c7680a887a0ceed01c8692d6958...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</th>\n",
       "      <td>2</td>\n",
       "      <td>('26/09/2023 16:16:39',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716463</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>66a7db9ee1500d5f9fa5da26563cfd7b68f1f5ba3daba2...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393a4eab-4b10-48e4-8d06-2fecadfa3b48</th>\n",
       "      <td>3</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>livro</td>\n",
       "      <td>prov_livro_registro</td>\n",
       "      <td>SPLIT_PAGES</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>b960962503987f6e05f5646d71a789facfe4e80ccb8890...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2457b7-ea5c-4191-acf0-bc8edc04879e</th>\n",
       "      <td>4</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932860</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>23a28a363c2d2c8b700ac4775164f7c0f0e2d6cef6166d...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6b5af8f-78dc-4627-9322-9c3b70f46a48</th>\n",
       "      <td>5</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932562</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>54045f4c09341d9f8d69438e7afe71eff46bb4e731392b...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c</th>\n",
       "      <td>6</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -4.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>ddd09bb806dc79e98a74c5cf1adc6a5bd23ea1b4f1bfa7...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ef2477eb-67ca-43bf-bab4-826d872d47e7</th>\n",
       "      <td>7</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -6.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.936102</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>8910a092d3aa53b6a1eb805c783245493760a1c46dadfa...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fd74ace6-6582-4e71-ada9-f21760846ade</th>\n",
       "      <td>8</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -3.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.934921</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>25387d066a46925acba7ddfe3cd97e2e70f92838ef4312...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c8a7cd74-931c-4b38-814f-779874d69417</th>\n",
       "      <td>9</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932562</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>8be881c377bf3064ef61f014fd14602cc736a73b69de8c...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95df6a78-d1f0-4c98-b349-96f1e9d6b10c</th>\n",
       "      <td>10</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>160014</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817916</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>d936f98e3cf1e773a6a5f489e4db46f6cfade5b947177e...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184149d-ac46-473a-8246-a39b2a9f302d</th>\n",
       "      <td>11</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>160014</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809813</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>45372e561f1d4d4a658de7d7a42150e13fd44ae226dc1b...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6b1c342f-8049-410f-957b-fd1bf0ffc8c7</th>\n",
       "      <td>12</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>126623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473714</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>a35df231141af673ed89b49f32288ef8fd313858e9467b...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3f115ed4-885f-4d2a-b2d5-c42da4348d42</th>\n",
       "      <td>13</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>138565</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423344</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>9a30f46ca2e14dbb0cf11654ab56fbdf83fd5782eb98f4...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      seq                 date_time     batch  \\\n",
       "document_unique_id                                                              \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357    1  ('26/09/2023 16:16:39',)  Batch_23   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2    2  ('26/09/2023 16:16:39',)  Batch_23   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    3  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    4  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    5  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    6  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    7  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    8  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    9  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c   10  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d   11  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7   12  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42   13  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "\n",
       "                                     sigla_tipo fase_processo nome_atividade  \\\n",
       "document_unique_id                                                             \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357      nfs_e       analise   scan_analise   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2      nfs_e       analise   scan_analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48      nfs_e       analise   scan_analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e      nfs_e       analise   scan_analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48      nfs_e       analise   scan_analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c      nfs_e       analise   scan_analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7      nfs_e       analise   scan_analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade      nfs_e       analise   scan_analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417      nfs_e       analise   scan_analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c      nfs_e       analise   scan_analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d      nfs_e       analise   scan_analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7      nfs_e       analise   scan_analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42      nfs_e       analise   scan_analise   \n",
       "\n",
       "                                        status_documento acao_executada  \\\n",
       "document_unique_id                                                        \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357        root_analise        Analise   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  PREPROCESS_EXTRACT        Analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48        root_analise        Analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  PREPROCESS_EXTRACT        Analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48        root_analise        Analise   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c        root_analise        Analise   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7        root_analise        Analise   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade        root_analise        Analise   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417        root_analise        Analise   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c        root_analise        Analise   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d        root_analise        Analise   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7        root_analise        Analise   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42        root_analise        Analise   \n",
       "\n",
       "                                                                     original_file_name  \\\n",
       "document_unique_id                                                                        \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357                     MESQUITA_PDF_31282023_2258.zip   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                                              1.pdf   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48                     Livro de Registro do ISSQN.pdf   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                                        2023 -5.pdf   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                                        2023 -7.pdf   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c                                        2023 -4.pdf   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7                                        2023 -6.pdf   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade                                        2023 -3.pdf   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417                                        2023 -8.pdf   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c                                          31-07.pdf   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                     directory  ...  pdf_pesquisavel  \\\n",
       "document_unique_id                              ...                    \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  root_dir  ...              NaN   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     teste  ...              0.0   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    115964  ...              NaN   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    159871  ...              1.0   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    159871  ...              1.0   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c    159871  ...              1.0   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7    159871  ...              1.0   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade    159871  ...              1.0   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417    159871  ...              1.0   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c    160014  ...              1.0   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d    160014  ...              1.0   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7    126623  ...              1.0   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42    138565  ...              1.0   \n",
       "\n",
       "                                         score  palavra_chave  \\\n",
       "document_unique_id                                              \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357       NaN            zip   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  0.716463        default   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48       NaN          livro   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  0.932860        default   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  0.932562        default   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  1.000000        default   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  0.936102        default   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  0.934921        default   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  0.932562        default   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  0.817916        default   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  0.809813        default   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7  0.473714        default   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42  0.423344        default   \n",
       "\n",
       "                                             document_tag  \\\n",
       "document_unique_id                                          \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357              doc_zip   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     prov_nota_fiscal   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  prov_livro_registro   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e     prov_nota_fiscal   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48     prov_nota_fiscal   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c     prov_nota_fiscal   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7     prov_nota_fiscal   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade     prov_nota_fiscal   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417     prov_nota_fiscal   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c     prov_nota_fiscal   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d     prov_nota_fiscal   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7     prov_nota_fiscal   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42     prov_nota_fiscal   \n",
       "\n",
       "                                              action_item level  \\\n",
       "document_unique_id                                                \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  ARCHIEVE_EXTRACTION     2   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2   PREPROCESS_EXTRACT     3   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48          SPLIT_PAGES     3   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e   PREPROCESS_EXTRACT     3   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48   PREPROCESS_EXTRACT     3   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c   PREPROCESS_EXTRACT     3   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7   PREPROCESS_EXTRACT     3   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade   PREPROCESS_EXTRACT     3   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417   PREPROCESS_EXTRACT     3   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c   PREPROCESS_EXTRACT     3   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d   PREPROCESS_EXTRACT     3   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7           NO_PROCESS     3   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42           NO_PROCESS     3   \n",
       "\n",
       "                                                 parent_document_unique_id  \\\n",
       "document_unique_id                                                           \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "\n",
       "                                                                              file_hash  \\\n",
       "document_unique_id                                                                        \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  8d7038d712373364fa4c7680a887a0ceed01c8692d6958...   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  66a7db9ee1500d5f9fa5da26563cfd7b68f1f5ba3daba2...   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  b960962503987f6e05f5646d71a789facfe4e80ccb8890...   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  23a28a363c2d2c8b700ac4775164f7c0f0e2d6cef6166d...   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  54045f4c09341d9f8d69438e7afe71eff46bb4e731392b...   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  ddd09bb806dc79e98a74c5cf1adc6a5bd23ea1b4f1bfa7...   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  8910a092d3aa53b6a1eb805c783245493760a1c46dadfa...   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  25387d066a46925acba7ddfe3cd97e2e70f92838ef4312...   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  8be881c377bf3064ef61f014fd14602cc736a73b69de8c...   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  d936f98e3cf1e773a6a5f489e4db46f6cfade5b947177e...   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  45372e561f1d4d4a658de7d7a42150e13fd44ae226dc1b...   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7  a35df231141af673ed89b49f32288ef8fd313858e9467b...   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42  9a30f46ca2e14dbb0cf11654ab56fbdf83fd5782eb98f4...   \n",
       "\n",
       "                                                                              file_path  \\\n",
       "document_unique_id                                                                        \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  pipeline_extracao_documentos/2_documentos_para...   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  pipeline_extracao_documentos/2_documentos_para...   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  pipeline_extracao_documentos/2_documentos_para...   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  pipeline_extracao_documentos/2_documentos_para...   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  pipeline_extracao_documentos/2_documentos_para...   \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c  pipeline_extracao_documentos/2_documentos_para...   \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7  pipeline_extracao_documentos/2_documentos_para...   \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade  pipeline_extracao_documentos/2_documentos_para...   \n",
       "c8a7cd74-931c-4b38-814f-779874d69417  pipeline_extracao_documentos/2_documentos_para...   \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c  pipeline_extracao_documentos/2_documentos_para...   \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d  pipeline_extracao_documentos/2_documentos_para...   \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7  pipeline_extracao_documentos/2_documentos_para...   \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42  pipeline_extracao_documentos/2_documentos_para...   \n",
       "\n",
       "                                     informations  \n",
       "document_unique_id                                 \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357               \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2               \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48               \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e               \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48               \n",
       "d6b2bfd0-f5ba-4678-a8d7-9d3a16cb7c6c               \n",
       "ef2477eb-67ca-43bf-bab4-826d872d47e7               \n",
       "fd74ace6-6582-4e71-ada9-f21760846ade               \n",
       "c8a7cd74-931c-4b38-814f-779874d69417               \n",
       "95df6a78-d1f0-4c98-b349-96f1e9d6b10c               \n",
       "6184149d-ac46-473a-8246-a39b2a9f302d               \n",
       "6b1c342f-8049-410f-957b-fd1bf0ffc8c7               \n",
       "3f115ed4-885f-4d2a-b2d5-c42da4348d42               \n",
       "\n",
       "[13 rows x 22 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. XXX Buscar proximo Batch caso nao esteja rodando email\n",
    "batch_name = utl.busca_proximo_batch(conf_export_plan_path)\n",
    "\n",
    "\n",
    "\n",
    "# 2. XXX IMPORTANTE - Modelo a ser utilizado para carregar o dict doc_content\n",
    "doc_content = {}\n",
    "doc_content = load_doc_content_from_file()\n",
    "\n",
    "\n",
    "\n",
    "# 3. XXX Definiçao do path para salvar o arquivo\n",
    "file_path_root_pipe = os.path.join(map_analise_path, df_root_pipe_file + batch_name + \".xlsx\")\n",
    "\n",
    "\n",
    "# 4. XXX Ler a planilha e cria df_documento_recebido\n",
    "df_root_pipe = pd.read_excel(file_path_root_pipe)\n",
    "\n",
    "\n",
    "# 5. XXX  Ajustar o indice\n",
    "df_root_pipe.set_index('document_unique_id', inplace=True)\n",
    "\n",
    "\n",
    "df_root_pipe.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento/Batch_23/MESQUITA_PDF_31282023_2258/159871/2023 -4.pdf'\n",
    "original_file_name = os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"1. CABECALHO\"\n",
    "mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "context_mapping = \"data_cabecalho\"\n",
    "def_replace = True \n",
    "model_map = 'MESQUITA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novas funcoes - que estao tambem no 1_map_analise e que servem de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.B XXX Funçao de criacao do PDF Pesquisavel\n",
    "def run_ocrmypdf(input_file, output_file):\n",
    "    command = [\n",
    "        'ocrmypdf',\n",
    "        '--language', 'por',\n",
    "        '--deskew',\n",
    "        '--force-ocr',\n",
    "        input_file,\n",
    "        output_file\n",
    "    ]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"OCRmyPDF completed successfully. Output saved to {output_file}.\")\n",
    "    else:\n",
    "        print(f\"OCRmyPDF failed with error: {result.stderr.decode('utf-8')}\")\n",
    "        \n",
    "        \n",
    "# 1.A XXX Extracao de texto de todo o documento - PDF PESQUISAVEL\t\n",
    "def extracao_texto_PDF_P(i, document_unique_id, nome_arquivo, file_path, debug):    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text_P = page.get_text(\"text\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    texto_PDF_P = re.sub('\\s+', ' ', text_P).strip()  \n",
    "    if debug:\n",
    "        print(f'\\nFUNC analise_texto_PDF: doc.:{nome_arquivo}   texto_PDF_P: \\n\\n{texto_PDF}\\n\\n')\n",
    "\n",
    "    return texto_PDF_P  \n",
    "\n",
    "\n",
    "# 1.B XXX Extracao de texto de todo o documento - RASTER PDF\n",
    "def extracao_texto_Raster_P(i, document_unique_id, nome_arquivo, file_path, debug):    \n",
    "    \n",
    "    output_file = None\n",
    "    txt_document_file = None\n",
    "    \n",
    "    input_file = file_path\n",
    "    \n",
    "    #output_file = \"/home/dani-boy/extractNF/processamentos/temp/documento.pdf\"\n",
    "    output_file = os.path.join(raster_process_pdf_path, document_unique_id + '.pdf')\n",
    "\n",
    "    # 1. XXX Executar o comando OCRmyPDF\n",
    "    run_ocrmypdf(input_file, output_file)\n",
    "\n",
    "    txt_document_file = os.path.join(raster_process_txt_path, document_unique_id + '.txt')\n",
    "\n",
    "    txt_dir = os.path.dirname(txt_document_file)\n",
    "    if not os.path.exists(txt_dir):\n",
    "        os.makedirs(txt_dir)\n",
    "\n",
    "    # Execute o comando\n",
    "    subprocess.run([\"pdftotext\", output_file, txt_document_file])\n",
    "\n",
    "    # 3. XXX Ler o arquivo TXT\n",
    "    with open(txt_document_file, 'r', encoding='utf-8') as arquivo:\n",
    "        texto_OCR_R = arquivo.read()\n",
    "    texto_Raster_P = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "    \n",
    "    os.remove(output_file)\n",
    "    os.remove(txt_document_file)\n",
    "    \n",
    "    return texto_Raster_P  \n",
    "\n",
    "\n",
    "# 2. XXX Analise de silimaridade doc1 x doc2\n",
    "def analisa_similiaridade_doc(doc1, doc2):\n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "\n",
    "    # Calculando Similaridade de Cosseno\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
    "\n",
    "    print(f\"Score de Similaridade: {similarity_scores[0][0]}\")\n",
    "    \n",
    "    return similarity_scores[0][0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.A Extracao de texto de todo o documento - PDF PESQUISAVEL\t\n",
    "def extrai_texto_PDF_P(idx, row, row_info, section, map_directory, original_file_name, file_path, debug):    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text_P = page.get_text(\"text\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    texto_PDF_P = text_P.replace('\\n', ' ') \n",
    "    if debug:\n",
    "        print(f'\\nFUNC extrai_texto_PDF_P: doc.:{original_file_name} | diretorio: {map_directory}  texto_PDF_P: \\n\\n{texto_PDF_P}\\n\\n')\n",
    "\n",
    "    return texto_PDF_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_cabecalho_PDF_P(idx, row, row_info, section, matches, doc, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        section = row_frame['section_json']\n",
    "        label = row_frame['label']\n",
    "        reference = row_frame['reference']\n",
    "        string_pesquisa = row_frame['marcador_inicio']  \n",
    "        \n",
    "        raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "        \n",
    "        most_similar_reference = max([reference], key=lambda x: similar(x, raw_value))\n",
    "        ##print(f'\\nmost_similar_reference: {most_similar_reference}\\n')\n",
    "        final_value = raw_value.split(\":\", 1)[-1].strip()\n",
    "        data_box_valores[label] = final_value\n",
    "\n",
    "    return data_box_valores        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrac_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug):   \n",
    "     \n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "\n",
    "    # Busco a imagem np do documento\n",
    "    image_np_row_info = row_info.get('image_np')\n",
    "\n",
    "    # busco coordenadas para o contexto\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "\n",
    "    # 2. usando a funcao de extracao de coordenadas por contexto    \n",
    "    coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    x0 = int(x0)\n",
    "    y0 = int(y0)\n",
    "    x1 = int(x1)\n",
    "    y1 = int(y1) \n",
    "    # 3. Cropo a imagem - novo modelo\n",
    "    cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "    # 4. Converto para PIL\n",
    "    cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "    # 6. Executo OCR\n",
    "    texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "    # 7. Trato o texto extraido = text_splited\n",
    "    texto_cabechalho_PDF_Raster = re.sub('\\s+', ' ', texto_extraido).strip() \n",
    "\n",
    "    if debug:\n",
    "        plt.imshow(cropped_image_np)\n",
    "        plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "        plt.show()\n",
    "        print(f'texto_cabechalho_PDF_Raster: {texto_cabechalho_PDF_Raster}\\n')  \n",
    "    \n",
    "    return texto_cabechalho_PDF_Raster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajusta_texto_Raster_P(document_unique_id, original_text, texto_cabechalho_PDF_Raster):\n",
    "\n",
    "    # Passa pelo mapeamento de doc ents para ajustar o texto\n",
    "    doc, tokens, ents = show_ent_new(original_text, patterns=patterns)\n",
    "\n",
    "    nome_prefeitura_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "    nome_prefeitura_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "    secretaria_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'secretaria'][0]\n",
    "    secretaria_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'secretaria'][0]\n",
    "    tipo_documento_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "    tipo_documento_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "    prestador_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '2. PRESTADOR DE SERVIÇO'][0]\n",
    "\n",
    "    bloco_prefeitura = original_text[nome_prefeitura_start_char:nome_prefeitura_end_char]\n",
    "    bloco_secretaria = original_text[secretaria_start_char:secretaria_end_char]\n",
    "    bloco_tipo_documento = original_text[tipo_documento_start_char:tipo_documento_end_char]\n",
    "    bloco_inicio_prestador = original_text[prestador_start_char:]\n",
    "\n",
    "    recomposed_text = bloco_prefeitura + ' | ' + bloco_secretaria + ' | ' + bloco_tipo_documento  + ' | ' + texto_cabechalho_PDF_Raster + ' | ' + bloco_inicio_prestador\n",
    "    \n",
    "    return recomposed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapeia_cabecalho(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "\n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        section = row_frame['section_json']\n",
    "        label = row_frame['label']\n",
    "        reference = row_frame['reference']\n",
    "        string_pesquisa = row_frame['marcador_inicio']  \n",
    "        \n",
    "        raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "        \n",
    "        most_similar_reference = max([reference], key=lambda x: similar(x, raw_value))\n",
    "        ##print(f'\\nmost_similar_reference: {most_similar_reference}\\n')\n",
    "        final_value = raw_value.split(\":\", 1)[-1].strip()\n",
    "        data_box_valores[label] = final_value\n",
    "    \n",
    "    return data_box_valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>2.x</b> ExecuÇao do Pipeline de Extracao </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta e o principio da melhor funcao do mundo\n",
    "def extracao_pipeline(qualquer_df, doc_content, fase, atividade, status, debug=False, prestador=True, tomador=True, servicos=True, total=True, cnae=True, valores_impostos=True, complementares=True, outras_informacoes=True, observacoes=True):\n",
    "    \n",
    "    doc_info = {}\n",
    "    resumo = {}\n",
    "    row_teste_info = []\n",
    "    time_now = cron.timenow_pt_BR()\n",
    "    func_fase = fase\n",
    "    func_atividade = atividade\n",
    "    func_status = status\n",
    "    lista_dicts = []\n",
    "    conf_processo = {}\n",
    "    lista_conferencia = []\n",
    "   \n",
    "    i = 1\n",
    "    for idx, row in qualquer_df.iterrows():\n",
    "        dados_iniciais = {}\n",
    "        row_info = row.to_dict()\n",
    "        message_erro = []\n",
    "        # 1. Mapeamento de informacoes do DF\n",
    "        map_document_unique_id = idx\n",
    "        map_seq = row['seq']\n",
    "        map_batch_name = row['batch']\n",
    "        map_fase_processo = row['fase_processo']\n",
    "        map_nome_atividade = row['nome_atividade']\n",
    "        map_status_documento = row['status_documento']\n",
    "        map_original_file_name = row['original_file_name']\n",
    "        map_directory = row['directory']\n",
    "        map_one_page = row['one_page']\n",
    "        map_palavra_chave = row['palavra_chave']\n",
    "        map_document_tag = row['document_tag']\n",
    "        map_action_item = row['action_item']\n",
    "        map_pdf_pesquisavel = row['pdf_pesquisavel']\n",
    "        map_level = row['level']\n",
    "        file_path = row['file_path']\n",
    "        row_info['document_unique_id'] = map_document_unique_id\n",
    "    \n",
    "        # XXX Nivel 1 - Definindo que documentos serao tratados   \n",
    "        \n",
    "        \n",
    "         \n",
    "        if map_status_documento == 'PREPROCESS_EXTRACT':\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            # try:\n",
    "            # 1. Buscando o texto do documento pelo doc_content\n",
    "            texto_dict = doc_content.get(map_document_unique_id, {}).get('content', 'valor_padrao')\n",
    "            # 2. XXX IMPORTANTE - Efetuo a busca de entidades e efetuo a tokenizaÇao do documento\n",
    "            doc, tokens, ents = show_ent_new(texto_dict, patterns=patterns)\n",
    "            \n",
    "            matches = matcher(doc)\n",
    "            \n",
    "            prefeitura_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"nome_prefeitura\"][0]\n",
    "            de_para_pm = [ent.id_ for ent in doc.ents if ent.label_ == \"nome_prefeitura\"][0]\n",
    "            secretaria_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"secretaria\"][0]\n",
    "            tipo_documento_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"tipo_documento\"][0]\n",
    "            \n",
    "            f_type = 'document'\n",
    "            result = utl.filtrar_df(frames_nf_v4_df, type=f_type, de_para_pm=de_para_pm)\n",
    "            model_map = result['model'].values[0]\n",
    "            if debug:\n",
    "                print(f'\\nresult: {result}\\n')\n",
    "            \n",
    "            \n",
    "            section = \"1. CABECALHO\"\n",
    "            valores = {}\n",
    "            mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "            context_mapping = \"data_cabecalho\"\n",
    "            def_replace = True\n",
    "            \n",
    "            if map_pdf_pesquisavel == False:\n",
    "                # if debug:\n",
    "                print(\"irei gerar a imagem_np\")\n",
    "                imagem_gray, image_resized_name = convert_resize_gray(map_original_file_name, file_path, image_resized_path)\n",
    "                imagem_gray_rgb = imagem_gray.convert(\"RGB\")\n",
    "                imagem_gray_np = np.array(imagem_gray_rgb)\n",
    "                row_info['image_np'] = imagem_gray_np\n",
    "                \n",
    "                mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "                context_mapping = \"data_cabecalho\"\n",
    "                def_replace = True\n",
    "                \n",
    "                # vou tratar o texto do cabecalho\n",
    "                texto_cabechalho_PDF_Raster = extrac_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "                \n",
    "                print(f'\\n1. texto_cabechalho_PDF_Raster: {texto_cabechalho_PDF_Raster}\\n')\n",
    "                \n",
    "                # Ajusto o texto todo\n",
    "                if texto_cabechalho_PDF_Raster:\n",
    "                    texto_dict = ajusta_texto_Raster_P(map_document_unique_id, texto_dict, texto_cabechalho_PDF_Raster)\n",
    "                    print(f'\\n2. texto_dict: {texto_dict}\\n')\n",
    "                    # Atualizao do doc_content\n",
    "                    doc_content[map_document_unique_id]['content'] = texto_dict\n",
    "                    \n",
    "        \n",
    "            valores = mapeia_cabecalho(idx, row, row_info, doc_content, doc, matches, section, mapping_method, context_mapping, map_pdf_pesquisavel, model_map, map_original_file_name, file_path, debug)\n",
    "            print(f'\\nvalores: {valores}\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "            row_info['model'] = model_map\n",
    "            row_info['tipo_nota_fiscal'] = tipo_documento_map\n",
    "            row_info['secretaria'] = secretaria_map\n",
    "            row_info['prefeitura'] = prefeitura_map\n",
    "            row_info.update(valores)\n",
    "            information_row_info = \"Este e apenas um comeco - mas bem comeco mesmo\"\n",
    "            action_item_row_info = 'CONTINUE_PROCESS'\n",
    "            \n",
    "                # action_item_row_info = 'CONTINUE_PROCESS'\n",
    "                # row_info['action_item'] = action_item_row_info\n",
    "                # information_row_info = 'iniciado processamento'\n",
    "                # row_info['informations'] = information_row_info\n",
    "                # 0. DADOS GERAIS DOCUMENTO\n",
    "                # # 1. Buscando o texto do documento\n",
    "                # texto_dict = doc_content.get(map_document_unique_id, {}).get('content', 'valor_padrao')\n",
    "                # print(f'\\nmap_seq: {map_seq} | doc.: {map_original_file_name} texto_dict: \\n{texto_dict}\\n\\n')\n",
    "              \n",
    "                #print(f'\\nNivel 1 - map_seq: {map_seq} | pref.: {prefeitura_map} de_para_pm: {de_para_pm} | documento: {map_original_file_name}')\n",
    "\n",
    "                #print(f'\\nNivel 1 - map_seq: {map_seq} | pref.: {prefeitura_map} de_para_pm: {de_para_pm} | model: {model} | documento: {map_original_file_name}')\n",
    "            # except Exception as e:\n",
    "            #     msg = (f'Erro ao processar_dados_iniciais: {e}')\n",
    "            # finally:\n",
    "\n",
    "   \n",
    "            # XXX Nivel 2 - Definindo que os documentos legiveis serao tratados\n",
    "            if action_item_row_info == 'CONTINUE_PROCESS':\n",
    "                \n",
    "                # 1. CABECALHO\n",
    "                # try:\n",
    "   \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                # if pdf_pesquisavel_map:\n",
    "                #      valores = processar_cabecalho_PDF_P(idx, row, row_info, section, matches, doc, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)\n",
    "                #      row_info.update(valores) \n",
    "                # # else:\n",
    "                #     valores = processar_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)   \n",
    "                #     row_info.update(valores)\n",
    "         \n",
    "                # #status_documento_row_info = row_info.get('status_documento')\n",
    "                # action_item_row_info = row_info.get('action_item')\n",
    "                # information_row_info = row_info.get('informations')   \n",
    "                information_row_info = \"Este e apenas um comeco\"\n",
    "                action_item_row_info = 'CONTINUE_PROCESS'\n",
    "                \n",
    "                # XXX Nivel 3 - Definindo que os documentos legiveis serao tratados realmente\n",
    "                if action_item_row_info == 'BREAK_PROCESS':\n",
    "                    #msg = (f'Processo inicial: {map_batch_name} | {map_original_file_name} | diretorio: {map_directory} - information_row_info: {information_row_info}')\n",
    "                    if debug:\n",
    "                        print(f'\\nINFELIZMENTE - seq: {map_seq} doc: {map_original_file_name} dir: {map_directory} - NAO SERA PROCESSADO  | inf: {information_row_info} \\n\\n')\n",
    "               \n",
    "                    #row_info['informations'] = msg\n",
    "                    # logging.error(msg)\n",
    "                    lista_dicts.append(row_info)\n",
    "                    continue \n",
    "                \n",
    "                    \n",
    "                elif action_item_row_info == 'CONTINUE_PROCESS':\n",
    "                    if debug:\n",
    "                        print(f'\\nEBA, BORA CONTINUAR - seq: {map_seq} - proxima section: | PDF Pesquisavel: {pdf_pesquisavel_map} doc: {map_original_file_name} dir: {map_directory} | action_item: {action_item_row_info} | inf: {information_row_info} \\n\\n')\n",
    "                        print()\n",
    "                        print(valores)\n",
    "                    \n",
    "                    information_row_info = 'Cabecalho processado'\n",
    "                    row_info['informations'] = information_row_info\n",
    "                    \n",
    "                    \n",
    "                    # guarda_texto_doc = {}\n",
    "                    # guarda_texto_doc, linhas = cria_guarda_doc_ref_R_PDF(idx, row, de_para_map, model_map, map_original_file_name, file_path, image_resized_path, debug)\n",
    "            \n",
    "                    # 2. PRESTADOR DE SERVIÇO\n",
    "                    if prestador == True:\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        valores = {}\n",
    "                        erros_prestador = {}\n",
    "                        data_tomador = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_prestador_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            valores = extrai_prestador_R_PDF(idx, row, row_info, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        \n",
    "                        if not isinstance(valores, dict):\n",
    "                            msg_erro = (f\"\\nErro na linha {idx}: 'valores' não é um dicionário. Tipo: {type(valores)}, Valor: {valores}\")\n",
    "                        else:\n",
    "                            row_info.update(valores)\n",
    "                            \n",
    "                        # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                        # if debug:\n",
    "                        #     print(msg)\n",
    "                        # logging.info(msg)\n",
    "                    \n",
    "                    # 3. TOMADOR DE SERVIÇO\n",
    "                    if tomador == True:\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        \n",
    "                        valores = {}\n",
    "                        erros = []\n",
    "                        data_tomador = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        \n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_tomador_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        else:   \n",
    "                            valores = extrai_tomador_R_PDF(idx, row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                            \n",
    "                        if not isinstance(valores, dict):\n",
    "                            print(f\"\\nErro na linha {idx}: 'valores' não é um dicionário. Tipo: {type(valores)}, Valor: {valores}\")\n",
    "                        else:\n",
    "                            row_info.update(valores)\n",
    "                        \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)\n",
    "                    \n",
    "                    # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                    if servicos == True:\n",
    "                        if debug:\n",
    "                            print(f'processando servicos para: {map_original_file_name}')\n",
    "                        section = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                        valores = {}\n",
    "                        nf_data_servico = {} \n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        \n",
    "                        if pdf_pesquisavel_map:\n",
    "                            nf_data_servico = processar_servicos_pdf_pesquisavel(row, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            label = \"discriminacao_servicos\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = True\n",
    "                            \n",
    "                            # ItSs  working\n",
    "                            texto_extraido = extracao_documento_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            row_info[label] = texto_extraido\n",
    "                            \n",
    "                        msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                        if debug:\n",
    "                            print(msg)\n",
    "                        logging.info(msg)     \n",
    "\n",
    "\n",
    "                        try:\n",
    "                            texto_extraido = nf_data_servico['discriminacao_servicos'] \n",
    "                            row_info['discriminacao_servicos'] = texto_extraido \n",
    "                        except Exception as e:\n",
    "                            msg = (f\"doc: {map_original_file_name} | {e}\")\n",
    "                            discrimanacao_servico = \"Descricao nao encontrada\"\n",
    "                            row_info['discriminacao_servicos'] = texto_extraido\n",
    "\n",
    "                    \n",
    "                    # 5. VALOR TOTAL\n",
    "                    if total == True:\n",
    "                        section = \"5. VALOR TOTAL\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        #valores = {}\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valor_total_documento = processar_valor_total_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)\n",
    "                            if valor_total_documento:\n",
    "                                if debug:\n",
    "                                    print(f'\\nvalor_total_documento: {valor_total_documento} | doc: {map_original_file_name}\\n')\n",
    "                                row_info['valor_total_nota'] = valor_total_documento\n",
    "                        else:\n",
    "                            label = \"valor_total_nota\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = True\n",
    "                            texto_extraido = extracao_documento_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            if texto_extraido: \n",
    "                                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', texto_extraido)\n",
    "                                if valor_total_match:\n",
    "                                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                                    try:\n",
    "                                        # valores['secao'] = section\n",
    "                                        valor_total_documento = float(valor_total_sem_formatacao)\n",
    "                                    except Exception as e:\n",
    "                                        # valores['secao'] = section\n",
    "                                        valor_total_documento = 0.0\n",
    "                                        msg = (f'Processo inicial: {batch_name} | {map_original_file_name:>25} | diretorio: {map_directory} | {e}')\n",
    "                                        #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")\n",
    "                        \n",
    "                                    if valor_total_documento:\n",
    "                                        if debug:\n",
    "                                            print(f'\\nvalor_total_documento: {valor_total_documento} | doc: {map_original_file_name}\\n')\n",
    "                                        row_info['valor_total_nota'] = valor_total_documento\n",
    "         \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)\n",
    "                    \n",
    "                    # 6. CNAE e Item da Lista de Serviços \n",
    "                    if cnae == True:\n",
    "                        section = \"6. CNAE e Item da Lista de Serviços\"\n",
    "                        data_box_valores = {}\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        f_0_cnae = 0.95\n",
    "                        f_1_cnae = 1.15\n",
    "                        f_0_it = 0.95     #0.95\n",
    "                        f_1_it = 1.15    # 1\n",
    "                        \n",
    "                        mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "                        context_mapping = \"data_cnae\"\n",
    "                        def_replace = True\n",
    "                        \n",
    "                        if pdf_pesquisavel_map:\n",
    "                            data_box_valores = extracao_documento_CNAE_ITEM_PDF_P(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, def_replace, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            data_box_valores = extracao_documento_CNAE_ITEM_R_PDF(idx, row, row_info, guarda_texto_doc, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, def_replace, map_original_file_name, file_path, debug)\n",
    "                            \n",
    "                        if data_box_valores:\n",
    "                            row_info.update(data_box_valores)    \n",
    "\n",
    "                    \n",
    "                    # 7. VALORES E IMPOSTOS\n",
    "                    if valores_impostos == True:\n",
    "                        section = \"7. VALORES E IMPOSTOS\"\n",
    "                        # if debug:\n",
    "                        print(f'processando {section} para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                        valores = {}\n",
    "                        nf_data_valores = {}\n",
    "                        lista_impostos = []\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_valores_impostos_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                            row_info.update(valores)\n",
    "                        \n",
    "                        else:\n",
    "                            tipo = \"field_box\"\n",
    "                            father_value = \"5_frame_valores_impostos\"\n",
    "                            valores = extracao_impostos_R_PDF(section, tipo, father_value, de_para_map, model_map, map_original_file_name, file_path)\n",
    "                            #print(valores)\n",
    "                            row_info.update(valores)\n",
    "                        \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg) \n",
    "                    \n",
    "                    # 8. DADOS COMPLEMENTARES\n",
    "                    if complementares == True:\n",
    "                        section = '8. DADOS COMPLEMENTARES'\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        nf_data_dados_complementares = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            nf_data_valores = extrai_dados_complementares_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            label = \"dados_complementares\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = False\n",
    "                            # ItSs  working\n",
    "                            texto_extraido = extracao_complementar_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            row_info[label] = texto_extraido  \n",
    "\n",
    "                    \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)     \n",
    "                    \n",
    "                    # 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "                    if outras_informacoes == True:\n",
    "                        section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        tipo = \"field_box\"\n",
    "                        father_value = \"5_frame_inf_criticas\"\n",
    "                        valores = {} \n",
    "                        nf_data_outras_informacoes = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_outras_informacoes_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                        else:\n",
    "                            section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "                            tipo = \"field_box\"\n",
    "                            father_value = \"5_frame_inf_criticas\"\n",
    "                            valores = extracao_inforacoes_criticas_R_PDF(section, tipo, father_value, de_para_map, model_map, map_original_file_name, file_path)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                            \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)          \n",
    "                            \n",
    "                    \n",
    "                    # 10. OBSERVACOES\n",
    "                    if observacoes == True:  \n",
    "                        section = \"10. OBSERVACOES\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')  \n",
    "                        data_observacao = {}\n",
    "                        valores = {}\n",
    "                        f_0 = 0.9\n",
    "                        f_1 = 1.1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_outras_informacoes_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                        else:\n",
    "                            section = '10. OBSERVACOES'\n",
    "                            tipo = \"field_box\"\n",
    "                            father_value = \"6_section_inf_complementares_criticas\" \n",
    "                            \n",
    "                            label = \"observacao\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = True\n",
    "                            valores = extracao_observacoees_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                    \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)           \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                lista_dicts.append(row_info)\n",
    "                \n",
    "                \n",
    "            elif action_item_row_info == 'BREAK_PROCESS':\n",
    "                \n",
    "                msg = (f'Documento sem qualidade para pesquisa inicial: {map_batch_name} | {map_original_file_name} | diretorio: {map_directory}')\n",
    "                row_info['informations'] = msg  \n",
    "                \n",
    "            \n",
    "                lista_dicts.append(row_info)\n",
    "                continue\n",
    "                         \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        elif map_status_documento == 'NO_PROCESS':\n",
    "            msg = (f'Documento nao sera tratado neste escopo: {map_batch_name} | {map_original_file_name} | diretorio: {map_directory}')\n",
    "            row_info['action_item'] = \"NO_PROCESS\"    \n",
    "            row_info['informations'] = msg \n",
    "            lista_dicts.append(row_info)\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        #lista_dicts.append(row_info)\n",
    "        i += 1\n",
    "\n",
    "    #logging.info(f'processamento finalizado para: {batch_name}') \n",
    "    print(f'processamento de {i} documentos')\n",
    "    novo_df = pd.DataFrame(lista_dicts)\n",
    "    #return lista_dicts\n",
    "    return novo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irei gerar a imagem_np\n",
      "\n",
      "1. texto_cabechalho_PDF_Raster: Número da Nota: 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B\n",
      "\n",
      "\n",
      "2. texto_dict: PREFEITURA MUNICIPAL DE MAGE | SECRETARIA MUNICIPAL DA FAZENDA | NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e | Número da Nota: 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B | PRESTADOR DE SERVIÇOS CPF/CNPJ: 51.246.375/0001-77 Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ TOMADOR CPF/CNPJ: 12.324.674/0001-20 Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 DISCRIMINAÇÃO DOS SERVIÇOS Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL VALOR TOTAL DA NOTA: R$ 252.836,00 CNAE - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. VALOR SERVIÇOS: R$ 252.836,00 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 252.836,00 ALÍQUOTA: 2,01% VALOR ISS: R$ 5.082,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR INSS: R$ 0,00 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 252.836,00 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ Observação: - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) https://nfs-e.mage.rj.gov.br\n",
      "\n",
      "\n",
      "valores: {'numero_nota_fiscal': '1', 'competencia': 'Julho/2023', 'dt_hr_emissao': '31/07/2023 17:29:00', 'codigo_verificacao': '4ADEE6A7B'}\n",
      "\n",
      "\n",
      "valores: {'numero_nota_fiscal': '20235', 'competencia': 'Julho/2023', 'dt_hr_emissao': '27/07/2023 15:13:00', 'codigo_verificacao': '92ED36652'}\n",
      "\n",
      "processamento de 14 documentos\n"
     ]
    }
   ],
   "source": [
    "# analisar_pdf_pesquisavel\n",
    "fase = 'analise'\n",
    "atividade = 'PREPROCESS' \n",
    "status = 'PREPROCESS_EXTRACT'\n",
    "raw_document_list = []\n",
    "dados_prest = {}\n",
    "\n",
    "lista_dicts = []\n",
    "#logging.info(f'Execuçao do pipeline para {batch_name} | df_root_pipe: {file_path_root_pipe} fase: {fase} atividade: {atividade} status: {status}  template: {ver}')\n",
    "\n",
    "# 1. Processar somente dados iniciais e cabeçalho\n",
    "df = extracao_pipeline(df_root_pipe, doc_content, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>date_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>sigla_tipo</th>\n",
       "      <th>fase_processo</th>\n",
       "      <th>nome_atividade</th>\n",
       "      <th>status_documento</th>\n",
       "      <th>acao_executada</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>...</th>\n",
       "      <th>document_unique_id</th>\n",
       "      <th>image_np</th>\n",
       "      <th>model</th>\n",
       "      <th>tipo_nota_fiscal</th>\n",
       "      <th>secretaria</th>\n",
       "      <th>prefeitura</th>\n",
       "      <th>numero_nota_fiscal</th>\n",
       "      <th>competencia</th>\n",
       "      <th>dt_hr_emissao</th>\n",
       "      <th>codigo_verificacao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>('26/09/2023 16:16:39',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>...</td>\n",
       "      <td>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>MAGE</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MAGE</td>\n",
       "      <td>1</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>31/07/2023 17:29:00</td>\n",
       "      <td>4ADEE6A7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>ab2457b7-ea5c-4191-acf0-bc8edc04879e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MESQUITA</td>\n",
       "      <td>NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e</td>\n",
       "      <td>SECRETARIA MUNICIPAL DA FAZENDA</td>\n",
       "      <td>PREFEITURA MUNICIPAL DE MESQUITA</td>\n",
       "      <td>20235</td>\n",
       "      <td>Julho/2023</td>\n",
       "      <td>27/07/2023 15:13:00</td>\n",
       "      <td>92ED36652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq                 date_time     batch sigla_tipo fase_processo  \\\n",
       "0    2  ('26/09/2023 16:16:39',)  Batch_23      nfs_e       analise   \n",
       "1    4  ('26/09/2023 16:16:50',)  Batch_23      nfs_e       analise   \n",
       "\n",
       "  nome_atividade    status_documento acao_executada original_file_name  \\\n",
       "0   scan_analise  PREPROCESS_EXTRACT        Analise              1.pdf   \n",
       "1   scan_analise  PREPROCESS_EXTRACT        Analise        2023 -5.pdf   \n",
       "\n",
       "  directory  ...                    document_unique_id  \\\n",
       "0     teste  ...  27df9e70-b5fb-45b7-8f59-0c04ed9728e2   \n",
       "1    159871  ...  ab2457b7-ea5c-4191-acf0-bc8edc04879e   \n",
       "\n",
       "                                            image_np     model  \\\n",
       "0  [[[255, 255, 255], [255, 255, 255], [255, 255,...      MAGE   \n",
       "1                                                NaN  MESQUITA   \n",
       "\n",
       "                             tipo_nota_fiscal  \\\n",
       "0  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "1  NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e   \n",
       "\n",
       "                        secretaria                        prefeitura  \\\n",
       "0  SECRETARIA MUNICIPAL DA FAZENDA      PREFEITURA MUNICIPAL DE MAGE   \n",
       "1  SECRETARIA MUNICIPAL DA FAZENDA  PREFEITURA MUNICIPAL DE MESQUITA   \n",
       "\n",
       "  numero_nota_fiscal  competencia        dt_hr_emissao codigo_verificacao  \n",
       "0                  1   Julho/2023  31/07/2023 17:29:00          4ADEE6A7B  \n",
       "1              20235   Julho/2023  27/07/2023 15:13:00          92ED36652  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>date_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>sigla_tipo</th>\n",
       "      <th>fase_processo</th>\n",
       "      <th>nome_atividade</th>\n",
       "      <th>status_documento</th>\n",
       "      <th>acao_executada</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>...</th>\n",
       "      <th>pdf_pesquisavel</th>\n",
       "      <th>score</th>\n",
       "      <th>palavra_chave</th>\n",
       "      <th>document_tag</th>\n",
       "      <th>action_item</th>\n",
       "      <th>level</th>\n",
       "      <th>parent_document_unique_id</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>file_path</th>\n",
       "      <th>informations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4433a03b-d30a-4c92-80fc-015912e1f357</th>\n",
       "      <td>1</td>\n",
       "      <td>('26/09/2023 16:16:39',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zip</td>\n",
       "      <td>doc_zip</td>\n",
       "      <td>ARCHIEVE_EXTRACTION</td>\n",
       "      <td>2</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>8d7038d712373364fa4c7680a887a0ceed01c8692d6958...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27df9e70-b5fb-45b7-8f59-0c04ed9728e2</th>\n",
       "      <td>2</td>\n",
       "      <td>('26/09/2023 16:16:39',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.716463</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>66a7db9ee1500d5f9fa5da26563cfd7b68f1f5ba3daba2...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393a4eab-4b10-48e4-8d06-2fecadfa3b48</th>\n",
       "      <td>3</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>livro</td>\n",
       "      <td>prov_livro_registro</td>\n",
       "      <td>SPLIT_PAGES</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>b960962503987f6e05f5646d71a789facfe4e80ccb8890...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab2457b7-ea5c-4191-acf0-bc8edc04879e</th>\n",
       "      <td>4</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932860</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>23a28a363c2d2c8b700ac4775164f7c0f0e2d6cef6166d...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b6b5af8f-78dc-4627-9322-9c3b70f46a48</th>\n",
       "      <td>5</td>\n",
       "      <td>('26/09/2023 16:16:50',)</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>nfs_e</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932562</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>3</td>\n",
       "      <td>511c5820-d1d1-4c39-bfd6-6f6df5975fd4</td>\n",
       "      <td>54045f4c09341d9f8d69438e7afe71eff46bb4e731392b...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      seq                 date_time     batch  \\\n",
       "document_unique_id                                                              \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357    1  ('26/09/2023 16:16:39',)  Batch_23   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2    2  ('26/09/2023 16:16:39',)  Batch_23   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    3  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    4  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    5  ('26/09/2023 16:16:50',)  Batch_23   \n",
       "\n",
       "                                     sigla_tipo fase_processo nome_atividade  \\\n",
       "document_unique_id                                                             \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357      nfs_e       analise   scan_analise   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2      nfs_e       analise   scan_analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48      nfs_e       analise   scan_analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e      nfs_e       analise   scan_analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48      nfs_e       analise   scan_analise   \n",
       "\n",
       "                                     status_documento acao_executada  \\\n",
       "document_unique_id                                                     \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357     root_analise        Analise   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     root_analise        Analise   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48     root_analise        Analise   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e     root_analise        Analise   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48     root_analise        Analise   \n",
       "\n",
       "                                                  original_file_name  \\\n",
       "document_unique_id                                                     \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  MESQUITA_PDF_31282023_2258.zip   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2                           1.pdf   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  Livro de Registro do ISSQN.pdf   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e                     2023 -5.pdf   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48                     2023 -7.pdf   \n",
       "\n",
       "                                     directory  ...  pdf_pesquisavel  \\\n",
       "document_unique_id                              ...                    \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  root_dir  ...              NaN   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     teste  ...              0.0   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48    115964  ...              NaN   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e    159871  ...              1.0   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48    159871  ...              1.0   \n",
       "\n",
       "                                         score  palavra_chave  \\\n",
       "document_unique_id                                              \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357       NaN            zip   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  0.716463        default   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48       NaN          livro   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  0.932860        default   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  0.932562        default   \n",
       "\n",
       "                                             document_tag  \\\n",
       "document_unique_id                                          \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357              doc_zip   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2     prov_nota_fiscal   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  prov_livro_registro   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e     prov_nota_fiscal   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48     prov_nota_fiscal   \n",
       "\n",
       "                                              action_item level  \\\n",
       "document_unique_id                                                \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  ARCHIEVE_EXTRACTION     2   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2   PREPROCESS_EXTRACT     3   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48          SPLIT_PAGES     3   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e   PREPROCESS_EXTRACT     3   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48   PREPROCESS_EXTRACT     3   \n",
       "\n",
       "                                                 parent_document_unique_id  \\\n",
       "document_unique_id                                                           \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  511c5820-d1d1-4c39-bfd6-6f6df5975fd4   \n",
       "\n",
       "                                                                              file_hash  \\\n",
       "document_unique_id                                                                        \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  8d7038d712373364fa4c7680a887a0ceed01c8692d6958...   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  66a7db9ee1500d5f9fa5da26563cfd7b68f1f5ba3daba2...   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  b960962503987f6e05f5646d71a789facfe4e80ccb8890...   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  23a28a363c2d2c8b700ac4775164f7c0f0e2d6cef6166d...   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  54045f4c09341d9f8d69438e7afe71eff46bb4e731392b...   \n",
       "\n",
       "                                                                              file_path  \\\n",
       "document_unique_id                                                                        \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357  pipeline_extracao_documentos/2_documentos_para...   \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2  pipeline_extracao_documentos/2_documentos_para...   \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48  pipeline_extracao_documentos/2_documentos_para...   \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e  pipeline_extracao_documentos/2_documentos_para...   \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48  pipeline_extracao_documentos/2_documentos_para...   \n",
       "\n",
       "                                     informations  \n",
       "document_unique_id                                 \n",
       "4433a03b-d30a-4c92-80fc-015912e1f357               \n",
       "27df9e70-b5fb-45b7-8f59-0c04ed9728e2               \n",
       "393a4eab-4b10-48e4-8d06-2fecadfa3b48               \n",
       "ab2457b7-ea5c-4191-acf0-bc8edc04879e               \n",
       "b6b5af8f-78dc-4627-9322-9c3b70f46a48               \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_root_pipe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"PREFEITURA MUNICIPAL DE MAGE | SECRETARIA MUNICIPAL DA FAZENDA | NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e | Número da Nota: 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B | PRESTADOR DE SERVIÇOS CPF/CNPJ: 51.246.375/0001-77 Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ TOMADOR CPF/CNPJ: 12.324.674/0001-20 Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 DISCRIMINAÇÃO DOS SERVIÇOS Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL VALOR TOTAL DA NOTA: R$ 252.836,00 CNAE - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. VALOR SERVIÇOS: R$ 252.836,00 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 252.836,00 ALÍQUOTA: 2,01% VALOR ISS: R$ 5.082,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR INSS: R$ 0,00 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 252.836,00 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ Observação: - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) https://nfs-e.mage.rj.gov.br\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stt:  48 | end: 52 | string_id:            INSCRICAO_MUNICIPAL   span.text:                 Inscrição Municipal: 1007689 \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texto)\n",
    "\n",
    "# Executar o Matcher no Doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PREFEITURA MUNICIPAL DE MAGE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_prefeitura</span>\n",
       "</mark>\n",
       " | \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #2ADB5E, #1FA346); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SECRETARIA MUNICIPAL DA FAZENDA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">secretaria</span>\n",
       "</mark>\n",
       " | \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #09D6FF, #08A0D1); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">tipo_documento</span>\n",
       "</mark>\n",
       " | \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Número da Nota:\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B | \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PRESTADOR DE SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    51.246.375/0001-77\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TOMADOR\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    12.324.674/0001-20\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DISCRIMINAÇÃO DOS SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR TOTAL DA NOTA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 252.836,00 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CNAE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 252.836,00 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 252.836,00 ALÍQUOTA: 2,01% VALOR ISS: R$ 5.082,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR INSS: R$ 0,00 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 252.836,00 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DADOS COMPLEMENTARES\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OUTRAS INFORMAÇÕES / CRITICAS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Observação:\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " - \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Prestador\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) \n",
       "<mark class=\"entity\" style=\"background: #EE8AF8; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    https://nfs-e.mage.rj.gov.br\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">encerrador</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc, tokens, ents = show_ent_new(texto, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |                       PREFEITURA MUNICIPAL DE MAGE |           nome_prefeitura |                             PM_MAGE  |      4   ||        0 |     28\n",
      "    5 |                    SECRETARIA MUNICIPAL DA FAZENDA |                secretaria |                          SECRETARIA  |      9   ||       31 |     62\n",
      "   10 |         NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e |            tipo_documento |                               NFS-e  |     17   ||       65 |    107\n",
      "   18 |                                    Número da Nota: |              nome_section |                        1. CABECALHO  |     22   ||      110 |    125\n",
      "   39 |                              PRESTADOR DE SERVIÇOS |              nome_section |             2. PRESTADOR DE SERVIÇO  |     42   ||      228 |    249\n",
      "   46 |                                 51.246.375/0001-77 |                      CNPJ |                                      |     48   ||      260 |    278\n",
      "   96 |                                            TOMADOR |              nome_section |               3. TOMADOR DE SERVIÇO  |     97   ||      560 |    567\n",
      "  101 |                                 12.324.674/0001-20 |                      CNPJ |                                      |    103   ||      578 |    596\n",
      "  157 |                         DISCRIMINAÇÃO DOS SERVIÇOS |              nome_section |       4. DESCRIMINACAO DOS SERVIÇOS  |    160   ||      855 |    881\n",
      "  270 |                                VALOR TOTAL DA NOTA |              nome_section |                      5. VALOR TOTAL  |    274   ||     1510 |   1529\n",
      "  277 |                                               CNAE |              nome_section | 6. CNAE e Item da Lista de Serviços  |    278   ||     1545 |   1549\n",
      "  318 |                                     VALOR SERVIÇOS |              nome_section |               7. VALORES E IMPOSTOS  |    320   ||     1806 |   1820\n",
      "  397 |                               DADOS COMPLEMENTARES |              nome_section |             8. DADOS COMPLEMENTARES  |    399   ||     2153 |   2173\n",
      "  399 |                      OUTRAS INFORMAÇÕES / CRITICAS |              nome_section |    9. OUTRAS INFORMAÇOES / CRITICAS  |    403   ||     2174 |   2203\n",
      "  432 |                                        Observação: |              nome_section |                     10. OBSERVACOES  |    434   ||     2377 |   2388\n",
      "  435 |                                          Prestador |              nome_section |             2. PRESTADOR DE SERVIÇO  |    436   ||     2391 |   2400\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'{ent.start:>5} | {ent.text:>50} | {ent.label_:>25} | {ent.id_:>35}  |   {ent.end:>4}   ||   {ent.start_char:>6} | {ent.end_char:>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, start, end in tokens:\n",
    "    print(f'token: {token:>20} | start: {start:>3} | end: {end:>3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CPF/CNPJ: 51.246.375/0001-77 Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ '"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. PRESTADOR DE SERVIÇO\n",
    "prestador_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '2. PRESTADOR DE SERVIÇO'][0]\n",
    "tomador_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '3. TOMADOR DE SERVIÇO'][0]\n",
    "bloco_prestador = texto[prestador_end_char:tomador_start_char]\n",
    "bloco_prestador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' CPF/CNPJ: 12.324.674/0001-20 Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 '"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. TOMADOR DE SERVIÇO\n",
    "tomador_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '3. TOMADOR DE SERVIÇO'][0]\n",
    "servicos_star_char = [ent.start_char for ent in doc.ents if ent.id_ == '4. DESCRIMINACAO DOS SERVIÇOS'][0]\n",
    "bloco_tomador = texto[tomador_end_char:servicos_star_char]\n",
    "bloco_tomador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL '"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "servicos_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '4. DESCRIMINACAO DOS SERVIÇOS'][0]\n",
    "valor_total_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '5. VALOR TOTAL'][0]\n",
    "bloco_discriminacao_servico = texto[servicos_end_char:valor_total_start_char]\n",
    "bloco_discriminacao_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CNAE - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. '"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. CNAE e Item da Lista de Serviços\n",
    "valor_cnae_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '6. CNAE e Item da Lista de Serviços'][0]\n",
    "valores_impostos_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '7. VALORES E IMPOSTOS'][0]\n",
    "bloco_cnae_itens = texto[valor_cnae_start_char:valores_impostos_start_char]\n",
    "bloco_cnae_itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. DADOS COMPLEMENTARES\n",
    "dados_complementares_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '8. DADOS COMPLEMENTARES'][0]\n",
    "outras_informacoes_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '9. OUTRAS INFORMAÇOES / CRITICAS'][0]\n",
    "bloco_dados_comentares = texto[dados_complementares_end_char:outras_informacoes_start_char]\n",
    "bloco_dados_comentares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ '"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "outras_informacoes_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '9. OUTRAS INFORMAÇOES / CRITICAS'][0]\n",
    "observacoes_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '10. OBSERVACOES'][0]\n",
    "bloco_outras_informacoes = texto[outras_informacoes_end_char:observacoes_start_char]\n",
    "bloco_outras_informacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) '"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. OBSERVACOES\n",
    "observacoes_end_char = [ent.end_char for ent in doc.ents if ent.id_ == '10. OBSERVACOES'][0]\n",
    "encerrador_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'encerrador'][0]\n",
    "bloco_observacoes = texto[observacoes_end_char:encerrador_start_char]\n",
    "bloco_observacoes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFEITURA MUNICIPAL DE MAGE | SECRETARIA MUNICIPAL DA FAZENDA | NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e | Número da Nota: 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B | PRESTADOR DE SERVIÇOS CPF/CNPJ: 51.246.375/0001-77 Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ TOMADOR CPF/CNPJ: 12.324.674/0001-20 Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 DISCRIMINAÇÃO DOS SERVIÇOS Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL VALOR TOTAL DA NOTA: R$ 252.836,00 CNAE - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. VALOR SERVIÇOS: R$ 252.836,00 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 252.836,00 ALÍQUOTA: 2,01% VALOR ISS: R$ 5.082,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR INSS: R$ 0,00 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 252.836,00 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ Observação: - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) https://nfs-e.mage.rj.gov.br'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_text = \"T 3,25 IBPT) https://nfs-e.mage.rj.gov.br\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(span_text, patterns=patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inscrição municipal'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valor = 'Inscrição Municipal'\n",
    "valor.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "inscricao_municipal = [\n",
    "    {\"LOWER\": \"inscrição\"},\n",
    "    {\"LOWER\": \"municipal\"},\n",
    "    {\"TEXT\": \":\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "  \n",
    "]\n",
    "matcher.add(\"INSCRICAO_MUNICIPAL\", [inscricao_municipal])\n",
    "\n",
    "inscricao_municipal = [\n",
    "    {\"LOWER\": \"inscrição\"},\n",
    "    {\"LOWER\": \"municipal\"},\n",
    "    {\"TEXT\": \":\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "  \n",
    "]\n",
    "matcher.add(\"INSCRICAO_MUNICIPAL\", [inscricao_municipal])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>T_texto</th>\n",
       "      <th>T_shape</th>\n",
       "      <th>T_is_alpha</th>\n",
       "      <th>T_is_digit</th>\n",
       "      <th>T_is_title</th>\n",
       "      <th>T_is_punct</th>\n",
       "      <th>T_is_sent_start</th>\n",
       "      <th>T_is_right_punct</th>\n",
       "      <th>T_is_stop</th>\n",
       "      <th>T_is_quote</th>\n",
       "      <th>T_is_currency</th>\n",
       "      <th>T_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>X</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3,25</td>\n",
       "      <td>d,dd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(NumType=Card)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>IBPT</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Masc, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://nfs-e.mage.rj.gov.br</td>\n",
       "      <td>xxxx://xxx-x.xxxx.xx.xxx.xx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Sing)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                       T_texto                      T_shape T_is_alpha  \\\n",
       "0  0                             T                            X       True   \n",
       "1  1                          3,25                         d,dd      False   \n",
       "2  2                          IBPT                         XXXX       True   \n",
       "3  3                             )                            )      False   \n",
       "4  4  https://nfs-e.mage.rj.gov.br  xxxx://xxx-x.xxxx.xx.xxx.xx      False   \n",
       "\n",
       "  T_is_digit T_is_title T_is_punct T_is_sent_start T_is_right_punct T_is_stop  \\\n",
       "0      False       True      False            True            False     False   \n",
       "1      False      False      False           False            False     False   \n",
       "2      False      False      False           False            False     False   \n",
       "3      False      False       True           False             True     False   \n",
       "4      False      False      False            True            False     False   \n",
       "\n",
       "  T_is_quote T_is_currency                                            T_morph  \n",
       "0      False         False  (Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...  \n",
       "1      False         False                                     (NumType=Card)  \n",
       "2      False         False                         (Gender=Masc, Number=Sing)  \n",
       "3      False         False                                                 ()  \n",
       "4      False         False                          (Gender=Fem, Number=Sing)  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisys\n",
    "syntatic = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_shape\", \"T_is_alpha\", \"T_is_digit\", \"T_is_title\", \"T_is_punct\", \"T_is_sent_start\", \"T_is_right_punct\", \"T_is_stop\", \"T_is_quote\", \"T_is_currency\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    syntatic.loc[i,\"id\"] = token.i\n",
    "    syntatic.loc[i,\"T_texto\"] = token.text\n",
    "    syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "    syntatic.loc[i,\"T_is_alpha\"] = token.is_alpha\n",
    "    syntatic.loc[i,\"T_is_digit\"] = token.is_digit\n",
    "    syntatic.loc[i,\"T_is_title\"] = token.is_title\n",
    "    syntatic.loc[i,\"T_is_punct\"] = token.is_punct\n",
    "    syntatic.loc[i,\"T_is_sent_start\"] = token.is_sent_start\n",
    "    syntatic.loc[i,\"T_is_right_punct\"] = token.is_right_punct\n",
    "    syntatic.loc[i,\"T_is_stop\"] = token.is_stop\n",
    "    syntatic.loc[i,\"T_is_quote\"] = token.is_quote\n",
    "    syntatic.loc[i,\"T_is_currency\"] = token.is_currency\n",
    "    syntatic.loc[i,\"T_morph\"] = token.morph\n",
    "    i = i+1\n",
    "\n",
    "syntatic.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto extraído:  Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL VALOR TOTA\n"
     ]
    }
   ],
   "source": [
    "# Posições de início e fim\n",
    "start_pos = 881\n",
    "end_pos = 1520\n",
    "\n",
    "# Extraindo a sub-string usando slicing\n",
    "extracted_text = texto[start_pos:end_pos]\n",
    "\n",
    "print(f\"Texto extraído: {extracted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAGÉ . - RJ CEP: 25935196 DISCRIMINAÇÃO DOS SERVIÇOS Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloco_discriminacao_servico = original_text[servicos_end_char:valor_total_start_char]\n",
    "bloco_discriminacao_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "servicos_end = [ent.end for ent in doc.ents if ent.id_ == '4. DESCRIMINACAO DOS SERVIÇOS'][0]\n",
    "servicos_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valor_total_start = [ent.start for ent in doc.ents if ent.id_ == '5. VALOR TOTAL'][0]\n",
    "valor_total_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B | PRESTADOR DE SERVIÇOS CPF/CNPJ: 51.246.375'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloco_discriminacao_servico = texto[servicos_end:valor_total_start]\n",
    "bloco_discriminacao_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajusta_texto_Raster_P(document_unique_id, original_text, texto_cabechalho_PDF_Raster):\n",
    "\n",
    "    # Passa pelo mapeamento de doc ents para ajustar o texto\n",
    "    doc, tokens, ents = show_ent_new(original_text, patterns=patterns)\n",
    "\n",
    "    nome_prefeitura_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "    nome_prefeitura_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "    secretaria_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'secretaria'][0]\n",
    "    secretaria_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'secretaria'][0]\n",
    "    tipo_documento_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "    tipo_documento_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "    prestador_start_char = [ent.start_char for ent in doc.ents if ent.id_ == '2. PRESTADOR DE SERVIÇO'][0]\n",
    "\n",
    "    bloco_prefeitura = original_text[nome_prefeitura_start_char:nome_prefeitura_end_char]\n",
    "    bloco_secretaria = original_text[secretaria_start_char:secretaria_end_char]\n",
    "    bloco_tipo_documento = original_text[tipo_documento_start_char:tipo_documento_end_char]\n",
    "    bloco_inicio_prestador = original_text[prestador_start_char:]\n",
    "\n",
    "    recomposed_text = bloco_prefeitura + ' | ' + bloco_secretaria + ' | ' + bloco_tipo_documento  + ' | ' + texto_cabechalho_PDF_Raster + ' | ' + bloco_inicio_prestador\n",
    "    \n",
    "    return recomposed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_root_pipe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte do mapeamento do cabeÇalho para Raster_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_unique_id = '27df9e70-b5fb-45b7-8f59-0c04ed9728e2'\n",
    "texto_R_PDF = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "texto_R_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_R_PDF, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = doc_content.get(document_unique_id, {}).get('file_path', 'valor_padrao')\n",
    "map_original_file_name =  doc_content.get(document_unique_id, {}).get('original_file_name', 'valor_padrao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info = {}\n",
    "\n",
    "imagem_gray, image_resized_name = convert_resize_gray(map_original_file_name, file_path, image_resized_path)\n",
    "imagem_gray_rgb = imagem_gray.convert(\"RGB\")\n",
    "imagem_gray_np = np.array(imagem_gray_rgb)\n",
    "row_info['image_np'] = imagem_gray_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"1. CABECALHO\"\n",
    "mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "context_mapping = \"data_cabecalho\"\n",
    "def_replace = True \n",
    "model_map = 'MAGE'\n",
    "pdf_pesquisavel_map = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stt:   0 | end:  5 | string_id:             numero_nota_fiscal   span.text:                            Número da Nota: 1 \n",
      "\n",
      "stt:   5 | end:  8 | string_id:                    competencia   span.text:                      Competência: Julho/2023 \n",
      "\n",
      "stt:   8 | end: 16 | string_id:                  dt_hr_emissao   span.text:  Data e Hora da Emissão: 31/07/2023 17:29:00 \n",
      "\n",
      "stt:  16 | end: 20 | string_id:             codigo_verificacao   span.text:                Código Verificação: 4ADEE6A7B \n"
     ]
    }
   ],
   "source": [
    "\n",
    "    # if string_id == 'numero_nota_fiscal':\n",
    "    #     print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')\n",
    "    # elif string_id == 'competencia':    \n",
    "    #     print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')\n",
    "    # elif string_id == 'dt_hr_emissao':\n",
    "    #     print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')\n",
    "    # elif string_id == 'codigo_verificacao':\n",
    "    #     print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'numero_nota'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Número da Nota: 1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "raw_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numero_nota_fiscal': '1',\n",
       " 'competencia': 'Julho/2023',\n",
       " 'dt_hr_emissao': '31/07/2023 17:29:00',\n",
       " 'codigo_verificacao': '4ADEE6A7B'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_box_valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomposicao do documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numero_nota_fiscal': '1',\n",
       " 'competencia': 'Julho/2023',\n",
       " 'dt_hr_emissao': '31/07/2023 17:29:00',\n",
       " 'codigo_verificacao': '4ADEE6A7B'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_box_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Número da Nota: 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_cabechalho_PDF_Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_c = nlp(texto_cabechalho_PDF_Raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'31/07/2023, 17:33 Nota Fiscal de Serviços Eletrônica (NFSe) Número da Nota: PREFEITURA MUNICIPAL DE MAGE Competência: SECRETARIA MUNICIPAL DA FAZENDA 1 Julho/2023 NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B PRESTADOR DE SERVIÇOS CPF/CNPJ: 51.246.375/0001-77 Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ TOMADOR CPF/CNPJ: 12.324.674/0001-20 Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 DISCRIMINAÇÃO DOS SERVIÇOS Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL VALOR TOTAL DA NOTA: R$ 252.836,00 CNAE - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. VALOR SERVIÇOS: R$ 252.836,00 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 252.836,00 ALÍQUOTA: 2,01% VALOR ISS: R$ 5.082,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR INSS: R$ 0,00 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 252.836,00 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ Observação: - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) https://nfs-e.mage.rj.gov.br'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_unique_id = '27df9e70-b5fb-45b7-8f59-0c04ed9728e2'\n",
    "texto_R_PDF = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "texto_R_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"27/07/2023, 15:14 Nota Fiscal de Serviços Eletrônica (NFSe) https://nfe.mesquita.rj.gov.br 1/1 PREFEITURA MUNICIPAL DE MESQUITA SECRETARIA MUNICIPAL DA FAZENDA NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Número da Nota: 20235 Competência: Julho/2023 Data e Hora da Emissão: 27/07/2023 15:13:00 Código Verificação: 92ED36652 PRESTADOR DE SERVIÇOS CPF/CNPJ: 50.921.369/0001-05 Inscrição Municipal: 952538 Telefone: 2297268232.. Inscrição Estadual: Nome/Razão Social: MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA Nome de Fantasia: Endereço: RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesquita-RJ E-mail: LARA_VSORIA@HOTMAIL.COM TOMADOR DE SERVIÇOS CPF/CNPJ: 06.047.087/0033-16 | INSC:MUNICIPAL: RG: Telefone: Inscrição Estadual: Nome/Razão Social: REDE D'OR SAO LUIZ S.A. Endereço: OLINDA ELLIS N° 93 BAIRRO: CAMPO GRANDE CIDADE: RIO DE JANEIRO - RJ CEP: 23045160 E-mail: Não Informado DISCRIMINAÇÃO DOS SERVIÇOS Ref a Plantões de Fevereiro, 2h no Setor de Radiologia - Médica: Lara Veiga Soria Catuladeira. VALOR TOTAL DA NOTA: R$ 1.469,32 CNAE - 8630502 - ATIVIDADE MÉDICA AMBULATORIAL COM RECURSOS PARA REALIZAÇÃO DE EXAMES COMPLEMENTARES Item da Lista de Serviços - 4.03 - HOSPITAIS, CLÍNICAS, LABORATÓRIOS, SANATÓRIOS, MANICÔMIOS, CASAS DE SAÚDE, PRONTOS-SOCORROS, AMBULATÓRIOS E CONGÊNERES. VALOR SERVIÇOS: R$ 1.469,32 VALOR DEDUÇÃO: R$ 0,00 DESC. INCOND: R$ 0,00 BASE DE CÁLCULO: R$ 1.469,32 ALÍQUOTA: 2,01% VALOR ISS: R$ 29,53 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 ____________________________________________________________________ VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR INSS: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR LÍQUIDO: R$ 1.469,32 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim ( 2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Mesquita - RJ LOCAL INCIDÊNCIA Mesquita - RJ Observação: LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 DE DEZEMBRO DE 2012. - PRESTADOR OPTANTE DO SIMPLES NACIONAL (ALÍQUOTA: 2,01 %) ESTA NFS-E FOI EMITIDA EM SUBSTITUIÇÃO À NFS-E 20232 Valor Aproximado dos Tributos Federais R$ 197,62 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 32,77 (Alíq IBPT 2,23 IBPT)\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_unique_id = 'ab2457b7-ea5c-4191-acf0-bc8edc04879e'\n",
    "texto_PDF_P = doc_content.get(document_unique_id, {}).get('content', 'valor_padrao')\n",
    "texto_PDF_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_PDF_P, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero_nota_fiscal: 31/07/2023, 17:33 Nota Fiscal\n",
      "competencia: de Serviços Eletrônica\n",
      "dt_hr_emissao: (NFSe) Número da Nota: PREFEITURA\n",
      "codigo_verificacao: MUNICIPAL DE MAGE Competência\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc_c)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |                       PREFEITURA MUNICIPAL DE MAGE |           nome_prefeitura |                             PM_MAGE  |      4   ||        0 |     28\n",
      "    6 |                    SECRETARIA MUNICIPAL DA FAZENDA |                secretaria |                          SECRETARIA  |     10   ||       42 |     73\n",
      "   12 |         NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e |            tipo_documento |                               NFS-e  |     19   ||       87 |    129\n",
      "   31 |                              PRESTADOR DE SERVIÇOS |              nome_section |             2. PRESTADOR DE SERVIÇO  |     34   ||      204 |    225\n",
      "   38 |                                 51.246.375/0001-77 |                      CNPJ |                                      |     40   ||      236 |    254\n",
      "   88 |                                            TOMADOR |              nome_section |               3. TOMADOR DE SERVIÇO  |     89   ||      536 |    543\n",
      "   93 |                                 12.324.674/0001-20 |                      CNPJ |                                      |     95   ||      554 |    572\n",
      "  149 |                         DISCRIMINAÇÃO DOS SERVIÇOS |              nome_section |       4. DESCRIMINACAO DOS SERVIÇOS  |    152   ||      831 |    857\n",
      "  262 |                                VALOR TOTAL DA NOTA |              nome_section |                      5. VALOR TOTAL  |    266   ||     1486 |   1505\n",
      "  269 |                                               CNAE |              nome_section | 6. CNAE e Item da Lista de Serviços  |    270   ||     1521 |   1525\n",
      "  310 |                                     VALOR SERVIÇOS |              nome_section |               7. VALORES E IMPOSTOS  |    312   ||     1782 |   1796\n",
      "  389 |                               DADOS COMPLEMENTARES |              nome_section |             8. DADOS COMPLEMENTARES  |    391   ||     2129 |   2149\n",
      "  391 |                      OUTRAS INFORMAÇÕES / CRITICAS |              nome_section |    9. OUTRAS INFORMAÇOES / CRITICAS  |    395   ||     2150 |   2179\n",
      "  424 |                                         Observação |              nome_section |                     10. OBSERVACOES  |    425   ||     2353 |   2363\n",
      "  427 |                                          Prestador |              nome_section |             2. PRESTADOR DE SERVIÇO  |    428   ||     2367 |   2376\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'{ent.start:>5} | {ent.text:>50} | {ent.label_:>25} | {ent.id_:>35}  |   {ent.end:>4}   ||   {ent.start_char:>6} | {ent.end_char:>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'31/07/2023, 17:33 Nota Fiscal de Serviços Eletrônica (NFSe) Número da Nota: PREFEITURA MUNICIPAL DE MAGE Competência: SECRETARIA MUNICIPAL DA FAZENDA 1 Julho/2023 NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B PRESTADOR DE SERVIÇOS CPF/CNPJ: 51.246.375/0001-77 Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ TOMADOR CPF/CNPJ: 12.324.674/0001-20 Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 DISCRIMINAÇÃO DOS SERVIÇOS Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL VALOR TOTAL DA NOTA: R$ 252.836,00 CNAE - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. VALOR SERVIÇOS: R$ 252.836,00 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 252.836,00 ALÍQUOTA: 2,01% VALOR ISS: R$ 5.082,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR INSS: R$ 0,00 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 252.836,00 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ Observação: - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) https://nfs-e.mage.rj.gov.br'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seu texto OCR completo\n",
    "original_text = texto_R_PDF\n",
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(original_text, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFEITURA MUNICIPAL DE MAGE | SECRETARIA MUNICIPAL DA FAZENDA | NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e | Número da Nota: 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B | PRESTADOR DE SERVIÇOS CPF/CNPJ: 51.246.375/0001-77 Inscrição Municipal: 1007689 Telefone: Inscrição Estadual: 2176361620.. Nome/Razão Social: BOM GOSTO TRANSPORTES E SERVICOS Nome de Fantasia: BOM GOSTO TRANSPORTES Endereço: VINTE E CINCO ,115,PARQUE SAYONARA E-mail: FISCALQATECS.COM.BR PA 12913222 LTDA (VILA INHOMIRIM) - Magé-RJ TOMADOR CPF/CNPJ: 12.324.674/0001-20 Telefone: | - INSC:MUNICIPAL: DE SERVIÇOS RG: Inscrição Estadual: Nome/Razão Social: BOM GOSTO 2010 COMERCIO DE ALIMENTOS LTDA Endereço: VINTE E UM Nº 125 BAIRRO: PARQUE SAYONARA (VILA INHOMIRIM) E-mail: fiscalDatecs.com.br CIDADE: MAGÉ . - RJ CEP: 25935196 DISCRIMINAÇÃO DOS SERVIÇOS Serviços prestados conforme contrato. Informações em atendimento a Lei nº 12.741/2012. Valor aproximado dos tributos incidentes nesta operação: Tributos da União.............. 3,99% Tributos do Estado............. 0,00% Tributos do Município.......... 2,01% - Dispensa de retenção das Contribuições Sociais(PIS/COFINS/CSLL), conforme IN SRF nº 459/2004, art. 3º, Il. - Dispensa de retenção da contribuição previdenciária (INSS),conforme IN RFB nº 971/2009, art.119, por falta de previsão legal. - Dispensa de retenção do IRRF, conforme IN RFB nº 765/2007, art. 1º. - DOCUMENTO EMITIDO POR ME OU EPP OPTANTEPELO SIMPLES NACIONAL VALOR TOTAL DA NOTA: R$ 252.836,00 CNAE - 4930202 - TRANSPORTE RODOVIÁRIO DE CARGA, EXCETO PRODUTOS PERIGOSOS E MUDANÇAS, INTERMUNICIPAL, INTERESTADUAL Item da Lista de Serviços - 16.01 - SERVIÇOS DE TRANSPORTE COLETIVO MUNICIPAL RODOVIÁRIO, METROVIÁRIO, FERROVIÁRIO E AQUAVIÁRIO DE PASSAGEIROS. VALOR SERVIÇOS: R$ 252.836,00 VALOR | DEDUÇÃO: R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CALCULO: R$ 252.836,00 ALÍQUOTA: 2,01% VALOR ISS: R$ 5.082,00 VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR INSS: R$ 0,00 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 VALOR LÍQUIDO: R$ 252.836,00 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ Observação: - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 34006,44 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíg 0,00 IBPT) e Municipal de R$ 8217,17 (Alíq IBPT 3,25 IBPT) https://nfs-e.mage.rj.gov.br'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(recomposed_text, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |                       PREFEITURA MUNICIPAL DE MAGE |           nome_prefeitura |                             PM_MAGE  |      4   ||        0 |     28\n",
      "    5 |                    SECRETARIA MUNICIPAL DA FAZENDA |                secretaria |                          SECRETARIA  |      9   ||       31 |     62\n",
      "   10 |         NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e |            tipo_documento |                               NFS-e  |     17   ||       65 |    107\n",
      "   18 |                                    Número da Nota: |              nome_section |                        1. CABECALHO  |     22   ||      110 |    125\n",
      "   39 |                              PRESTADOR DE SERVIÇOS |              nome_section |             2. PRESTADOR DE SERVIÇO  |     42   ||      228 |    249\n",
      "   46 |                                 51.246.375/0001-77 |                      CNPJ |                                      |     48   ||      260 |    278\n",
      "   96 |                                            TOMADOR |              nome_section |               3. TOMADOR DE SERVIÇO  |     97   ||      560 |    567\n",
      "  101 |                                 12.324.674/0001-20 |                      CNPJ |                                      |    103   ||      578 |    596\n",
      "  157 |                         DISCRIMINAÇÃO DOS SERVIÇOS |              nome_section |       4. DESCRIMINACAO DOS SERVIÇOS  |    160   ||      855 |    881\n",
      "  270 |                                VALOR TOTAL DA NOTA |              nome_section |                      5. VALOR TOTAL  |    274   ||     1510 |   1529\n",
      "  277 |                                               CNAE |              nome_section | 6. CNAE e Item da Lista de Serviços  |    278   ||     1545 |   1549\n",
      "  318 |                                     VALOR SERVIÇOS |              nome_section |               7. VALORES E IMPOSTOS  |    320   ||     1806 |   1820\n",
      "  397 |                               DADOS COMPLEMENTARES |              nome_section |             8. DADOS COMPLEMENTARES  |    399   ||     2153 |   2173\n",
      "  399 |                      OUTRAS INFORMAÇÕES / CRITICAS |              nome_section |    9. OUTRAS INFORMAÇOES / CRITICAS  |    403   ||     2174 |   2203\n",
      "  432 |                                         Observação |              nome_section |                     10. OBSERVACOES  |    433   ||     2377 |   2387\n",
      "  435 |                                          Prestador |              nome_section |             2. PRESTADOR DE SERVIÇO  |    436   ||     2391 |   2400\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'{ent.start:>5} | {ent.text:>50} | {ent.label_:>25} | {ent.id_:>35}  |   {ent.end:>4}   ||   {ent.start_char:>6} | {ent.end_char:>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texto_amostra = \"NFS-e Número da Nota: 20234 Competência: Julho/2023\"\n",
    "texto_amostra = \"'outras informações / criticas'\"\n",
    "\n",
    "doc = nlp(texto_amostra)\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisys\n",
    "syntatic = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_shape\", \"T_is_alpha\", \"T_is_digit\", \"T_is_title\", \"T_is_punct\", \"T_is_sent_start\", \"T_is_right_punct\", \"T_is_stop\", \"T_is_quote\", \"T_is_currency\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    syntatic.loc[i,\"id\"] = token.i\n",
    "    syntatic.loc[i,\"T_texto\"] = token.text\n",
    "    syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "    syntatic.loc[i,\"T_is_alpha\"] = token.is_alpha\n",
    "    syntatic.loc[i,\"T_is_digit\"] = token.is_digit\n",
    "    syntatic.loc[i,\"T_is_title\"] = token.is_title\n",
    "    syntatic.loc[i,\"T_is_punct\"] = token.is_punct\n",
    "    syntatic.loc[i,\"T_is_sent_start\"] = token.is_sent_start\n",
    "    syntatic.loc[i,\"T_is_right_punct\"] = token.is_right_punct\n",
    "    syntatic.loc[i,\"T_is_stop\"] = token.is_stop\n",
    "    syntatic.loc[i,\"T_is_quote\"] = token.is_quote\n",
    "    syntatic.loc[i,\"T_is_currency\"] = token.is_currency\n",
    "    syntatic.loc[i,\"T_morph\"] = token.morph\n",
    "    i = i+1\n",
    "\n",
    "syntatic.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization for tokens \n",
    "lemmatization = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"Texto\",\"Lemma\", \"Tag\", \"Tag_explainned\", \"token_POS\", \"POS_explainned\", \"dep\", \"T. Head\", \"dep explained\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    lemmatization.loc[i,\"id\"] = token.i\n",
    "    lemmatization.loc[i,\"Texto\"] = token.text\n",
    "    lemmatization.loc[i,\"Lemma\"] = token.lemma_\n",
    "    lemmatization.loc[i,\"Tag\"] = token.tag_\n",
    "    lemmatization.loc[i,\"Tag_explainned\"] = spacy.explain(token.tag_)\n",
    "    lemmatization.loc[i,\"token_POS\"] = token.pos_\n",
    "    lemmatization.loc[i,\"POS_explainned\"] = spacy.explain(token.pos_)\n",
    "    lemmatization.loc[i,\"dep\"] = token.dep_\n",
    "    lemmatization.loc[i,\"T. Head\"] = token.head.text\n",
    "    lemmatization.loc[i,\"dep explained\"] = token.morph\n",
    "    \n",
    "    i = i+1\n",
    "lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "\n",
    "clean_text = text.replace(': ', ':').replace(', ', ',')\n",
    "\n",
    "clean_text = re.sub('\\s+', ' ', text.replace(': ', ':').replace(', ', ',')).strip()\n",
    "\n",
    "text_splited = texto.split('\\n')\n",
    "text_splited = [x for x in text_splited if x.strip()]\n",
    "text_splited = [s.replace(\";\", \"\").strip() for s in text_splited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ocrmypdf(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o subset para analise\n",
    "df_conf = df[['seq', 'batch', 'original_file_name', 'directory','status_documento', 'model', 'secao', 'prefeitura', 'de_para_pm', 'model', 'action_item', 'pdf_pesquisavel', 'processo', 'numero_nota_fiscal', 'competencia', 'dt_hr_emissao', 'codigo_verificacao','conf_cod' ]]\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando DF para analises\n",
    "df.set_index('document_unique_id', inplace=True)\n",
    "\n",
    "ordem_status = ['PREPROCESS_EXTRACT', 'NO_PROCESS', 'root_analise']\n",
    "ordem_action_item = ['CONTINUE_PROCESS', 'BREAK_PROCESS', 'NO_PROCESS']\n",
    "\n",
    "\n",
    "df['status_documento'] = pd.Categorical(df['status_documento'], categories=ordem_status, ordered=True)\n",
    "df['action_item'] = pd.Categorical(df['action_item'], categories=ordem_action_item, ordered=True)\n",
    "\n",
    "df.sort_values(by=['status_documento', 'action_item', 'seq'], ascending=[True, True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX 1.Processar todas as secoes do documento\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=True, tomador=True, servicos=True, total=True, cnae=True, valores_impostos=True, complementares=True, outras_informacoes=True, observacoes=True)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Processar valor Total\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=True, cnae=False, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 6. Processar CNAE\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=True, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 7. Processar Impostos\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 8. complementar e observaçoes\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=False, complementares=True, outras_informacoes=True, observacoes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Matcher Patterns\n",
    "#======================================== 1. CABECALHO\n",
    "# 1. Número da Nota:\n",
    "numero_nota_pattern = [\n",
    "    {\"LOWER\": \"número\"},\n",
    "    {\"LOWER\": \"da\"},\n",
    "    {\"LOWER\": \"nota\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True}\n",
    "]\n",
    "matcher.add(\"numero_nota_fiscal\", [numero_nota_pattern])\n",
    "\n",
    "\n",
    "# 2. Competência:\n",
    "competencia_pattern = [\n",
    "    {\"LOWER\": \"competência\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"?\"},\n",
    "    {\"ORTH\": {\"REGEX\": \"^[A-Z][a-z]+/[0-9]{4}$\"}}   \n",
    "]    \n",
    "matcher.add(\"competencia\", [competencia_pattern])\n",
    "\n",
    "# 3. Data e Hora de Emissão:\n",
    "data_hora_emissao_pattern = [\n",
    "    {\"LOWER\": \"data\"},\n",
    "    {\"LOWER\": \"e\"},\n",
    "    {\"LOWER\": \"hora\"},\n",
    "    {\"LOWER\": \"da\"},\n",
    "    {\"LOWER\": \"emissão\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"SHAPE\": \"dd/dd/dddd\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"SHAPE\": \"dd:dd:dd\"}\n",
    "]\n",
    "matcher.add(\"dt_hr_emissao\", [data_hora_emissao_pattern])\n",
    "\n",
    "# 4. Código de Verificação:\n",
    "codigo_verificacao_pattern = [\n",
    "    {\"LOWER\": \"código\"},\n",
    "    {\"LOWER\": \"verificação\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_ASCII\": True, \"LENGTH\": 9}\n",
    "]\n",
    "matcher.add(\"codigo_verificacao\", [codigo_verificacao_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#========================================  5. VALOR TOTAL\n",
    "valor_total_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"total\"},\n",
    "    {\"LOWER\": \"da\", \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"nota\", \"OP\": \"?\"},\n",
    "    {\"TEXT\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_TOTAL\", [valor_total_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#======================================== 7. VALORES E IMPOSTOS\n",
    "# 1. VALOR_SERVICOS\n",
    "valor_servicos_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"serviços\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"VALOR_SERVICOS\", [valor_servicos_pattern])\n",
    "\n",
    "\n",
    "# 2. VALOR DEDUÇÃO:\n",
    "valor_deducao_pattern = [\n",
    "    {\"LOWER\": \"dedução\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"VALOR_DEDUCAO\", [valor_deducao_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 3. DESC. INCOND: RASTER_PDF\n",
    "valor_incondR_pattern = [\n",
    "    {\"LOWER\": \"base\"},\n",
    "    {\"LOWER\": \"de\"},\n",
    "    {\"IS_SPACE\": True},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "]\n",
    "matcher.add(\"VALOR_INCONDP\", [valor_incondR_pattern])\n",
    "\n",
    "\n",
    "# 3.A DESC. INCOND: - PDF_Pesquisavel   #DESC. INCOND:\n",
    "valor_incond_patternP = [\n",
    "    {\"LOWER\": \"desc\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"incond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "]\n",
    "matcher.add(\"VALOR_INCONDR\", [valor_incond_patternP])\n",
    "\n",
    "\n",
    "\n",
    "# 4. BASE DE CÁLCULO:  RASTER_PDF\n",
    "valor_calculoR_pattern = [\n",
    "    {\"LOWER\": \"cálculo\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_CALCULOR\", [valor_calculoR_pattern])\n",
    "\n",
    "\n",
    "# 4.A BASE DE CÁLCULO:  PDF_P\n",
    "valor_calculoP_pattern = [\n",
    "    {\"LOWER\": \"base\"},\n",
    "    {\"LOWER\": \"de\"},\n",
    "    {\"LOWER\": \"cálculo\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_CALCULOP\", [valor_calculoP_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 5. Alíquota d,dd\n",
    "valor_aliquota_pattern = [\n",
    "    {\"LOWER\": \"alíquota\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"d,dd\", \"OP\": \"?\"},\n",
    "    {\"ORTH\": \"%\"}\n",
    "\n",
    "]\n",
    "matcher.add(\"VALOR_ALIQUOTA\", [valor_aliquota_pattern])\n",
    "\n",
    "# 5.1 Alíquota d\n",
    "valor_aliquota2_pattern = [\n",
    "    {\"LOWER\": \"alíquota\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"d\", \"OP\": \"?\"},\n",
    "    {\"ORTH\": \"%\"}\n",
    "\n",
    "]\n",
    "matcher.add(\"VALOR_ALIQUOTA2\", [valor_aliquota2_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 6. VALOR ISS:\n",
    "valor_iss_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_ISS\", [valor_iss_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 7. VALOR ISS RETIDO:\n",
    "valor_issretido_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"LOWER\": \"retido\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_ISSRETIDO\", [valor_issretido_pattern])\n",
    "\n",
    "\n",
    "# 8. DESC. COND:\n",
    "valor_desccond_pattern = [\n",
    "    {\"LOWER\": \"desc\"},\n",
    "    {\"ORTH\": \".\"},\n",
    "    {\"LOWER\": \"cond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_DESCCOND\", [valor_desccond_pattern])\n",
    "\n",
    "\n",
    "# 9. VALOR PIS:\n",
    "valor_pis_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"pis\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_PIS\", [valor_pis_pattern])\n",
    "\n",
    "\n",
    "# 10. VALOR COFINS:\n",
    "valor_cofins_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"cofins\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_COFINS\", [valor_cofins_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 11. VALOR IR:\n",
    "valor_ir_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"ir\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_IR\", [valor_ir_pattern])\n",
    "\n",
    "\n",
    "# 12. VALOR INSS:\n",
    "valor_inss_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"inss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_INSS\", [valor_inss_pattern])\n",
    "\n",
    "\n",
    "# 13. VALOR CSLL:\n",
    "valor_csll_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"csll\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_CSLL\", [valor_csll_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 14. OUTRAS RETENÇÕES:\n",
    "valor_outrasreten_pattern = [\n",
    "    {\"LOWER\": \"outras\"},\n",
    "    {\"LOWER\": \"retenções\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_OUTRAS\", [valor_outrasreten_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 15. VALOR LÍQUIDO:\n",
    "valor_liquido_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"líquido\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_LIQUIDO\", [valor_liquido_pattern])\n",
    "\n",
    "\n",
    "\n",
    "#======================================== 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "# 1. EXIGIBILIDADE ISS\n",
    "exigibilidade_iss_pattern = [\n",
    "    {\"LOWER\": \"exigibilidade\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"LOWER\": {\"IN\": [\"exigivel\", \"não exigivel\"]}}\n",
    "]\n",
    "matcher.add(\"EXIGIBILIDADE_ISS\", [exigibilidade_iss_pattern])\n",
    "\n",
    "\n",
    "# 2. REGIME TRIBUTAÇÃO\n",
    "padrao_regime_tributacao = [\n",
    "    {\"LOWER\": \"regime\"},\n",
    "    {\"LOWER\": \"tributação\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"+\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"*\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": \"simples\", \"OP\": \"?\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"REGIME_TRIBUTACAO\", [padrao_regime_tributacao])\n",
    "\n",
    "# 3. SIMPLES NACIONAL = NAO\n",
    "simples_nacional_nao_pattern = [\n",
    "    {\"LOWER\": \"simples\"},\n",
    "    {\"LOWER\": \"nacional\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": \"não\"}\n",
    "]\n",
    "matcher.add(\"SIMPLES_NACIONAL_NAO\", [simples_nacional_nao_pattern])\n",
    "\n",
    "# 3.1 SIMPLES NACIONAL = SIM\n",
    "simples_nacional_pattern = [\n",
    "    {\"LOWER\": \"simples\"},\n",
    "    {\"LOWER\": \"nacional\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": \"sim\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \"(\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \"%\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \")\", \"OP\": \"?\"}\n",
    "]\n",
    "matcher.add(\"SIMPLES_NACIONAL_SIM\", [simples_nacional_pattern])\n",
    "\n",
    "\n",
    "# 4. ISSQN RETIDO\n",
    "issqn_retido_pattern = [\n",
    "    {\"LOWER\": \"issqn\"},\n",
    "    {\"LOWER\": \"retido\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": {\"IN\": [\"sim\", \"não\"]}}\n",
    "]\n",
    "matcher.add(\"ISSQN_RETIDO\", [issqn_retido_pattern])\n",
    "\n",
    "\n",
    "# 5. LOCAL. PRESTAÇÃO SERVIÇO\n",
    "local_prestacao_servico_pattern = [\n",
    "    {\"LOWER\": \"local\"},\n",
    "    {\"ORTH\": \".\"},\n",
    "    {\"LOWER\": \"prestação\"},\n",
    "    {\"LOWER\": \"serviço\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"+\"},  # para lidar com múltiplos espaços\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # para a cidade\n",
    "    {\"ORTH\": \"-\", \"OP\": \"?\"},\n",
    "    {\"IS_UPPER\": True, \"LENGTH\": 2, \"OP\": \"?\"}  # para a sigla do estado\n",
    "]\n",
    "matcher.add(\"LOCAL_PRESTACAO_SERVICO\", [local_prestacao_servico_pattern])\n",
    "\n",
    "# 6. LOCAL INCIDÊNCIA\n",
    "local_incidencia_pattern = [\n",
    "    {\"LOWER\": \"local\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"incidência\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # Nome da cidade\n",
    "    {\"ORTH\": \"-\", \"OP\": \"?\"},  # Hífen opcional\n",
    "    {\"SHAPE\": \"XX\", \"OP\": \"?\"}  # Sigla do estado\n",
    "]\n",
    "matcher.add(\"LOCAL_INCIDENCIA\", [local_incidencia_pattern])\n",
    "\n",
    "\n",
    "# observacao_pattern = [\n",
    "#     {\"LOWER\": \"observação\"},\n",
    "#     {\"ORTH\": \":\"},\n",
    "#     {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "#     {\"LOWER\": \"-\", \"OP\": \"?\"},\n",
    "#     {\"IS_PRINT\": True, \"OP\": \"+\"}\n",
    "# ]\n",
    "\n",
    "# matcher.add(\"OBSERVACAO\", [observacao_pattern])# 6. Alíquota\n",
    "valor_aliquota_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"+\"},\n",
    "    {\"ORTH\": \"\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \"%\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "colors = {\n",
    "            \"secretaria\": \"linear-gradient(90deg, #2ADB5E, #1FA346)\", # Verde Degrade\n",
    "            \"tipo_documento\": \"linear-gradient(90deg, #09D6FF, #08A0D1)\", #Azul medio degrade\n",
    "            \"nome_prefeitura\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", # Roxo claro para lilaz - degrade bem bacana\n",
    "            \"nome_section\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\", #  lilaz - Degrade\n",
    "            \"nome_section\": \"#FFEA7F\", # Laranja claro\n",
    "            \"SAFRA\": \"#CCA10C\", # Terracota\n",
    "            \"SAFRA\": \"#AB9BFC\", # Roxo claro \n",
    "            \"CNPJ\": \"#7AECEC\", # Azul bem claro\n",
    "            \"NOME\": \"#EE8AF8\" # Rosa medio\n",
    "        }          \n",
    "\n",
    "patternsPrefeitura = [\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mesquita\"}], \"id\": \"PM_MESQUITA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mage\"}], \"id\": \"PM_MAGE\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsSection = [     \n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"número\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}, {\"ORTH\": \":\"}], \"id\": \"1. CABECALHO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"discriminação\"}, {\"LOWER\": \"dos\"}, {\"LOWER\": \"serviços\"}], \"id\": \"4. DESCRIMINACAO DOS SERVIÇOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"total\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}], \"id\": \"5. VALOR TOTAL\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"cnae\"}], \"id\": \"6. CNAE e Item da Lista de Serviços\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"serviços\"}], \"id\": \"7. VALORES E IMPOSTOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"dados\"}, {\"LOWER\": \"complementares\"}], \"id\": \"8. DADOS COMPLEMENTARES\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"outras\"}, {\"LOWER\": \"informações\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"criticas\"}], \"id\": \"9. OUTRAS INFORMAÇOES / CRITICAS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"observação\"}], \"id\": \"10. OBSERVACOES\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsSecretarias = [{\"label\": \"secretaria\", \"pattern\": [{\"LOWER\": \"secretaria\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"fazenda\"},], \"id\": \"SECRETARIA\"}] \n",
    "\n",
    "\n",
    "patternsTipoDocumento = [\n",
    "                        {\"label\": \"tipo_documento\", \"pattern\": [{\"LOWER\": \"nota\"}, {\"LOWER\": \"fiscal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}, {\"LOWER\": \"eletrônica\"}, {\"LOWER\": \"-\"}, {\"LOWER\": \"nfs-e\"}], \"id\": \"NFS-e\"}\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsIdentificaEntidade = [\n",
    "                            {\"label\": \"CNPJ\", \"pattern\": [{\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}$\"}}], \"id\": \"cpf_cnpj_com_mascara\"}\n",
    "                            ]\n",
    "\n",
    "\n",
    "\n",
    "patternsCnpj = [\n",
    "    {\n",
    "        \"label\": \"CNPJ\",\n",
    "        \"pattern\": [\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/$\"}},\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{4}-\\d{2}$\"}}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patternsTemp = [\n",
    "                    {\"label\":\"TOTAL\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"}, {\"LOWER\": \"total\", \"OP\":\"*\"}], \"id\": \"qtde-total\"},\n",
    "                    {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entregue\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                    {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entreguei\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                    {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"foram\", \"OP\":\"?\"},{\"LOWER\": \"entregues\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                    {\"label\":\"SALDO\", \"pattern\": [{\"LOWER\": \"saldo\",\"OP\":\"*\"}], \"id\": \"qtde-saldo\"}]\n",
    "\n",
    "\n",
    "patternsOthers = [{\"label\": \"PERSON\", \"pattern\": \"Daniel\", \"id\": \"pessoa-daniel\"}] \n",
    " \n",
    "patternsCult = [\n",
    "    {\n",
    "        \"label\":\"CULTURA\",\n",
    "        \"pattern\": [\n",
    "            {\"LOWER\": \"soja\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"milho\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"sorgo\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"trigo\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"milheto\", \"OP\":\"?\"},  \n",
    "            \n",
    "        ],    \n",
    "    \"id\": \"cultura\"}]\n",
    "\n",
    "patternsQuant = [{\"label\":\"TOTAL\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"}, {\"LOWER\": \"total\", \"OP\":\"*\"}], \"id\": \"qtde-total\"},\n",
    "                 {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entregue\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                 {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entreguei\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                 {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"foram\", \"OP\":\"?\"},{\"LOWER\": \"entregues\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                 {\"label\":\"SALDO\", \"pattern\": [{\"LOWER\": \"saldo\",\"OP\":\"*\"}], \"id\": \"qtde-saldo\"}]\n",
    "\n",
    "\n",
    "patternsSafra = [{\"label\":\"SAFRA\", \"pattern\": [{\"LOWER\": \"safra\", \"OP\":\"?\"},{\"LOWER\": \"safras\", \"OP\":\"?\"}], \"id\": \"safra\"}]\n",
    "\n",
    "\n",
    "patternsNroSafra = [{\"label\":\"NR_SAF\", \"pattern\": [{\"SHAPE\": \"dd/dd\", \"OP\":\"*\"}], \"id\": \"nro_safra\"},\n",
    "                    {\"label\":\"NR_SAF\", \"pattern\": [{\"lower\": \"próxima\", \"OP\":\"*\"}], \"id\": \"nro_safra\"},\n",
    "                    {\"label\":\"NR_SAF\", \"pattern\": [{\"lower\": \"passada\", \"OP\":\"*\"}], \"id\": \"nro_safra\"}]   \n",
    "\n",
    "patternsCliente = [{\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"berdinazzi\"}], \"id\": \"cli-berdinazzi\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"lopito\"}], \"id\": \"cli-lopito\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"bungue\"}], \"id\": \"cli-bungue\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"bunge\", \"bongue\", \"bumgue\"]}}}], \"id\": \"cli-bungue\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"berdinazi\"]}}}], \"id\": \"cli-berdinazzi\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"matarazzo\"]}}}], \"id\": \"cli-matarazzo\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"mezenga\"]}}}], \"id\": \"cli-mezenga\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"rei\"}, {\"LOWER\": \"do\"}, {\"LOWER\": \"gado\"}], \"id\": \"cli-reidogado\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"rei-do-gado\"]}}}], \"id\": \"cli-reidogado\"},   \n",
    "                   ]\n",
    "\n",
    "\n",
    "patternsContrato = [{\"label\": \"CONTRATO\", \"pattern\": [{\"LOWER\": \"contrato\", \"OP\":\"?\"}], \"id\": \"contrato\"},\n",
    "                    {\"label\": \"CONTRATO\", \"pattern\": [{\"LOWER\": \"contratos\", \"OP\":\"?\"}], \"id\": \"contrato\"}]\n",
    "\n",
    "patternsNroContrato = [{\"label\": \"NR_CONT\", \"pattern\": [{\"SHAPE\": \"dddX\", \"OP\":\"*\"}], \"id\": \"nro_contrato\"},\n",
    "                       {\"label\": \"NR_CONT\", \"pattern\": [{\"POS\": \"NUM\", \"SHAPE\": \"ddd\", \"OP\": \"*\"},\n",
    "                                                            {\"POS\": \"PROPN\", \"SHAPE\": \"X\", \"OP\": \"*\"}], \"id\": \"nro_contrato\"}]\n",
    "\n",
    "patternsIntent = [{\"label\": \"INTENT\", \"pattern\": [{\"IS_TITLE\": True, \"OP\":\"*\"}], \"id\": \"user-intent\"},\n",
    "                  {\"label\": \"INTENT\", \"pattern\": [{\"POS\": \"ADJ\", \"OP\":\"*\"}, {\"POS\": \"VERB\", \"OP\":\"*\"}], \"id\": \"user-intent\"},\n",
    "                  {\"label\": \"INTENT\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"preciso\", \"gostaria\", \"informar\"]}}}], \"id\": \"user-intent\"}]\n",
    "\n",
    "\n",
    "patterns = patternsPrefeitura + patternsSection + patternsSecretarias + patternsTipoDocumento + patternsIdentificaEntidade + patternsCnpj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.B CABECALHO XXX Funcoes de extracao -cabecalho Raster\n",
    "def processar_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    data_box_conferencia = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    # Busco a imagem np do documento\n",
    "    image_np_row_info = row_info.get('image_np')\n",
    "    \n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "    data_box_valores['processo'] = context_mapping\n",
    "    data_box_valores['conf_cod'] = 0\n",
    "\n",
    "\n",
    "                     \n",
    "    \n",
    "    # busco coordenadas para o contexto\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "   \n",
    "    # 2. usando a funcao de extracao de coordenadas por contexto    \n",
    "    coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    x0 = int(x0)\n",
    "    y0 = int(y0)\n",
    "    x1 = int(x1)\n",
    "    y1 = int(y1) \n",
    "    # 3. Cropo a imagem - novo modelo\n",
    "    cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "    data_box_conferencia[f'box_{context_mapping}'] = cropped_image_np\n",
    "    data_box_conferencia[f'coordinates_{context_mapping}'] = coordinates\n",
    "    # 4. Converto para PIL\n",
    "    cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "    # 6. Executo OCR\n",
    "    texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "    # 7. Trato o texto extraido = text_splited\n",
    "    text_splited = texto_extraido_cabecalho(texto_extraido)\n",
    "    if debug:\n",
    "        print()\n",
    "        plt.imshow(cropped_image_np)\n",
    "        plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "        plt.show()\n",
    "        print(f'\\ncoordinates {coordinates} - \\ntexto_extraido:\\n{text_splited}\\n')\n",
    "        \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "    \n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        try:\n",
    "            section = row_frame['section_json']\n",
    "            label = row_frame['label']\n",
    "            reference = row_frame['reference']\n",
    "            string_pesquisa = row_frame['marcador_inicio']  \n",
    "            keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "            texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "            data_box_valores[label] = texto\n",
    "            if debug:\n",
    "               print(f'\\nidx: {index_frame:> 3} | label: {label} |  string_pesquisa:{string_pesquisa} | dentro do try do raster PDF cabecalho - texto: \\n{texto}\\n\\n')\n",
    "        except Exception as e:\n",
    "            msg = (f\"{e}\")\n",
    "            data_box_conferencia[label] = msg\n",
    "    \n",
    "\n",
    "    # Verificações após o loop\n",
    "    for key, value in data_box_valores.items():\n",
    "        if key == 'numero_nota_fiscal' and value is None:\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "        \n",
    "        elif key == 'codigo_verificacao' and value != None:\n",
    "            codigo_verificacao_nf = value\n",
    "            tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "            data_box_valores['conf_cod'] = tam_codigo_verificacao\n",
    "            \n",
    "        \n",
    "        elif key != 'numero_nota_fiscal' and value is None:\n",
    "            logging.error(f\" {batch_name_row_info} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "            \n",
    "      # if value is None:\n",
    "        #     logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "\n",
    "    \n",
    "    return data_box_valores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
