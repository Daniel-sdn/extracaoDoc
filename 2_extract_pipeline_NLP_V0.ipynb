{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark> <b> > 2.0 </b> Pipeline de Extracao de dados de documentos - NLP </mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2_extract_pipeline_NLP_V0.ipynb</b>    |     Atual notebook com as funçoes para processamento de documentos com soluçao NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules e config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "import subprocess\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from urllib import response\n",
    "\n",
    "from outlook_msg import Message\n",
    "import extract_msg\n",
    "import zipfile\n",
    "from pyunpack import Archive\n",
    "import py7zr\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import PyPDF2\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "import locale\n",
    "import time, copy\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import cv2\n",
    "import fitz  # Módulo PyMuPDF\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "import matplotlib.pyplot as plt\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Token\n",
    "from spacy.language import Language\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "# Modulos da solucao\n",
    "# import modules.extrai_pdf_pesquisavel as Extc\n",
    "import modules.cronometro as cron\n",
    "import modules.nova_extracao_pdf_pesquisavel as novaextra \n",
    "import modules.trata_model as tmod\n",
    "import modules.trata_pdf as tpdf\n",
    "import modules.utils as utl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.remove_pipe('ner')\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.utf8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. XXX Path para planilha de processamento de batches\n",
    "conf_export_plan_path = 'processamentos/processamento_batches/df_conf_export_batch.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "# 2. XXX  Tratando nome de carga do df_processamento\n",
    "map_analise_path = \"processamentos/mapeamento_analise\"\n",
    "\n",
    "# 3. XXX  prefixo de nome do arquivo de exportaçao\n",
    "df_root_pipe_file = \"df_root_\"\n",
    "\n",
    "\n",
    "\n",
    "# 6. IMPORTANTE - MUDOU - Path para gestao de imagens resized\n",
    "image_resized_path = \"processamentos/temp/images/processadas\"\n",
    "\n",
    "\n",
    "#### Config - E-mail\n",
    "# 1. Caminho do arquivo uma mensagem especifica\n",
    "msg_dir_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/11_emails'\n",
    "\n",
    "# 2. Path para arquivos atachados compactados\n",
    "msg_attachment_zip = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/13_attachments'\n",
    "\n",
    "\n",
    "#### Config - messages\n",
    "# 3. Caminho do arquivo uma mensagem especifica\n",
    "msg_outros_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/12_messages'\n",
    "\n",
    "# 4. Path para arquivos recebidos manualmente\n",
    "arquivos_recebidos_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/14_documentos_recebidos'\n",
    "\n",
    "\n",
    "####Config Processamento Pipeline\n",
    "\n",
    "# 5. Path para documentos para extracao\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"pipeline_extracao_documentos/5_documentos_processados/jsons\"\n",
    "\n",
    "# 7. Path para DFs e CSVs exportados\n",
    "export_path = \"pipeline_extracao_documentos/6_geral_administacao/exports\"\n",
    "\n",
    "# 8. Path para lixeira\n",
    "root_garbage_path = \"pipeline_extracao_documentos/0_lixeira\"\n",
    "\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "cnae_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets/CNAE_X_ITEM_SERVICO_PREFEITURAS.xlsx\"\n",
    "\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "#Modelo atual\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "# definindo localizadcao para pt_BR\n",
    "locale.setlocale(locale.LC_TIME, \"pt_BR.utf8\")\n",
    "\n",
    "# logging.basicConfig(\n",
    "#     filename='config/log_ocorrencias.log',\n",
    "#     level=logging.INFO, \n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "#     datefmt='%d/%m/%Y %H:%M:%S'\n",
    "# )\n",
    "\n",
    "# logging.info(\"kernel reiniciado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes originais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>A.</b> Funcoes de Imagem </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX IMPORTANTE - ESTA E A FUNCAO PARA SER UTILIZADA: POIS CONVERTE PARA CINZA E RESIZE: (4134, 5846)\n",
    "def convert_resize_gray(original_file_name, file_path, image_resized_path):\n",
    "\n",
    "    name_image = utl.conv_filename_no_ext(original_file_name)\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(name_image)}.jpg')\n",
    "    pages = convert_from_path(file_path, 500, poppler_path=poppler_path)\n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((4134, 5846))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "    imagem_gray = resized_pages[0].convert('L')\n",
    "    imagem_gray.save(image_resized_name, 'JPEG')\n",
    "\n",
    "    return  imagem_gray, image_resized_name\n",
    "\n",
    "# XXX Pequenos mas poderosos\n",
    "def extract_text_PIL(image, coordinates):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    image_croped = image.crop((x0, y0, x1, y1))\n",
    "    texto_extraido = pytesseract.image_to_string(image_croped, lang='por', config='--psm 6')\n",
    "    return texto_extraido \n",
    "\n",
    "\n",
    "# 5. XXX Ajusta textoYYY\n",
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>B.</b> Funcoes de Frames </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funçao importante para buscar coordenadas do frame em funçao do contexto\n",
    "def get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo):\n",
    "    \n",
    "    row_frame = utl.filtrar_df(frames_nf_v4_df, model=model_map, context_mapping=context_mapping, type=tipo)\n",
    "    \n",
    "    # Verificando se row_frame não está vazio\n",
    "    if not row_frame.empty:\n",
    "        # Acessando a primeira linha do DataFrame filtrado e depois acessando as colunas\n",
    "        coodinates = [((row_frame.iloc[0]['x0_p'], row_frame.iloc[0]['y0_p'], row_frame.iloc[0]['x1_p'], row_frame.iloc[0]['y1_p']) if pdf_pesquisavel_map else (row_frame.iloc[0]['x0'], row_frame.iloc[0]['y0'], row_frame.iloc[0]['x1'], row_frame.iloc[0]['y1']))]\n",
    "    else:\n",
    "        # Retornando uma tupla de valores NaN se o DataFrame filtrado estiver vazio\n",
    "        coodinates = [(float('nan'), float('nan'), float('nan'), float('nan'))]\n",
    "    \n",
    "    return coodinates\n",
    "\n",
    "\n",
    "\n",
    "# XXXpara buscar melhor as coordendas dos FRAMES\n",
    "def get_coordinates_filter(pdf_pesquisavel_map, model, tipo, label, section):\n",
    "    \n",
    "    row_frame = utl.filtrar_df(frames_nf_v4_df, model=model, type=tipo, label=label, section_json=section)\n",
    "    \n",
    "    # Verificando se row_frame não está vazio\n",
    "    if not row_frame.empty:\n",
    "        # Acessando a primeira linha do DataFrame filtrado e depois acessando as colunas\n",
    "        coodinates = [((row_frame.iloc[0]['x0_p'], row_frame.iloc[0]['y0_p'], row_frame.iloc[0]['x1_p'], row_frame.iloc[0]['y1_p']) if pdf_pesquisavel_map else (row_frame.iloc[0]['x0'], row_frame.iloc[0]['y0'], row_frame.iloc[0]['x1'], row_frame.iloc[0]['y1']))]\n",
    "    else:\n",
    "        # Retornando uma tupla de valores NaN se o DataFrame filtrado estiver vazio\n",
    "        coodinates = [(float('nan'), float('nan'), float('nan'), float('nan'))]\n",
    "    \n",
    "    return coodinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>C.</b> Funcoes de Processamento e Extracao </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.A Dados iniciais - PDF PESQUISAVEL\t\n",
    "def pesquisa_prefeitura_pdf_pesquisavel(idx, row, row_info, map_directory, original_file_name, file_path, debug):    \n",
    "    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 4\n",
    "    x1 = 600\n",
    "    y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\ndentro da funçao: pesquisa_prefeitura_pdf_pesquisavel: doc.:{original_file_name} | diretorio: {map_directory}  text: \\n\\n{text}\\n\\n')\n",
    "    \n",
    "    if text:\n",
    "       page_number = 0\n",
    "       #print(page_number)\n",
    "    else:\n",
    "       page_number = 1\n",
    "       #print(page_number)\n",
    "    \n",
    "    pdf_document.close()\n",
    "   \n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0. INFOMACOES INICIAIS - RASTER PDF\n",
    "def processar_dados_iniciais(idx, row, row_info, section, map_directory, original_file_name, file_path, debug):\n",
    "    \n",
    "    # lista_texto_extraido = []\n",
    "\n",
    "    nf_dados_doc = {}\n",
    "    nf_dados_doc['secao'] = section\n",
    "    pdf_pesquisavel = None\n",
    "    extracted_txt = pesquisa_prefeitura_pdf_pesquisavel(idx, row, row_info, map_directory, original_file_name, file_path, debug)\n",
    "    if debug:\n",
    "        print(f'\\n1. funcao: processar_dados_iniciais: doc.:{original_file_name} | diretorio: {map_directory} apos funcao: pesquisa_prefeitura_pdf_pesquisavel: extracted_txt:\\n{extracted_txt}\\n\\n')\n",
    "    \n",
    "    if extracted_txt:\n",
    "        pdf_pesquisavel = True\n",
    "        print(f'extracted_txt: {extracted_txt} - portanto pdf_pesquisavel: {pdf_pesquisavel} ')\n",
    "        \n",
    "    else:\n",
    "        pdf_pesquisavel = False\n",
    "        print(f'extracted_txt: {extracted_txt} - portanto pdf_pesquisavel: {pdf_pesquisavel} ') \n",
    "       \n",
    "       \n",
    "        # WTF\n",
    "        x0 = 220\n",
    "        y0 = 0\n",
    "        x1= 3858\n",
    "        y1 = 1572\n",
    "        \n",
    "        # usando novo processo que gera o arquivo \"on the fly\" imagem_gray (converte PDF para imagem de tamanho grande (4134, 5846) - torna-a cinza e a salva)\n",
    "        imagem_gray, image_resized_name = convert_resize_gray(original_file_name, file_path, image_resized_path)\n",
    "        extracted_txt = extract_text_PIL(imagem_gray, (x0, y0, x1, y1))\n",
    "        #print(f'extracted_txt: {extracted_txt}')\n",
    "        if debug:\n",
    "            print(f'\\n2. funcao: processar_dados_iniciaisdoc.:{original_file_name} | diretorio: {map_directory}  apos : extract_text_PIL: extracted_txt:\\n{extracted_txt}\\n\\n')\n",
    "    \n",
    "    nf_dados_doc['file_name'] = original_file_name    \n",
    "    nf_dados_doc['pdf_pesquisavel'] = pdf_pesquisavel \n",
    "    value = {}   \n",
    "    texto_tratado = texto_extraido(extracted_txt)\n",
    "    value = define_dados_iniciais(idx, row, row_info, texto_tratado, debug)\n",
    "    if debug:\n",
    "        print(f'\\n3. funcao: processar_dados_iniciais doc.:{original_file_name} | diretorio: {map_directory} | apos funcao: define_dados_iniciais() value \\n{value}\\n\\n')\n",
    "    if value:\n",
    "        nf_dados_doc.update(value)\n",
    "   \n",
    "\n",
    "\n",
    "    return nf_dados_doc\n",
    "\n",
    "\n",
    "# 1.B CABECALHO XXX Funcoes de extracao -cabecalho Raster\n",
    "def processar_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    data_box_conferencia = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    # Busco a imagem np do documento\n",
    "    image_np_row_info = row_info.get('image_np')\n",
    "    \n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "    data_box_valores['processo'] = context_mapping\n",
    "    data_box_valores['conf_cod'] = 0\n",
    "\n",
    "\n",
    "                     \n",
    "    \n",
    "    # busco coordenadas para o contexto\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "    #print(f'\\n2. Dentro func: section: {section} mapping_method: {mapping_method} | context_mapping: {context_mapping} | model_map: {model_map} | original_file_name: {original_file_name}\\n')\n",
    "   \n",
    "    # 2. usando a funcao de extracao de coordenadas por contexto    \n",
    "    coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    #print(f'x0: {x0} | y0: {y0} | x1: {x1} | y1: {y1}')\n",
    "    x0 = int(x0)\n",
    "    y0 = int(y0)\n",
    "    x1 = int(x1)\n",
    "    y1 = int(y1) \n",
    "    # 3. Cropo a imagem - novo modelo\n",
    "    cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "    data_box_conferencia[f'box_{context_mapping}'] = cropped_image_np\n",
    "    data_box_conferencia[f'coordinates_{context_mapping}'] = coordinates\n",
    "    # 4. Converto para PIL\n",
    "    cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "    # 6. Executo OCR\n",
    "    texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "    # 7. Trato o texto extraido = text_splited\n",
    "    text_splited = texto_extraido_cabecalho(texto_extraido)\n",
    "    if debug:\n",
    "        print()\n",
    "        plt.imshow(cropped_image_np)\n",
    "        plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "        plt.show()\n",
    "        print(f'\\ncoordinates {coordinates} - \\ntexto_extraido:\\n{text_splited}\\n')\n",
    "        \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "    \n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        try:\n",
    "            section = row_frame['section_json']\n",
    "            label = row_frame['label']\n",
    "            reference = row_frame['reference']\n",
    "            string_pesquisa = row_frame['marcador_inicio']  \n",
    "            keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "            texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "            data_box_valores[label] = texto\n",
    "            if debug:\n",
    "               print(f'\\nidx: {index_frame:> 3} | label: {label} |  string_pesquisa:{string_pesquisa} | dentro do try do raster PDF cabecalho - texto: \\n{texto}\\n\\n')\n",
    "        except Exception as e:\n",
    "            msg = (f\"{e}\")\n",
    "            data_box_conferencia[label] = msg\n",
    "    \n",
    "\n",
    "    # Verificações após o loop\n",
    "    for key, value in data_box_valores.items():\n",
    "        if key == 'numero_nota_fiscal' and value is None:\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "        \n",
    "        elif key == 'codigo_verificacao' and value != None:\n",
    "            codigo_verificacao_nf = value\n",
    "            tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "            data_box_valores['conf_cod'] = tam_codigo_verificacao\n",
    "            \n",
    "        \n",
    "        elif key != 'numero_nota_fiscal' and value is None:\n",
    "            logging.error(f\" {batch_name_row_info} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "            \n",
    "      # if value is None:\n",
    "        #     logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "\n",
    "    \n",
    "    return data_box_valores\n",
    "\n",
    "# 1.A CABECALHO - PDF PESQUISAVEL  \n",
    "def extrai_cabecalho_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, de_para_pm, model_map, f_0, f_1, original_file_name, file_path, debug):\n",
    "    \n",
    "    nf_data_cabecalho = {}\n",
    "    lista_erros = []\n",
    "    label = \"1_frame_dados_nf\"\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    nf_data_cabecalho['secao'] = section\n",
    "    nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "    nf_data_cabecalho['informations'] = information_row_info\n",
    "    nf_data_cabecalho['processo'] = 'mapeamento regex - PDF pesquisavel'\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\n\\n2. dentro da funçao extrai_cabecalho_PDF: batch_name: {batch_name_row_info}\\n\\n')\n",
    "    \n",
    "    pdf_document = fitz.open(file_path)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]    \n",
    "    tipo = \"frame\"\n",
    "\n",
    "    coordinates = get_coordinates_filter(pdf_pesquisavel_map=pdf_pesquisavel_map, model=model_map, tipo=tipo, label=label, section=section)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    y0 = y0 * f_0\n",
    "    y1 = y1 * f_1\n",
    "    \n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    if debug:\n",
    "        print(f'\\n3. x0: {x0}, y0: {y0}, x1: {x1}, y1: {y1} f_0: {f_0} f_1: {f_1} | text: \\n{text} \\n\\n')\n",
    "\n",
    "    try:\n",
    "        numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "        if numero_nota_match:\n",
    "            numero_nf = numero_nota_match.group(1)\n",
    "            nf_data_cabecalho['numero_nota_fiscal'] = numero_nf\n",
    "            #nf_data_cabecalho['informations'] = 'documento com numero de nota fiscal'\n",
    "            if debug:\n",
    "                print(f'\\nnr_nro_nf: {nr_nro_nf} - doc: {original_file_name}\\n')\n",
    "        else:\n",
    "            msg = (f\"Número da Nota não encontrado\")\n",
    "            nf_data_cabecalho['numero_nota_fiscal'] = None\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            nf_data_cabecalho['informations'] = information_row_info\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "    except Exception as e:\n",
    "        msg = (f\"doc: {original_file_name} | numero NF nao encontrado {e}\")\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = None\n",
    "        information_row_info = 'Número da Nota não encontrado'\n",
    "        nf_data_cabecalho['informations'] = information_row_info\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        nf_data_cabecalho['action_item'] = action_item_row_info\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair codigo Verificacao\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        codigo_verificacao_nf = codigo_verificacao_match.group(1)\n",
    "        nf_data_cabecalho['codigo_verificacao'] =  codigo_verificacao_nf\n",
    "        tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "        nf_data_cabecalho['conf_cod'] = tam_codigo_verificacao\n",
    "        \n",
    "    \n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    return nf_data_cabecalho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark> <b>1.X</b> Funcoes NLP </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ent_new(text, patterns):\n",
    "    #nlp = spacy.blank(\"pt\")\n",
    "    #ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    ruler.add_patterns(patterns)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = []\n",
    "    ents = []\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        span = doc.char_span(ent.start_char, ent.end_char, label=ent.label_)\n",
    "        ents.append(span)\n",
    "        \n",
    "    for token in doc:\n",
    "        start = token.idx\n",
    "        end = start + len(token)\n",
    "        tokens.append((token.text, start, end))\n",
    "        \n",
    "    return doc, tokens, ents\n",
    "\n",
    "\n",
    "\n",
    "# chunk.text, chunk.start, chunk.end, chunk.root.head.lemma_, chunk.root.dep_, chunk.doc\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocrmypdf(input_file, output_file):\n",
    "    command = [\n",
    "        'ocrmypdf',\n",
    "        '--language', 'por',\n",
    "        '--deskew',\n",
    "        input_file,\n",
    "        output_file\n",
    "    ]\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"OCRmyPDF completed successfully. Output saved to {output_file}.\")\n",
    "    else:\n",
    "        print(f\"OCRmyPDF failed with error: {result.stderr.decode('utf-8')}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# Função para definir o atributo \"is_cnpj\"\n",
    "@Language.component(\"set_cnpj_attribute\")\n",
    "def set_cnpj_attribute(doc):\n",
    "    for i, token in enumerate(doc):\n",
    "        if i < len(doc) - 1:\n",
    "            next_token = doc[i + 1]\n",
    "            if token.shape_ == \"dd.ddd.ddd/\" and next_token.shape_ == \"dddd-dd\":\n",
    "                token._.is_cnpj = True\n",
    "                next_token._.is_cnpj = True\n",
    "            else:\n",
    "                token._.is_cnpj = False\n",
    "    return doc        \n",
    "\n",
    "\n",
    "# Registro do atributo 'is_cnpj'\n",
    "Token.set_extension('is_cnpj', force=True, default=False)\n",
    "\n",
    "\n",
    "# Função para aplicar o matcher\n",
    "@Language.component(\"apply_cnpj_matcher\")\n",
    "def apply_cnpj_matcher(doc):\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        for token in span:\n",
    "            token._.is_cnpj = True\n",
    "    return doc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"set_cnpj_attribute\") # Adicione esta etapa se você quiser definir o atributo manualmente\n",
    "\n",
    "nlp.add_pipe(\"apply_cnpj_matcher\")  # Adicione esta etapa para aplicar o matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matcher Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Matcher Patterns\n",
    "#======================================== 1. CABECALHO\n",
    "# 1. Número da Nota:\n",
    "numero_nota_pattern = [\n",
    "    {\"LOWER\": \"número\"},\n",
    "    {\"LOWER\": \"da\"},\n",
    "    {\"LOWER\": \"nota\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True}\n",
    "]\n",
    "matcher.add(\"numero_nota_fiscal\", [numero_nota_pattern])\n",
    "\n",
    "\n",
    "# 2. Competência:\n",
    "competencia_pattern = [\n",
    "    {\"LOWER\": \"competência\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"?\"},\n",
    "    {\"ORTH\": {\"REGEX\": \"^[A-Z][a-z]+/[0-9]{4}$\"}}   \n",
    "]    \n",
    "matcher.add(\"competencia\", [competencia_pattern])\n",
    "\n",
    "# 3. Data e Hora de Emissão:\n",
    "data_hora_emissao_pattern = [\n",
    "    {\"LOWER\": \"data\"},\n",
    "    {\"LOWER\": \"e\"},\n",
    "    {\"LOWER\": \"hora\"},\n",
    "    {\"LOWER\": \"da\"},\n",
    "    {\"LOWER\": \"emissão\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"SHAPE\": \"dd/dd/dddd\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"SHAPE\": \"dd:dd:dd\"}\n",
    "]\n",
    "matcher.add(\"dt_hr_emissao\", [data_hora_emissao_pattern])\n",
    "\n",
    "# 4. Código de Verificação:\n",
    "codigo_verificacao_pattern = [\n",
    "    {\"LOWER\": \"código\"},\n",
    "    {\"LOWER\": \"verificação\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_ASCII\": True, \"LENGTH\": 9}\n",
    "]\n",
    "matcher.add(\"codigo_verificacao\", [codigo_verificacao_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#========================================  5. VALOR TOTAL\n",
    "valor_total_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"total\"},\n",
    "    {\"LOWER\": \"da\", \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"nota\", \"OP\": \"?\"},\n",
    "    {\"TEXT\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_TOTAL\", [valor_total_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#======================================== 7. VALORES E IMPOSTOS\n",
    "# 1. VALOR_SERVICOS\n",
    "valor_servicos_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"serviços\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"VALOR_SERVICOS\", [valor_servicos_pattern])\n",
    "\n",
    "\n",
    "# 2. VALOR DEDUÇÃO:\n",
    "valor_deducao_pattern = [\n",
    "    {\"LOWER\": \"dedução\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "\n",
    "matcher.add(\"VALOR_DEDUCAO\", [valor_deducao_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 3. DESC. INCOND: RASTER_PDF\n",
    "valor_incondR_pattern = [\n",
    "    {\"LOWER\": \"base\"},\n",
    "    {\"LOWER\": \"de\"},\n",
    "    {\"IS_SPACE\": True},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "]\n",
    "matcher.add(\"VALOR_INCONDP\", [valor_incondR_pattern])\n",
    "\n",
    "\n",
    "# 3.A DESC. INCOND: - PDF_Pesquisavel   #DESC. INCOND:\n",
    "valor_incond_patternP = [\n",
    "    {\"LOWER\": \"desc\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"incond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}    \n",
    "]\n",
    "matcher.add(\"VALOR_INCONDR\", [valor_incond_patternP])\n",
    "\n",
    "\n",
    "\n",
    "# 4. BASE DE CÁLCULO:  RASTER_PDF\n",
    "valor_calculoR_pattern = [\n",
    "    {\"LOWER\": \"cálculo\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_CALCULOR\", [valor_calculoR_pattern])\n",
    "\n",
    "\n",
    "# 4.A BASE DE CÁLCULO:  PDF_P\n",
    "valor_calculoP_pattern = [\n",
    "    {\"LOWER\": \"base\"},\n",
    "    {\"LOWER\": \"de\"},\n",
    "    {\"LOWER\": \"cálculo\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},  # para lidar com possíveis quebras de linha\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_CALCULOP\", [valor_calculoP_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 5. Alíquota d,dd\n",
    "valor_aliquota_pattern = [\n",
    "    {\"LOWER\": \"alíquota\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"d,dd\", \"OP\": \"?\"},\n",
    "    {\"ORTH\": \"%\"}\n",
    "\n",
    "]\n",
    "matcher.add(\"VALOR_ALIQUOTA\", [valor_aliquota_pattern])\n",
    "\n",
    "# 5.1 Alíquota d\n",
    "valor_aliquota2_pattern = [\n",
    "    {\"LOWER\": \"alíquota\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"d\", \"OP\": \"?\"},\n",
    "    {\"ORTH\": \"%\"}\n",
    "\n",
    "]\n",
    "matcher.add(\"VALOR_ALIQUOTA2\", [valor_aliquota2_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 6. VALOR ISS:\n",
    "valor_iss_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_ISS\", [valor_iss_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 7. VALOR ISS RETIDO:\n",
    "valor_issretido_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"LOWER\": \"retido\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_ISSRETIDO\", [valor_issretido_pattern])\n",
    "\n",
    "\n",
    "# 8. DESC. COND:\n",
    "valor_desccond_pattern = [\n",
    "    {\"LOWER\": \"desc\"},\n",
    "    {\"ORTH\": \".\"},\n",
    "    {\"LOWER\": \"cond\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_DESCCOND\", [valor_desccond_pattern])\n",
    "\n",
    "\n",
    "# 9. VALOR PIS:\n",
    "valor_pis_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"pis\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_PIS\", [valor_pis_pattern])\n",
    "\n",
    "\n",
    "# 10. VALOR COFINS:\n",
    "valor_cofins_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"cofins\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_COFINS\", [valor_cofins_pattern])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 11. VALOR IR:\n",
    "valor_ir_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"ir\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_IR\", [valor_ir_pattern])\n",
    "\n",
    "\n",
    "# 12. VALOR INSS:\n",
    "valor_inss_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"inss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_INSS\", [valor_inss_pattern])\n",
    "\n",
    "\n",
    "# 13. VALOR CSLL:\n",
    "valor_csll_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"csll\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_CSLL\", [valor_csll_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 14. OUTRAS RETENÇÕES:\n",
    "valor_outrasreten_pattern = [\n",
    "    {\"LOWER\": \"outras\"},\n",
    "    {\"LOWER\": \"retenções\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_OUTRAS\", [valor_outrasreten_pattern])\n",
    "\n",
    "\n",
    "\n",
    "# 15. VALOR LÍQUIDO:\n",
    "valor_liquido_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"líquido\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"SHAPE\": \"X$\"},\n",
    "    {\"MORPH\": \"NumType=Card\", \"OP\": \"+\"},\n",
    "    {\"LOWER\": \".\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"VALOR_LIQUIDO\", [valor_liquido_pattern])\n",
    "\n",
    "\n",
    "\n",
    "#======================================== 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "# 1. EXIGIBILIDADE ISS\n",
    "exigibilidade_iss_pattern = [\n",
    "    {\"LOWER\": \"exigibilidade\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"LOWER\": {\"IN\": [\"exigivel\", \"não exigivel\"]}}\n",
    "]\n",
    "matcher.add(\"EXIGIBILIDADE_ISS\", [exigibilidade_iss_pattern])\n",
    "\n",
    "\n",
    "# 2. REGIME TRIBUTAÇÃO\n",
    "padrao_regime_tributacao = [\n",
    "    {\"LOWER\": \"regime\"},\n",
    "    {\"LOWER\": \"tributação\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"+\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"*\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": \"simples\", \"OP\": \"?\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"*\"}\n",
    "]\n",
    "matcher.add(\"REGIME_TRIBUTACAO\", [padrao_regime_tributacao])\n",
    "\n",
    "# 3. SIMPLES NACIONAL = NAO\n",
    "simples_nacional_nao_pattern = [\n",
    "    {\"LOWER\": \"simples\"},\n",
    "    {\"LOWER\": \"nacional\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": \"não\"}\n",
    "]\n",
    "matcher.add(\"SIMPLES_NACIONAL_NAO\", [simples_nacional_nao_pattern])\n",
    "\n",
    "# 3.1 SIMPLES NACIONAL = SIM\n",
    "simples_nacional_pattern = [\n",
    "    {\"LOWER\": \"simples\"},\n",
    "    {\"LOWER\": \"nacional\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": \"sim\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \"(\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \",\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \"%\", \"OP\": \"?\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \")\", \"OP\": \"?\"}\n",
    "]\n",
    "matcher.add(\"SIMPLES_NACIONAL_SIM\", [simples_nacional_pattern])\n",
    "\n",
    "\n",
    "# 4. ISSQN RETIDO\n",
    "issqn_retido_pattern = [\n",
    "    {\"LOWER\": \"issqn\"},\n",
    "    {\"LOWER\": \"retido\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"LOWER\": {\"IN\": [\"sim\", \"não\"]}}\n",
    "]\n",
    "matcher.add(\"ISSQN_RETIDO\", [issqn_retido_pattern])\n",
    "\n",
    "\n",
    "# 5. LOCAL. PRESTAÇÃO SERVIÇO\n",
    "local_prestacao_servico_pattern = [\n",
    "    {\"LOWER\": \"local\"},\n",
    "    {\"ORTH\": \".\"},\n",
    "    {\"LOWER\": \"prestação\"},\n",
    "    {\"LOWER\": \"serviço\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"+\"},  # para lidar com múltiplos espaços\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # para a cidade\n",
    "    {\"ORTH\": \"-\", \"OP\": \"?\"},\n",
    "    {\"IS_UPPER\": True, \"LENGTH\": 2, \"OP\": \"?\"}  # para a sigla do estado\n",
    "]\n",
    "matcher.add(\"LOCAL_PRESTACAO_SERVICO\", [local_prestacao_servico_pattern])\n",
    "\n",
    "# 6. LOCAL INCIDÊNCIA\n",
    "local_incidencia_pattern = [\n",
    "    {\"LOWER\": \"local\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"incidência\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\": \"+\"},  # Nome da cidade\n",
    "    {\"ORTH\": \"-\", \"OP\": \"?\"},  # Hífen opcional\n",
    "    {\"SHAPE\": \"XX\", \"OP\": \"?\"}  # Sigla do estado\n",
    "]\n",
    "matcher.add(\"LOCAL_INCIDENCIA\", [local_incidencia_pattern])\n",
    "\n",
    "\n",
    "# observacao_pattern = [\n",
    "#     {\"LOWER\": \"observação\"},\n",
    "#     {\"ORTH\": \":\"},\n",
    "#     {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "#     {\"LOWER\": \"-\", \"OP\": \"?\"},\n",
    "#     {\"IS_PRINT\": True, \"OP\": \"+\"}\n",
    "# ]\n",
    "\n",
    "# matcher.add(\"OBSERVACAO\", [observacao_pattern])# 6. Alíquota\n",
    "valor_aliquota_pattern = [\n",
    "    {\"LOWER\": \"valor\"},\n",
    "    {\"LOWER\": \"iss\"},\n",
    "    {\"ORTH\": \":\"},\n",
    "    {\"IS_SPACE\": True, \"OP\": \"*\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"+\"},\n",
    "    {\"ORTH\": \"\", \"OP\": \"?\"},\n",
    "    {\"IS_DIGIT\": True, \"OP\": \"*\"},\n",
    "    {\"ORTH\": \"%\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "colors = {\n",
    "            \"secretaria\": \"linear-gradient(90deg, #2ADB5E, #1FA346)\", # Verde Degrade\n",
    "            \"tipo_documento\": \"linear-gradient(90deg, #09D6FF, #08A0D1)\", #Azul medio degrade\n",
    "            \"nome_prefeitura\": \"linear-gradient(90deg, #aa9cfc, #fc9ce7)\", # Roxo claro para lilaz - degrade bem bacana\n",
    "            \"nome_section\": \"linear-gradient(90deg, #FFA9FB, #BF7FBC)\", #  lilaz - Degrade\n",
    "            \"nome_section\": \"#FFEA7F\", # Laranja claro\n",
    "            \"SAFRA\": \"#CCA10C\", # Terracota\n",
    "            \"SAFRA\": \"#AB9BFC\", # Roxo claro \n",
    "            \"CNPJ\": \"#7AECEC\", # Azul bem claro\n",
    "            \"NOME\": \"#EE8AF8\" # Rosa medio\n",
    "        }          \n",
    "\n",
    "patternsPrefeitura = [\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mesquita\"}], \"id\": \"PM_MESQUITA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"mage\"}], \"id\": \"PM_MAGE\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"},\n",
    "                        {\"label\": \"nome_prefeitura\", \"pattern\": [{\"LOWER\": \"prefeitura\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"sao\"}, {\"LOWER\": \"pedro\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"aldeia\"}], \"id\": \"PM_SPA\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsSection = [     \n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"número\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}, {\"ORTH\": \":\"}], \"id\": \"1. CABECALHO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"prestador\"}], \"id\": \"2. PRESTADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"tomador\"}], \"id\": \"3. TOMADOR DE SERVIÇO\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"discriminação\"}, {\"LOWER\": \"dos\"}, {\"LOWER\": \"serviços\"}], \"id\": \"4. DESCRIMINACAO DOS SERVIÇOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"total\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"nota\"}], \"id\": \"5. VALOR TOTAL\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"cnae\"}], \"id\": \"6. CNAE e Item da Lista de Serviços\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"valor\"}, {\"LOWER\": \"serviços\"}], \"id\": \"7. VALORES E IMPOSTOS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"dados\"}, {\"LOWER\": \"complementares\"}], \"id\": \"8. DADOS COMPLEMENTARES\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"outras\"}, {\"LOWER\": \"informações\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"criticas\"}], \"id\": \"9. OUTRAS INFORMAÇOES / CRITICAS\"},\n",
    "                        {\"label\": \"nome_section\", \"pattern\": [{\"LOWER\": \"observação\"}], \"id\": \"10. OBSERVACOES\"}\n",
    "\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsSecretarias = [{\"label\": \"secretaria\", \"pattern\": [{\"LOWER\": \"secretaria\"}, {\"LOWER\": \"municipal\"}, {\"LOWER\": \"da\"}, {\"LOWER\": \"fazenda\"},], \"id\": \"SECRETARIA\"}] \n",
    "\n",
    "\n",
    "patternsTipoDocumento = [\n",
    "                        {\"label\": \"tipo_documento\", \"pattern\": [{\"LOWER\": \"nota\"}, {\"LOWER\": \"fiscal\"}, {\"LOWER\": \"de\"}, {\"LOWER\": \"serviços\"}, {\"LOWER\": \"eletrônica\"}, {\"LOWER\": \"-\"}, {\"LOWER\": \"nfs-e\"}], \"id\": \"NFS-e\"}\n",
    "                        ]\n",
    "\n",
    "\n",
    "patternsIdentificaEntidade = [\n",
    "                            {\"label\": \"CNPJ\", \"pattern\": [{\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}$\"}}], \"id\": \"cpf_cnpj_com_mascara\"}\n",
    "                            ]\n",
    "\n",
    "\n",
    "\n",
    "patternsCnpj = [\n",
    "    {\n",
    "        \"label\": \"CNPJ\",\n",
    "        \"pattern\": [\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{2}\\.\\d{3}\\.\\d{3}/$\"}},\n",
    "            {\"ORTH\": {\"REGEX\": \"^\\d{4}-\\d{2}$\"}}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "patternsTemp = [\n",
    "                    {\"label\":\"TOTAL\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"}, {\"LOWER\": \"total\", \"OP\":\"*\"}], \"id\": \"qtde-total\"},\n",
    "                    {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entregue\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                    {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entreguei\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                    {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"foram\", \"OP\":\"?\"},{\"LOWER\": \"entregues\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                    {\"label\":\"SALDO\", \"pattern\": [{\"LOWER\": \"saldo\",\"OP\":\"*\"}], \"id\": \"qtde-saldo\"}]\n",
    "\n",
    "\n",
    "patternsOthers = [{\"label\": \"PERSON\", \"pattern\": \"Daniel\", \"id\": \"pessoa-daniel\"}] \n",
    " \n",
    "patternsCult = [\n",
    "    {\n",
    "        \"label\":\"CULTURA\",\n",
    "        \"pattern\": [\n",
    "            {\"LOWER\": \"soja\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"milho\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"sorgo\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"trigo\", \"OP\":\"?\"},\n",
    "            {\"LOWER\": \"milheto\", \"OP\":\"?\"},  \n",
    "            \n",
    "        ],    \n",
    "    \"id\": \"cultura\"}]\n",
    "\n",
    "patternsQuant = [{\"label\":\"TOTAL\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"}, {\"LOWER\": \"total\", \"OP\":\"*\"}], \"id\": \"qtde-total\"},\n",
    "                 {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entregue\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                 {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"quantidade\", \"OP\":\"?\"},{\"LOWER\": \"entreguei\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                 {\"label\":\"ENTREGUE\", \"pattern\": [{\"LOWER\": \"foram\", \"OP\":\"?\"},{\"LOWER\": \"entregues\",\"OP\":\"*\"}],\"id\": \"qtde-entregue\"},\n",
    "                 {\"label\":\"SALDO\", \"pattern\": [{\"LOWER\": \"saldo\",\"OP\":\"*\"}], \"id\": \"qtde-saldo\"}]\n",
    "\n",
    "\n",
    "patternsSafra = [{\"label\":\"SAFRA\", \"pattern\": [{\"LOWER\": \"safra\", \"OP\":\"?\"},{\"LOWER\": \"safras\", \"OP\":\"?\"}], \"id\": \"safra\"}]\n",
    "\n",
    "\n",
    "patternsNroSafra = [{\"label\":\"NR_SAF\", \"pattern\": [{\"SHAPE\": \"dd/dd\", \"OP\":\"*\"}], \"id\": \"nro_safra\"},\n",
    "                    {\"label\":\"NR_SAF\", \"pattern\": [{\"lower\": \"próxima\", \"OP\":\"*\"}], \"id\": \"nro_safra\"},\n",
    "                    {\"label\":\"NR_SAF\", \"pattern\": [{\"lower\": \"passada\", \"OP\":\"*\"}], \"id\": \"nro_safra\"}]   \n",
    "\n",
    "patternsCliente = [{\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"berdinazzi\"}], \"id\": \"cli-berdinazzi\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"lopito\"}], \"id\": \"cli-lopito\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"bungue\"}], \"id\": \"cli-bungue\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"bunge\", \"bongue\", \"bumgue\"]}}}], \"id\": \"cli-bungue\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"berdinazi\"]}}}], \"id\": \"cli-berdinazzi\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"matarazzo\"]}}}], \"id\": \"cli-matarazzo\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"mezenga\"]}}}], \"id\": \"cli-mezenga\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"LOWER\": \"rei\"}, {\"LOWER\": \"do\"}, {\"LOWER\": \"gado\"}], \"id\": \"cli-reidogado\"},\n",
    "                   {\"label\": \"CLIENTE\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"rei-do-gado\"]}}}], \"id\": \"cli-reidogado\"},   \n",
    "                   ]\n",
    "\n",
    "\n",
    "patternsContrato = [{\"label\": \"CONTRATO\", \"pattern\": [{\"LOWER\": \"contrato\", \"OP\":\"?\"}], \"id\": \"contrato\"},\n",
    "                    {\"label\": \"CONTRATO\", \"pattern\": [{\"LOWER\": \"contratos\", \"OP\":\"?\"}], \"id\": \"contrato\"}]\n",
    "\n",
    "patternsNroContrato = [{\"label\": \"NR_CONT\", \"pattern\": [{\"SHAPE\": \"dddX\", \"OP\":\"*\"}], \"id\": \"nro_contrato\"},\n",
    "                       {\"label\": \"NR_CONT\", \"pattern\": [{\"POS\": \"NUM\", \"SHAPE\": \"ddd\", \"OP\": \"*\"},\n",
    "                                                            {\"POS\": \"PROPN\", \"SHAPE\": \"X\", \"OP\": \"*\"}], \"id\": \"nro_contrato\"}]\n",
    "\n",
    "patternsIntent = [{\"label\": \"INTENT\", \"pattern\": [{\"IS_TITLE\": True, \"OP\":\"*\"}], \"id\": \"user-intent\"},\n",
    "                  {\"label\": \"INTENT\", \"pattern\": [{\"POS\": \"ADJ\", \"OP\":\"*\"}, {\"POS\": \"VERB\", \"OP\":\"*\"}], \"id\": \"user-intent\"},\n",
    "                  {\"label\": \"INTENT\", \"pattern\": [{\"TEXT\": {\"FUZZY\": {\"IN\": [\"preciso\", \"gostaria\", \"informar\"]}}}], \"id\": \"user-intent\"}]\n",
    "\n",
    "\n",
    "patterns = patternsPrefeitura + patternsSection + patternsSecretarias + patternsTipoDocumento + patternsIdentificaEntidade + patternsCnpj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prefeitura municipal de sao pedro da aldeia'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valor = 'PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA'\n",
    "valor.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 - Processo de Extracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2.x</b> Templates e Dics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames_nf_v4_df: 2.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def define_dados_iniciais(idx, row, row_info, texto_tratado, debug):\n",
    "    \n",
    "    dados_iniciais_nf = {}\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    \n",
    "    dados_iniciais_nf['action_item'] = action_item_row_info\n",
    "    dados_iniciais_nf['informations'] = information_row_info\n",
    "    \n",
    "    print(f'\\nDentro da func define_dados_iniciais:  -action_item_row_info: {action_item_row_info}')\n",
    "   \n",
    "\n",
    "\n",
    "    prefeitura_encontrada = None\n",
    "    de_para_encontrado = None\n",
    "\n",
    "    # 7. ZZZ Dicionário para mapear Prefeitura com sua sigla\n",
    "    de_para_prefeitura = {\n",
    "        \"PREFEITURA DA CIDADE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA DA CIDADE DE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA MUNICIPAL DE MAGE\": \"PM_MAGE\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA\": \"PM_SPA\",\n",
    "        \"MUNICIPAL DE SAO PEDRO DA ALDEIA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA\\nALDEIA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE SAO PEDRO DA\": \"PM_SPA\",\n",
    "        \"PREFEITURA MUNICIPAL DE MESQUITA\": \"PM_MESQUITA\",\n",
    "        \"PREFEITURA MUNICIPAL DE DE MESQUITA\": \"PM_MESQUITA\",\n",
    "        # ... adicione \n",
    "    }\n",
    "    \n",
    "\n",
    "    templates = {\n",
    "        (\"PM_MAGE\", None): \"MAGE\",\n",
    "        (\"PM_SPA\", None): \"SPA\",\n",
    "        (\"PM_MESQUITA\", None): \"MESQUITA\",\n",
    "        (\"Pague agora com o seu Pix\", None): \"NAO_PROCESSAR\",\n",
    "        # ... adicione outras combinações aqui\n",
    "    }\n",
    "\n",
    "    cnpj_encontrado = None\n",
    "    # Verifique cada linha do texto\n",
    "    for linha in texto_tratado:\n",
    "        for pref in de_para_prefeitura.keys():\n",
    "            if pref in linha:\n",
    "                #print(linha)\n",
    "                prefeitura_encontrada = pref\n",
    "                dados_iniciais_nf['prefeitura'] = prefeitura_encontrada\n",
    "                if debug:\n",
    "                    print(f'\\n4.funcao: define_dados_iniciais(texto_tratado) - dentro do loop for de pesquisa prefeitura - prefeitura_encontrada: \\n{prefeitura_encontrada}\\n\\n')\n",
    "    # Saímos do loop, agora vamos verificar qual template usar\n",
    "    if prefeitura_encontrada:\n",
    "        de_para_pm = de_para_prefeitura.get(prefeitura_encontrada)\n",
    "        dados_iniciais_nf['de_para_pm'] = de_para_pm\n",
    "        if debug:\n",
    "            print(f'\\n5.funcao: define_dados_iniciais(texto_tratado) - if prefeitura_encontrada - de_para_pm \\n{de_para_pm}\\n\\n')\n",
    "        if not de_para_pm:\n",
    "            de_para_pm = de_para_prefeitura.get(prefeitura_encontrada, \"NAO_PROCESSAR\")\n",
    "            dados_iniciais_nf['de_para_pm'] = de_para_pm\n",
    "            #print(de_para_pm)\n",
    "    else:\n",
    "        de_para_pm = \"NAO_PROCESSAR\"\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        information_row_info = 'Nao identificado dados iniciais para o documento'\n",
    "        \n",
    "     \n",
    "        \n",
    "    # Verifique cada linha do texto\n",
    "    for linha in texto_tratado:\n",
    "        for de_para, cnpj in templates.keys():\n",
    "            if cnpj and cnpj in linha:\n",
    "                cnpj_encontrado = cnpj\n",
    "                dados_iniciais_nf['cnpj_encontrado'] = cnpj_encontrado\n",
    "                \n",
    "                \n",
    "    # Saímos do loop, agora vamos verificar qual template usar\n",
    "    if de_para_pm:\n",
    "        template_usar = templates.get((de_para_pm, cnpj_encontrado))\n",
    "        logging.info(f'usara template {template_usar} para: {cnpj_encontrado}')\n",
    "        # print(template_usar)\n",
    "        dados_iniciais_nf['model'] = template_usar\n",
    "        if not template_usar:\n",
    "            template_usar = templates.get((de_para_pm, None), \"TEMPLATE_NAO_ENCONTRADO\")\n",
    "            dados_iniciais_nf['model'] = 'NAO_ENC.' \n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'model nao encontrado'\n",
    "    else:\n",
    "        template_usar = \"TEMPLATE_NAO_ENCONTRADO\"\n",
    "        dados_iniciais_nf['model'] = 'NAO_ENC.'\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        information_row_info = 'model nao encontrado'\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    #Confirmando se template existe em frames    \n",
    "    try:        \n",
    "        f_type = 'frame'\n",
    "        #template_usar = 'SAO_PEDRO_SUPERMIX'\n",
    "        result = filtrar_df(frames_nf_v4_df, type=f_type, de_para_pm=de_para_pm, model=template_usar)\n",
    "        model = result['model'].values[0]\n",
    "        if model:\n",
    "            template_oficial = model\n",
    "            if model == template_usar:\n",
    "                dados_iniciais_nf['model'] = template_oficial\n",
    "            else:    \n",
    "                template_usar = \"necessario cadastrar\"\n",
    "                dados_iniciais_nf['model'] = \"CADASTRAR\"\n",
    "                \n",
    "            dados_iniciais_nf['model'] = template_usar\n",
    "        else:\n",
    "            template_usar = \"necessario cadastrar\"\n",
    "            dados_iniciais_nf['model'] = \"CADASTRAR\"\n",
    "\n",
    "                \n",
    "    except Exception as e:\n",
    "       error_msg = (f\"Erro busca do template: {e}\") \n",
    "    \n",
    "    dados_iniciais_nf['action_item'] = action_item_row_info \n",
    "    dados_iniciais_nf['informations'] = information_row_info         \n",
    "        \n",
    "    return dados_iniciais_nf  \n",
    "\n",
    "\n",
    "\n",
    "nf_model_path = \"config/modelos/frames_nf_v11.xlsx\"\n",
    "\n",
    "#Le a planilha e cria do DF\n",
    "frames_nf_v4_df = pd.read_excel(nf_model_path)\n",
    "\n",
    "\n",
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'section']\n",
    "frames_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']\n",
    "\n",
    "ver = tmod.get_template_version(frames_nf_v4_df, 'MAGE')\n",
    "\n",
    "frames_nf_v4_df.head(5)\n",
    "\n",
    "print(f'frames_nf_v4_df: {ver}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>date_time</th>\n",
       "      <th>batch</th>\n",
       "      <th>fase_processo</th>\n",
       "      <th>nome_atividade</th>\n",
       "      <th>status_documento</th>\n",
       "      <th>acao_executada</th>\n",
       "      <th>original_file_name</th>\n",
       "      <th>directory</th>\n",
       "      <th>one_page</th>\n",
       "      <th>pages</th>\n",
       "      <th>palavra_chave</th>\n",
       "      <th>document_tag</th>\n",
       "      <th>action_item</th>\n",
       "      <th>level</th>\n",
       "      <th>parent_document_unique_id</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>file_path</th>\n",
       "      <th>informations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6f1a0643-7918-493d-8d93-39ae66a23b5d</th>\n",
       "      <td>1</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>MESQUITA_PDF_31282023_2258.zip</td>\n",
       "      <td>root_dir</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>zip</td>\n",
       "      <td>doc_zip</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>2</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>8d7038d712373364fa4c7680a887a0ceed01c8692d6958...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350d180-8ed9-4334-8189-796f4499d851</th>\n",
       "      <td>2</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>1.pdf</td>\n",
       "      <td>teste</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>66a7db9ee1500d5f9fa5da26563cfd7b68f1f5ba3daba2...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93d95698-277c-40b2-b501-cb84476109bb</th>\n",
       "      <td>3</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>Livro de Registro do ISSQN.pdf</td>\n",
       "      <td>115964</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>livro</td>\n",
       "      <td>prov_livro_registro</td>\n",
       "      <td>NO_PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>b960962503987f6e05f5646d71a789facfe4e80ccb8890...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84bc5464-fcdb-4245-8b10-b2167a80405b</th>\n",
       "      <td>4</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -5.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>23a28a363c2d2c8b700ac4775164f7c0f0e2d6cef6166d...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752b1a8-9e22-477a-a317-5eb636327c9d</th>\n",
       "      <td>5</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -7.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>54045f4c09341d9f8d69438e7afe71eff46bb4e731392b...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e1ed80a3-d062-4ce6-ade8-70ad8ea746be</th>\n",
       "      <td>6</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -4.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>ddd09bb806dc79e98a74c5cf1adc6a5bd23ea1b4f1bfa7...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa</th>\n",
       "      <td>7</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -6.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>8910a092d3aa53b6a1eb805c783245493760a1c46dadfa...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816b01a-8aa8-4831-9e0b-14c42dfbecde</th>\n",
       "      <td>8</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -3.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>25387d066a46925acba7ddfe3cd97e2e70f92838ef4312...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>PREPROCESS_EXTRACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d9a5adbb-84c5-4df9-93e8-25bb809ed940</th>\n",
       "      <td>9</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>159871</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>8be881c377bf3064ef61f014fd14602cc736a73b69de8c...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155053e9-8f4f-4afe-8954-5367d3022780</th>\n",
       "      <td>10</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>160014</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>d936f98e3cf1e773a6a5f489e4db46f6cfade5b947177e...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a393d3ee-a5eb-4bd3-b901-5e676685274d</th>\n",
       "      <td>11</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>160014</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>45372e561f1d4d4a658de7d7a42150e13fd44ae226dc1b...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54070363-11d5-4bb1-ab61-5bd44efa762a</th>\n",
       "      <td>12</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>126623</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>a35df231141af673ed89b49f32288ef8fd313858e9467b...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729b22b-0b6e-45ea-9be3-4cb5073e59ca</th>\n",
       "      <td>13</td>\n",
       "      <td>24/09/2023 09:23:12</td>\n",
       "      <td>Batch_23</td>\n",
       "      <td>analise</td>\n",
       "      <td>scan_analise</td>\n",
       "      <td>root_analise</td>\n",
       "      <td>Analise</td>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>138565</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>default</td>\n",
       "      <td>prov_nota_fiscal</td>\n",
       "      <td>PROCESS</td>\n",
       "      <td>3</td>\n",
       "      <td>8c142beb-753b-4ad8-adff-4ca10f0bf7e7</td>\n",
       "      <td>9a30f46ca2e14dbb0cf11654ab56fbdf83fd5782eb98f4...</td>\n",
       "      <td>pipeline_extracao_documentos/2_documentos_para...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      seq            date_time     batch  \\\n",
       "document_unique_id                                                         \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d    1  24/09/2023 09:23:12  Batch_23   \n",
       "3350d180-8ed9-4334-8189-796f4499d851    2  24/09/2023 09:23:12  Batch_23   \n",
       "93d95698-277c-40b2-b501-cb84476109bb    3  24/09/2023 09:23:12  Batch_23   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b    4  24/09/2023 09:23:12  Batch_23   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d    5  24/09/2023 09:23:12  Batch_23   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be    6  24/09/2023 09:23:12  Batch_23   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa    7  24/09/2023 09:23:12  Batch_23   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde    8  24/09/2023 09:23:12  Batch_23   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940    9  24/09/2023 09:23:12  Batch_23   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780   10  24/09/2023 09:23:12  Batch_23   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d   11  24/09/2023 09:23:12  Batch_23   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a   12  24/09/2023 09:23:12  Batch_23   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca   13  24/09/2023 09:23:12  Batch_23   \n",
       "\n",
       "                                     fase_processo nome_atividade  \\\n",
       "document_unique_id                                                  \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d       analise   scan_analise   \n",
       "3350d180-8ed9-4334-8189-796f4499d851       analise   scan_analise   \n",
       "93d95698-277c-40b2-b501-cb84476109bb       analise   scan_analise   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b       analise   scan_analise   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d       analise   scan_analise   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be       analise   scan_analise   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa       analise   scan_analise   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde       analise   scan_analise   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940       analise   scan_analise   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780       analise   scan_analise   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d       analise   scan_analise   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a       analise   scan_analise   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca       analise   scan_analise   \n",
       "\n",
       "                                        status_documento acao_executada  \\\n",
       "document_unique_id                                                        \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d        root_analise        Analise   \n",
       "3350d180-8ed9-4334-8189-796f4499d851  PREPROCESS_EXTRACT        Analise   \n",
       "93d95698-277c-40b2-b501-cb84476109bb        root_analise        Analise   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b        root_analise        Analise   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d        root_analise        Analise   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be  PREPROCESS_EXTRACT        Analise   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa        root_analise        Analise   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde        root_analise        Analise   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940        root_analise        Analise   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780        root_analise        Analise   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d        root_analise        Analise   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a        root_analise        Analise   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca        root_analise        Analise   \n",
       "\n",
       "                                                                     original_file_name  \\\n",
       "document_unique_id                                                                        \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d                     MESQUITA_PDF_31282023_2258.zip   \n",
       "3350d180-8ed9-4334-8189-796f4499d851                                              1.pdf   \n",
       "93d95698-277c-40b2-b501-cb84476109bb                     Livro de Registro do ISSQN.pdf   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b                                        2023 -5.pdf   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d                                        2023 -7.pdf   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be                                        2023 -4.pdf   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa                                        2023 -6.pdf   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde                                        2023 -3.pdf   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940                                        2023 -8.pdf   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780                                          31-07.pdf   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                     directory  one_page  pages palavra_chave  \\\n",
       "document_unique_id                                                              \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d  root_dir     False      0           zip   \n",
       "3350d180-8ed9-4334-8189-796f4499d851     teste      True      1       default   \n",
       "93d95698-277c-40b2-b501-cb84476109bb    115964     False      4         livro   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b    159871      True      1       default   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d    159871      True      1       default   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be    159871      True      1       default   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa    159871      True      1       default   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde    159871      True      1       default   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940    159871      True      1       default   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780    160014      True      1       default   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d    160014      True      1       default   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a    126623      True      1       default   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca    138565      True      1       default   \n",
       "\n",
       "                                             document_tag action_item  level  \\\n",
       "document_unique_id                                                             \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d              doc_zip  NO_PROCESS      2   \n",
       "3350d180-8ed9-4334-8189-796f4499d851     prov_nota_fiscal     PROCESS      3   \n",
       "93d95698-277c-40b2-b501-cb84476109bb  prov_livro_registro  NO_PROCESS      3   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b     prov_nota_fiscal     PROCESS      3   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d     prov_nota_fiscal     PROCESS      3   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be     prov_nota_fiscal     PROCESS      3   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa     prov_nota_fiscal     PROCESS      3   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde     prov_nota_fiscal     PROCESS      3   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940     prov_nota_fiscal     PROCESS      3   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780     prov_nota_fiscal     PROCESS      3   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d     prov_nota_fiscal     PROCESS      3   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a     prov_nota_fiscal     PROCESS      3   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca     prov_nota_fiscal     PROCESS      3   \n",
       "\n",
       "                                                 parent_document_unique_id  \\\n",
       "document_unique_id                                                           \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "3350d180-8ed9-4334-8189-796f4499d851  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "93d95698-277c-40b2-b501-cb84476109bb  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca  8c142beb-753b-4ad8-adff-4ca10f0bf7e7   \n",
       "\n",
       "                                                                              file_hash  \\\n",
       "document_unique_id                                                                        \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d  8d7038d712373364fa4c7680a887a0ceed01c8692d6958...   \n",
       "3350d180-8ed9-4334-8189-796f4499d851  66a7db9ee1500d5f9fa5da26563cfd7b68f1f5ba3daba2...   \n",
       "93d95698-277c-40b2-b501-cb84476109bb  b960962503987f6e05f5646d71a789facfe4e80ccb8890...   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b  23a28a363c2d2c8b700ac4775164f7c0f0e2d6cef6166d...   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d  54045f4c09341d9f8d69438e7afe71eff46bb4e731392b...   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be  ddd09bb806dc79e98a74c5cf1adc6a5bd23ea1b4f1bfa7...   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa  8910a092d3aa53b6a1eb805c783245493760a1c46dadfa...   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde  25387d066a46925acba7ddfe3cd97e2e70f92838ef4312...   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940  8be881c377bf3064ef61f014fd14602cc736a73b69de8c...   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780  d936f98e3cf1e773a6a5f489e4db46f6cfade5b947177e...   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d  45372e561f1d4d4a658de7d7a42150e13fd44ae226dc1b...   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a  a35df231141af673ed89b49f32288ef8fd313858e9467b...   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca  9a30f46ca2e14dbb0cf11654ab56fbdf83fd5782eb98f4...   \n",
       "\n",
       "                                                                              file_path  \\\n",
       "document_unique_id                                                                        \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d  pipeline_extracao_documentos/2_documentos_para...   \n",
       "3350d180-8ed9-4334-8189-796f4499d851  pipeline_extracao_documentos/2_documentos_para...   \n",
       "93d95698-277c-40b2-b501-cb84476109bb  pipeline_extracao_documentos/2_documentos_para...   \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b  pipeline_extracao_documentos/2_documentos_para...   \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d  pipeline_extracao_documentos/2_documentos_para...   \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be  pipeline_extracao_documentos/2_documentos_para...   \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa  pipeline_extracao_documentos/2_documentos_para...   \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde  pipeline_extracao_documentos/2_documentos_para...   \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940  pipeline_extracao_documentos/2_documentos_para...   \n",
       "155053e9-8f4f-4afe-8954-5367d3022780  pipeline_extracao_documentos/2_documentos_para...   \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d  pipeline_extracao_documentos/2_documentos_para...   \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a  pipeline_extracao_documentos/2_documentos_para...   \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca  pipeline_extracao_documentos/2_documentos_para...   \n",
       "\n",
       "                                            informations  \n",
       "document_unique_id                                        \n",
       "6f1a0643-7918-493d-8d93-39ae66a23b5d                 NaN  \n",
       "3350d180-8ed9-4334-8189-796f4499d851  PREPROCESS_EXTRACT  \n",
       "93d95698-277c-40b2-b501-cb84476109bb                 NaN  \n",
       "84bc5464-fcdb-4245-8b10-b2167a80405b                 NaN  \n",
       "2752b1a8-9e22-477a-a317-5eb636327c9d                 NaN  \n",
       "e1ed80a3-d062-4ce6-ade8-70ad8ea746be  PREPROCESS_EXTRACT  \n",
       "7f909b5e-0ee5-48ca-bd4a-c4bc58b94daa                 NaN  \n",
       "1816b01a-8aa8-4831-9e0b-14c42dfbecde  PREPROCESS_EXTRACT  \n",
       "d9a5adbb-84c5-4df9-93e8-25bb809ed940                 NaN  \n",
       "155053e9-8f4f-4afe-8954-5367d3022780                 NaN  \n",
       "a393d3ee-a5eb-4bd3-b901-5e676685274d                 NaN  \n",
       "54070363-11d5-4bb1-ab61-5bd44efa762a                 NaN  \n",
       "4729b22b-0b6e-45ea-9be3-4cb5073e59ca                 NaN  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. XXX Buscar proximo Batch caso nao esteja rodando email\n",
    "batch_name = utl.busca_proximo_batch(conf_export_plan_path)\n",
    "\n",
    "# 2. XXX Definiçao do path para salvar o arquivo\n",
    "file_path_root_pipe = os.path.join(map_analise_path, df_root_pipe_file + batch_name + \".xlsx\")\n",
    "\n",
    "\n",
    "#3. XXX Ler a planilha e cria df_documento_recebido\n",
    "df_root_pipe = pd.read_excel(file_path_root_pipe)\n",
    "\n",
    "\n",
    "#4. XXX  Ajustar o indice\n",
    "df_root_pipe.set_index('document_unique_id', inplace=True)\n",
    "\n",
    "\n",
    "df_root_pipe.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento/Batch_23/MESQUITA_PDF_31282023_2258/159871/2023 -4.pdf'\n",
    "original_file_name = os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"1. CABECALHO\"\n",
    "mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "context_mapping = \"data_cabecalho\"\n",
    "def_replace = True \n",
    "model_map = 'MESQUITA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novas funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.A Extracao de texto de todo o documento - PDF PESQUISAVEL\t\n",
    "def extrai_texto_PDF_P(idx, row, row_info, section, map_directory, original_file_name, file_path, debug):    \n",
    "    \n",
    "   # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text_P = page.get_text(\"text\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "    \n",
    "    texto_PDF_P = text_P.replace('\\n', ' ') \n",
    "    if debug:\n",
    "        print(f'\\nFUNC extrai_texto_PDF_P: doc.:{original_file_name} | diretorio: {map_directory}  texto_PDF_P: \\n\\n{texto_PDF_P}\\n\\n')\n",
    "\n",
    "    return texto_PDF_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_cabecalho_PDF_P(idx, row, row_info, section, matches, doc, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    data_box_valores = {}\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        section = row_frame['section_json']\n",
    "        label = row_frame['label']\n",
    "        reference = row_frame['reference']\n",
    "        string_pesquisa = row_frame['marcador_inicio']  \n",
    "        \n",
    "        raw_value = next((doc[start:end].text for match_id, start, end in matches if nlp.vocab.strings[match_id] == label), None)\n",
    "        \n",
    "        most_similar_reference = max([reference], key=lambda x: similar(x, raw_value))\n",
    "        ##print(f'\\nmost_similar_reference: {most_similar_reference}\\n')\n",
    "        final_value = raw_value.split(\":\", 1)[-1].strip()\n",
    "        data_box_valores[label] = final_value\n",
    "\n",
    "    return data_box_valores        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> <b>2.x</b> ExecuÇao do Pipeline de Extracao </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta e o principio da melhor funcao do mundo\n",
    "def extracao_pipeline(qualquer_df, fase, atividade, status, debug=False, prestador=True, tomador=True, servicos=True, total=True, cnae=True, valores_impostos=True, complementares=True, outras_informacoes=True, observacoes=True):\n",
    "    \n",
    "    doc_info = {}\n",
    "    resumo = {}\n",
    "    row_teste_info = []\n",
    "    time_now = cron.timenow_pt_BR()\n",
    "    func_fase = fase\n",
    "    func_atividade = atividade\n",
    "    func_status = status\n",
    "    lista_dicts = []\n",
    "    conf_processo = {}\n",
    "    lista_conferencia = []\n",
    "   \n",
    "    i = 1\n",
    "    for idx, row in qualquer_df.iterrows():\n",
    "        dados_iniciais = {}\n",
    "        row_info = row.to_dict()\n",
    "        message_erro = []\n",
    "        # 1. Mapeamento de informacoes do DF\n",
    "        map_document_unique_id = idx\n",
    "        map_seq = row['seq']\n",
    "        map_batch_name = row['batch']\n",
    "        map_fase_processo = row['fase_processo']\n",
    "        map_nome_atividade = row['nome_atividade']\n",
    "        map_status_documento = row['status_documento']\n",
    "        map_original_file_name = row['original_file_name']\n",
    "        map_directory = row['directory']\n",
    "        map_one_page = row['one_page']\n",
    "        map_palavra_chave = row['palavra_chave']\n",
    "        map_document_tag = row['document_tag']\n",
    "        map_action_item = row['action_item']\n",
    "        map_level = row['level']\n",
    "        file_path = row['file_path']\n",
    "        row_info['document_unique_id'] = map_document_unique_id\n",
    "    \n",
    "        # XXX Nivel 1 - Definindo que documentos serao tratados    \n",
    "        if map_status_documento == 'PREPROCESS_EXTRACT':\n",
    "            \n",
    "            action_item_row_info = 'CONTINUE_PROCESS'\n",
    "            row_info['action_item'] = action_item_row_info\n",
    "            information_row_info = 'iniciado processamento'\n",
    "            row_info['informations'] = information_row_info\n",
    "            # 0. DADOS GERAIS DOCUMENTO\n",
    "            section = \"0. DADOS INICIAIS\"\n",
    "            try:\n",
    "                valores = {}\n",
    "                # 1. XXX Extracao de todos os dados do documento PDF Pesquisavel\n",
    "                texto_PDF = extrai_texto_PDF_P(idx, row, row_info, section, map_directory, map_original_file_name, file_path, debug)\n",
    "                \n",
    "                \n",
    "                if texto_PDF:\n",
    "                    pdf_pesquisavel_map = True\n",
    "                else:\n",
    "                    ppdf_pesquisavel_mapl = False\n",
    "                    valores = extrai_texto_R_PDF(idx, row, row_info, section, map_directory, map_original_file_name, file_path, debug)\n",
    "                    \n",
    "                \n",
    "                # 2. XXX IMPORTANTE - Efetuo a busca de entidades e efetuo a tokenizaÇao do documento\n",
    "                doc, tokens, ents = show_ent_new(texto_PDF, patterns=patterns)\n",
    "                \n",
    "                matches = matcher(doc)\n",
    "                \n",
    "                prefeitura_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"nome_prefeitura\"][0]\n",
    "                de_para_pm = [ent.id_ for ent in doc.ents if ent.label_ == \"nome_prefeitura\"][0]\n",
    "                secretaria_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"secretaria\"][0]\n",
    "                tipo_documento_map = [ent.orth_ for ent in doc.ents if ent.label_ == \"tipo_documento\"][0]\n",
    "                \n",
    "                #print(f'\\nNivel 1 - map_seq: {map_seq} | pref.: {prefeitura_map} de_para_pm: {de_para_pm} | documento: {map_original_file_name}')\n",
    "                f_type = 'document'\n",
    "                result = utl.filtrar_df(frames_nf_v4_df, type=f_type, de_para_pm=de_para_pm)\n",
    "                #print(result)\n",
    "                model_map = result['model'].values[0]\n",
    "                #print(f'\\nNivel 1 - map_seq: {map_seq} | pref.: {prefeitura_map} de_para_pm: {de_para_pm} | model: {model} | documento: {map_original_file_name}')\n",
    "            except Exception as e:\n",
    "                msg = (f'Erro ao processar_dados_iniciais: {e}')\n",
    "            finally:\n",
    "                row_info['pdf_pesquisavel'] = pdf_pesquisavel_map\n",
    "                row_info['texto_PDF'] = texto_PDF\n",
    "                row_info['doc_PDF'] = doc\n",
    "                row_info['model'] = model_map\n",
    "                row_info['tipo_nota_fiscal'] = tipo_documento_map\n",
    "                row_info['secretaria'] = secretaria_map\n",
    "                row_info['prefeitura'] = prefeitura_map\n",
    "                information_row_info = \"Este e apenas um comeco - mas bem comeco mesmo\"\n",
    "                action_item_row_info = 'CONTINUE_PROCESS'\n",
    "   \n",
    "            # XXX Nivel 2 - Definindo que os documentos legiveis serao tratados\n",
    "            if action_item_row_info == 'CONTINUE_PROCESS':\n",
    "                \n",
    "                # if not pdf_pesquisavel_map:\n",
    "                #     # NOVO PROCESSO DE TRATAMENTO DE IMAGEM - Convertendo a imagem para numpy array\n",
    "                #     if debug:\n",
    "                #         print(\"irei gerar a imagem_np\")\n",
    "                #     imagem_gray, image_resized_name = convert_resize_gray(map_original_file_name, file_path, image_resized_path)\n",
    "                #     imagem_gray_rgb = imagem_gray.convert(\"RGB\")\n",
    "                #     imagem_gray_np = np.array(imagem_gray_rgb)\n",
    "                #     row_info['image_np'] = imagem_gray_np\n",
    "                \n",
    "                # 1. CABECALHO\n",
    "                # try:\n",
    "                section = \"1. CABECALHO\"\n",
    "                valores = {}\n",
    "                mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "                context_mapping = \"data_cabecalho\"\n",
    "                def_replace = True \n",
    "                \n",
    "                if pdf_pesquisavel_map:\n",
    "                     valores = processar_cabecalho_PDF_P(idx, row, row_info, section, matches, doc, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)\n",
    "                     row_info.update(valores) \n",
    "                # else:\n",
    "                #     valores = processar_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)   \n",
    "                #     row_info.update(valores)\n",
    "         \n",
    "                # #status_documento_row_info = row_info.get('status_documento')\n",
    "                # action_item_row_info = row_info.get('action_item')\n",
    "                # information_row_info = row_info.get('informations')   \n",
    "                information_row_info = \"Este e apenas um comeco\"\n",
    "                action_item_row_info = 'CONTINUE_PROCESS'\n",
    "                \n",
    "                # XXX Nivel 3 - Definindo que os documentos legiveis serao tratados realmente\n",
    "                if action_item_row_info == 'BREAK_PROCESS':\n",
    "                    #msg = (f'Processo inicial: {map_batch_name} | {map_original_file_name} | diretorio: {map_directory} - information_row_info: {information_row_info}')\n",
    "                    if debug:\n",
    "                        print(f'\\nINFELIZMENTE - seq: {map_seq} doc: {map_original_file_name} dir: {map_directory} - NAO SERA PROCESSADO  | inf: {information_row_info} \\n\\n')\n",
    "               \n",
    "                    #row_info['informations'] = msg\n",
    "                    # logging.error(msg)\n",
    "                    lista_dicts.append(row_info)\n",
    "                    continue \n",
    "                \n",
    "                    \n",
    "                elif action_item_row_info == 'CONTINUE_PROCESS':\n",
    "                    if debug:\n",
    "                        print(f'\\nEBA, BORA CONTINUAR - seq: {map_seq} - proxima section: | PDF Pesquisavel: {pdf_pesquisavel_map} doc: {map_original_file_name} dir: {map_directory} | action_item: {action_item_row_info} | inf: {information_row_info} \\n\\n')\n",
    "                        print()\n",
    "                        print(valores)\n",
    "                    \n",
    "                    information_row_info = 'Cabecalho processado'\n",
    "                    row_info['informations'] = information_row_info\n",
    "                    \n",
    "                    \n",
    "                    # guarda_texto_doc = {}\n",
    "                    # guarda_texto_doc, linhas = cria_guarda_doc_ref_R_PDF(idx, row, de_para_map, model_map, map_original_file_name, file_path, image_resized_path, debug)\n",
    "            \n",
    "                    # 2. PRESTADOR DE SERVIÇO\n",
    "                    if prestador == True:\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        valores = {}\n",
    "                        erros_prestador = {}\n",
    "                        data_tomador = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_prestador_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            valores = extrai_prestador_R_PDF(idx, row, row_info, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        \n",
    "                        if not isinstance(valores, dict):\n",
    "                            msg_erro = (f\"\\nErro na linha {idx}: 'valores' não é um dicionário. Tipo: {type(valores)}, Valor: {valores}\")\n",
    "                        else:\n",
    "                            row_info.update(valores)\n",
    "                            \n",
    "                        # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                        # if debug:\n",
    "                        #     print(msg)\n",
    "                        # logging.info(msg)\n",
    "                    \n",
    "                    # 3. TOMADOR DE SERVIÇO\n",
    "                    if tomador == True:\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        \n",
    "                        valores = {}\n",
    "                        erros = []\n",
    "                        data_tomador = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        \n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_tomador_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        else:   \n",
    "                            valores = extrai_tomador_R_PDF(idx, row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                            \n",
    "                        if not isinstance(valores, dict):\n",
    "                            print(f\"\\nErro na linha {idx}: 'valores' não é um dicionário. Tipo: {type(valores)}, Valor: {valores}\")\n",
    "                        else:\n",
    "                            row_info.update(valores)\n",
    "                        \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)\n",
    "                    \n",
    "                    # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                    if servicos == True:\n",
    "                        if debug:\n",
    "                            print(f'processando servicos para: {map_original_file_name}')\n",
    "                        section = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                        valores = {}\n",
    "                        nf_data_servico = {} \n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        \n",
    "                        if pdf_pesquisavel_map:\n",
    "                            nf_data_servico = processar_servicos_pdf_pesquisavel(row, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            label = \"discriminacao_servicos\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = True\n",
    "                            \n",
    "                            # ItSs  working\n",
    "                            texto_extraido = extracao_documento_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            row_info[label] = texto_extraido\n",
    "                            \n",
    "                        msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                        if debug:\n",
    "                            print(msg)\n",
    "                        logging.info(msg)     \n",
    "\n",
    "\n",
    "                        try:\n",
    "                            texto_extraido = nf_data_servico['discriminacao_servicos'] \n",
    "                            row_info['discriminacao_servicos'] = texto_extraido \n",
    "                        except Exception as e:\n",
    "                            msg = (f\"doc: {map_original_file_name} | {e}\")\n",
    "                            discrimanacao_servico = \"Descricao nao encontrada\"\n",
    "                            row_info['discriminacao_servicos'] = texto_extraido\n",
    "\n",
    "                    \n",
    "                    # 5. VALOR TOTAL\n",
    "                    if total == True:\n",
    "                        section = \"5. VALOR TOTAL\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        #valores = {}\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valor_total_documento = processar_valor_total_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, model_map, map_original_file_name, file_path, debug)\n",
    "                            if valor_total_documento:\n",
    "                                if debug:\n",
    "                                    print(f'\\nvalor_total_documento: {valor_total_documento} | doc: {map_original_file_name}\\n')\n",
    "                                row_info['valor_total_nota'] = valor_total_documento\n",
    "                        else:\n",
    "                            label = \"valor_total_nota\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = True\n",
    "                            texto_extraido = extracao_documento_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            if texto_extraido: \n",
    "                                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', texto_extraido)\n",
    "                                if valor_total_match:\n",
    "                                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                                    try:\n",
    "                                        # valores['secao'] = section\n",
    "                                        valor_total_documento = float(valor_total_sem_formatacao)\n",
    "                                    except Exception as e:\n",
    "                                        # valores['secao'] = section\n",
    "                                        valor_total_documento = 0.0\n",
    "                                        msg = (f'Processo inicial: {batch_name} | {map_original_file_name:>25} | diretorio: {map_directory} | {e}')\n",
    "                                        #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")\n",
    "                        \n",
    "                                    if valor_total_documento:\n",
    "                                        if debug:\n",
    "                                            print(f'\\nvalor_total_documento: {valor_total_documento} | doc: {map_original_file_name}\\n')\n",
    "                                        row_info['valor_total_nota'] = valor_total_documento\n",
    "         \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)\n",
    "                    \n",
    "                    # 6. CNAE e Item da Lista de Serviços \n",
    "                    if cnae == True:\n",
    "                        section = \"6. CNAE e Item da Lista de Serviços\"\n",
    "                        data_box_valores = {}\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        f_0_cnae = 0.95\n",
    "                        f_1_cnae = 1.15\n",
    "                        f_0_it = 0.95     #0.95\n",
    "                        f_1_it = 1.15    # 1\n",
    "                        \n",
    "                        mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "                        context_mapping = \"data_cnae\"\n",
    "                        def_replace = True\n",
    "                        \n",
    "                        if pdf_pesquisavel_map:\n",
    "                            data_box_valores = extracao_documento_CNAE_ITEM_PDF_P(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, def_replace, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            data_box_valores = extracao_documento_CNAE_ITEM_R_PDF(idx, row, row_info, guarda_texto_doc, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, def_replace, map_original_file_name, file_path, debug)\n",
    "                            \n",
    "                        if data_box_valores:\n",
    "                            row_info.update(data_box_valores)    \n",
    "\n",
    "                    \n",
    "                    # 7. VALORES E IMPOSTOS\n",
    "                    if valores_impostos == True:\n",
    "                        section = \"7. VALORES E IMPOSTOS\"\n",
    "                        # if debug:\n",
    "                        print(f'processando {section} para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                        valores = {}\n",
    "                        nf_data_valores = {}\n",
    "                        lista_impostos = []\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_valores_impostos_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                            row_info.update(valores)\n",
    "                        \n",
    "                        else:\n",
    "                            tipo = \"field_box\"\n",
    "                            father_value = \"5_frame_valores_impostos\"\n",
    "                            valores = extracao_impostos_R_PDF(section, tipo, father_value, de_para_map, model_map, map_original_file_name, file_path)\n",
    "                            #print(valores)\n",
    "                            row_info.update(valores)\n",
    "                        \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg) \n",
    "                    \n",
    "                    # 8. DADOS COMPLEMENTARES\n",
    "                    if complementares == True:\n",
    "                        section = '8. DADOS COMPLEMENTARES'\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        nf_data_dados_complementares = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            nf_data_valores = extrai_dados_complementares_PDF_P(idx, row, row_info, section, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path, debug)\n",
    "                        else:\n",
    "                            label = \"dados_complementares\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = False\n",
    "                            # ItSs  working\n",
    "                            texto_extraido = extracao_complementar_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            row_info[label] = texto_extraido  \n",
    "\n",
    "                    \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)     \n",
    "                    \n",
    "                    # 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "                    if outras_informacoes == True:\n",
    "                        section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')\n",
    "                        tipo = \"field_box\"\n",
    "                        father_value = \"5_frame_inf_criticas\"\n",
    "                        valores = {} \n",
    "                        nf_data_outras_informacoes = {}\n",
    "                        f_0 = 1\n",
    "                        f_1 = 1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_outras_informacoes_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                        else:\n",
    "                            section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "                            tipo = \"field_box\"\n",
    "                            father_value = \"5_frame_inf_criticas\"\n",
    "                            valores = extracao_inforacoes_criticas_R_PDF(section, tipo, father_value, de_para_map, model_map, map_original_file_name, file_path)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                            \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)\n",
    "                    # logging.info(msg)          \n",
    "                            \n",
    "                    \n",
    "                    # 10. OBSERVACOES\n",
    "                    if observacoes == True:  \n",
    "                        section = \"10. OBSERVACOES\"\n",
    "                        if debug:\n",
    "                            print(f'processando {section} para: {map_original_file_name}')  \n",
    "                        data_observacao = {}\n",
    "                        valores = {}\n",
    "                        f_0 = 0.9\n",
    "                        f_1 = 1.1\n",
    "                        if pdf_pesquisavel_map:\n",
    "                            valores = extrai_outras_informacoes_PDF_P(row, pdf_pesquisavel_map, de_para_map, model_map, f_0, f_1, map_original_file_name, file_path)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                        else:\n",
    "                            section = '10. OBSERVACOES'\n",
    "                            tipo = \"field_box\"\n",
    "                            father_value = \"6_section_inf_complementares_criticas\" \n",
    "                            \n",
    "                            label = \"observacao\"\n",
    "                            tipo = \"field_box\"\n",
    "                            def_replace = True\n",
    "                            valores = extracao_observacoees_R_PDF(idx, row, guarda_texto_doc, section, tipo, label, de_para_map, model_map, def_replace, map_original_file_name, debug)\n",
    "                            if valores:\n",
    "                                row_info.update(valores)\n",
    "                    \n",
    "                    # msg = (f'secao: {section:>15} processada para: {map_original_file_name} - diretorio: {map_directory}')\n",
    "                    # if debug:\n",
    "                    #     print(msg)           \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                lista_dicts.append(row_info)\n",
    "                \n",
    "                \n",
    "            elif action_item_row_info == 'BREAK_PROCESS':\n",
    "                \n",
    "                msg = (f'Documento sem qualidade para pesquisa inicial: {map_batch_name} | {map_original_file_name} | diretorio: {map_directory}')\n",
    "                row_info['informations'] = msg  \n",
    "                \n",
    "            \n",
    "                lista_dicts.append(row_info)\n",
    "                continue\n",
    "                         \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        elif map_status_documento == 'NO_PROCESS':\n",
    "            msg = (f'Documento nao sera tratado neste escopo: {map_batch_name} | {map_original_file_name} | diretorio: {map_directory}')\n",
    "            row_info['action_item'] = \"NO_PROCESS\"    \n",
    "            row_info['informations'] = msg \n",
    "            lista_dicts.append(row_info)\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        #lista_dicts.append(row_info)\n",
    "        i += 1\n",
    "\n",
    "    #logging.info(f'processamento finalizado para: {batch_name}') \n",
    "    print(f'processamento de {i} documentos')\n",
    "    novo_df = pd.DataFrame(lista_dicts)\n",
    "    return lista_dicts\n",
    "    #return novo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRmyPDF completed successfully. Output saved to /home/dani-boy/extractNF/processamentos/temp/documento.pdf.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'pdf_pesquisavel_map' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m lista_dicts \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#logging.info(f'Execuçao do pipeline para {batch_name} | df_root_pipe: {file_path_root_pipe} fase: {fase} atividade: {atividade} status: {status}  template: {ver}')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# 1. Processar somente dados iniciais e cabeçalho\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m lista_dicts \u001b[39m=\u001b[39m extracao_pipeline(df_root_pipe, fase, atividade, status, debug\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, prestador\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, tomador\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, servicos\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, total\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, cnae\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, valores_impostos\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, complementares\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, outras_informacoes\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, observacoes\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb Cell 32\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mErro ao processar_dados_iniciais: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m     row_info[\u001b[39m'\u001b[39m\u001b[39mpdf_pesquisavel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pdf_pesquisavel_map\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m     row_info[\u001b[39m'\u001b[39m\u001b[39mtexto_PDF\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m texto_PDF\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/2_extract_pipeline_NLP_V0.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m     row_info[\u001b[39m'\u001b[39m\u001b[39mdoc_PDF\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m doc\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'pdf_pesquisavel_map' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# analisar_pdf_pesquisavel\n",
    "fase = 'analise'\n",
    "atividade = 'PREPROCESS' \n",
    "status = 'PREPROCESS_EXTRACT'\n",
    "raw_document_list = []\n",
    "dados_prest = {}\n",
    "\n",
    "lista_dicts = []\n",
    "#logging.info(f'Execuçao do pipeline para {batch_name} | df_root_pipe: {file_path_root_pipe} fase: {fase} atividade: {atividade} status: {status}  template: {ver}')\n",
    "\n",
    "# 1. Processar somente dados iniciais e cabeçalho\n",
    "lista_dicts = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_PDF_Pesquisavel = lista_dicts[0]['texto_PDF']\n",
    "texto_PDF_Pesquisavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_PDF_Pesquisavel, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processo Raster - documento todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"pipeline_extracao_documentos/0_arquivos_teste_pipeline/pdf_raster/Mage/Techmuniz 0032 Sys Manager.pdf\"\n",
    "output_file = \"/home/dani-boy/extractNF/processamentos/temp/documento.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.B Extracao de texto de todo o documento - RASTER PDF\t\n",
    "def extrai_texto_R_PDF(idx, row, row_info, section, map_directory, original_file_name, file_path, debug):    \n",
    "    \n",
    "    input_file = file_path\n",
    "\n",
    "    # 1. XXX Executar o comando OCRmyPDF\n",
    "    run_ocrmypdf(input_file, output_file)\n",
    "\n",
    "    # 2. XXX Executar o comando OCRmyPDF    \n",
    "    !pdftotext processamentos/temp/documento.pdf processamentos/temp/txt/documento.txt\n",
    "\n",
    "    # 3. XXX Ler o arquivo TXT\n",
    "    with open('processamentos/temp/txt/documento.txt', 'r', encoding='utf-8') as arquivo:\n",
    "        texto_OCR_R = arquivo.read()\n",
    "        \n",
    "    texto_PDF_Raster = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "    \n",
    "    if debug:\n",
    "        print(f'\\nFUNC extrai_texto_PDF_P: doc.:{original_file_name} | diretorio: {map_directory}  texto_PDF_Raster: \\n\\n{texto_PDF_Raster}\\n\\n')\n",
    "\n",
    "    return texto_PDF_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_PDF = extrai_texto_PDF_P(idx, row, row_info, section, map_directory, map_original_file_name, file_path, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCRmyPDF completed successfully. Output saved to /home/dani-boy/extractNF/processamentos/temp/documento.pdf.\n"
     ]
    }
   ],
   "source": [
    "input_file = file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_hr_emissao: Data e Hora da Emissão: 31/07/2023 17:29:00\n",
      "codigo_verificacao: Código Verificação: 4ADEE6A7B\n",
      "SIMPLES_NACIONAL_SIM: SIMPLES NACIONAL\n",
      "VALOR_TOTAL: VALOR TOTAL DA NOTA: R$ 252.836,00\n",
      "VALOR_SERVICOS: VALOR SERVIÇOS: R$ 252.836,00\n",
      "VALOR_DEDUCAO: DEDUÇÃO: R$ 0,00\n",
      "VALOR_ALIQUOTA: ALÍQUOTA: 2,01%\n",
      "VALOR_ISS: VALOR ISS: R$ 5.082,00\n",
      "VALOR_PIS: VALOR PIS: R$ 0,00\n",
      "VALOR_COFINS: VALOR COFINS: R$ 0,00\n",
      "VALOR_IR: VALOR IR: R$ 0,00\n",
      "VALOR_CSLL: VALOR CSLL: R$ 0,00\n",
      "VALOR_OUTRAS: OUTRAS RETENÇÕES: R$ 0,00\n",
      "VALOR_INSS: VALOR INSS: R$ 0,00\n",
      "VALOR_ISSRETIDO: VALOR ISS RETIDO: R$ 0,00\n",
      "VALOR_DESCCOND: DESC. COND: R$ 0,00\n",
      "VALOR_LIQUIDO: VALOR LÍQUIDO: R$ 252.836,00\n",
      "EXIGIBILIDADE_ISS: EXIGIBILIDADE ISS Exigivel\n",
      "SIMPLES_NACIONAL_SIM: SIMPLES NACIONAL\n",
      "SIMPLES_NACIONAL_SIM: SIMPLES NACIONAL Sim\n",
      "SIMPLES_NACIONAL_SIM: SIMPLES NACIONAL Sim (\n",
      "ISSQN_RETIDO: ISSQN RETIDO Não\n",
      "LOCAL_INCIDENCIA: LOCAL INCIDÊNCIA Magé\n",
      "LOCAL_INCIDENCIA: LOCAL INCIDÊNCIA Magé -\n",
      "LOCAL_INCIDENCIA: LOCAL INCIDÊNCIA Magé - RJ\n",
      "SIMPLES_NACIONAL_SIM: Simples Nacional\n",
      "SIMPLES_NACIONAL_SIM: Simples Nacional (\n",
      "VALOR_ALIQUOTA: Alíquota: 2,01 %\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">27/07/2023, 15:25 Nota Fiscal de Serviços Eletrônica (NFSe) https://nfe.mesquita.rj.gov.br 1/1 \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PREFEITURA MUNICIPAL DE MESQUITA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_prefeitura</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #2ADB5E, #1FA346); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SECRETARIA MUNICIPAL DA FAZENDA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">secretaria</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #09D6FF, #08A0D1); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">tipo_documento</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Número da Nota:\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " 20238 Competência: Julho/2023 Data e Hora da Emissão: 27/07/2023 15:21:00 Código Verificação: 3C86CC2F2 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PRESTADOR DE SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ:  \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    50.921.369/0001-05\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " Inscrição Municipal:  952538 Telefone:  2297268232.. Inscrição Estadual:   Nome/Razão Social: MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA Nome de Fantasia: Endereço: RUA PROCOPIO ,631 LOJA A ,SANTO ELIAS - Mesquita-RJ E-mail: LARA_VSORIA@HOTMAIL.COM \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TOMADOR DE SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ:  \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    06.047.087/0033-16\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       "    |     INSC:MUNICIPAL: 1664085 RG:   Telefone: Inscrição Estadual:   Nome/Razão Social: REDE D'OR SAO LUIZ S.A. Endereço:  OLINDA ELLIS N° 93 BAIRRO: CAMPO GRANDE CIDADE: RIO DE JANEIRO - RJ CEP: 23045160 E-mail: Não Informado \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DISCRIMINAÇÃO DOS SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " Ref a Plantões de Maio, 60h no Setor de Radiologia - Médica: Lara Veiga Soria Catuladeira. \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR TOTAL DA NOTA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 7.133,60 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CNAE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " - 8630502 - ATIVIDADE MÉDICA AMBULATORIAL COM RECURSOS PARA REALIZAÇÃO DE EXAMES COMPLEMENTARES Item da Lista de Serviços - 4.03 - HOSPITAIS, CLÍNICAS, LABORATÓRIOS, SANATÓRIOS, MANICÔMIOS, CASAS DE SAÚDE, PRONTOS-SOCORROS, AMBULATÓRIOS E CONGÊNERES.   \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 7.133,60 VALOR DEDUÇÃO: R$ 0,00 DESC. INCOND: R$ 0,00 BASE DE CÁLCULO: R$ 7.133,60 ALÍQUOTA: 2,01% VALOR ISS: R$ 143,39 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 ____________________________________________________________________ VALOR PIS: R$ 0,00 VALOR COFINS: R$ 0,00 VALOR IR: R$ 0,00 VALOR INSS: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR LÍQUIDO: R$ 7.133,60 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DADOS COMPLEMENTARES\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OUTRAS INFORMAÇÕES / CRITICAS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " EXIGIBILIDADE ISS Exigivel REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim ( 2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Mesquita - RJ LOCAL INCIDÊNCIA Mesquita - RJ \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Observação\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": LEI DA TRANSPARÊNCIA FISCAL NR. 12.741, DE 8 DE DEZEMBRO DE 2012. - \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PRESTADOR\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " OPTANTE DO SIMPLES NACIONAL (ALÍQUOTA: 2,01 %) Valor Aproximado dos Tributos Federais R$ 959,47 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 159,08 (Alíq IBPT 2,23 IBPT) </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_PDF_Pesquisavel, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.B CABECALHO XXX Funcoes de extracao -cabecalho Raster\n",
    "def processar_cabecalho_R_PDF(idx, row, row_info, section, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    data_box_conferencia = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    \n",
    "    batch_name_row_info = row_info.get('batch')\n",
    "    #status_documento_row_info = row_info.get('status_documento')\n",
    "    information_row_info = row_info.get('informations')\n",
    "    action_item_row_info = row_info.get('action_item')\n",
    "    \n",
    "    # Busco a imagem np do documento\n",
    "    image_np_row_info = row_info.get('image_np')\n",
    "    \n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "    data_box_valores['processo'] = context_mapping\n",
    "    data_box_valores['conf_cod'] = 0\n",
    "\n",
    "\n",
    "                     \n",
    "    \n",
    "    # busco coordenadas para o contexto\n",
    "    if mapping_method == \"frame_&_sframe_field\":\n",
    "        tipo_4_coordinates = \"frame\"\n",
    "        tipo_4_filter = \"sframe_field\"\n",
    "    \n",
    "   \n",
    "    # 2. usando a funcao de extracao de coordenadas por contexto    \n",
    "    coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "    x0, y0, x1, y1 = coordinates[0]\n",
    "    x0 = int(x0)\n",
    "    y0 = int(y0)\n",
    "    x1 = int(x1)\n",
    "    y1 = int(y1) \n",
    "    # 3. Cropo a imagem - novo modelo\n",
    "    cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "    data_box_conferencia[f'box_{context_mapping}'] = cropped_image_np\n",
    "    data_box_conferencia[f'coordinates_{context_mapping}'] = coordinates\n",
    "    # 4. Converto para PIL\n",
    "    cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "    # 6. Executo OCR\n",
    "    texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "    # 7. Trato o texto extraido = text_splited\n",
    "    text_splited = texto_extraido_cabecalho(texto_extraido)\n",
    "    if debug:\n",
    "        print()\n",
    "        plt.imshow(cropped_image_np)\n",
    "        plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "        plt.show()\n",
    "        print(f'\\ncoordinates {coordinates} - \\ntexto_extraido:\\n{text_splited}\\n')\n",
    "        \n",
    "    # 8. Efetuo o filtro para a iteracao\n",
    "    filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "    \n",
    "    # 9. iter sobre o filtro\n",
    "    for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "        try:\n",
    "            section = row_frame['section_json']\n",
    "            label = row_frame['label']\n",
    "            reference = row_frame['reference']\n",
    "            string_pesquisa = row_frame['marcador_inicio']  \n",
    "            keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "            texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "            data_box_valores[label] = texto\n",
    "            if debug:\n",
    "               print(f'\\nidx: {index_frame:> 3} | label: {label} |  string_pesquisa:{string_pesquisa} | dentro do try do raster PDF cabecalho - texto: \\n{texto}\\n\\n')\n",
    "        except Exception as e:\n",
    "            msg = (f\"{e}\")\n",
    "            data_box_conferencia[label] = msg\n",
    "    \n",
    "\n",
    "    # Verificações após o loop\n",
    "    for key, value in data_box_valores.items():\n",
    "        if key == 'numero_nota_fiscal' and value is None:\n",
    "            action_item_row_info = 'BREAK_PROCESS'\n",
    "            information_row_info = 'Número da Nota não encontrado'\n",
    "            #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "        \n",
    "        elif key == 'codigo_verificacao' and value != None:\n",
    "            codigo_verificacao_nf = value\n",
    "            tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "            data_box_valores['conf_cod'] = tam_codigo_verificacao\n",
    "            \n",
    "        \n",
    "        elif key != 'numero_nota_fiscal' and value is None:\n",
    "            logging.error(f\" {batch_name_row_info} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "            \n",
    "      # if value is None:\n",
    "        #     logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "\n",
    "    data_box_valores['action_item'] = action_item_row_info\n",
    "    data_box_valores['informations'] = information_row_info\n",
    "\n",
    "    \n",
    "    return data_box_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/dani-boy/extractNF/pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento/Batch_23/MESQUITA_PDF_31282023_2258/teste/1.pdf\"\n",
    "map_original_file_name = os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_info = {}\n",
    "\n",
    "imagem_gray, image_resized_name = convert_resize_gray(map_original_file_name, file_path, image_resized_path)\n",
    "imagem_gray_rgb = imagem_gray.convert(\"RGB\")\n",
    "imagem_gray_np = np.array(imagem_gray_rgb)\n",
    "row_info['image_np'] = imagem_gray_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"1. CABECALHO\"\n",
    "mapping_method = \"frame_&_sframe_field\" # significa que as coordenadas estao em frames e os valores dos campos nos sframe_fields\n",
    "context_mapping = \"data_cabecalho\"\n",
    "def_replace = True \n",
    "model_map = 'MAGE'\n",
    "pdf_pesquisavel_map = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_box_valores = {}\n",
    "data_box_valores['secao'] = section\n",
    "\n",
    "# Busco a imagem np do documento\n",
    "image_np_row_info = row_info.get('image_np')\n",
    "\n",
    "# busco coordenadas para o contexto\n",
    "if mapping_method == \"frame_&_sframe_field\":\n",
    "    tipo_4_coordinates = \"frame\"\n",
    "    tipo_4_filter = \"sframe_field\"\n",
    "\n",
    "# 2. usando a funcao de extracao de coordenadas por contexto    \n",
    "coordinates = get_coordinates_filter_by_context(pdf_pesquisavel_map, model_map, context_mapping, tipo_4_coordinates)\n",
    "x0, y0, x1, y1 = coordinates[0]\n",
    "x0 = int(x0)\n",
    "y0 = int(y0)\n",
    "x1 = int(x1)\n",
    "y1 = int(y1) \n",
    "# 3. Cropo a imagem - novo modelo\n",
    "cropped_image_np = image_np_row_info[y0:y1, x0:x1] # ajustar nos demais\n",
    "# 4. Converto para PIL\n",
    "cropped_image_pil = Image.fromarray(cropped_image_np)\n",
    "# 6. Executo OCR\n",
    "texto_extraido = pytesseract.image_to_string(cropped_image_pil, lang='por')\n",
    "# 7. Trato o texto extraido = text_splited\n",
    "texto_cabechalho_PDF_Raster = re.sub('\\s+', ' ', texto_extraido).strip() \n",
    "\n",
    "plt.imshow(cropped_image_np)\n",
    "plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_cabechalho_PDF_Raster, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero_nota_fiscal: Número da Nota: 1\n",
      "competencia: Competência: Julho/2023\n",
      "dt_hr_emissao: Data e Hora da Emissão: 31/07/2023 17:29:00\n",
      "codigo_verificacao: Código Verificação: 4ADEE6A7B\n"
     ]
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stt:  34 | end: 42 | string_id:                  dt_hr_emissao   span.text:  Data e Hora da Emissão: 31/07/2023 17:29:00 \n",
      "\n",
      "stt:  42 | end: 46 | string_id:             codigo_verificacao   span.text:                Código Verificação: 4ADEE6A7B \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texto_PDF_Raster)\n",
    "\n",
    "# Executar o Matcher no Doc\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    if string_id == 'numero_nota_fiscal':\n",
    "        print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')\n",
    "    elif string_id == 'competencia':    \n",
    "        print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')\n",
    "    elif string_id == 'dt_hr_emissao':\n",
    "        print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')\n",
    "    elif string_id == 'codigo_verificacao':\n",
    "        print(f'\\nstt: {start:>3} | end:{end:>3} | string_id: {string_id:>30}   span.text:{span.text:>45} ')    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Número da Nota: PREFEITURA MUNICIPAL DE MAGE já Competência: SECRETARIA MUNICIPAL DA FAZENDA Julho/2023 NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Data e Hora da Emissão: 26/07/2023 11:42:00] Código Verificação: 8A10EE0EF PRESTADOR DE SERVIÇOS CPF/CNPJ: 06.014.264/0001-80 Inscrição Municipal: 20525 Telefone: Inscrição Estadual: 2125160368. Nome/Razão n” a Social: TECHMUNIZ SOLUÇÕES TILTDA. Nome de Fantasia: Endereço: PÇA DR. NILO PECANHA ,137 SL 101 PARTE ,CENTRO - Magé-RJ E-mail: REGISTROGQLAFSCONTABILIDADE.COM.BR TOMADOR DE SERVIÇOS CPF/CNPJ: 01.369.056/0002-61 | | INSC:MUNICIPAL: RG: Telefone: Inscrição Estadual: Nome/Razão Social: SYS MANAGER INFORMATICA Endereço: LTDA. ALMIRANTE JÚLIO DE SÁ BIERRENBACH Nº 200 BLOCO 1B SALAS 101B 102B 121B 122B 123B 124B 125B BAIRRO: JACAREPAGUÁ CIDADE: RIO DE JANEIRO E-mail: NÃO INFORMADO - RJ CEP: 22775028 DISCRIMINAÇÃO DOS SERVIÇOS Prestação de serviço de instalação de Software - Documento emitido por ME ou EPP optante pelo Simples Nacional Prestação de serviços realizados em julho/2023 Dados bancários Banco: 0260 - Nu Pagamentos S.A. Agência: 0001 C/C: 31108642-3 Chave PIX: 06.014.264/0001-80 VALOR TOTAL DA NOTA: R$ 14.978,88 CNAE - 6209100 - SUPORTE TÉCNICO, MANUTENÇÃO E OUTROS SERVIÇOS EM TECNOLOGIA DA INFORMAÇÃO Item da Lista de Serviços - 1.07 - SUPORTE TÉCNICO EM INFORMÁTICA, INCLUSIVE INSTALAÇÃO, CONFIGURAÇÃO E MANUTENÇÃO DE PROGRAMAS DE COMPUTAÇÃO E BANCOS DE DADOS. [m]' E [=] a, Th nã VALOR SERVIÇOS: R$ 14.978,88 VALOR | DEDUÇÃO: R$ 0,00 VALOR PIS: R$ 0,00 VALOR COFINS: VALOR IR: R$ 0,00 R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CÁLCULO: R$ 14.978,88 ALÍQUOTA: 2,01% — VALORISS: R$ 301,08 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 do dh, : VALOR INSS: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR LÍQUIDO: R$ 14.978,88 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel Observação: REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 2014,66 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 441,88 (Alíq IBPT 2,95 IBPT)\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. XXX Ler o arquivo TXT\n",
    "with open('processamentos/temp/txt/documento.txt', 'r', encoding='utf-8') as arquivo:\n",
    "    texto_OCR_R = arquivo.read()\n",
    "    \n",
    "texto_PDF_Raster = re.sub('\\s+', ' ', texto_OCR_R).strip()  \n",
    "texto_PDF_Raster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Número da Nota:\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PREFEITURA MUNICIPAL DE MAGE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_prefeitura</span>\n",
       "</mark>\n",
       " já Competência: \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #2ADB5E, #1FA346); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SECRETARIA MUNICIPAL DA FAZENDA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">secretaria</span>\n",
       "</mark>\n",
       " Julho/2023 \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #09D6FF, #08A0D1); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">tipo_documento</span>\n",
       "</mark>\n",
       " Data e Hora da Emissão: 26/07/2023 11:42:00] Código Verificação: 8A10EE0EF \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PRESTADOR DE SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    06.014.264/0001-80\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " Inscrição Municipal: 20525 Telefone: Inscrição Estadual: 2125160368. Nome/Razão n” a Social: TECHMUNIZ SOLUÇÕES TILTDA. Nome de Fantasia: Endereço: PÇA DR. NILO PECANHA ,137 SL 101 PARTE ,CENTRO - Magé-RJ E-mail: REGISTROGQLAFSCONTABILIDADE.COM.BR \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TOMADOR DE SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    01.369.056/0002-61\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " | | INSC:MUNICIPAL: RG: Telefone: Inscrição Estadual: Nome/Razão Social: SYS MANAGER INFORMATICA Endereço: LTDA. ALMIRANTE JÚLIO DE SÁ BIERRENBACH Nº 200 BLOCO 1B SALAS 101B 102B 121B 122B 123B 124B 125B BAIRRO: JACAREPAGUÁ CIDADE: RIO DE JANEIRO E-mail: NÃO INFORMADO - RJ CEP: 22775028 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DISCRIMINAÇÃO DOS SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " Prestação de serviço de instalação de Software - Documento emitido por ME ou EPP optante pelo Simples Nacional Prestação de serviços realizados em julho/2023 Dados bancários Banco: 0260 - Nu Pagamentos S.A. Agência: 0001 C/C: 31108642-3 Chave PIX: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    06.014.264/0001-80\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR TOTAL DA NOTA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 14.978,88 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CNAE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " - 6209100 - SUPORTE TÉCNICO, MANUTENÇÃO E OUTROS SERVIÇOS EM TECNOLOGIA DA INFORMAÇÃO Item da Lista de Serviços - 1.07 - SUPORTE TÉCNICO EM INFORMÁTICA, INCLUSIVE INSTALAÇÃO, CONFIGURAÇÃO E MANUTENÇÃO DE PROGRAMAS DE COMPUTAÇÃO E BANCOS DE DADOS. [m]' E [=] a, Th nã \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 14.978,88 VALOR | DEDUÇÃO: R$ 0,00 VALOR PIS: R$ 0,00 VALOR COFINS: VALOR IR: R$ 0,00 R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CÁLCULO: R$ 14.978,88 ALÍQUOTA: 2,01% — VALORISS: R$ 301,08 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 do dh, : VALOR INSS: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR LÍQUIDO: R$ 14.978,88 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DADOS COMPLEMENTARES\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OUTRAS INFORMAÇÕES / CRITICAS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " EXIGIBILIDADE ISS Exigivel \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Observação\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ - \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Prestador\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 2014,66 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 441,88 (Alíq IBPT 2,95 IBPT)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc, tokens, ents = show_ent_new(texto_PDF_Raster, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |                                    Número da Nota: |              nome_section |                        1. CABECALHO  |      4   ||        0 |     15\n",
      "    4 |                       PREFEITURA MUNICIPAL DE MAGE |           nome_prefeitura |                             PM_MAGE  |      8   ||       16 |     44\n",
      "   11 |                    SECRETARIA MUNICIPAL DA FAZENDA |                secretaria |                          SECRETARIA  |     15   ||       61 |     92\n",
      "   16 |         NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e |            tipo_documento |                               NFS-e  |     23   ||      104 |    146\n",
      "   36 |                              PRESTADOR DE SERVIÇOS |              nome_section |             2. PRESTADOR DE SERVIÇO  |     39   ||      222 |    243\n",
      "   43 |                                 06.014.264/0001-80 |                      CNPJ |                                      |     45   ||      254 |    272\n",
      "   91 |                                TOMADOR DE SERVIÇOS |              nome_section |               3. TOMADOR DE SERVIÇO  |     94   ||      521 |    540\n",
      "   98 |                                 01.369.056/0002-61 |                      CNPJ |                                      |    100   ||      551 |    569\n",
      "  159 |                         DISCRIMINAÇÃO DOS SERVIÇOS |              nome_section |       4. DESCRIMINACAO DOS SERVIÇOS  |    162   ||      858 |    884\n",
      "  206 |                                 06.014.264/0001-80 |                      CNPJ |                                      |    208   ||     1133 |   1151\n",
      "  208 |                                VALOR TOTAL DA NOTA |              nome_section |                      5. VALOR TOTAL  |    212   ||     1152 |   1171\n",
      "  215 |                                               CNAE |              nome_section | 6. CNAE e Item da Lista de Serviços  |    216   ||     1186 |   1190\n",
      "  269 |                                     VALOR SERVIÇOS |              nome_section |               7. VALORES E IMPOSTOS  |    271   ||     1458 |   1472\n",
      "  352 |                               DADOS COMPLEMENTARES |              nome_section |             8. DADOS COMPLEMENTARES  |    354   ||     1810 |   1830\n",
      "  354 |                      OUTRAS INFORMAÇÕES / CRITICAS |              nome_section |    9. OUTRAS INFORMAÇOES / CRITICAS  |    358   ||     1831 |   1860\n",
      "  361 |                                         Observação |              nome_section |                     10. OBSERVACOES  |    362   ||     1888 |   1898\n",
      "  390 |                                          Prestador |              nome_section |             2. PRESTADOR DE SERVIÇO  |    391   ||     2048 |   2057\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(f'{ent.start:>5} | {ent.text:>50} | {ent.label_:>25} | {ent.id_:>35}  |   {ent.end:>4}   ||   {ent.start_char:>6} | {ent.end_char:>6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mark_char = [ent.start_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "mark_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secretaria_char = [ent.start_char for ent in doc.ents if ent.label_ == 'secretaria'][0]\n",
    "secretaria_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "start_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número da Nota: PREFEITURA MUNICIPAL DE MAGE já Competência: SECRETARIA MUNICIPAL DA FAZENDA Julho/2023 NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Número da Nota: 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B PREFEITURA MUNICIPAL DE MAGE já Competência: SECRETARIA MUNICIPAL DA FAZENDA Julho/2023 NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e Data e Hora da Emissão: 26/07/2023 11:42:00] Código Verificação: 8A10EE0EF PRESTADOR DE SERVIÇOS CPF/CNPJ: 06.014.264/0001-80 Inscrição Municipal: 20525 Telefone: Inscrição Estadual: 2125160368. Nome/Razão n” a Social: TECHMUNIZ SOLUÇÕES TILTDA. Nome de Fantasia: Endereço: PÇA DR. NILO PECANHA ,137 SL 101 PARTE ,CENTRO - Magé-RJ E-mail: REGISTROGQLAFSCONTABILIDADE.COM.BR TOMADOR DE SERVIÇOS CPF/CNPJ: 01.369.056/0002-61 | | INSC:MUNICIPAL: RG: Telefone: Inscrição Estadual: Nome/Razão Social: SYS MANAGER INFORMATICA Endereço: LTDA. ALMIRANTE JÚLIO DE SÁ BIERRENBACH Nº 200 BLOCO 1B SALAS 101B 102B 121B 122B 123B 124B 125B BAIRRO: JACAREPAGUÁ CIDADE: RIO DE JANEIRO E-mail: NÃO INFORMADO - RJ CEP: 22775028 DISCRIMINAÇÃO DOS SERVIÇOS Prestação de serviço de instalação de Software - Documento emitido por ME ou EPP optante pelo Simples Nacional Prestação de serviços realizados em julho/2023 Dados bancários Banco: 0260 - Nu Pagamentos S.A. Agência: 0001 C/C: 31108642-3 Chave PIX: 06.014.264/0001-80 VALOR TOTAL DA NOTA: R$ 14.978,88 CNAE - 6209100 - SUPORTE TÉCNICO, MANUTENÇÃO E OUTROS SERVIÇOS EM TECNOLOGIA DA INFORMAÇÃO Item da Lista de Serviços - 1.07 - SUPORTE TÉCNICO EM INFORMÁTICA, INCLUSIVE INSTALAÇÃO, CONFIGURAÇÃO E MANUTENÇÃO DE PROGRAMAS DE COMPUTAÇÃO E BANCOS DE DADOS. [m]' E [=] a, Th nã VALOR SERVIÇOS: R$ 14.978,88 VALOR | DEDUÇÃO: R$ 0,00 VALOR PIS: R$ 0,00 VALOR COFINS: VALOR IR: R$ 0,00 R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CÁLCULO: R$ 14.978,88 ALÍQUOTA: 2,01% — VALORISS: R$ 301,08 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 do dh, : VALOR INSS: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR LÍQUIDO: R$ 14.978,88 DADOS COMPLEMENTARES OUTRAS INFORMAÇÕES / CRITICAS EXIGIBILIDADE ISS Exigivel Observação: REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ - Prestador Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 2014,66 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 441,88 (Alíq IBPT 2,95 IBPT)\n"
     ]
    }
   ],
   "source": [
    "# Seu texto OCR do cabeçalho\n",
    "header_text = texto_cabechalho_PDF_Raster\n",
    "\n",
    "# Seu texto OCR completo\n",
    "original_text = texto_PDF_Raster\n",
    "\n",
    "# Localizando as posições das seções relevantes\n",
    "tipo_documento_end_char = [ent.end_char for ent in doc.ents if ent.label_ == 'tipo_documento'][0]\n",
    "nome_prefeitura_start_char = [ent.start_char for ent in doc.ents if ent.label_ == 'nome_prefeitura'][0]\n",
    "\n",
    "# Eliminando o texto que precede a 'nome_prefeitura'\n",
    "cleaned_text = original_text[nome_prefeitura_start_char:]\n",
    "\n",
    "# Inserindo o texto do cabeçalho após o 'tipo_documento'\n",
    "recomposed_text = original_text[:tipo_documento_end_char] + ' ' + header_text + ' ' + cleaned_text\n",
    "\n",
    "print(recomposed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Número da Nota:\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PREFEITURA MUNICIPAL DE MAGE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_prefeitura</span>\n",
       "</mark>\n",
       " já Competência: \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #2ADB5E, #1FA346); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SECRETARIA MUNICIPAL DA FAZENDA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">secretaria</span>\n",
       "</mark>\n",
       " Julho/2023 \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #09D6FF, #08A0D1); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">tipo_documento</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Número da Nota:\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " 1 Competência: Julho/2023 Data e Hora da Emissão: 31/07/2023 17:29:00 Código Verificação: 4ADEE6A7B \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PREFEITURA MUNICIPAL DE MAGE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_prefeitura</span>\n",
       "</mark>\n",
       " já Competência: \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #2ADB5E, #1FA346); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    SECRETARIA MUNICIPAL DA FAZENDA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">secretaria</span>\n",
       "</mark>\n",
       " Julho/2023 \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #09D6FF, #08A0D1); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">tipo_documento</span>\n",
       "</mark>\n",
       " Data e Hora da Emissão: 26/07/2023 11:42:00] Código Verificação: 8A10EE0EF \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    PRESTADOR DE SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    06.014.264/0001-80\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " Inscrição Municipal: 20525 Telefone: Inscrição Estadual: 2125160368. Nome/Razão n” a Social: TECHMUNIZ SOLUÇÕES TILTDA. Nome de Fantasia: Endereço: PÇA DR. NILO PECANHA ,137 SL 101 PARTE ,CENTRO - Magé-RJ E-mail: REGISTROGQLAFSCONTABILIDADE.COM.BR \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TOMADOR DE SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " CPF/CNPJ: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    01.369.056/0002-61\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " | | INSC:MUNICIPAL: RG: Telefone: Inscrição Estadual: Nome/Razão Social: SYS MANAGER INFORMATICA Endereço: LTDA. ALMIRANTE JÚLIO DE SÁ BIERRENBACH Nº 200 BLOCO 1B SALAS 101B 102B 121B 122B 123B 124B 125B BAIRRO: JACAREPAGUÁ CIDADE: RIO DE JANEIRO E-mail: NÃO INFORMADO - RJ CEP: 22775028 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DISCRIMINAÇÃO DOS SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " Prestação de serviço de instalação de Software - Documento emitido por ME ou EPP optante pelo Simples Nacional Prestação de serviços realizados em julho/2023 Dados bancários Banco: 0260 - Nu Pagamentos S.A. Agência: 0001 C/C: 31108642-3 Chave PIX: \n",
       "<mark class=\"entity\" style=\"background: #7AECEC; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    06.014.264/0001-80\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CNPJ</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR TOTAL DA NOTA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 14.978,88 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CNAE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " - 6209100 - SUPORTE TÉCNICO, MANUTENÇÃO E OUTROS SERVIÇOS EM TECNOLOGIA DA INFORMAÇÃO Item da Lista de Serviços - 1.07 - SUPORTE TÉCNICO EM INFORMÁTICA, INCLUSIVE INSTALAÇÃO, CONFIGURAÇÃO E MANUTENÇÃO DE PROGRAMAS DE COMPUTAÇÃO E BANCOS DE DADOS. [m]' E [=] a, Th nã \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    VALOR SERVIÇOS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": R$ 14.978,88 VALOR | DEDUÇÃO: R$ 0,00 VALOR PIS: R$ 0,00 VALOR COFINS: VALOR IR: R$ 0,00 R$ 0,00 DESC. INCOND: BASE DE R$ 0,00 CÁLCULO: R$ 14.978,88 ALÍQUOTA: 2,01% — VALORISS: R$ 301,08 VALOR ISS RETIDO: R$ 0,00 DESC. COND: R$ 0,00 do dh, : VALOR INSS: R$ 0,00 VALOR CSLL: R$ 0,00 OUTRAS RETENÇÕES: R$ 0,00 VALOR LÍQUIDO: R$ 14.978,88 \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DADOS COMPLEMENTARES\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    OUTRAS INFORMAÇÕES / CRITICAS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " EXIGIBILIDADE ISS Exigivel \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Observação\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       ": REGIME TRIBUTAÇÃO Sociedade Limitada SIMPLES NACIONAL Sim (2,01% ) ISSQN RETIDO Não LOCAL. PRESTAÇÃO SERVIÇO Magé - RJ LOCAL INCIDÊNCIA Magé - RJ - \n",
       "<mark class=\"entity\" style=\"background: #FFEA7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Prestador\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">nome_section</span>\n",
       "</mark>\n",
       " Optante do Simples Nacional (Alíquota: 2,01 %) Valor Aproximado dos Tributos Federais R$ 2014,66 (Alíq 13,45), Tributos Estaduais R$ 0,00 (Alíq 0,00 IBPT) e Municipal de R$ 441,88 (Alíq IBPT 2,95 IBPT)</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc, tokens, ents = show_ent_new(recomposed_text, patterns=patterns)\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_cabecalho_R_PDF(idx, row, row_info, section, matches, doc, mapping_method, context_mapping, pdf_pesquisavel_map, model_map, original_file_name, file_path, debug):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_splited = texto_extraido_cabecalho(texto_extraido)\n",
    "if debug:\n",
    "    print()\n",
    "    plt.imshow(cropped_image_np)\n",
    "    plt.axis('off')  # Desativa os eixos para uma visualização mais limpa\n",
    "    plt.show()\n",
    "    print(f'\\ncoordinates {coordinates} - \\ntexto_extraido:\\n{text_splited}\\n')\n",
    "    \n",
    "# 8. Efetuo o filtro para a iteracao\n",
    "filtered_frame_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model_map) & (frames_nf_v4_df['context_mapping'] == context_mapping) & (frames_nf_v4_df['type'] == tipo_4_filter)]\n",
    "\n",
    "# 9. iter sobre o filtro\n",
    "for index_frame, row_frame in filtered_frame_nf_v4_df.iterrows():\n",
    "    try:\n",
    "        section = row_frame['section_json']\n",
    "        label = row_frame['label']\n",
    "        reference = row_frame['reference']\n",
    "        string_pesquisa = row_frame['marcador_inicio']  \n",
    "        keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        data_box_valores[label] = texto\n",
    "        if debug:\n",
    "            print(f'\\nidx: {index_frame:> 3} | label: {label} |  string_pesquisa:{string_pesquisa} | dentro do try do raster PDF cabecalho - texto: \\n{texto}\\n\\n')\n",
    "    except Exception as e:\n",
    "        msg = (f\"{e}\")\n",
    "        data_box_conferencia[label] = msg\n",
    "\n",
    "\n",
    "# Verificações após o loop\n",
    "for key, value in data_box_valores.items():\n",
    "    if key == 'numero_nota_fiscal' and value is None:\n",
    "        action_item_row_info = 'BREAK_PROCESS'\n",
    "        information_row_info = 'Número da Nota não encontrado'\n",
    "        #logging.error(f\" {batch_name} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir\n",
    "    \n",
    "    elif key == 'codigo_verificacao' and value != None:\n",
    "        codigo_verificacao_nf = value\n",
    "        tam_codigo_verificacao = len(codigo_verificacao_nf)\n",
    "        data_box_valores['conf_cod'] = tam_codigo_verificacao\n",
    "        \n",
    "    \n",
    "    elif key != 'numero_nota_fiscal' and value is None:\n",
    "            logging.error(f\" {batch_name_row_info} |  doc: {original_file_name:>25} | setion:{section:20} | item: {key:>20} | erro na extracaçao | file_path: {file_path:>40} \")  # Ou registre o erro de outra forma que preferir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texto_amostra = \"NFS-e Número da Nota: 20234 Competência: Julho/2023\"\n",
    "texto_amostra = \"'outras informações / criticas'\"\n",
    "\n",
    "doc = nlp(texto_amostra)\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Exibir os resultados\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Obter a string de identificação\n",
    "    span = doc[start:end]  # Obter o trecho correspondente\n",
    "    print(f\"{string_id}: {span.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>T_texto</th>\n",
       "      <th>T_shape</th>\n",
       "      <th>T_is_alpha</th>\n",
       "      <th>T_is_digit</th>\n",
       "      <th>T_is_title</th>\n",
       "      <th>T_is_punct</th>\n",
       "      <th>T_is_sent_start</th>\n",
       "      <th>T_is_right_punct</th>\n",
       "      <th>T_is_stop</th>\n",
       "      <th>T_is_quote</th>\n",
       "      <th>T_is_currency</th>\n",
       "      <th>T_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>outras</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Plur, PronType=Ind)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>informações</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Plur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>criticas</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Plur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id      T_texto T_shape T_is_alpha T_is_digit T_is_title T_is_punct  \\\n",
       "0  0            '       '      False      False      False       True   \n",
       "1  1       outras    xxxx       True      False      False      False   \n",
       "2  2  informações    xxxx       True      False      False      False   \n",
       "3  3            /       /      False      False      False       True   \n",
       "4  4     criticas    xxxx       True      False      False      False   \n",
       "5  5            '       '      False      False      False       True   \n",
       "\n",
       "  T_is_sent_start T_is_right_punct T_is_stop T_is_quote T_is_currency  \\\n",
       "0            True             True     False       True         False   \n",
       "1           False            False      True      False         False   \n",
       "2           False            False     False      False         False   \n",
       "3           False            False     False      False         False   \n",
       "4           False            False     False      False         False   \n",
       "5           False             True     False       True         False   \n",
       "\n",
       "                                   T_morph  \n",
       "0                                       ()  \n",
       "1  (Gender=Fem, Number=Plur, PronType=Ind)  \n",
       "2                (Gender=Fem, Number=Plur)  \n",
       "3                                       ()  \n",
       "4                (Gender=Fem, Number=Plur)  \n",
       "5                                       ()  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisys\n",
    "syntatic = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_shape\", \"T_is_alpha\", \"T_is_digit\", \"T_is_title\", \"T_is_punct\", \"T_is_sent_start\", \"T_is_right_punct\", \"T_is_stop\", \"T_is_quote\", \"T_is_currency\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    syntatic.loc[i,\"id\"] = token.i\n",
    "    syntatic.loc[i,\"T_texto\"] = token.text\n",
    "    syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "    syntatic.loc[i,\"T_is_alpha\"] = token.is_alpha\n",
    "    syntatic.loc[i,\"T_is_digit\"] = token.is_digit\n",
    "    syntatic.loc[i,\"T_is_title\"] = token.is_title\n",
    "    syntatic.loc[i,\"T_is_punct\"] = token.is_punct\n",
    "    syntatic.loc[i,\"T_is_sent_start\"] = token.is_sent_start\n",
    "    syntatic.loc[i,\"T_is_right_punct\"] = token.is_right_punct\n",
    "    syntatic.loc[i,\"T_is_stop\"] = token.is_stop\n",
    "    syntatic.loc[i,\"T_is_quote\"] = token.is_quote\n",
    "    syntatic.loc[i,\"T_is_currency\"] = token.is_currency\n",
    "    syntatic.loc[i,\"T_morph\"] = token.morph\n",
    "    i = i+1\n",
    "\n",
    "syntatic.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization for tokens \n",
    "lemmatization = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"Texto\",\"Lemma\", \"Tag\", \"Tag_explainned\", \"token_POS\", \"POS_explainned\", \"dep\", \"T. Head\", \"dep explained\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    lemmatization.loc[i,\"id\"] = token.i\n",
    "    lemmatization.loc[i,\"Texto\"] = token.text\n",
    "    lemmatization.loc[i,\"Lemma\"] = token.lemma_\n",
    "    lemmatization.loc[i,\"Tag\"] = token.tag_\n",
    "    lemmatization.loc[i,\"Tag_explainned\"] = spacy.explain(token.tag_)\n",
    "    lemmatization.loc[i,\"token_POS\"] = token.pos_\n",
    "    lemmatization.loc[i,\"POS_explainned\"] = spacy.explain(token.pos_)\n",
    "    lemmatization.loc[i,\"dep\"] = token.dep_\n",
    "    lemmatization.loc[i,\"T. Head\"] = token.head.text\n",
    "    lemmatization.loc[i,\"dep explained\"] = token.morph\n",
    "    \n",
    "    i = i+1\n",
    "lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = re.sub('\\s+', ' ', texto_OCR_R).strip()\n",
    "\n",
    "clean_text = text.replace(': ', ':').replace(', ', ',')\n",
    "\n",
    "clean_text = re.sub('\\s+', ' ', text.replace(': ', ':').replace(', ', ',')).strip()\n",
    "\n",
    "text_splited = texto.split('\\n')\n",
    "text_splited = [x for x in text_splited if x.strip()]\n",
    "text_splited = [s.replace(\";\", \"\").strip() for s in text_splited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ocrmypdf(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o subset para analise\n",
    "df_conf = df[['seq', 'batch', 'original_file_name', 'directory','status_documento', 'model', 'secao', 'prefeitura', 'de_para_pm', 'model', 'action_item', 'pdf_pesquisavel', 'processo', 'numero_nota_fiscal', 'competencia', 'dt_hr_emissao', 'codigo_verificacao','conf_cod' ]]\n",
    "df_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando DF para analises\n",
    "df.set_index('document_unique_id', inplace=True)\n",
    "\n",
    "ordem_status = ['PREPROCESS_EXTRACT', 'NO_PROCESS', 'root_analise']\n",
    "ordem_action_item = ['CONTINUE_PROCESS', 'BREAK_PROCESS', 'NO_PROCESS']\n",
    "\n",
    "\n",
    "df['status_documento'] = pd.Categorical(df['status_documento'], categories=ordem_status, ordered=True)\n",
    "df['action_item'] = pd.Categorical(df['action_item'], categories=ordem_action_item, ordered=True)\n",
    "\n",
    "df.sort_values(by=['status_documento', 'action_item', 'seq'], ascending=[True, True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX 1.Processar todas as secoes do documento\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=True, tomador=True, servicos=True, total=True, cnae=True, valores_impostos=True, complementares=True, outras_informacoes=True, observacoes=True)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Processar valor Total\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=True, cnae=False, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 6. Processar CNAE\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=True, valores_impostos=False, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 7. Processar Impostos\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=, complementares=False, outras_informacoes=False, observacoes=False)\n",
    "\n",
    "# 8. complementar e observaçoes\n",
    "#df = extracao_pipeline(df_root_pipe, fase, atividade, status, debug=False, prestador=False, tomador=False, servicos=False, total=False, cnae=False, valores_impostos=False, complementares=True, outras_informacoes=True, observacoes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
