{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.utf8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import platform\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from urllib import response\n",
    "\n",
    "from outlook_msg import Message\n",
    "import extract_msg\n",
    "import zipfile\n",
    "from pyunpack import Archive\n",
    "import py7zr\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "from fuzzywuzzy import fuzz\n",
    "import PyPDF2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "import locale\n",
    "import time, copy\n",
    "from pytz import timezone\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import cv2\n",
    "import fitz  # Módulo PyMuPDF\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "# Modulos da solucao\n",
    "import modules.extrai_pdf_pesquisavel as Extc\n",
    "import modules.cronometro as cron\n",
    "\n",
    "\n",
    "\n",
    "#### Config - E-mail\n",
    "# 1. Caminho do arquivo uma mensagem especifica\n",
    "msg_dir_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/11_emails'\n",
    "\n",
    "# 2. Path para arquivos atachados compactados\n",
    "msg_attachment_zip = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/13_attachments'\n",
    "\n",
    "\n",
    "#### Config - messages\n",
    "# 3. Caminho do arquivo uma mensagem especifica\n",
    "msg_outros_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/12_messages'\n",
    "\n",
    "# 4. Path para arquivos recebidos manualmente\n",
    "arquivos_recebidos_path = 'pipeline_extracao_documentos/1_emails_documentos_recebidos/14_documentos_recebidos'\n",
    "\n",
    "\n",
    "####Config Processamento Pipeline\n",
    "\n",
    "# 5. Path para documentos para extracao\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao/21_aguardando_processamento\"\n",
    "\n",
    "# 6. Path para gestao de imagens resized\n",
    "image_resized_path = \"pipeline_extracao_documentos/6_geral_administacao/temp_docs/images/processadas\"\n",
    "\n",
    "\n",
    "# 7. Path para DFs e CSVs exportados\n",
    "export_path = \"pipeline_extracao_documentos/6_geral_administacao/exports\"\n",
    "\n",
    "# 8. Path para lixeira\n",
    "root_garbage_path = \"pipeline_extracao_documentos/0_lixeira\"\n",
    "\n",
    "\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "#Modelo atual\n",
    "#tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "# definindo localizadcao para pt_BR\n",
    "locale.setlocale(locale.LC_TIME, \"pt_BR.utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tratamento de exceções\n",
    "tratamento_excecoes_path = \"pipeline_extracao_documentos/3_tratamento_excecoes_batches\"\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "cnae_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets/CNAE_X_ITEM_SERVICO_PREFEITURAS.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.extrai_pdf_pesquisavel as Extc\n",
    "\n",
    "import os\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_model_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/frames_nf_v9.xlsx\"\n",
    "\n",
    "# 11. path para datasets CNAE e Itens de Serviço\n",
    "nf_datasets_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "\n",
    "#Le a planilha e cria do DF\n",
    "frames_nf_v4_df = pd.read_excel(nf_model_path)\n",
    "\n",
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'section']\n",
    "frames_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura do arquivo de processamento de notas fiscais\n",
    "path_to_processamento_nf = \"pipeline_extracao_documentos/6_geral_administacao/exports/processamento_nf.xlsx\"\n",
    "\n",
    "df_extract = pd.read_excel(path_to_processamento_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. XXX SE deseja importar o DF df_analise_pipe\n",
    "\n",
    "df_analise_pipe_path = \"Em_HOLD/df_mapeamento_e_analise2.xlsx\"\n",
    "\n",
    "\n",
    "#Le a planilha e cria df_documento_recebido\n",
    "df_analise_pipe = pd.read_excel(df_analise_pipe_path)\n",
    "\n",
    "# Ajusta o indice\n",
    "df_analise_pipe.set_index('document_unique_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pesquisa_dict_prefeitura_modelo(texto):\n",
    "\n",
    "    # 7. ZZZ Dicionário para mapear Prefeitura e/ou CNPJ para um template específico\n",
    "    templates = {\n",
    "        (\"PREFEITURA DA CIDADE MAGE\", \"30.693.231/0001-99\"): \"MAGE_MAICON\",\n",
    "        (\"PREFEITURA DA CIDADE MAGE\", \"23.317.112/0001-76\"): \"MAGE_MFF\",\n",
    "        (\"PREFEITURA DA CIDADE MAGE\", None): \"MAGE\",\n",
    "        (\"PREFEITURA MUNICIPAL DE MAGE\", None): \"MAGE\",\n",
    "        (\"PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA\", \"47.945.459/0001-21\"): \"SAO_PEDRO_GOAT\",\n",
    "        (\"PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA\", \"68.687.722/0001-08\"): \"SAO_PEDRO_GM\",\n",
    "        (\"PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA\", \"34.230.979/0038-06\"): \"SAO_PEDRO_SUPERMIX\",\n",
    "        (\"PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA\", None): \"SAO_PEDRO\",\n",
    "        (\"Pague agora com o seu Pix\", None): \"NAO_PROCESSAR\",\n",
    "        # ... adicione outras combinações aqui\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # 8. ZZZ Consistencia para buscar modelo\n",
    "    prefeitura_encontrada = None\n",
    "    cnpj_encontrado = None\n",
    "\n",
    "    # Verifique cada linha do texto\n",
    "    for linha in texto:\n",
    "        for pref, cnpj in templates.keys():\n",
    "            if pref in linha:\n",
    "                #print(linha)\n",
    "                prefeitura_encontrada = pref\n",
    "            if cnpj and cnpj in linha:\n",
    "                cnpj_encontrado = cnpj\n",
    "\n",
    "    # Saímos do loop, agora vamos verificar qual template usar\n",
    "    if prefeitura_encontrada:\n",
    "        template_usar = templates.get((prefeitura_encontrada, cnpj_encontrado))\n",
    "        if not template_usar:\n",
    "            template_usar = templates.get((prefeitura_encontrada, None), \"NAO_PROCESSAR\")\n",
    "    else:\n",
    "        template_usar = \"NAO_PROCESSAR\"\n",
    "\n",
    "    return template_usar, prefeitura_encontrada, cnpj_encontrado\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX Usando na criacao da imagem \n",
    "def conv_filename_no_ext(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename \n",
    "\n",
    "# XXX Funcao ajustada para convertere e resize\n",
    "def convertResize(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \n",
    "    name_image = conv_filename_no_ext(doc2convert)\n",
    "    \n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(name_image)}.jpg')\n",
    "    #print(f'image_resized_name: {image_resized_name}\\n')\n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "        image_2work = resized_pages[0]\n",
    "        \n",
    "    return image_2work, image_resized_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'3 em executa model_frame - antes do for {model} se: {secao} |f_frame_name: {f_frame_name} | f_tipo: {f_tipo}')\n",
    "    \n",
    "    \n",
    "\n",
    "        #print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "        \n",
    "    return texto_extraido_pil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funçoes REGEX e Extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para extrair número da string\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\b\\d+(\\.\\d+)?\\b', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "# Funcao importante - process_line\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "def format_number(number_str):\n",
    "    # Check for percentage and handle it\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # You can multiply by 100 here if needed\n",
    "\n",
    "    # Check if the string contains \"R$\" or a comma, indicating the original format\n",
    "    if 'R$' in number_str or ',' in number_str:\n",
    "        # Original format: Remove 'R$', replace dots with nothing, and replace commas with dots\n",
    "        number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    else:\n",
    "        # New format: Extract only the numeric part using regex\n",
    "        number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)\n",
    "\n",
    "# Funçao de formatacao de numeros\n",
    "def format_number2(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)\n",
    "\n",
    "\n",
    "\n",
    "#1. funcao: find_value_after_keyword_out_frame_up\n",
    "def find_value_after_keyword_out_frame_up(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "        if text_list[index + 1] not in default_keyword_list:\n",
    "            return text_list[index + 1]\n",
    "        else:\n",
    "            return None\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            for default_keyword in default_keyword_list:\n",
    "                if default_keyword in text_list:\n",
    "                    # Caso especial para 'Nome/Razão Social:'\n",
    "                    if keyword == 'Nome/Razão Social:':\n",
    "                        return text_list[0]\n",
    "        return None\n",
    "    \n",
    "#2. find_value_after_keyword_out_frame_down  \n",
    "def find_value_after_keyword_out_frame_down(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "#3. find_value_after_keyword_fuzz\n",
    "def find_value_after_keyword_fuzz(keyword, text_list, default_keyword_list=None, fuzziness_threshold=80):\n",
    "    closest_match = None\n",
    "    closest_match_score = 0\n",
    "    \n",
    "    for i, text in enumerate(text_list):\n",
    "        score = fuzz.ratio(keyword, text)\n",
    "        \n",
    "        if score > closest_match_score:\n",
    "            closest_match_score = score\n",
    "            closest_match = text\n",
    "        \n",
    "        if closest_match_score > fuzziness_threshold:\n",
    "            break\n",
    "\n",
    "    if closest_match_score > fuzziness_threshold:\n",
    "        index = text_list.index(closest_match)\n",
    "        if index + 1 < len(text_list):\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None  \n",
    "\n",
    "\n",
    "    \n",
    "def pesquisa_keyword(string_pesquisa, text_splited, keyword_list):\n",
    "\n",
    "    resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "\n",
    "    if resultado_extraido_fuzz == None:\n",
    "        resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "        if resultado_extraido_frame_up == None:\n",
    "            resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "            resultado_extraido = resultado_extraido_frame_down\n",
    "        else:\n",
    "            resultado_extraido = resultado_extraido_frame_up\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_fuzz           \n",
    "    #print(resultado_extraido)\n",
    "    return resultado_extraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_PIL(image, coordinates):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    image_croped = image.crop((x0, y0, x1, y1))\n",
    "    texto_extraido = pytesseract.image_to_string(image_croped, lang='por')\n",
    "    return texto_extraido \n",
    "\n",
    "\n",
    "# 6. XXX Ajusta texto para PDF RASTER NO CABECALHO\n",
    "def texto_extraido_cabecalho(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    text_splited = [s.replace(\")\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta e o principio da melhor funcao do mundo\n",
    "def extracao_pipeline(qualquer_df, fase, atividade, status):\n",
    "    \n",
    "    linhas_analise = []\n",
    "    bloco_1_list = []\n",
    "    bloco_2_list = []\n",
    "    bloco_3_list = []\n",
    "    imagens_list = []  \n",
    "    new_data = [] \n",
    "    \n",
    "    pre_processo = ['nro_nota', 'competencia', 'dt_hr_emissao', 'codigo_verificacao', 'ajustar_nome', 'split_paginas', 'ajustar_imagem', 'buscar_nome_prefeitura', 'enviar_canceladas', 'enviar_listagens']\n",
    "    \n",
    "    time_now = cron.timenow_pt_BR()\n",
    "    \n",
    "    fase_processo_atual = fase\n",
    "    atividade_processo_atual = atividade\n",
    "    status_documento_atual = status\n",
    "    \n",
    "    i = 1\n",
    "    for idx, row in qualquer_df.iterrows():\n",
    "        message_erro = []\n",
    "        \n",
    "        # 1. Mapeamento de informacoes do DF\n",
    "        document_unique_id = idx\n",
    "        seq_df = row['seq']\n",
    "        batch_name = row['batch']\n",
    "        fase_processo = row['fase_processo']\n",
    "        nome_atividade = row['nome_atividade']\n",
    "        status_documento = row['status_documento']\n",
    "        original_file_name = row['original_file_name']\n",
    "        file_directory = row['directory']\n",
    "        level = row['level']\n",
    "        d_type = row['level']\n",
    "        document_type = row['document_type']\n",
    "        pdf_pesquisavel = row['pdf_pesquisavel']\n",
    "        one_page_doc = row['one_page']\n",
    "        modelo = row['modelo']\n",
    "        \n",
    "        prefeitura = row['prefeitura']\n",
    "        \n",
    "        parent_document_unique_id = row['parent_document_unique_id']\n",
    "        file_path = row['file_path']\n",
    "        file_hash = row['file_hash']\n",
    "        \n",
    "        # 2. Busca modelo\n",
    "        if (not status_documento == 'NAO_PROCESSAR') or (not document_type == 'outros') or (not one_page_doc == True):\n",
    "            \n",
    "            if atividade_processo_atual == 'extracao_prestador':\n",
    "            #print(f' 1 - seq: {seq_df} | file: {original_file_name} |status_documento: {status_documento} pdf_pesquisavel: {pdf_pesquisavel}\\n')\n",
    "                if status_documento == status_documento_atual:\n",
    "         \n",
    "                    print(f'seq_df: {seq_df} status_documento: {status_documento} | modelo: {modelo:>20} | file: {original_file_name:>40} | prefeitura: {prefeitura:>55} | {pdf_pesquisavel}\\n')\n",
    "                    \n",
    "                    result_list = []\n",
    "                    \n",
    "                    dfcnpj_prestador = {}\n",
    "                    dfincricao_prestador = {}\n",
    "                    dfdados_prestador = {}\n",
    "                        \n",
    "                    # doc2convert = original_file_name\n",
    "                    section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                    modelo = 'SAO_PEDRO_SUPERMIX'\n",
    "                    f_tipo = 'frame'\n",
    "                    \n",
    "                    dfcnpj_prestador, dfincricao_prestador, dfdados_prestador, textoextraido  = processar_dados_dados_documentos(row, original_file_name, file_path, pdf_pesquisavel, section, modelo, f_tipo)\n",
    "                    \n",
    "                    print(f'\\n {dfcnpj_prestador}\\n{dfincricao_prestador}\\n{dfdados_prestador}\\n')\n",
    "                    \n",
    "               \n",
    "      \n",
    "\n",
    "\n",
    "                i += 1\n",
    "              \n",
    "    return textoextraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_df: 20 status_documento: OK | modelo:                 MAGE | file:                              NF 6228.pdf | prefeitura:                            PREFEITURA MUNICIPAL DE MAGE | 1.0\n",
      "\n",
      "doc pdf_pesquisavel:         2_frame_cnpj_prestador | id: 245 | x0:    0.0 y0:  100.0 x1:  600.0 y1:  236.0 \n",
      "doc pdf_pesquisavel:    2_frame_inscricao_prestador | id: 249 | x0:    0.0 y0:  100.0 x1:  600.0 y1:  236.0 \n",
      "doc pdf_pesquisavel:        2_frame_dados_prestador | id: 252 | x0:    0.0 y0:  100.0 x1:  600.0 y1:  236.0 \n",
      "\n",
      " {}\n",
      "{}\n",
      "{}\n",
      "\n",
      "seq_df: 60 status_documento: OK | modelo:   SAO_PEDRO_SUPERMIX | file:        1_5145819163654095684_page_24.pdf | prefeitura:             PREFEITURA MUNICIPAL DE SAO PEDRO DA ALDEIA | 0.0\n",
      "\n",
      "doc raster_pdf:         2_frame_cnpj_prestador | id: 245 | x0:  100.0 y0:  423.0 x1:  550.0 y1:  600.0 \n",
      "2 extract_fields_cnpj:  CPF/CNPJ:\n",
      "34.230.979/0038-06\n",
      "\n",
      "Telefone:\n",
      "2621 1551\n",
      "\n",
      "\n",
      "doc raster_pdf:    2_frame_inscricao_prestador | id: 249 | x0:  550.0 y0:  423.0 x1:  929.0 y1:  588.0 \n",
      "extract_fields_inscricao  PRE\n",
      "\n",
      "Inscrição Municipal:\n",
      "102250\n",
      "Inscrição Estadual:\n",
      "\n",
      "doc raster_pdf:        2_frame_dados_prestador | id: 252 | x0:  100.0 y0:  591.0 x1: 1207.0 y1:  759.0 \n",
      " extract_fields_dados Nome/Razão Social:\n",
      "\n",
      "SUPERMIX CONCRETO SA\n",
      "\n",
      "Endereço:\n",
      "\n",
      "ROD RJ 140 ,S/N KM.04 ,CAMPO REDONDO - São Pedro da Aldeia-RJ\n",
      "E-mail:\n",
      "\n",
      "NFEA038QSUPERMIX.COM.BR\n",
      "\n",
      "\n",
      " {'cpf_cnpj_com_mascara': '34.230.979/0038-06', 'cpf_cnpj_sem_mascara': '34230979003806', 'telefone': '2621 1551'}\n",
      "{'inscricao_municipal': ' ', 'inscricao_estadual': ' '}\n",
      "{'razao_social': ' ', 'nome_fantasia': ' ', 'endereco': ' ', 'email': ' '}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3B. XXX Efetuo a extracao de dados\n",
    "# analisar_pdf_pesquisavel\n",
    "fase = 'analise' # 'pre-processamento'\n",
    "atividade = 'extracao_prestador' #'pesquisar_prefeitura' # pesquisar_prefeitura  pesquisar_modelo    mensagem_status = \"Reavaliar_PDF_Pesquisavel\"\n",
    "status = 'OK'\n",
    "\n",
    "meu_texto_cnpj_prestador = {}\n",
    "\n",
    "dados_lista_texto_extraido = []\n",
    "#raw_texto = extracao_pipeline(df_analise_pipe, fase, atividade, status)\n",
    "textoextraido_nao = extracao_pipeline(subset_df, fase, atividade, status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_dados_dados_documentos(row, original_file_name, file_path, pdf_pesquisavel, section, modelo, f_tipo):\n",
    "    \n",
    "    data_box_valores = {'secao': section}\n",
    "    #lista_texto_extraido = []\n",
    "    \n",
    "    nf_cnpj_prestador = {}\n",
    "    nf_incricao_prestador = {}\n",
    "    nf_dados_prestador = {}\n",
    "    \n",
    "    model = row['modelo']\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        f_tipo = 'frame'\n",
    "        \n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == modelo) & (frames_nf_v4_df['section_json'] == section) & (frames_nf_v4_df['type'] == f_tipo)]\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        pdf_document = fitz.open(file_path)\n",
    "        page_number = 0\n",
    "        page = pdf_document[page_number]\n",
    "    else:\n",
    "        image_2work, image_resized_name = convertResize(original_file_name, file_path, image_resized_path)\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "        frame_id = row_frame['id']\n",
    "        label = row_frame['label']\n",
    "        x0, y0, x1, y1 = (row_frame['x0_p'], row_frame['y0_p'], row_frame['x1_p'], row_frame['y1_p']) if pdf_pesquisavel else (row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'])\n",
    "        \n",
    "        print(f'doc {\"pdf_pesquisavel\" if pdf_pesquisavel else \"raster_pdf\"}: {label:>30} | id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} ')\n",
    "        \n",
    "        if pdf_pesquisavel:\n",
    "            texto_extraido = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "            #data_box_valores['processo'] = \"PDF_PESQUISAVEL\"\n",
    "            #texto_to_process = texto_pdf\n",
    "        else:\n",
    "            texto_extraido = extract_text_PIL(image_2work, (x0, y0, x1, y1))\n",
    "            if label == '2_frame_cnpj_prestador':\n",
    "                nf_cnpj_prestador = extract_fields_cnpj(texto_extraido, original_file_name)\n",
    "            elif label == '2_frame_inscricao_prestador':\n",
    "                nf_incricao_prestador = extract_fields_inscricao(texto_extraido, original_file_name)\n",
    "            elif label == '2_frame_dados_prestador':\n",
    "                nf_dados_prestador = extract_fields_dados(texto_extraido, original_file_name) \n",
    "            #data_box_valores['processo'] = \"RASTER_PDF\"\n",
    "            #texto_to_process = texto_extraido_pil\n",
    "\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        pdf_document.close()\n",
    "        \n",
    "    return nf_cnpj_prestador, nf_incricao_prestador, nf_dados_prestador, texto_extraido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields_cnpj(texto_extraido, original_file_name): \n",
    "  \n",
    "    message_erro = []\n",
    "    \n",
    "    data_nf_cnpj_prestador = {}\n",
    "      \n",
    "    print(f'2 extract_fields_cnpj:  {texto_extraido}')\n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in texto_extraido:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', texto_extraido)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "            data_nf_cnpj_prestador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "            data_nf_cnpj_prestador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "    else:\n",
    "        data_nf_cnpj_prestador['cpf_cnpj_com_mascara'] = None\n",
    "        data_nf_cnpj_prestador['cpf_cnpj_sem_mascara'] = None            \n",
    "            \n",
    "            \n",
    "    telefone_str = None\n",
    "\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', texto_extraido)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        data_nf_cnpj_prestador['telefone'] = telefone_str\n",
    "    else:\n",
    "        data_nf_cnpj_prestador['telefone'] = None \n",
    "    \n",
    "    #print(data_nf_cnpj_prestador)    \n",
    "\n",
    "             \n",
    "    return data_nf_cnpj_prestador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in dados_lista_texto_extraido[1]:\n",
    "    #print(f\"Chave: {key}\")\n",
    "    #print(f\"Valor: {value}\")\n",
    "\n",
    "        print(f\"Valor: {value}\")\n",
    "    \n",
    "    #print()  # Isso imprime uma linha vazia para separar as entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in dadinho.items():\n",
    "    #print(f\"Chave: {key}\")\n",
    "    #print(f\"Valor: {value}\")\n",
    "    if key == '2_frame_cnpj_prestador':\n",
    "        print(f\"kye: {key}, Valor: {value}\")\n",
    "    elif key == '2_frame_inscricao_prestador':\n",
    "        print(f\"kye: {key}, Valor: {value}\")\n",
    "    elif key == '2_frame_dados_prestador':\n",
    "        print(f\"kye: {key}, Valor: {value}\")\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_dados_dados_documentos(row, original_file_name, file_path, pdf_pesquisavel, section, modelo, f_tipo):\n",
    "    \n",
    "    data_box_valores = {'secao': section, 'erros': []}\n",
    "    lista_texto_extraido = []\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        f_tipo = 'frame'\n",
    "        \n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == modelo) & (frames_nf_v4_df['section_json'] == section) & (frames_nf_v4_df['type'] == f_tipo)]\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        pdf_document = fitz.open(file_path)\n",
    "        page_number = 0\n",
    "        page = pdf_document[page_number]\n",
    "    else:\n",
    "        image_2work, image_resized_name = convertResize(original_file_name, file_path, image_resized_path)\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "        frame_id = row_frame['id']\n",
    "        frame_label = row_frame['label']\n",
    "        x0, y0, x1, y1 = (row_frame['x0_p'], row_frame['y0_p'], row_frame['x1_p'], row_frame['y1_p']) if pdf_pesquisavel else (row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'])\n",
    "        \n",
    "        print(f'doc {\"pdf_pesquisavel\" if pdf_pesquisavel else \"raster_pdf\"}: {frame_label:>30} | id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} ')\n",
    "        \n",
    "        if pdf_pesquisavel:\n",
    "            texto_pdf = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "            data_box_valores['processo'] = \"PDF_PESQUISAVEL\"\n",
    "            texto_to_process = texto_pdf\n",
    "        else:\n",
    "            texto_extraido_pil = extract_text_PIL(image_2work, (x0, y0, x1, y1))\n",
    "            data_box_valores['processo'] = \"RASTER_PDF\"\n",
    "            texto_to_process = texto_extraido_pil\n",
    "        \n",
    "        label = row_frame['label']\n",
    "        if label in ['2_frame_cnpj_prestador', '2_frame_inscricao_prestador', '2_frame_dados_prestador']:\n",
    "            #print(f'{data_box_valores[\"processo\"]} {label}: {texto_to_process}')\n",
    "            extraction_function = globals()[f'extract_fields_{label.split(\"_\")[2]}']\n",
    "            data_box_valores[label], new_errors = extraction_function(texto_to_process, original_file_name)\n",
    "            data_box_valores['erros'].extend(new_errors)\n",
    "            \n",
    "    lista_texto_extraido.append(data_box_valores)\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        pdf_document.close()\n",
    "        \n",
    "    return lista_texto_extraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_dados_dados_documentos(row, original_file_name, file_path, pdf_pesquisavel, section, modelo, f_tipo):\n",
    "    \n",
    "    data_box_valores = {'secao': section}\n",
    "    lista_texto_extraido = []\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        f_tipo = 'frame'\n",
    "        \n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == modelo) & (frames_nf_v4_df['section_json'] == section) & (frames_nf_v4_df['type'] == f_tipo)]\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        pdf_document = fitz.open(file_path)\n",
    "        page_number = 0\n",
    "        page = pdf_document[page_number]\n",
    "    else:\n",
    "        image_2work, image_resized_name = convertResize(original_file_name, file_path, image_resized_path)\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "        frame_id = row_frame['id']\n",
    "        frame_label = row_frame['label']\n",
    "        x0, y0, x1, y1 = (row_frame['x0_p'], row_frame['y0_p'], row_frame['x1_p'], row_frame['y1_p']) if pdf_pesquisavel else (row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'])\n",
    "        \n",
    "        print(f'doc {\"pdf_pesquisavel\" if pdf_pesquisavel else \"raster_pdf\"}: {frame_label:>30} | id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} ')\n",
    "        \n",
    "        if pdf_pesquisavel:\n",
    "            texto_pdf = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "            data_box_valores['processo'] = \"PDF_PESQUISAVEL\"\n",
    "            texto_to_process = texto_pdf\n",
    "        else:\n",
    "            texto_extraido_pil = extract_text_PIL(image_2work, (x0, y0, x1, y1))\n",
    "            data_box_valores['processo'] = \"RASTER_PDF\"\n",
    "            texto_to_process = texto_extraido_pil\n",
    "        \n",
    "        label = row_frame['label']\n",
    "        if label in ['2_frame_cnpj_prestador', '2_frame_inscricao_prestador', '2_frame_dados_prestador']:\n",
    "            print(f'{data_box_valores[\"processo\"]} {label}: {texto_to_process}')\n",
    "            extraction_function = globals()[f'extract_fields_{label.split(\"_\")[2]}']\n",
    "            data_box_valores[label] = extraction_function(texto_to_process, original_file_name)\n",
    "            #data_box_valores[label], new_errors = extraction_function(texto_to_process, original_file_name)\n",
    "            #data_box_valores['erros'].extend(new_errors)\n",
    "            \n",
    "    lista_texto_extraido.append(data_box_valores)\n",
    "    \n",
    "    if pdf_pesquisavel:\n",
    "        pdf_document.close()\n",
    "        \n",
    "    return lista_texto_extraido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_dados_dados_documentos(row, original_file_name, file_path, pdf_pesquisavel, section, modelo, f_tipo):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    lista_texto_extraido = []\n",
    "    \n",
    "    \n",
    "    if pdf_pesquisavel == True:\n",
    "        f_tipo = 'frame'\n",
    "        \n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == modelo) & (frames_nf_v4_df['section_json'] == section) & (frames_nf_v4_df['type'] == f_tipo)]\n",
    "    \n",
    "    for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "        frame_id = row_frame['id']\n",
    "        frame_label = row_frame['label']\n",
    "    \n",
    "        if pdf_pesquisavel == True:\n",
    "            x0, y0, x1, y1 = row_frame['x0_p'], row_frame['y0_p'], row_frame['x1_p'], row_frame['y1_p']\n",
    "            print(f'doc pdf_pesquisavel: {frame_label:>30} | id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} ')        \n",
    "\n",
    "            pdf_document = fitz.open(file_path)\n",
    "            page_number = 0  # Defina o número da página que deseja analisar\n",
    "            page = pdf_document[page_number]\n",
    "            nf_data_prestador = {}\n",
    "            # Extrair texto dentro do retângulo\n",
    "            texto_pdf = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "            data_box_valores['processo'] = \"PDF_PESQUISAVEL\"\n",
    "            label = row_frame['label']\n",
    "            \n",
    "            pdf_document.close()\n",
    "            \n",
    "            if label == '2_frame_cnpj_prestador':\n",
    "                print(f'2_frame_cnpj_prestador: {texto_pdf}')\n",
    "                dados_cnpj_prestador, data_box_valores['erros']  = extract_fields_cnpj_prestador(texto_pdf, original_file_name)\n",
    "                if dados_cnpj_prestador:\n",
    "                    data_box_valores[label] = dados_cnpj_prestador\n",
    "                data_box_valores[label] = dados_cnpj_prestador\n",
    "                \n",
    "            \n",
    "            elif label == '2_frame_inscricao_prestador':\n",
    "                print(f'2_frame_inscricao_prestador: {texto_pdf}')\n",
    "                dados_inscricao_prestador, data_box_valores['erros'] = extract_fields_inscricao_prestador(texto_pdf, original_file_name)\n",
    "                data_box_valores[label] = dados_inscricao_prestador\n",
    "            \n",
    "            elif label == '2_frame_dados_prestador':\n",
    "                print(f'2_frame_dados_prestador: {texto_pdf}')\n",
    "                data_dados_prestador, data_box_valores['erros'] = extract_fields_dados_prestador(texto_pdf, original_file_name)\n",
    "                data_box_valores[label] = data_dados_prestador      \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "            print(f'doc raster_pdf: {frame_label:>30} | id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} ')\n",
    "            image_2work, image_resized_name = convertResize(original_file_name, file_path, image_resized_path)\n",
    "\n",
    "            texto_extraido_pil = extract_text_PIL(image_2work, (x0, y0, x1, y1))\n",
    "            data_box_valores['processo'] = \"RASTER_PDF\"\n",
    "            #lista_texto_extraido.append(texto_extraido_pil)\n",
    "            label = row_frame['label']\n",
    "            \n",
    "            if label == '2_frame_cnpj_prestador':\n",
    "                print(f'RASTER 2_frame_cnpj_prestador: {texto_extraido_pil}')\n",
    "                dados_cnpj_prestador, data_box_valores['erros'] = extract_fields_cnpj_prestador(texto_extraido_pil, original_file_name)\n",
    "                data_box_valores[label] = dados_cnpj_prestador\n",
    "                \n",
    "                \n",
    "            elif label == '2_frame_inscricao_prestador':\n",
    "                print(f'RASTER 2_frame_inscricao_prestador: {texto_extraido_pil}')\n",
    "                dados_inscricao_prestador, data_box_valores['erros'] = extract_fields_inscricao_prestador(texto_extraido_pil, original_file_name)\n",
    "                data_box_valores[label] = dados_inscricao_prestador\n",
    "               \n",
    "                \n",
    "            elif label == '2_frame_dados_prestador':\n",
    "                print(f'RASTER 2_frame_dados_prestador: {texto_extraido_pil}')\n",
    "                data_dados_prestador, data_box_valores['erros'] = extract_fields_dados_prestador(texto_extraido_pil, original_file_name)\n",
    "                data_box_valores[label] = data_dados_prestador\n",
    "                \n",
    "\n",
    "    lista_texto_extraido.append(data_box_valores)\n",
    "        \n",
    "        \n",
    "    #print(f'frame_label: {frame_label:>30} | id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} ')\n",
    "    return lista_texto_extraido, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_processar_dados_antigo(row, file_path, image_2work, section, modelo, f_tipo):\n",
    "    \n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    lista_texto_extraido = []\n",
    "    \n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == modelo) & (frames_nf_v4_df['section_json'] == section) & (frames_nf_v4_df['type'] == f_tipo)]\n",
    "    \n",
    "    for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "    \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        \n",
    "        texto_extraido_pil = extract_text_PIL(image_2work, (x0, y0, x1, y1))\n",
    "        lista_texto_extraido.append(texto_extraido_pil)\n",
    "        \n",
    "        frame_id = row_frame['id']\n",
    "        frame_label = row_frame['label']\n",
    "        \n",
    "        print(f'frame_label: {frame_label:>30} | id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} ')\n",
    "        \n",
    "\n",
    "        label = row_frame['label']\n",
    "        data_box_valores[label] = texto_extraido_pil\n",
    "        \n",
    "        \n",
    "    return data_box_valores    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields_cnpj_prestador_raster_pdf(row, texto_cnpj_prestador): \n",
    "  \n",
    "    message_erro = []\n",
    "  \n",
    "    # # print(f'2 dentro do try {model} se: {secao} |f_frame_name: {f_frame_name} | f_tipo: {f_tipo} | raw_texto_pil: {raw_texto_pil}')\n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in texto_cnpj_prestador:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', texto_cnpj_prestador)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "            cpf_cnpj_com_mascara_prestador = cpf_cnpj_formatado_match.group(1)\n",
    "            cpf_cnpj_sem_mascara_prestador = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "    else:\n",
    "        cpf_cnpj_com_mascara_prestador = None\n",
    "        cpf_cnpj_sem_mascara_prestador = None            \n",
    "            \n",
    "            \n",
    "    telefone_str = None\n",
    "\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', texto_cnpj_prestador)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        telefone_prestatador_frame = telefone_str\n",
    "    else:\n",
    "        telefone_prestatador_frame = None \n",
    "\n",
    "             \n",
    "    return cpf_cnpj_com_mascara_prestador, cpf_cnpj_sem_mascara_prestador, telefone_prestatador_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = [20, 60]\n",
    "subset_df = df_analise_pipe[df_analise_pipe['seq'].isin(valores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_pipe.query('status_documento == \"OK\" and pdf_pesquisavel == False ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Usando query para Filtrar Baseado em Condições Complexas\n",
    "subset_df_analise_pipe = df_analise_pipe.query('seq == 63')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model) & (frames_nf_v4_df['label'] == f_frame_name) & (frames_nf_v4_df['type'] == f_tipo)]\n",
    "\n",
    "for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "    \n",
    "    x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "    texto_extraido_pil = extract_text_PIL(image_2work, (x0, y0, x1, y1)) # PONTO IMPORTANTE\n",
    "    print(f'3 - executa: {model} | {secao} | {f_frame_name}  x0: {x0} y0: {y0} x1: {x1} y1: {y1}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secao = \"1 - CABECALHO\"\n",
    "section = \"1 - CABECALHO\"\n",
    "f_frame_name = \"1_frame_dados_nf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_nf_v4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "f_tipo = \"sframe_field\"\n",
    "modelo = \"SAO_PEDRO_SUPERMIX\"\n",
    "\n",
    "f_frame_name = \"1_frame_dados_nf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "model = 'SAO_PEDRO_SUPERMIX'\n",
    "f_tipo = 'frame'\n",
    "f_frame_name = \"2_frame_inscricao_prestador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == modelo) & (frames_nf_v4_df['label'] == f_frame_name) & (frames_nf_v4_df['type'] == f_tipo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == modelo) & (frames_nf_v4_df['section_json'] == section) & (frames_nf_v4_df['type'] == f_tipo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "    \n",
    "    x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "    \n",
    "    texto_extraido_pil = extract_text_PIL(image_2work, (x0, y0, x1, y1))\n",
    "    \n",
    "    frame_id = row_frame['id']\n",
    "    frame_label = row_frame['label']\n",
    "    \n",
    "    print(f'id: {frame_id:>3} | x0: {x0:>6} y0: {y0:>6} x1: {x1:>6} y1: {y1:>6} | frame_label: {frame_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/temp_docs/images/processadas/1_5145819163654095684_page_31.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for color names to RGB values\n",
    "color_mapping = {\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"orange\": (255, 165, 0),\n",
    "    \"green\": (0, 128, 50),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"yellow\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "# Reload the image to start fresh\n",
    "image = Image.open(name_image_2work)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define a font size for the labels using the default PIL font\n",
    "font_size = 100\n",
    "#font = ImageFont.load_default()\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf\", 30, encoding=\"unic\")\n",
    "\n",
    "# Update the draw_box function to use the larger font size with the default font\n",
    "def draw_box(row):\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    color = color_mapping.get(row['color'], (0, 0, 0)) # Default to black if color not found\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
    "    label = str(row['label']) if pd.notnull(row['label']) else None # Check for missing label\n",
    "    if label:\n",
    "        draw.text((x0 + 5, y0 + 5), label, fill=color, font=font)\n",
    "\n",
    "# Draw the boundaries\n",
    "#draw_box(boundaries_info)\n",
    "\n",
    "\n",
    "def draw_box_model(modelo,\n",
    "                   boundaries_info=None,\n",
    "                   sections_info=None,\n",
    "                   frames_info=None,\n",
    "                   field_boxes_info=None,\n",
    "                   draw_boundaries=True,\n",
    "                   draw_sections=True,\n",
    "                   draw_frames=True,\n",
    "                   draw_field_boxes=True):\n",
    "    \n",
    "    # Draw boundaries if requested\n",
    "    if draw_boundaries and boundaries_info is not None:\n",
    "        filtered_boundaries_info = boundaries_info[boundaries_info['model'] == modelo]\n",
    "        for index, row in filtered_boundaries_info.iterrows():\n",
    "            draw_box(row)\n",
    "\n",
    "    # Draw sections if requested\n",
    "    if draw_sections and sections_info is not None:\n",
    "        filtered_sections_info = sections_info[sections_info['model'] == modelo]\n",
    "        for index, row in filtered_sections_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw frames if requested\n",
    "    if draw_frames and frames_info is not None:\n",
    "        filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "        for index, row in filtered_frames_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw field boxes if requested\n",
    "    if draw_field_boxes and field_boxes_info is not None:\n",
    "        filtered_field_boxes_info = field_boxes_info[field_boxes_info['model'] == modelo]\n",
    "        for index, row in filtered_field_boxes_info.iterrows():\n",
    "            draw_box(row)\n",
    "    \n",
    "    # Show the image with selected drawings\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'SAO_PEDRO_SUPERMIX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw everything\n",
    "draw_box_model(modelo, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    frame_seq = row_frame['seq']\n",
    "    frame_model = row_frame['model']\n",
    "    frame_label = row_frame['label']\n",
    "    frame_type = row_frame['type']\n",
    "    frame_section = row_frame['section_json']\n",
    "    frame_reference = row_frame['reference']\n",
    "    frame_father = row_frame['father']\n",
    "    frame_id = row_frame['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_nf_v4_filter = filtrar_df_multiplos(frames_nf_v4_df, section_json=\"== '2. PRESTADOR DE SERVIÇO'\", model=\"== 'SAO_PEDRO_SUPERMIX'\", type=\"== 'frame'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_df(df, **kwargs):\n",
    "    query = \" & \".join(f\"{key} == @kwargs['{key}']\" for key in kwargs)\n",
    "    result = df.query(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_df_multiplos(df, **kwargs):\n",
    "    query = \" & \".join(f\"{key} {value}\" if isinstance(value, str) and value.startswith((\">\", \"<\", \">=\", \"<=\", \"!=\", \"==\")) else f\"{key} == @value\" for key, value in kwargs.items())\n",
    "    result = df.query(query, local_dict=kwargs)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_nf_v4_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in frames_nf_v4_filter.iterrows:\n",
    "    print(idx, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = result['x0'].values[0]\n",
    "x1 = result['x1'].values[0]\n",
    "y0 = result['y0'].values[0]\n",
    "y1 = result['y1'].values[0]\n",
    "label = result['label'].values[0]\n",
    "\n",
    "print(f' x0: {x0} y0: {y0} x1: {x1} y1: {y1} label: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordenates_tipo(section, modelo, tipo):\n",
    "    \n",
    "    result = filtrar_df(frames_nf_v4_df, section_json=section, model=modelo, type=tipo)\n",
    "    x0 = result['x0'].values[0]\n",
    "    x1 = result['x1'].values[0]\n",
    "    y0 = result['y0'].values[0]\n",
    "    y1 = result['y1'].values[0]\n",
    "    label = result['label'].values[0]\n",
    "    \n",
    "    \n",
    "    return x0, x1, y0, y1, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coordenates_tipo(section, modelo, tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordenates(section, modelo):\n",
    "    \n",
    "    result = filtrar_df(frames_nf_v4_df, section_json=section, model=modelo)\n",
    "    x0 = result['x0'].values[0]\n",
    "    x1 = result['x1'].values[0]\n",
    "    y0 = result['y0'].values[0]\n",
    "    y1 = result['y1'].values[0]\n",
    "    label = result['label'].values[0]\n",
    "    \n",
    "    \n",
    "    return x0, x1, y0, y1, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coordenates(section, 'SAO_PEDRO_SUPERMIX')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
