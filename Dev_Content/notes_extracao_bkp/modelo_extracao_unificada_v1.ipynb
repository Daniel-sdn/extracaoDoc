{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Extracao Unificada V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "import PyPDF2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from outlook_msg import Message\n",
    "import extract_msg\n",
    "\n",
    "import locale\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. path para documentos PDF (omelhor se estiverem dentro de um unico diretorio)\n",
    "root_pdf_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 2. path para documentos PDF que podem estar aguardando para serem processados\n",
    "root_pdf_aguardando_path = \"pipeline_extracao_documentos/3_tratamento_excecoes/pdf_aguardando_processar\"\n",
    "\n",
    "\n",
    "\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# path para e-mails recebidos com documentos\n",
    "email_recebido_documento_path = \"pipeline_extracao_documentos/1_emails\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. path para documentos PDF externos para serem processados\n",
    "root_external_pdf_path = \"content_from_pdftool/data/data_pdf/NF_para_processamento/NFRJ_PDF_para _ocr\"\n",
    "# 4. path para documentos PDF PESQUISAVEIS externos para serem processados\n",
    "root_external_pdf_pesquisavel_path = \"content_from_pdftool/data/data_pdf/NF_processadas/NFRJ/fwdnotasfiscaisemitidaslmpadalegal\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. path para imagem padrao\n",
    "image_resized_path = 'pipeline_extracao_documentos/6_geral_administacao/images/processadas'\n",
    "\n",
    "# 6. path para log\n",
    "log_path = 'pipeline_extracao_documentos/6_geral_administacao/logs'\n",
    "\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"pipeline_extracao_documentos/5_documentos_processados/jsons\"\n",
    "\n",
    "# 8. path para NFs processadas\n",
    "nf_processada_path = \"pipeline_extracao_documentos/5_documentos_processados\"\n",
    "\n",
    "\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "\n",
    "# 9. path para modelos\n",
    "nf_model_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/frames_nf_v6.xlsx\"\n",
    "\n",
    "# 10. path para dicionario de modelos\n",
    "model_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/models.csv\"\n",
    "\n",
    "# 11. path para datasets CNAE e Itens de Serviço\n",
    "nf_datasets_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "\n",
    "\n",
    "### PRESTAR ATENCAO\n",
    "modelo = 'mage_1'\n",
    "\n",
    "\n",
    "# VERIFICAR\n",
    "tgt_imagens = \"pipeline_extracao_documentos/6_geral_administacao/images\"\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n",
    "\n",
    "#### IMPORTANTE - Nro Batch\n",
    "batch_name = \"Batch_8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Interacao para pesquisar prefeitura\n",
    "def pesquisa_texto(texto):\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', texto)\n",
    "    if nome_prefeitura_match:\n",
    "        is_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        \n",
    "        return  is_prefeitura\n",
    "    else:\n",
    "        raise ValueError(\"Nao consegui pesquisar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao importante - process_line\n",
    "\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><mark> NAO RODAR </mark></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. dicionario para ocorrencias dos documentos pesquisados\n",
    "analise_doc_nf = {}\n",
    "file_data = []\n",
    "# 2. caminho usado dinamicamente para funcao poder ser utizada em outras area da estrutura de diretorios\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "# Inicialização do DataFrame\n",
    "colunas = [\"documento\", \"pdf\", \"batch\", \"pesquisavel\", \"paginas\", \"metadata\"]\n",
    "analise_df = pd.DataFrame(columns=colunas)\n",
    "i = 0\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        dados_pdf = None  # Inicialização fora do try/catch\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            documento_pdf = True\n",
    "\n",
    "            pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "                \n",
    "            if not pesquisavel:\n",
    "                \n",
    "                if paginas == 1:\n",
    "                    #1. Converto para imagem\n",
    "                    image_2work, name_image_2work = convertResizeAnalise_1page(file, file_path, image_resized_path)\n",
    "\n",
    "\n",
    "                    #2_frame_dados_prestador:  0\t552\t2067\t785\n",
    "\n",
    "\n",
    "                    #2. Defino cordenandas, string_pesquisa e label  550\t380\t1357\t555\n",
    "                    v_x0 = 0#406\n",
    "                    v_y0 = 552#0\n",
    "                    v_x1 = 2067#1540\n",
    "                    v_y1 = 785#380\n",
    "                    string_pesquisa = \"Nome/Razão Social:\"\n",
    "                    label = \"testando pesquisas regex\"\n",
    "                    \n",
    "                    #3. Print do teste\n",
    "                    print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas} | string_pesquisa: \"{string_pesquisa}\"\\ncoordenadas ocr: v_x0 = {v_x0}, v_y0 = {v_y0}, v_x1 = {v_x1}, v_y1 = {v_y1}\\n')\n",
    "                    \n",
    "                    #4. Processo OCR\n",
    "                    text_splited, text_frame = ocr_RasterPDF_free(image_2work, v_x0, v_y0, v_x1, v_y1)\n",
    "                                        \n",
    "                    #5. Itero sobre text_splited (lista)\n",
    "                    a = 0\n",
    "                    for texto_spl in text_splited:\n",
    "                        print(f'texto_spl linha {a}: {texto_spl}')\n",
    "                        #6. chamo funcao process_line\n",
    "                        verificacao_texto = process_line(texto_spl, string_pesquisa, label)\n",
    "                        if verificacao_texto:\n",
    "                            print(f'\\n1. nro: {i} | file: {file}\\nverificacao_texto: {verificacao_texto}\\n')\n",
    "                        a +=1    \n",
    "                    \n",
    "                   \n",
    "                    #6. Imprimo valores de text_splited\n",
    "                    print(f'2. text_splited:\\n{text_splited}\\n')\n",
    "                    print(f'\\n\\n=============================================================================================')\n",
    "                    \n",
    "                    \n",
    "                    i +=1\n",
    "                    \n",
    "                    \n",
    "# 1. dicionario para ocorrencias dos documentos pesquisados\n",
    "analise_doc_nf = {}\n",
    "file_data = []\n",
    "# 2. caminho usado dinamicamente para funcao poder ser utizada em outras area da estrutura de diretorios\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "\n",
    "\n",
    "# Inicialização do DataFrame\n",
    "colunas = [\"documento\", \"pdf\", \"batch\", \"pesquisavel\", \"paginas\", \"metadata\"]\n",
    "analise_df = pd.DataFrame(columns=colunas)\n",
    "\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        dados_pdf = None  # Inicialização fora do try/catch\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            documento_pdf = True\n",
    "            try:\n",
    "                pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "                \n",
    "                \n",
    "                                \n",
    "                if not pesquisavel:\n",
    "                    if paginas == 1:\n",
    "                        image_2work, name_image_2work = convertResizeAnalise_1page(file, file_path, image_resized_path)\n",
    "                        text_splited, text_frame  = ocr_RasterPDF(name_image_2work)\n",
    "                    \n",
    "                    \n",
    "                    print(f'\\ntext_splited: {text_splited}, text_frame: {text_frame}')\n",
    "                    \n",
    "                    #print(file, \"nao e pesquisavel\")\n",
    "                \n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao verificar o PDF: {e}\")\n",
    "            # Adicionando uma nova linha ao DataFrame\n",
    "            nova_linha_df = pd.DataFrame([{\n",
    "                \"pdf\": documento_pdf,\n",
    "                \"documento\": file,\n",
    "                \"batch\": batch_name,\n",
    "                \"pesquisavel\": pesquisavel,\n",
    "                \"paginas\": paginas,\n",
    "                \"metadata\": metadados\n",
    "            }])\n",
    "            \n",
    "            analise_df['pdf'] = analise_df['pdf'].astype(bool)\n",
    "            analise_df['pesquisavel'] = analise_df['pesquisavel'].astype(bool)\n",
    "\n",
    "            analise_df = pd.concat([analise_df, nova_linha_df], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            documento_pdf = False\n",
    "            # Adicione lógica para outros tipos de arquivo, se necessário                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Funcao de conversao e resize do documento\n",
    "def convertResize_analise(nome_documento, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(nome_documento)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pequisaModel(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "            return  nome_prefeitura\n",
    "        else:\n",
    "            raise ValueError(\"Nao acho nome de prefeitura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le a planilha e cria do DF\n",
    "frames_nf_v3_df = pd.read_excel(nf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seq</th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>box</th>\n",
       "      <th>t_value</th>\n",
       "      <th>father</th>\n",
       "      <th>label</th>\n",
       "      <th>reference</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>Largura</th>\n",
       "      <th>Altura</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>1</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>2</td>\n",
       "      <td>boundaries</td>\n",
       "      <td>green</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>2567.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>3</td>\n",
       "      <td>section</td>\n",
       "      <td>red</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14.803272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>4</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>5</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>string</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>nome_prefeitura</td>\n",
       "      <td>PREFEITURA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>73</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>issqn_retido</td>\n",
       "      <td>ISSQN RETIDO</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>74</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_pretacao_servico</td>\n",
       "      <td>LOCAL. PRESTAÇÃO SERVIÇO</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>75</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_incidencia</td>\n",
       "      <td>LOCAL INCIDÊNCIA</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>76</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>uma observação</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>77</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>observação</td>\n",
       "      <td>OBSERVAÇÃO:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  seq          type   color  box t_value  \\\n",
       "0   mage_1    1      document     NaN  NaN     NaN   \n",
       "1   mage_1    2    boundaries   green  yes     NaN   \n",
       "2   mage_1    3       section     red  yes     NaN   \n",
       "3   mage_1    4         frame  purple  yes     NaN   \n",
       "4   mage_1    5  sframe_field     NaN   no  string   \n",
       "..     ...  ...           ...     ...  ...     ...   \n",
       "72  mage_1   73     field_box  orange  yes  string   \n",
       "73  mage_1   74     field_box  orange  yes  string   \n",
       "74  mage_1   75     field_box  orange  yes  string   \n",
       "75  mage_1   76         frame  purple  NaN     NaN   \n",
       "76  mage_1   77  sframe_field     NaN   no     NaN   \n",
       "\n",
       "                                   father                              label  \\\n",
       "0                                     NaN             modelo_prefeitura_mage   \n",
       "1                  modelo_prefeitura_mage  boundaries_modelo_prefeitura_mage   \n",
       "2       boundaries_modelo_prefeitura_mage             1_section_cabecalho_nf   \n",
       "3                  1_section_cabecalho_nf              1_frame_prefeitura_nf   \n",
       "4                   1_frame_prefeitura_nf                    nome_prefeitura   \n",
       "..                                    ...                                ...   \n",
       "72                   5_frame_inf_criticas                       issqn_retido   \n",
       "73                   5_frame_inf_criticas             local_pretacao_servico   \n",
       "74                   5_frame_inf_criticas                   local_incidencia   \n",
       "75  6_section_inf_complementares_criticas                 5_frame_observacao   \n",
       "76                     5_frame_observacao                         observação   \n",
       "\n",
       "                   reference      x0      y0      x1      y1  Largura  Altura  \\\n",
       "0                        NaN     0.0     0.0  2067.0  2923.0   2067.0  2923.0   \n",
       "1                        NaN   144.0    99.0  1925.0  2666.0   1781.0  2567.0   \n",
       "2                        NaN     0.0     0.0  2067.0   380.0   2067.0   380.0   \n",
       "3                        NaN   406.0     0.0  1540.0   380.0   1030.0   380.0   \n",
       "4                 PREFEITURA     NaN     NaN     NaN     NaN      NaN     NaN   \n",
       "..                       ...     ...     ...     ...     ...      ...     ...   \n",
       "72              ISSQN RETIDO  1066.0  2425.0  1328.0  2521.0    262.0    96.0   \n",
       "73  LOCAL. PRESTAÇÃO SERVIÇO  1328.0  2425.0  1638.0  2521.0    310.0    96.0   \n",
       "74          LOCAL INCIDÊNCIA  1638.0  2425.0  1922.0  2521.0    284.0    96.0   \n",
       "75            uma observação   148.0  2521.0  1922.0  2676.0   1774.0   155.0   \n",
       "76               OBSERVAÇÃO:     NaN     NaN     NaN     NaN      0.0     0.0   \n",
       "\n",
       "             %  \n",
       "0          NaN  \n",
       "1   100.000000  \n",
       "2    14.803272  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "..         ...  \n",
       "72         NaN  \n",
       "73         NaN  \n",
       "74         NaN  \n",
       "75         NaN  \n",
       "76         NaN  \n",
       "\n",
       "[77 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_nf_v3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'section']\n",
    "frames_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seq</th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>box</th>\n",
       "      <th>t_value</th>\n",
       "      <th>father</th>\n",
       "      <th>label</th>\n",
       "      <th>reference</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>Largura</th>\n",
       "      <th>Altura</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>4</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>8</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_dados_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>14</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_cnpj_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>18</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_inscricao_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>21</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_dados_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>27</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_cnpj_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>32</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_inscricao_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>35</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_dados_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>40</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_descricao_totais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>42</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_valor_total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>45</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_cnae_itens_servico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>50</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_section_valores_dados</td>\n",
       "      <td>5_frame_valores_impostos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>67</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_dados_complementares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>69</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>76</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>uma observação</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  seq   type   color  box t_value  \\\n",
       "3   mage_1    4  frame  purple  yes     NaN   \n",
       "7   mage_1    8  frame  purple  yes     NaN   \n",
       "13  mage_1   14  frame  purple  yes     NaN   \n",
       "17  mage_1   18  frame  purple  yes     NaN   \n",
       "20  mage_1   21  frame  purple  yes     NaN   \n",
       "26  mage_1   27  frame  purple  yes     NaN   \n",
       "31  mage_1   32  frame  purple  yes     NaN   \n",
       "34  mage_1   35  frame  purple  yes     NaN   \n",
       "39  mage_1   40  frame  purple  yes     NaN   \n",
       "41  mage_1   42  frame  purple  yes     NaN   \n",
       "44  mage_1   45  frame  purple  yes     NaN   \n",
       "49  mage_1   50  frame  purple  yes     NaN   \n",
       "66  mage_1   67  frame  purple  yes     NaN   \n",
       "68  mage_1   69  frame  purple  yes     NaN   \n",
       "75  mage_1   76  frame  purple  NaN     NaN   \n",
       "\n",
       "                                   father                         label  \\\n",
       "3                  1_section_cabecalho_nf         1_frame_prefeitura_nf   \n",
       "7                  1_section_cabecalho_nf              1_frame_dados_nf   \n",
       "13            2_section_prestador_servico        2_frame_cnpj_prestador   \n",
       "17            2_section_prestador_servico   2_frame_inscricao_prestador   \n",
       "20            2_section_prestador_servico       2_frame_dados_prestador   \n",
       "26              3_section_tomador_servico          3_frame_cnpj_tomador   \n",
       "31              3_section_tomador_servico     3_frame_inscricao_tomador   \n",
       "34              3_section_tomador_servico         3_frame_dados_tomador   \n",
       "39              4_section_servicos_totais      4_frame_descricao_totais   \n",
       "41              4_section_servicos_totais           4_frame_valor_total   \n",
       "44              4_section_servicos_totais    4_frame_cnae_itens_servico   \n",
       "49                5_section_valores_dados      5_frame_valores_impostos   \n",
       "66  6_section_inf_complementares_criticas  5_frame_dados_complementares   \n",
       "68  6_section_inf_complementares_criticas          5_frame_inf_criticas   \n",
       "75  6_section_inf_complementares_criticas            5_frame_observacao   \n",
       "\n",
       "         reference      x0      y0      x1      y1  Largura  Altura   %  \n",
       "3              NaN   406.0     0.0  1540.0   380.0   1030.0   380.0 NaN  \n",
       "7              NaN  1633.0     0.0  2067.0   380.0    434.0   380.0 NaN  \n",
       "13             NaN     0.0   380.0   550.0   555.0    440.0   170.0 NaN  \n",
       "17             NaN   550.0   380.0  1357.0   555.0    917.0   170.0 NaN  \n",
       "20             NaN     0.0   552.0  2067.0   785.0   2067.0   235.0 NaN  \n",
       "26             NaN     0.0   785.0   550.0   983.0    440.0   198.0 NaN  \n",
       "31             NaN   550.0   785.0  1357.0   983.0    917.0   198.0 NaN  \n",
       "34             NaN     0.0   983.0  2067.0  1154.0   2067.0   171.0 NaN  \n",
       "39             NaN     0.0  1150.0  2067.0  1790.0   2067.0   690.0 NaN  \n",
       "41             NaN     0.0  1743.0  2067.0  1852.0   2067.0   104.0 NaN  \n",
       "44             NaN     0.0  1844.0  2067.0  1943.0   2067.0    99.0 NaN  \n",
       "49             NaN   344.0  1950.0  1953.0  2273.0   1609.0   323.0 NaN  \n",
       "66             NaN   148.0  2273.0  1925.0  2377.0   1777.0   104.0 NaN  \n",
       "68             NaN   148.0  2377.0  1925.0  2521.0   1777.0   144.0 NaN  \n",
       "75  uma observação   148.0  2521.0  1922.0  2676.0   1774.0   155.0 NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_boxes_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes migradas agora - domingo 22h23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Funcao de conversao e resize do documento\n",
    "def convertResize(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "# 2. Pesquisa prefeitura no documento\n",
    "def pequisaModel(image_name):\n",
    "\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1) \n",
    "            return  nome_prefeitura\n",
    "\n",
    "# 3. Ajusta o filename tirando caracteres especiais \n",
    "def conv_filename(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão\n",
    "    name, extension = title.rsplit('.', 1) if '.' in title else (title, \"\")\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    # Adicione a extensão de volta, se houver\n",
    "    if extension:\n",
    "        filename += '.' + extension.lower()\n",
    "\n",
    "    return filename\n",
    "\n",
    "# 4. Ajusta o filename tirando caracteres especiais e a\n",
    "def conv_filename_no_ext(title):\n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# 5. Verifica se PDF e pesquisavel ou nao e grava metadados dele\n",
    "def is_pdf_searchable_analise(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        pages = pdf_document.page_count\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        dados_pdf = pdf_document.metadata\n",
    "        pdf_document.close()\n",
    "        return is_searchable, dados_pdf, pages\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "# Funcao importante - process_line\n",
    "\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "def convertResizeAnalise_1page(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    resized_pages = []\n",
    "    for page in pages:\n",
    "        resized_page = page.resize((2067, 2923))\n",
    "        resized_pages.append(resized_page)\n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "# 2. Leitura do arquivo CSV e criação do dicionário modelos\n",
    "def create_model_dictionary(model_dict_path):\n",
    "    model_dictionary = {}\n",
    "    with open(model_dict_path, 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            prefeitura_name = row['prefeitura']\n",
    "            model_name = row['model']\n",
    "\n",
    "            if prefeitura_name not in model_dictionary:\n",
    "                model_dictionary[prefeitura_name] = model_name\n",
    "            \n",
    "            #model_dictionary[prefeitura_name].append(model_name)\n",
    "    \n",
    "    return model_dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_coordinates(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# secao: 8 - DADOS COMPLEMENTARES & 10. OBSERVACOES\n",
    "def extract_dados_from_frame(modelo, frame_father, section):\n",
    "    \n",
    "    data_dados_frame = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_frame = extract_text_from_coordinates(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        \n",
    "                \n",
    "    return extracted_text_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number(number_str):\n",
    "    # Check for percentage and handle it\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # You can multiply by 100 here if needed\n",
    "\n",
    "    # Check if the string contains \"R$\" or a comma, indicating the original format\n",
    "    if 'R$' in number_str or ',' in number_str:\n",
    "        # Original format: Remove 'R$', replace dots with nothing, and replace commas with dots\n",
    "        number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    else:\n",
    "        # New format: Extract only the numeric part using regex\n",
    "        number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funçao de formatacao de numeros\n",
    "def format_number2(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_frame(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields_box(modelo, father_value, section):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        #print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference'], row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1'] ))\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        if row_field['t_value'] == 'number':\n",
    "            # Formate o valor usando a função format_number\n",
    "            #print(\"vou verificar valor\")\n",
    "            value = format_number2(value)\n",
    "            #print(value)\n",
    "        # Armazene o texto extraído com o rótulo correspondente\n",
    "        label = row_field['label']\n",
    "        data_box_valores[label] = value\n",
    "        \n",
    "    return data_box_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move NF processadas ok\n",
    "def move_raster_pdf(document_path, raster_pdf_path, batch_name, doc2convert):\n",
    "    # Determine the destination directory\n",
    "    destination_dir = os.path.join(raster_pdf_path, batch_name)\n",
    "\n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Determine the destination path including the filename\n",
    "    destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "\n",
    "    # Move the file from the source path to the destination path\n",
    "    try:\n",
    "        shutil.move(document_path, destination_path)\n",
    "        print(f\"Sucesso ao mover: {document_path} para: {destination_path}\")\n",
    "        return True, destination_path, None  # Success, destination path, no error\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao mover: {document_path} para: {destination_path}: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return False, None, error_message  # Failure, no destination path, error message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo <mark>PDF Pesquisavel</mark> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes extracao PDF Pesquisavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "# 0. Pesquisa PDF\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 1. CABECALHO\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['nome_prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['tipo_nota_fiscal'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nr_nro_nf = numero_nota_match.group(1)\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = numero_nota_match.group(1)\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['codigo_verificacao'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "def extract_fields_prestador(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    nf_data_prestador = {}\n",
    "    \n",
    "    nf_data_prestador['secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['inscricao_estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador['telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['razao_social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['nome_fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['email'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['email'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "# 3. TOMADOR DE SERVIÇO\n",
    "def extract_fields_tomador(text):\n",
    "    nf_data_tomador = {}\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['rg'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['rg'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['inscricao_estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['razao_social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['email'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['email'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "def extract_fields_impostos(text):\n",
    "    nf_data_valores = {}\n",
    "    nf_data_valores['secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_servicos'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['valor_servicos'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_deducao'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_deducao'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_incond'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_incond'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['base_calculo'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['base_calculo'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['aliquota'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['aliquota'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss_retido'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss_retido'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_cond'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_cond'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_pis'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_pis'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_cofins'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_cofins'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_ir'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_ir'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_inss'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_inss'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_csll'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_csll'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['outras_retencoes'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['outras_retencoes'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_liquido'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_liquido'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_4.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_9.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_6.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_5.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_3.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_11.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_10.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_8.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: nota_fiscal_eletronica_7.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "As informações foram salvas em pipeline_extracao_documentos/5_documentos_processados/jsons\n"
     ]
    }
   ],
   "source": [
    "# 1. Leitura recursiva de diretorios e arquivos a partir de root\n",
    "nf_data_servico = {}\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "analise_doc_nf = {}\n",
    "file_data = []\n",
    "\n",
    "# 2. caminho usado dinamicamente para funcao poder ser utizada em outras area da estrutura de diretorios\n",
    "nome_arquivo_json = 'pipeline_extracao_documentos/5_documentos_processados/jsons'\n",
    "\n",
    "\n",
    "path_raster_pdf = \"pipeline_extracao_documentos/3_tratamento_excecoes/pdf_aguardando_processar\"\n",
    "\n",
    "root_pdf_path\n",
    "\n",
    "\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "# Inicialização do DataFrame\n",
    "colunas = [\"documento\", \"pdf\", \"batch\", \"pesquisavel\", \"paginas\", \"metadata\"]\n",
    "analise_df = pd.DataFrame(columns=colunas)\n",
    "i = 1\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    \n",
    "    for file in files:\n",
    "        doc2convert = file\n",
    "        document_path_1 = os.path.join(root, file)\n",
    "        file_path = os.path.join(root, file)\n",
    "        dados_pdf = None  # Inicialização fora do try/catch\n",
    "\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            documento_pdf = True\n",
    "            \n",
    "\n",
    "            \n",
    "            pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "            \n",
    "            print(f'\\nnro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                \n",
    "            if not pesquisavel:\n",
    "\n",
    "                move_raster_pdf(file_path, path_raster_pdf, batch_name, doc2convert)\n",
    "\n",
    "                #if paginas == 1:\n",
    "                if paginas > 1000:\n",
    "                    model = \"mage_1\"\n",
    "                    #1. Converto para imagem\n",
    "                    # 2. Ajusta o nome do arquivo tirando caracteres especiais e a extensao\n",
    "                    #doc2convert_named = conv_filename_no_ext(doc2convert)\n",
    "                    \n",
    "                    print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                    image_2work, name_image_2work = convertResizeAnalise_1page(file, file_path, image_resized_path)\n",
    "                    \n",
    "                    \n",
    "                   \n",
    "                    #frame_pesquisa = \"1_frame_dados_nf\"\n",
    "                    #frame_pesquisa = \"2_frame_dados_prestador\"\n",
    "                    #frame_pesquisa = \"2_frame_inscricao_prestador\"\n",
    "                    #frame_pesquisa = \"3_frame_inscricao_tomador\"\n",
    "                    #frame_pesquisa = \"3_frame_dados_tomador\"\n",
    "                    #frame_pesquisa = \"4_frame_descricao_totais\"\n",
    "                    #frame_pesquisa = \"4_frame_valor_total\"\n",
    "                    #frame_pesquisa = \"4_frame_cnae_itens_servico\"\n",
    "                    frame_pesquisa = \"5_frame_valores_impostos\"\n",
    "                    \n",
    "                    \n",
    "                    if frame_pesquisa == \"1_frame_prefeitura_nf\":\n",
    "                        # secao: 1 - CABECALHO\n",
    "                        data_cabecalho = {}\n",
    "                        f_father = \"1_frame_prefeitura_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                    elif frame_pesquisa == \"1_frame_dados_nf\":\n",
    "                        # secao: 1 - CABECALHO\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"1_frame_dados_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                    elif frame_pesquisa == \"2_frame_cnpj_prestador\":\n",
    "                        # secao: 2. PRESTADOR DE SERVIÇO\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_cnpj_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                    elif frame_pesquisa == \"2_frame_inscricao_prestador\":\n",
    "                        # secao: 2. PRESTADOR DE SERVIÇO\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_inscricao_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)       \n",
    "                        \n",
    "                    elif frame_pesquisa == \"2_frame_dados_prestador\":\n",
    "                        # secao: 2. PRESTADOR DE SERVIÇO\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_dados_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)   \n",
    "                        \n",
    "                    elif frame_pesquisa == \"3_frame_inscricao_tomador\":\n",
    "                        # secao: 3. TOMADOR DE SERVIÇO\n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_inscricao_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                        \n",
    "                    elif frame_pesquisa == \"3_frame_dados_tomador\":\n",
    "                        # secao: 3. TOMADOR DE SERVIÇO\n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_dados_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "              \n",
    "                    elif frame_pesquisa == \"4_frame_descricao_totais\":\n",
    "                        # secao: 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "                        data_servico = {}\n",
    "                        result = {}\n",
    "                        f_father = \"4_frame_descricao_totais\"\n",
    "                        section = \"4. DESCRIMINACAO DOS SERVIÇOS\" \n",
    "\n",
    "                        vx_0 = 125\n",
    "                        vy_0 = 1123\n",
    "                        vx_1 = 1934\n",
    "                        vy_1 = 1720\n",
    "\n",
    "                        data_servico['secao'] = section\n",
    "                        result, texto_extraido = ocr_RasterPDF_free(image_2work, vx_0, vy_0, vx_1, vy_1)\n",
    "                        nf_data_servico = {}\n",
    "                        label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                        \n",
    "                        if texto_extraido.startswith(label):\n",
    "                            text = texto_extraido[len(label):].strip()\n",
    "                        data_servico['discriminacao_servicos'] = text \n",
    "                        print(data_servico)\n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                    elif frame_pesquisa == \"4_frame_valor_total\":\n",
    "                        # secao: 5. VALOR TOTAL\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_valor_total\"\n",
    "                        section = \"5. VALOR TOTAL\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                        \n",
    "                        \n",
    "                         \n",
    "                    elif frame_pesquisa == \"4_frame_cnae_itens_servico\":\n",
    "                        # secao: 6. CNAE e Item da Lista de Serviços\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_cnae_itens_servico\"\n",
    "                        section = \"6. CNAE e Item da Lista de Serviços\"    \n",
    "                        Texto_extraido = extract_fields_box(model, f_father, section)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    elif frame_pesquisa == \"5_frame_valores_impostos\":\n",
    "                        data_valores = {}\n",
    "                        result = {}\n",
    "                        father_value = \"5_frame_valores_impostos\"\n",
    "                        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "                        result = extract_fields_box(modelo, father_value, section)\n",
    "                        if result:\n",
    "                            data_valores.update(result)\n",
    "                         \n",
    "\n",
    "                        \n",
    "                    elif frame_pesquisa == \"5_frame_observacao\":\n",
    "                        # secao: 10. OBSERVACOES\n",
    "                        data_observacao = {}\n",
    "                        f_father = \"5_frame_observacao\"\n",
    "                        section = \"10. OBSERVACOES\"\n",
    "                        \n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        Texto_extraido\n",
    "                        \n",
    "                    if i == 1000: #Define quantidade de tratamento de documentos raster PDF\n",
    "                        break\n",
    "                    \n",
    "                print(f'\\nRASTER PDF nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')                    \n",
    "                    \n",
    "\n",
    "                \n",
    "                    \n",
    "                i +=1 \n",
    "                \n",
    "            else:\n",
    "                #print(f'\\nPDF PESQUISAVEL nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                status = \"O PDF é pesquisável\"\n",
    "                # Carregar o arquivo PDF\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                # Página do PDF\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 4\n",
    "                x1 = 600\n",
    "                y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                if text:\n",
    "                    page_number = 0\n",
    "                else:\n",
    "                    page_number = 1\n",
    "                \n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                #pdf_document = fitz.open(file_path)\n",
    "                #page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    nro_nota = numero_nota = nf_data_cabecalho['numero_nota_fiscal']\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao verificar o PDF: {e}\")\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 530\n",
    "                x1 = 600\n",
    "                y1 = 540  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 545\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                  \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                nr_nro_nf = nro_nota\n",
    "                \n",
    "                nome_formado_json = \"Batch_8.json\"   \n",
    "                \n",
    "                #json_file_path = os.path.join(target_directory, diretorio, \".json\")\n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[nro_nota] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {nome_arquivo_json}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido\n",
    "text_splited = Texto_extraido.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splited = [s.replace(\":\", \"\") for s in text_splited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splited = [s.replace(\";\", \"\").strip() for s in text_splited]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splited = [x for x in text_splited if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### novissimas funcoes de extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_after_keyword_out_frame_up(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "        if text_list[index + 1] not in default_keyword_list:\n",
    "            return text_list[index + 1]\n",
    "        else:\n",
    "            return \"Valor não encontrado\"  # Ou pode retornar None ou uma string vazia, conforme sua necessidade\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            for default_keyword in default_keyword_list:\n",
    "                if default_keyword in text_list:\n",
    "                    # Caso especial para 'Nome/Razão Social:'\n",
    "                    if keyword == 'Nome/Razão Social:':\n",
    "                        return text_list[0]\n",
    "        return \"Keyword não encontrada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_after_keyword_out_frame_down(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return \"Keyword não encontrada\"\n",
    "        else:\n",
    "            return \"Keyword não encontrada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_after_keyword_fuzz(keyword, text_list, default_keyword_list=None, fuzziness_threshold=80):\n",
    "    closest_match = None\n",
    "    closest_match_score = 0\n",
    "    \n",
    "    for i, text in enumerate(text_list):\n",
    "        score = fuzz.ratio(keyword, text)\n",
    "        \n",
    "        if score > closest_match_score:\n",
    "            closest_match_score = score\n",
    "            closest_match = text\n",
    "        \n",
    "        if closest_match_score > fuzziness_threshold:\n",
    "            break\n",
    "\n",
    "    if closest_match_score > fuzziness_threshold:\n",
    "        index = text_list.index(closest_match)\n",
    "        if index + 1 < len(text_list):\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    else:\n",
    "        return \"Keyword não encontrada\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"1_frame_dados_nf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Número da Nota:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Competência:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Código Verificação:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"2_frame_inscricao_prestador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Inscrição Municipal:', 'Inscrição Estadual:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Municipal:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Estadual:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"2_frame_dados_prestador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Nome/Razão Social:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Nome de Fantasia:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Endereço:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"E-mail:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"3_frame_inscricao_tomador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['RG:', 'Inscrição Estadual:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"RG:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Estadual:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa =\"3_frame_dados_tomador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"Nome/Razão Social:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"Endereço:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"E-mail\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_descricao_totais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "if texto_extraido.startswith(label):\n",
    "    text = texto_extraido[len(label):].strip()\n",
    "nf_data_servico['discriminacao_servicos'] = text \n",
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_valor_total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r'R\\$\\s[\\d,.]+', Texto_extraido)\n",
    "\n",
    "if match:\n",
    "    extracted_value = match.group(0)\n",
    "else:\n",
    "    extracted_value = \"Valor não encontrado\"\n",
    "\n",
    "valor_total = format_number(extracted_value)\n",
    "\n",
    "print(valor_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_cnae_itens_servico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mage_cnae_x_item_servico_df = pd.read_excel('pipeline_extracao_documentos/6_geral_administacao/datasets/MAGE_CNAE_X_ITEM_SERVICO_V1.xlsx')\n",
    "\n",
    "# Creating a dictionary for CNAE codes and descriptions\n",
    "cnae_dict = dict(zip(mage_cnae_x_item_servico_df['cnae'], mage_cnae_x_item_servico_df['descricao_cnae']))\n",
    "item_servico_dict = dict(zip(mage_cnae_x_item_servico_df['item_servico'], mage_cnae_x_item_servico_df['descricao_item_servico']))\n",
    "\n",
    "\n",
    "\n",
    "# Função para extrair número da string\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\b\\d+(\\.\\d+)?\\b', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido\n",
    "text_splited = Texto_extraido.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando CNAE\n",
    "cnae_line = [line for line in text_splited if 'CNAE' in line][0]\n",
    "cnae_number = int(extract_number(cnae_line))\n",
    "cnae_value = cnae_dict.get(cnae_number, \"Valor não encontrado\")\n",
    "cnae_value = cnae_value.upper()\n",
    "cnae_value = str(cnae_number) + \" - \" + cnae_value\n",
    "print(cnae_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando Item de Serviço\n",
    "item_servico_line = [line for line in text_splited if 'Item da Lista de Serviços' in line][0]\n",
    "item_servico_number = float(extract_number(item_servico_line))\n",
    "item_servico_value = item_servico_dict.get(item_servico_number, \"Valor não encontrado\")\n",
    "item_servico_value = item_servico_value.upper()\n",
    "item_servico_value = str(item_servico_number) + \" - \" + item_servico_value\n",
    "print(item_servico_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenha Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0297 Raquel.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0299 Luciana.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for color names to RGB values\n",
    "color_mapping = {\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"orange\": (255, 165, 0),\n",
    "    \"green\": (0, 128, 50),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"yellow\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "# Reload the image to start fresh\n",
    "image = Image.open(name_image_2work)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define a font size for the labels using the default PIL font\n",
    "font_size = 100\n",
    "#font = ImageFont.load_default()\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf\", 30, encoding=\"unic\")\n",
    "\n",
    "# Update the draw_box function to use the larger font size with the default font\n",
    "def draw_box(row):\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    color = color_mapping.get(row['color'], (0, 0, 0)) # Default to black if color not found\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
    "    label = str(row['label']) if pd.notnull(row['label']) else None # Check for missing label\n",
    "    if label:\n",
    "        draw.text((x0 + 5, y0 + 5), label, fill=color, font=font)\n",
    "\n",
    "# Draw the boundaries\n",
    "#draw_box(boundaries_info)\n",
    "\n",
    "\n",
    "def draw_box_model(modelo,\n",
    "                   boundaries_info=None,\n",
    "                   sections_info=None,\n",
    "                   frames_info=None,\n",
    "                   field_boxes_info=None,\n",
    "                   draw_boundaries=True,\n",
    "                   draw_sections=True,\n",
    "                   draw_frames=True,\n",
    "                   draw_field_boxes=True):\n",
    "    \n",
    "    # Draw boundaries if requested\n",
    "    if draw_boundaries and boundaries_info is not None:\n",
    "        filtered_boundaries_info = boundaries_info[boundaries_info['model'] == modelo]\n",
    "        for index, row in filtered_boundaries_info.iterrows():\n",
    "            draw_box(row)\n",
    "\n",
    "    # Draw sections if requested\n",
    "    if draw_sections and sections_info is not None:\n",
    "        filtered_sections_info = sections_info[sections_info['model'] == modelo]\n",
    "        for index, row in filtered_sections_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw frames if requested\n",
    "    if draw_frames and frames_info is not None:\n",
    "        filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "        for index, row in filtered_frames_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw field boxes if requested\n",
    "    if draw_field_boxes and field_boxes_info is not None:\n",
    "        filtered_field_boxes_info = field_boxes_info[field_boxes_info['model'] == modelo]\n",
    "        for index, row in filtered_field_boxes_info.iterrows():\n",
    "            draw_box(row)\n",
    "    \n",
    "    # Show the image with selected drawings\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"mage_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw everything\n",
    "draw_box_model(modelo, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras funcoes deprecateds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
