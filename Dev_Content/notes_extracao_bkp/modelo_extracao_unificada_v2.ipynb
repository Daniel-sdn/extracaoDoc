{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Extracao Unificada V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "import PyPDF2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "\n",
    "import modules.ExtracaoPdf as Extc\n",
    "import modules.cronometro as cron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRESTAR ATENCAO\n",
    "modelo = 'mage_1'\n",
    "\n",
    "\n",
    "#### IMPORTANTE - Nro Batch\n",
    "batch_name = \"Batch_9\"\n",
    "\n",
    "\n",
    "# 1. path para documentos PDF (omelhor se estiverem dentro de um unico diretorio)\n",
    "root_pdf_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 2. path para documentos PDF que podem estar aguardando para serem processados\n",
    "root_pdf_aguardando_path = \"pipeline_extracao_documentos/3_tratamento_excecoes/pdf_aguardando_processar\"\n",
    "\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 3. path para documentos PDF externos para serem processados\n",
    "root_external_pdf_path = \"content_from_pdftool/data/data_pdf/NF_para_processamento/NFRJ_PDF_para _ocr\"\n",
    "# 4. path para documentos PDF PESQUISAVEIS externos para serem processados\n",
    "root_external_pdf_pesquisavel_path = \"content_from_pdftool/data/data_pdf/NF_processadas/NFRJ/fwdnotasfiscaisemitidaslmpadalegal\"\n",
    "\n",
    "# 5. path para imagem padrao\n",
    "image_resized_path = 'pipeline_extracao_documentos/6_geral_administacao/images/processadas'\n",
    "\n",
    "# 6. path para log\n",
    "log_path = 'pipeline_extracao_documentos/6_geral_administacao/logs'\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"pipeline_extracao_documentos/5_documentos_processados/jsons\"\n",
    "\n",
    "# 8. path para NFs processadas\n",
    "nf_processada_path = \"pipeline_extracao_documentos/5_documentos_processados\"\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "# 9. path para modelos\n",
    "nf_model_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/frames_nf_v7.xlsx\"\n",
    "\n",
    "# 10. path para dicionario de modelos\n",
    "model_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/models.csv\"\n",
    "\n",
    "# 11. path para datasets CNAE e Itens de Serviço\n",
    "nf_datasets_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "\n",
    "\n",
    "# VERIFICAR\n",
    "tgt_imagens = \"pipeline_extracao_documentos/6_geral_administacao/images\"\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento template do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le a planilha e cria do DF\n",
    "frames_nf_v4_df = pd.read_excel(nf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seq</th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>box</th>\n",
       "      <th>t_value</th>\n",
       "      <th>father</th>\n",
       "      <th>label</th>\n",
       "      <th>section_json</th>\n",
       "      <th>reference</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>Largura</th>\n",
       "      <th>Altura</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>1</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>2</td>\n",
       "      <td>boundaries</td>\n",
       "      <td>green</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>2567.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>3</td>\n",
       "      <td>section</td>\n",
       "      <td>red</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1 - CABECALHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14.803272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>4</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>1 - CABECALHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>5</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>string</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>nome_prefeitura</td>\n",
       "      <td>1 - CABECALHO</td>\n",
       "      <td>PREFEITURA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>73</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>issqn_retido</td>\n",
       "      <td>9. OUTRAS INFORMAÇOES / CRITICAS</td>\n",
       "      <td>ISSQN RETIDO</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>74</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_pretacao_servico</td>\n",
       "      <td>9. OUTRAS INFORMAÇOES / CRITICAS</td>\n",
       "      <td>LOCAL. PRESTAÇÃO SERVIÇO</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>75</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_incidencia</td>\n",
       "      <td>9. OUTRAS INFORMAÇOES / CRITICAS</td>\n",
       "      <td>LOCAL INCIDÊNCIA</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>76</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>10. OBSERVACOES</td>\n",
       "      <td>uma observação</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>77</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>observação</td>\n",
       "      <td>10. OBSERVACOES</td>\n",
       "      <td>OBSERVAÇÃO:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  seq          type   color  box t_value  \\\n",
       "0   mage_1    1      document     NaN  NaN     NaN   \n",
       "1   mage_1    2    boundaries   green  yes     NaN   \n",
       "2   mage_1    3       section     red  yes     NaN   \n",
       "3   mage_1    4         frame  purple  yes     NaN   \n",
       "4   mage_1    5  sframe_field     NaN   no  string   \n",
       "..     ...  ...           ...     ...  ...     ...   \n",
       "72  mage_1   73     field_box  orange  yes  string   \n",
       "73  mage_1   74     field_box  orange  yes  string   \n",
       "74  mage_1   75     field_box  orange  yes  string   \n",
       "75  mage_1   76         frame  purple  NaN     NaN   \n",
       "76  mage_1   77  sframe_field     NaN   no     NaN   \n",
       "\n",
       "                                   father                              label  \\\n",
       "0                                     NaN             modelo_prefeitura_mage   \n",
       "1                  modelo_prefeitura_mage  boundaries_modelo_prefeitura_mage   \n",
       "2       boundaries_modelo_prefeitura_mage             1_section_cabecalho_nf   \n",
       "3                  1_section_cabecalho_nf              1_frame_prefeitura_nf   \n",
       "4                   1_frame_prefeitura_nf                    nome_prefeitura   \n",
       "..                                    ...                                ...   \n",
       "72                   5_frame_inf_criticas                       issqn_retido   \n",
       "73                   5_frame_inf_criticas             local_pretacao_servico   \n",
       "74                   5_frame_inf_criticas                   local_incidencia   \n",
       "75  6_section_inf_complementares_criticas                 5_frame_observacao   \n",
       "76                     5_frame_observacao                         observação   \n",
       "\n",
       "                        section_json                 reference      x0  \\\n",
       "0                                NaN                       NaN     0.0   \n",
       "1                                NaN                       NaN   144.0   \n",
       "2                      1 - CABECALHO                       NaN     0.0   \n",
       "3                      1 - CABECALHO                       NaN   406.0   \n",
       "4                      1 - CABECALHO                PREFEITURA     NaN   \n",
       "..                               ...                       ...     ...   \n",
       "72  9. OUTRAS INFORMAÇOES / CRITICAS              ISSQN RETIDO  1066.0   \n",
       "73  9. OUTRAS INFORMAÇOES / CRITICAS  LOCAL. PRESTAÇÃO SERVIÇO  1328.0   \n",
       "74  9. OUTRAS INFORMAÇOES / CRITICAS          LOCAL INCIDÊNCIA  1638.0   \n",
       "75                   10. OBSERVACOES            uma observação   148.0   \n",
       "76                   10. OBSERVACOES               OBSERVAÇÃO:     NaN   \n",
       "\n",
       "        y0      x1      y1  Largura  Altura           %  \n",
       "0      0.0  2067.0  2923.0   2067.0  2923.0         NaN  \n",
       "1     99.0  1925.0  2666.0   1781.0  2567.0  100.000000  \n",
       "2      0.0  2067.0   380.0   2067.0   380.0   14.803272  \n",
       "3      0.0  1540.0   380.0   1030.0   380.0         NaN  \n",
       "4      NaN     NaN     NaN      NaN     NaN         NaN  \n",
       "..     ...     ...     ...      ...     ...         ...  \n",
       "72  2425.0  1328.0  2521.0    262.0    96.0         NaN  \n",
       "73  2425.0  1638.0  2521.0    310.0    96.0         NaN  \n",
       "74  2425.0  1922.0  2521.0    284.0    96.0         NaN  \n",
       "75  2521.0  1922.0  2676.0   1774.0   155.0         NaN  \n",
       "76     NaN     NaN     NaN      0.0     0.0         NaN  \n",
       "\n",
       "[77 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_nf_v4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'section']\n",
    "frames_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras funcoes possiveis com frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m frame_model \u001b[39m=\u001b[39m row_frame[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m frame_name \u001b[39m=\u001b[39m row_frame[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m \u001b[39mif\u001b[39;00m frame_model \u001b[39m==\u001b[39m model:\n\u001b[1;32m      8\u001b[0m     frame_father \u001b[39m=\u001b[39m row_frame[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     \u001b[39m# ... Select specific frames ...\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_model = row_frame['model']\n",
    "    frame_name = row_frame['label']\n",
    "    if frame_model == model:\n",
    "        frame_father = row_frame['label']\n",
    "        # ... Select specific frames ...\n",
    "        if frame_father == \"2_frame_cnpj_prestador\":\n",
    "        \n",
    "            \n",
    "            # Extrai coordenadas para recorte\n",
    "            x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "            extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "            nf_data_prestador = extract_fields_prestador_cnpj(extracted_text_frame)\n",
    "            \n",
    "        elif frame_father == \"2_frame_inscricao_prestador\":\n",
    "            # Extrai coordenadas para recorte\n",
    "            x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "            extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "            # 1. Prrestador de Servico - INSCRICAO ESTADUAL/MUNICIPAL\n",
    "            nf_data_prestador_incricao = {}\n",
    "\n",
    "            # Dividir o texto em linhas\n",
    "            linhas = extracted_text_frame.split('\\n')\n",
    "\n",
    "            # Inicializar variáveis para armazenar os valores\n",
    "            inscricao_municipal = None\n",
    "            inscricao_estadual = None\n",
    "\n",
    "\n",
    "            # Initialize variables\n",
    "            inscricao_municipal = \"\"\n",
    "            inscricao_estadual = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_boxes_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcoes de imagem e extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRIMEIRAS FUNCOES\n",
    "\n",
    "# 1. Interacao para pesquisar prefeitura\n",
    "def pesquisa_texto(texto):\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', texto)\n",
    "    if nome_prefeitura_match:\n",
    "        is_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        \n",
    "        return  is_prefeitura\n",
    "    else:\n",
    "        raise ValueError(\"Nao consegui pesquisar\")\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "# 3. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# Funcao importante - process_line\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Funcao de conversao e resize do documento\n",
    "def convertResize_analise(nome_documento, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(nome_documento)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "# Funcao de pesquisa de modelo\n",
    "def pequisaModel(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "            return  nome_prefeitura\n",
    "        else:\n",
    "            raise ValueError(\"Nao acho nome de prefeitura\")\n",
    "        \n",
    "# 1. Funcao de conversao e resize do documento\n",
    "def convertResize(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "\n",
    "# 2. Pesquisa prefeitura no documento\n",
    "def pequisaModel(image_name):\n",
    "\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1) \n",
    "            return  nome_prefeitura        \n",
    "        \n",
    "\n",
    "\n",
    "# 3. Ajusta o filename tirando caracteres especiais \n",
    "def conv_filename(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão\n",
    "    name, extension = title.rsplit('.', 1) if '.' in title else (title, \"\")\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    # Adicione a extensão de volta, se houver\n",
    "    if extension:\n",
    "        filename += '.' + extension.lower()\n",
    "\n",
    "    return filename\n",
    "\n",
    "# 4. Ajusta o filename tirando caracteres especiais e a\n",
    "def conv_filename_no_ext(title):\n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename  \n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# 5. Verifica se PDF e pesquisavel ou nao e grava metadados dele\n",
    "def is_pdf_searchable_analise(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        pages = pdf_document.page_count\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        dados_pdf = pdf_document.metadata\n",
    "        pdf_document.close()\n",
    "        return is_searchable, dados_pdf, pages\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "# Funcao importante - process_line\n",
    "\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "def convertResizeAnalise_1page(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    resized_pages = []\n",
    "    for page in pages:\n",
    "        resized_page = page.resize((2067, 2923))\n",
    "        resized_pages.append(resized_page)\n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "# 2. Leitura do arquivo CSV e criação do dicionário modelos\n",
    "def create_model_dictionary(model_dict_path):\n",
    "    model_dictionary = {}\n",
    "    with open(model_dict_path, 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            prefeitura_name = row['prefeitura']\n",
    "            model_name = row['model']\n",
    "\n",
    "            if prefeitura_name not in model_dictionary:\n",
    "                model_dictionary[prefeitura_name] = model_name\n",
    "            \n",
    "            #model_dictionary[prefeitura_name].append(model_name)\n",
    "    \n",
    "    return model_dictionary\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_coordinates(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# secao: 8 - DADOS COMPLEMENTARES & 10. OBSERVACOES\n",
    "def extract_dados_from_frame(modelo, frame_father, section):\n",
    "    \n",
    "    data_dados_frame = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_frame = extract_text_from_coordinates(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "                       \n",
    "                \n",
    "    return extracted_text_frame        \n",
    "        \n",
    "        \n",
    "def extract_text_from_frame(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "def format_number(number_str):\n",
    "    # Check for percentage and handle it\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # You can multiply by 100 here if needed\n",
    "\n",
    "    # Check if the string contains \"R$\" or a comma, indicating the original format\n",
    "    if 'R$' in number_str or ',' in number_str:\n",
    "        # Original format: Remove 'R$', replace dots with nothing, and replace commas with dots\n",
    "        number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    else:\n",
    "        # New format: Extract only the numeric part using regex\n",
    "        number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)\n",
    "\n",
    "# Funçao de formatacao de numeros\n",
    "def format_number2(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)\n",
    "\n",
    "\n",
    "def extract_fields_box(modelo, father_value, section):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        #print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference'], row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1'] ))\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        if row_field['t_value'] == 'number':\n",
    "            # Formate o valor usando a função format_number\n",
    "            #print(\"vou verificar valor\")\n",
    "            value = format_number2(value)\n",
    "            #print(value)\n",
    "        # Armazene o texto extraído com o rótulo correspondente\n",
    "        label = row_field['label']\n",
    "        data_box_valores[label] = value\n",
    "        \n",
    "    return data_box_valores\n",
    "\n",
    "# move NF processadas ok\n",
    "def move_raster_pdf(document_path, raster_pdf_path, batch_name, doc2convert):\n",
    "    # Determine the destination directory\n",
    "    destination_dir = os.path.join(raster_pdf_path, batch_name)\n",
    "\n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Determine the destination path including the filename\n",
    "    destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "\n",
    "    # Move the file from the source path to the destination path\n",
    "    try:\n",
    "        shutil.move(document_path, destination_path)\n",
    "        print(f\"Sucesso ao mover: {document_path} para: {destination_path}\")\n",
    "        return True, destination_path, None  # Success, destination path, no error\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao mover: {document_path} para: {destination_path}: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return False, None, error_message  # Failure, no destination path, error message\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_page_split(input_pdf_path):\n",
    "    \n",
    "    # Lista para guardar paginas\n",
    "    document_pages = []\n",
    "    # Abre o PDF\n",
    "    pdf = fitz.open(input_pdf_path)\n",
    "\n",
    "    # Número total de páginas no PDF\n",
    "    total_pages = len(pdf)\n",
    "\n",
    "    # Nome base para os arquivos de saída\n",
    "    base_name = input_pdf_path.split('.')[0]  # Remove a extensão do arquivo\n",
    "\n",
    "    # Loop para criar um novo PDF para cada página\n",
    "    for page_num in range(total_pages):\n",
    "        # Cria um novo objeto PDF\n",
    "        new_pdf = fitz.open()\n",
    "        # Adiciona a página atual ao novo PDF\n",
    "        new_pdf.insert_pdf(pdf, from_page=page_num, to_page=page_num)\n",
    "        # Nome do novo arquivo PDF\n",
    "        new_pdf_name = f\"{base_name}_page_{page_num + 1}.pdf\"\n",
    "        #splited_doc_path = os.path.join(destiny_path, new_pdf_name)\n",
    "        # Atualiza lista de paginas\n",
    "        document_pages.append(new_pdf_name)\n",
    "        # Salva o novo PDF\n",
    "        new_pdf.save(new_pdf_name)\n",
    "        # Fecha o novo PDF\n",
    "        new_pdf.close()\n",
    "\n",
    "    # Fecha o PDF original\n",
    "    pdf.close()\n",
    "    return document_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline  <mark>PDF Pesquisavel e Raster PDF</mark> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste <mark>RASTER_PDF</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dict dados dos documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as linhas\n",
    "rows_list = []\n",
    "\n",
    "# Função recursiva para adicionar linha\n",
    "def add_row_recursively(rows_list, \n",
    "                        index, \n",
    "                        Batch, \n",
    "                        diretorio_ori, \n",
    "                        arquivo_origem, \n",
    "                        arquivo_destino, \n",
    "                        data_hora, \n",
    "                        tipo_doc_pdf, \n",
    "                        qtd_paginas\n",
    "                        ):\n",
    "    if index == 0:\n",
    "        return rows_list\n",
    "    else:\n",
    "        new_row = {\n",
    "                    'index': index,\n",
    "                    'Batch': Batch,\n",
    "                    'diretorio_origem': diretorio_ori,\n",
    "                    'nome_arquivo_origem': arquivo_origem,\n",
    "                    'nome_arquivo_destino': arquivo_destino,\n",
    "                    'data_processamento': data_hora,\n",
    "                    'tipo_pdf': tipo_doc_pdf,\n",
    "                    'qut_paginas': qtd_paginas\n",
    "                    }\n",
    "        rows_list.append(new_row)\n",
    "        \n",
    "        return add_row_recursively(rows_list, index-1, Batch, diretorio_ori, arquivo_origem, arquivo_destino, data_hora, tipo_doc_pdf, qtd_paginas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processamento = pd.read_excel(\"pipeline_extracao_documentos/6_geral_administacao/datasets/df_processamento_7.xlsx\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cricao dos dados ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq =  0 | 1_frame_prefeitura_nf\n",
      "seq =  1 | 1_frame_dados_nf\n",
      "seq =  2 | 2_frame_cnpj_prestador\n",
      "seq =  3 | 2_frame_inscricao_prestador\n",
      "seq =  4 | 2_frame_dados_prestador\n",
      "seq =  5 | 3_frame_cnpj_tomador\n",
      "seq =  6 | 3_frame_inscricao_tomador\n",
      "seq =  7 | 3_frame_dados_tomador\n",
      "seq =  8 | 4_frame_descricao_totais\n",
      "seq =  9 | 4_frame_valor_total\n",
      "seq = 10 | 4_frame_cnae_itens_servico\n",
      "seq = 11 | 5_frame_valores_impostos\n",
      "seq = 12 | 5_frame_dados_complementares\n",
      "seq = 13 | 5_frame_inf_criticas\n",
      "seq = 14 | 5_frame_observacao\n",
      "\n",
      "\n",
      "Dados do teste: batch_name: Batch_RASTER_PDF_0 | frame: 1_frame_prefeitura_nf | model: mage_1 | tipo_pdf: RASTER_PDF\n",
      "\n",
      "root_doc_analise: pipeline_extracao_documentos/2_documentos_para_extracao/Batch_RASTER_PDF_0\n",
      "path_test_pdf: pipeline_extracao_documentos/4_area_testes/raster_pdf_4_test\n",
      "json_file_path: pipeline_extracao_documentos/5_documentos_processados/jsons/Batch_RASTER_PDF_0.json\n"
     ]
    }
   ],
   "source": [
    "#### IMPORTANTE - NRO BATCH PARA TESTE    0 = PDF_PESQUISAVEL | 1 = RASTER_PDF\n",
    "\n",
    "i_test = 1\n",
    "\n",
    "modelo = 'mage_1'\n",
    "\n",
    "model = 'mage_1' \n",
    "\n",
    "tipo_pdf = []\n",
    "tipo_pdf.append('PDF_PESQUISAVEL')\n",
    "tipo_pdf.append('RASTER_PDF')\n",
    "tipo_pdf[i_test]\n",
    "\n",
    "\n",
    "# Tratamento do Path de ORIGEM DO DOCUMENTOS PARA TESTE QUE SERAO MOVIDOS\n",
    "list_path_test = []\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/pdf_pesquisavel_4_test\")\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/raster_pdf_4_test\")\n",
    "list_path_test[i_test]\n",
    "\n",
    "# Frame para teste\n",
    "i_frame = 0\n",
    "\n",
    "frames_pesquisa = []\n",
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_name = row_frame['label']\n",
    "    frames_pesquisa.append(frame_name)\n",
    "\n",
    "# Nome Batch\n",
    "batch_name = \"Batch_\" + str(tipo_pdf[i_test]) + \"_\" + str(i_frame)\n",
    "\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "\n",
    "# Listagem dos frames de pesquisa\n",
    "i = 0\n",
    "for frame in frames_pesquisa:\n",
    "    print(f'seq ={i:>3} | {frame}')\n",
    "    i += 1\n",
    "    \n",
    "if frames_pesquisa[i_frame]:\n",
    "    print(f'\\n\\nDados do teste: batch_name: {batch_name} | frame: {frames_pesquisa[i_frame]} | model: {modelo} | tipo_pdf: {tipo_pdf[i_test]}')\n",
    "    \n",
    "    \n",
    "######### PATHS\n",
    "#1. path formado para busca de pdfs recursiva\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "\n",
    "#2. path para documentos teste RASTER PDF (ATRIBIDO DA LISTA)\n",
    "path_test_pdf = list_path_test[1]\n",
    "\n",
    "#3. path formado para nome do arquivo json\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "\n",
    "#Listando paths utilizados\n",
    "print(f'\\nroot_doc_analise: {root_doc_analise}\\npath_test_pdf: {path_test_pdf}\\njson_file_path: {json_file_path}')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funçao de mover documento de uma area para outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório onde você quer salvar os arquivos extraídos\n",
    "output_dir = os.path.join(documentos_extracao_path, batch_name)\n",
    "i_max = 2\n",
    "for root, dirs, files in os.walk(path_test_pdf):\n",
    "    #dir_name = os.path.basename(root)\n",
    "    i = 1\n",
    "    print(f'1. | {root}  | {dirs} \\n')\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        doc2test = file\n",
    "        pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "        print(f'\\n      iter: {i} diretorio: {dir_name} | Doc: {file} | reno: {doc2test}\\n\\n      pesquisavel: {pesquisavel}\\n      paginas = {paginas}\\n')\n",
    "        \n",
    "        doc2test_path = os.path.join(root, doc2test)\n",
    "        destination_path = os.path.join(output_dir, doc2test)\n",
    "        #destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "        #print(f'\\n      iter: {i} Documento: {file} | renomeado para: {doc2test}\\n\\n      mover de: output_dir = {doc2test_path}\\n      para: destination_path =  {destination_path}\\n')\n",
    "        if not os.path.exists(output_dir):\n",
    "           os.makedirs(output_dir) # estou criando o diretorio caso nao exista\n",
    "           \n",
    "        # Move the file from the source path to the destination path\n",
    "        try:\n",
    "            shutil.move(doc2test_path, destination_path)\n",
    "            print(f\"        Sucesso ao mover: {doc2test_path} para: {destination_path}\")\n",
    "        except Exception as e:\n",
    "            error_message = f\"      Erro ao mover: {doc2test_path} para: {destination_path}: {str(e)}\"\n",
    "            print(error_message)   \n",
    "        \n",
    "        if i == i_max: #Define quantidade de tratamento de documentos raster PDF\n",
    "            break\n",
    "        i += 1    \n",
    "    \n",
    "    \n",
    "print(f'\\ntotal de {i} documentos movidos')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ajusta o nome dos documentos e grava em dicionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustando o filename e criando o dicionario\n",
    "folder_file_dict = {}\n",
    "rows_list = []\n",
    "output_dir = os.path.join(documentos_extracao_path, batch_name)\n",
    "i = 0\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    folder_name = os.path.basename(root)\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "\n",
    "        new_name = conv_filename(file)\n",
    "        new_path_name = os.path.join(root, new_name)\n",
    "        #print(f'\\nfile: {file} | new_name: {new_name} ')\n",
    "        shutil.move(file_path, new_path_name)\n",
    "        folder_file_dict.setdefault(folder_name, []).append(new_name)\n",
    "        time_now = cron.timenow_pt_BR()\n",
    "        new_row = {\n",
    "                    'index': i,\n",
    "                    'Batch': batch_name,\n",
    "                    'diretorio_origem': folder_name,\n",
    "                    'nome_arquivo_origem': file,\n",
    "                    'nome_arquivo_destino': new_name,\n",
    "                    'data_processamento': time_now,\n",
    "                    'tipo_pdf': pesquisavel,\n",
    "                    'qut_paginas': paginas\n",
    "                    }\n",
    "        rows_list.append(new_row)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracao_files = pd.DataFrame(rows_list)\n",
    "df_extracao_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo atual de call de funcoes Raster PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame para teste\n",
    "i_frame = 0\n",
    "\n",
    "frames_pesquisa = []\n",
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_name = row_frame['label']\n",
    "    frames_pesquisa.append(frame_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sframe_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sframe_fields_info = sframe_fields_info[sframe_fields_info['model'] == modelo]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_name = row_frame['label']\n",
    "    frames_pesquisa.append(frame_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == f_father) & (sframe_fields_info['model'] == model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_nf_v4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nf_father: {f_father} |  model: {model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sframe_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    data_dados_frame = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['label'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_frame = extract_text_from_coordinates(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        \n",
    "        \n",
    "        label = row_frame['label']\n",
    "        data_dados_frame[label] = value\n",
    "        # data_dados_frame['seq'] = row_frame['seq']\n",
    "        # data_dados_frame['label'] = row_frame['label']\n",
    "        # data_dados_frame['reference'] = row_frame['reference']\n",
    "        \n",
    "                \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames_info = frames_info[frames_info['model'] == modelo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = \"1 - CABECALHO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames_info = frames_info[(frames_info['section_json'] == section) & (frames_info['model'] == model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     sframe_father = srow_frame['father']\n",
    "        \n",
    "        sframe_seq = srow_frame['seq']\n",
    "        sframe_label = srow_frame['label']\n",
    "        sframe_label = srow_frame['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = []\n",
    "# Modelo 1: Sequencia de todos os campos\n",
    "filtered_frames_info = frames_info[frames_info['model'] == model]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_seq = row_frame['seq']\n",
    "    frame_model = row_frame['model']\n",
    "    frame_label = row_frame['label']\n",
    "    frame_section = row_frame['section_json']\n",
    "    section.append(frame_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo 1: Sequencia de todos os campos\n",
    "filtered_frames_info = frames_info[frames_info['model'] == model]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_seq = row_frame['seq']\n",
    "    frame_model = row_frame['model']\n",
    "    frame_label = row_frame['label']\n",
    "    frame_section = row_frame['section_json']\n",
    "    #print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | label: {frame_name:>20} | section: {frame_section:>35} ')\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['model'] == frame_model) & (sframe_fields_info['section_json'] == frame_section) & (sframe_fields_info['father'] == frame_label)]\n",
    "    for sindex_frame, srow_frame in filtered_sframe_fields_info.iterrows():\n",
    "        sframe_section = srow_frame['section_json']\n",
    "        if sframe_section == frame_section:\n",
    "            sframe_seq = srow_frame['seq']\n",
    "            sframe_label = srow_frame['label']\n",
    "            sframe_model = srow_frame['model']\n",
    "            sframe_reference = srow_frame['reference']\n",
    "            print(f'\\fseq: {sframe_seq:>3} | model: {sframe_model:>8} | label: {sframe_label:>20} | section: {sframe_section:>35}  reference: {sframe_reference:>35} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOdelo 1: Sequencia de todos os campos por secao (filtro)\n",
    "\n",
    "section = \"1 - CABECALHO\"\n",
    "filtered_frames_info = frames_info[(frames_info['section_json'] == section) & (frames_info['model'] == model)]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_seq = row_frame['seq']\n",
    "    frame_model = row_frame['model']\n",
    "    frame_label = row_frame['label']\n",
    "    frame_section = row_frame['section_json']\n",
    "    #print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | label: {frame_name:>20} | section: {frame_section:>35} ')\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['model'] == frame_model) & (sframe_fields_info['section_json'] == frame_section) & (sframe_fields_info['father'] == frame_label)]\n",
    "    for sindex_frame, srow_frame in filtered_sframe_fields_info.iterrows():\n",
    "        sframe_section = srow_frame['section_json']\n",
    "        if sframe_section == frame_section:\n",
    "            sframe_seq = srow_frame['seq']\n",
    "            sframe_label = srow_frame['label']\n",
    "            sframe_model = srow_frame['model']\n",
    "            sframe_reference = srow_frame['reference']\n",
    "            print(f'\\fseq: {sframe_seq:>3} | model: {sframe_model:>8} | label: {sframe_label:>20} | section: {sframe_section:>35}  reference: {sframe_reference:>35} ')\n",
    "        \n",
    "   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        #print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference'], row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1'] ))\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        if row_field['t_value'] == 'number':\n",
    "            # Formate o valor usando a função format_number\n",
    "            #print(\"vou verificar valor\")\n",
    "            value = format_number2(value)\n",
    "            #print(value)\n",
    "        # Armazene o texto extraído com o rótulo correspondente\n",
    "        label = row_field['label']\n",
    "        data_box_valores[label] = value\n",
    "        \n",
    "    return data_box_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['section_json'] == section) & (frames_nf_v4_df['model'] == model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_frames_nf_v4_df = frames_nf_v4_df[frames_nf_v4_df['model'] == model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "    frame_seq = row_frame['seq']\n",
    "    frame_model = row_frame['model']\n",
    "    frame_label = row_frame['label']\n",
    "    frame_type = row_frame['type']\n",
    "    frame_section = row_frame['section_json']\n",
    "    frame_reference = row_frame['reference']\n",
    "    print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | label: {frame_name:>20} | section: {frame_section:>35} {frame_reference:>30}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    if frame_model == model:\n",
    "        frame_father = row_frame['label']\n",
    "        # ... Select specific frames ...\n",
    "        if frame_father == \"2_frame_cnpj_prestador\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_pesquisa = []\n",
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_sframe_fields_info = sframe_fields_info[sframe_fields_info['model'] == modelo]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    \n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == f_father) & (sframe_fields_info['model'] == model)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    frame_section_name = row_frame['section_json']\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['secao'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "    frame_section_name = row_frame['section_json']\n",
    "    frame_label_name = row_frame['label']\n",
    "    print(frame_label_name, frame_section_name)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " frame_label_name = row_frame['label']\n",
    "    frames_pesquisa.append(frame_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2search = frames_pesquisa[i_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if frames_pesquisa[i_frame]:\n",
    "    print(f'\\n\\nDados do teste: batch_name: {batch_name} | frame: {frames_pesquisa[i_frame]} | model: {modelo} | tipo_pdf: {tipo_pdf[i_test]} | path: {root_doc_analise}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_pesquisa[i_frame]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\fseq:   5 | model:   mage_1 | type:    sframe_field | Father: 1_frame_prefeitura_nf label:      nome_prefeitura | section:                       1 - CABECALHO                     PREFEITURA\n",
      "\fseq:   6 | model:   mage_1 | type:    sframe_field | Father: 1_frame_prefeitura_nf label:           secretaria | section:                       1 - CABECALHO                     SECRETARIA\n",
      "\fseq:   7 | model:   mage_1 | type:    sframe_field | Father: 1_frame_prefeitura_nf label:     tipo_nota_fiscal | section:                       1 - CABECALHO                    NOTA FISCAL\n",
      "\fseq:   9 | model:   mage_1 | type:    sframe_field | Father: 1_frame_dados_nf label:   numero_nota_fiscal | section:                       1 - CABECALHO                Número da Nota:\n",
      "\fseq:  10 | model:   mage_1 | type:    sframe_field | Father: 1_frame_dados_nf label:          competencia | section:                       1 - CABECALHO                   Competência:\n",
      "\fseq:  11 | model:   mage_1 | type:    sframe_field | Father: 1_frame_dados_nf label:        dt_hr_emissao | section:                       1 - CABECALHO        Data e Hora de Emissão:\n",
      "\fseq:  12 | model:   mage_1 | type:    sframe_field | Father: 1_frame_dados_nf label:   codigo_verificacao | section:                       1 - CABECALHO         Código de Verificação:\n",
      "\fseq:  15 | model:   mage_1 | type:    sframe_field | Father: 2_frame_cnpj_prestador label: cpf_cnpj_sem_mascara | section:             2. PRESTADOR DE SERVIÇO                      CPF/CNPJ:\n",
      "\fseq:  16 | model:   mage_1 | type:    sframe_field | Father: 2_frame_cnpj_prestador label: cpf_cnpj_com_mascara | section:             2. PRESTADOR DE SERVIÇO                      CPF/CNPJ:\n",
      "\fseq:  17 | model:   mage_1 | type:    sframe_field | Father: 2_frame_cnpj_prestador label:             telefone | section:             2. PRESTADOR DE SERVIÇO                      Telefone:\n",
      "\fseq:  19 | model:   mage_1 | type:    sframe_field | Father: 2_frame_inscricao_prestador label:  inscricao_municipal | section:             2. PRESTADOR DE SERVIÇO           Inscrição Municipal:\n",
      "\fseq:  20 | model:   mage_1 | type:    sframe_field | Father: 2_frame_inscricao_prestador label:   inscricao_estadual | section:             2. PRESTADOR DE SERVIÇO            Inscrição Estadual:\n",
      "\fseq:  22 | model:   mage_1 | type:    sframe_field | Father: 2_frame_dados_prestador label:         razao_social | section:             2. PRESTADOR DE SERVIÇO             Nome/Razão Social:\n",
      "\fseq:  23 | model:   mage_1 | type:    sframe_field | Father: 2_frame_dados_prestador label:        nome_fantasia | section:             2. PRESTADOR DE SERVIÇO              Nome de Fantasia:\n",
      "\fseq:  24 | model:   mage_1 | type:    sframe_field | Father: 2_frame_dados_prestador label:             endereco | section:             2. PRESTADOR DE SERVIÇO                      Endereço:\n",
      "\fseq:  25 | model:   mage_1 | type:    sframe_field | Father: 2_frame_dados_prestador label:                email | section:             2. PRESTADOR DE SERVIÇO                        E-mail:\n"
     ]
    }
   ],
   "source": [
    "i_frame = 0\n",
    "frames_pesquisa = []\n",
    "filtered_frames_nf_v4_df = frames_nf_v4_df[frames_nf_v4_df['model'] == model]\n",
    "for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "    frame_seq = row_frame['seq']\n",
    "    frame_model = row_frame['model']\n",
    "    frame_label = row_frame['label']\n",
    "    frame_type = row_frame['type']\n",
    "    frame_section = row_frame['section_json']\n",
    "    frame_reference = row_frame['reference']\n",
    "    frame_father = row_frame['father']\n",
    "    #if frame_section == \"1 - CABECALHO\" and frame_type == \"frame\":\n",
    "    if frame_section == \"1 - CABECALHO\":\n",
    "        frame_father = row_frame['father']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"1_frame_prefeitura_nf\" and frame_type == \"sframe_field\":\n",
    "        #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>20} | section: {frame_section:>35} {frame_reference:>30}')\n",
    "            result = {}\n",
    "            \n",
    "        elif frame_father == \"1_frame_dados_nf\" and frame_type == \"sframe_field\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>20} | section: {frame_section:>35} {frame_reference:>30}')\n",
    "            result = {} \n",
    "    elif frame_section == \"2. PRESTADOR DE SERVIÇO\":\n",
    "        frame_father = row_frame['father']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"2_frame_cnpj_prestador\" and frame_type == \"sframe_field\":\n",
    "        #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>20} | section: {frame_section:>35} {frame_reference:>30}')\n",
    "            result = {}\n",
    "            \n",
    "        elif frame_father == \"2_frame_inscricao_prestador\" and frame_type == \"sframe_field\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>20} | section: {frame_section:>35} {frame_reference:>30}')\n",
    "            result = {} \n",
    "        elif frame_father == \"2_frame_dados_prestador\" and frame_type == \"sframe_field\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>20} | section: {frame_section:>35} {frame_reference:>30}')\n",
    "            result = {}                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chamadas de funcao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # secao: 1 - CABECALHO\n",
    "                    #seq =  0 | 1_frame_prefeitura_nf\n",
    "                    if frame_pesquisa == \"1_frame_prefeitura_nf\":\n",
    "                        data_cabecalho = {}\n",
    "                        f_father = \"1_frame_prefeitura_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    #seq =  1 | 1_frame_dados_nf\n",
    "                    elif frame_pesquisa == \"1_frame_dados_nf\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"1_frame_dados_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 2. PRESTADOR DE SERVIÇO\n",
    "                    #seq =  2 | 2_frame_cnpj_prestador\n",
    "                    elif frame_pesquisa == \"2_frame_cnpj_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_cnpj_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                    #seq =  3 | 2_frame_inscricao_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_inscricao_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_inscricao_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)       \n",
    "                    \n",
    "                    #seq =  4 | 2_frame_dados_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_dados_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_dados_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                           \n",
    "                           \n",
    "                    # secao: 3 - TOMADOR       \n",
    "                    #seq =  5 | 3_frame_cnpj_tomador       \n",
    "                    elif frame_pesquisa == \"3_frame_cnpj_tomador\": #TBD\n",
    "                    \n",
    "                    #seq =  6 | 3_frame_inscricao_tomador \n",
    "                    elif frame_pesquisa == \"3_frame_inscricao_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_inscricao_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                    \n",
    "                    #seq =  7 | 3_frame_dados_tomador    \n",
    "                    elif frame_pesquisa == \"3_frame_dados_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_dados_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "                    #seq =  8 | 4_frame_descricao_totais\n",
    "                    elif frame_pesquisa == \"4_frame_descricao_totais\":\n",
    "                        data_servico = {}\n",
    "                        result = {}\n",
    "                        f_father = \"4_frame_descricao_totais\"\n",
    "                        section = \"4. DESCRIMINACAO DOS SERVIÇOS\" \n",
    "                        vx_0 = 125\n",
    "                        vy_0 = 1123\n",
    "                        vx_1 = 1934\n",
    "                        vy_1 = 1720\n",
    "                        data_servico['secao'] = section\n",
    "                        result, texto_extraido = ocr_RasterPDF_free(image_2work, vx_0, vy_0, vx_1, vy_1)\n",
    "                        nf_data_servico = {}\n",
    "                        label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                        if texto_extraido.startswith(label):\n",
    "                            text = texto_extraido[len(label):].strip()\n",
    "                        data_servico['discriminacao_servicos'] = text \n",
    "                        print(data_servico)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 5. VALOR TOTAL\n",
    "                    #seq =  9 | 4_frame_valor_total   \n",
    "                    elif frame_pesquisa == \"4_frame_valor_total\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_valor_total\"\n",
    "                        section = \"5. VALOR TOTAL\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                        \n",
    "                        \n",
    "                    # secao: 6. CNAE e Item da Lista de Serviços\n",
    "                    #seq = 10 | 4_frame_cnae_itens_servico     \n",
    "                    elif frame_pesquisa == \"4_frame_cnae_itens_servico\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_cnae_itens_servico\"\n",
    "                        section = \"6. CNAE e Item da Lista de Serviços\"    \n",
    "                        Texto_extraido = extract_fields_box(model, f_father, section)\n",
    "                        \n",
    "                    \n",
    "                    # secao: 7. VALORES E IMPOSTOS\n",
    "                    #seq = 11 | 5_frame_valores_impostos  \n",
    "                    elif frame_pesquisa == \"5_frame_valores_impostos\":\n",
    "                        data_valores = {}\n",
    "                        result = {}\n",
    "                        father_value = \"5_frame_valores_impostos\"\n",
    "                        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "                        result = extract_fields_box(modelo, father_value, section)\n",
    "                        if result:\n",
    "                            data_valores.update(result)\n",
    "                         \n",
    "\n",
    "                    #seq = 12 | 5_frame_dados_complementares\n",
    "                    elif frame_pesquisa == \"5_frame_dados_complementares\": #TDB\n",
    "                        \n",
    "                    \n",
    "                    #seq = 13 | 5_frame_inf_criticas\n",
    "                    elif frame_pesquisa == \"5_frame_inf_criticas\": #TDB    \n",
    "                    \n",
    "                    \n",
    "                    # secao: 10. OBSERVACOES  \n",
    "                    #seq = 14 | 5_frame_observacao  \n",
    "                    elif frame_pesquisa == \"5_frame_observacao\":\n",
    "                        data_observacao = {}\n",
    "                        f_father = \"5_frame_observacao\"\n",
    "                        section = \"10. OBSERVACOES\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        Texto_extraido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento multiplas paginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_document_pages = []\n",
    "\n",
    "nome_documento = \"pipeline_extracao_documentos/2_documentos_para_extracao/Batch_9/1_5148126179567338367.pdf\"\n",
    "\n",
    "path_destino = \"pipeline_extracao_documentos/2_documentos_para_extracao/Batch_9\"\n",
    "\n",
    "list_document_pages = simple_page_split(nome_documento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resized_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_doc_analise = \"pipeline_extracao_documentos/2_documentos_para_extracao/Batch_RASTER_PDF_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_doc_analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Leitura recursiva de diretorios e arquivos a partir de root\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "nf_data_servico = {}#VERIFICAR\n",
    "analise_doc_nf = {} #VERIFICAR\n",
    "file_data = [] #VERIFICAR\n",
    "\n",
    "list_document_pages = []\n",
    "#nro_nota = 0\n",
    "# TEMP\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "#3. path formado para nome do arquivo json\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "#root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "#print(root_doc_analise)\n",
    "i = 1\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    #print(dir_name)\n",
    "    for file in files:\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            doc2convert = file\n",
    "            document_path_1 = os.path.join(root, file)\n",
    "            pdf_document = fitz.open(document_path_1)\n",
    "            #page_number = 0  # Defina o número da página que deseja analisar\n",
    "            #page = pdf_document[page_number]\n",
    "            \n",
    "            documento_pdf = True\n",
    "            pesquisavel, metadados, paginas = is_pdf_searchable_analise(document_path_1)\n",
    "            #print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                \n",
    "            if not pesquisavel:\n",
    "                \n",
    "                image_2work, name_image_2work = convertResizeAnalise_1page(file, document_path_1, image_resized_path)\n",
    "                \n",
    "                nro_nota = 0\n",
    "                # Frame para teste\n",
    "                i_frame = 0\n",
    "                frames_pesquisa = []\n",
    "                filtered_frames_nf_v4_df = frames_nf_v4_df[frames_nf_v4_df['model'] == model]\n",
    "                for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "                    frame_seq = row_frame['seq']\n",
    "                    frame_model = row_frame['model']\n",
    "                    frame_label = row_frame['label']\n",
    "                    frame_type = row_frame['type']\n",
    "                    frame_section = row_frame['section_json']\n",
    "                    frame_reference = row_frame['reference']\n",
    "                    frame_father = row_frame['father']\n",
    "                    if frame_section == \"1 - CABECALHO\" and frame_type == \"frame\":\n",
    "                        data_cabecalho = {}\n",
    "                        data_cabecalho['secao'] = frame_section\n",
    "                        if frame_father == \"1_frame_prefeitura_nf\" and frame_type == \"sframe_field\":\n",
    "                        #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "                            frame_father = row_frame['father']\n",
    "                            print(f'\\fseq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>20} | section: {frame_section:>35} {frame_reference:>30}')\n",
    "                            result = {}\n",
    "                            data_from_pref = {}\n",
    "                            #Texto_extraido = extract_dados_from_frame(frame_model, frame_father, frame_section)\n",
    "                        #     result = extract_prefeitura(frame_label, frame_model, Texto_extraido)\n",
    "                        #     if result:\n",
    "                        #             data_from_pref.update(result)\n",
    "                                    \n",
    "                        #     if data_from_pref:\n",
    "                        #         data_cabecalho.update(data_from_pref) \n",
    "                        # elif frame_label == \"1_frame_dados_nf\":\n",
    "                        #     Texto_extraido = extract_dados_from_frame(frame_model, frame_label, frame_section)\n",
    "                                        \n",
    "                \n",
    "\n",
    "                                \n",
    "                    #print(Texto_extraido, f_father, section, data_from_frame)\n",
    "\n",
    "                    # #seq = 11 | 5_frame_valores_impostos  \n",
    "                    # elif frame_pesquisa == \"5_frame_valores_impostos\":\n",
    "                    #     data_valores = {}\n",
    "                    #     result = {}\n",
    "                    #     father_value = \"5_frame_valores_impostos\"\n",
    "                    #     section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "                    #     result = extract_fields_box(modelo, father_value, section)\n",
    "                    #     if result:\n",
    "                    #         data_from_frame.update(result)\n",
    "\n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                try:\n",
    "                    pdf_info[nro_nota] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": data_cabecalho,\n",
    "                        # \"data_prestador\": nf_data_prestador,\n",
    "                        # \"data_tomador\": nf_data_tomador,\n",
    "                        # \"data_servico\": nf_data_servico,\n",
    "                        # \"data_valor_total\": nf_data_valor_total,\n",
    "                        # \"data_CNAE\": nf_data_CNAE,\n",
    "                        # \"data_valores\": nf_data_valores,\n",
    "                        # \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        # \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        # \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": dir_name, #os.path.basename(root)\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                    \"Batch\": batch_name,\n",
    "                }\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao gerar o json: {e}\")\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "                \n",
    "                #print(pdf_info)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #if paginas == 1:\n",
    "                if paginas > 1000:\n",
    "\n",
    "                        \n",
    "                    if i == 1000: #Define quantidade de tratamento de documentos raster PDF\n",
    "                        break\n",
    "\n",
    "            i +=1 \n",
    "              \n",
    "            # 2. Tratamento PDF pesquisavel        \n",
    "            #else:\n",
    "                # #print(f'\\nPDF PESQUISAVEL nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                # status = \"O PDF é pesquisável\"\n",
    "                # # Carregar o arquivo PDF\n",
    "                # pdf_document = fitz.open(file_path)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "                # page_number = 0  # Defina o número da página que deseja analisar\n",
    "                # page = pdf_document[page_number]\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 4\n",
    "                # x1 = 600\n",
    "                # y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # if text:\n",
    "                #    page_number = 0\n",
    "                # else:\n",
    "                #    page_number = 1\n",
    "                \n",
    "                \n",
    "                # # 1 - cabecalho\n",
    "                # #pdf_document = fitz.open(file_path)\n",
    "                # #page_number = 0  # Defina o número da página que deseja analisar\n",
    "                # page = pdf_document[page_number]\n",
    "                # x0 = 0\n",
    "                # y0 = 0\n",
    "                # x1 = 600\n",
    "                # y1 = 110\n",
    "                \n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # nf_data_cabecalho = Extc.extract_fields_cabecalho(text)\n",
    "                # #nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # try:\n",
    "                #     nro_nota = nf_data_cabecalho['numero_nota_fiscal']\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Erro ao verificar o PDF: {e}\")\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                # # 2. PRESTADOR DE SERVIÇO\n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 100\n",
    "                # x1 = 600\n",
    "                # y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                # nf_data_prestador = Extc.extract_fields_prestador(text)\n",
    "                # #nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # # 3. TOMADOR DE SERVIÇO\n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 210\n",
    "                # x1 = 600\n",
    "                # y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                \n",
    "                # nf_data_tomador = Extc.extrac.extract_fields_tomador(text)\n",
    "                # #nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                # nf_data_servico = {}\n",
    "                # nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 330\n",
    "                # x1 = 600\n",
    "                # y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # # Remover quebras de linha e rótulo\n",
    "                # text = text.replace('\\n', ' ')\n",
    "                # label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                # if text.startswith(label):\n",
    "                #     text = text[len(label):].strip()\n",
    "\n",
    "                # # Atribuir texto ao dicionário\n",
    "                # nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # # 5. VALOR TOTAL\n",
    "                # nf_data_valor_total = {}\n",
    "                # nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 500\n",
    "                # x1 = 600\n",
    "                # y1 = 550  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                # valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                # if valor_total_match:\n",
    "                #     valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                #     nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # # 6. CNAE e Item da Lista de Serviços\n",
    "                # nf_data_CNAE = {}\n",
    "                # nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # # Definir retângulo de interesse CNAE\n",
    "                # x0 = 0\n",
    "                # y0 = 530\n",
    "                # x1 = 600\n",
    "                # y1 = 540  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # # Extrair CNAE\n",
    "                # nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                # if nf_data_CNAE_match:\n",
    "                #     # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                #     nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                #     # Remover quebras de linha\n",
    "                #     nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                #     nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # # Item da Lista de Serviços    \n",
    "                # # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                # x0 = 0\n",
    "                # y0 = 545\n",
    "                # x1 = 600\n",
    "                # y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # # Extrair Item da Lista de Serviços\n",
    "                # nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                # if nf_item_lista_servicos_match:\n",
    "                #     nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                #     # Remover quebras de linha\n",
    "                #     #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                #     nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                #     nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                  \n",
    "                \n",
    "                # # 7. VALORES E IMPOSTOS\n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 550\n",
    "                # x1 = 600\n",
    "                # y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # # Extrair campos e valores\n",
    "                # nf_data_valores = Extc.extract_fields_impostos(text)\n",
    "                # #nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # # 8. DADOS COMPLEMENTARES\n",
    "                # nf_data_dados_complementares = {}\n",
    "                # nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 650\n",
    "                # x1 = 600\n",
    "                # y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # # Remove a primeira ocorrência de \"Observação:\"\n",
    "                # text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                # if text == \" \":\n",
    "                #     text = \"NONE\"\n",
    "                #     nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                # else:    \n",
    "                #     # Extrair texto dentro do retângulo\n",
    "                #     nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 680\n",
    "                # x1 = 600\n",
    "                # y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # # Extrair campos e valores\n",
    "                # nf_data_outras_informacoes = Extc.extract_fields_outras_info(text)\n",
    "                # #nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # # 10. OBSERVACOES\n",
    "                # nf_data_observacao = {}\n",
    "                # nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # # Definir retângulo de interesse\n",
    "                # x0 = 0\n",
    "                # y0 = 725\n",
    "                # x1 = 600\n",
    "                # y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # # Remove a primeira ocorrência de \"Observação:\"\n",
    "                # text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # # Remover quebras de linha\n",
    "                # text = text.replace('\\n', ' ')\n",
    "\n",
    "                # # Extrair texto dentro do retângulo\n",
    "                # nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                # nr_nro_nf = nro_nota\n",
    "                \n",
    "                # nome_arquivo = file\n",
    "                # #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                # try:\n",
    "                #     pdf_info[nro_nota] = {\n",
    "                #     \"dados_NF_PDF\": {\n",
    "                #         \"data_cabecalho\": nf_data_cabecalho,\n",
    "                #         \"data_prestador\": nf_data_prestador,\n",
    "                #         \"data_tomador\": nf_data_tomador,\n",
    "                #         \"data_servico\": nf_data_servico,\n",
    "                #         \"data_valor_total\": nf_data_valor_total,\n",
    "                #         \"data_CNAE\": nf_data_CNAE,\n",
    "                #         \"data_valores\": nf_data_valores,\n",
    "                #         \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                #         \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                #         \"data_observacao\": nf_data_observacao,\n",
    "                #     },\n",
    "                #     \"diretorio\": dir_name, #os.path.basename(root)\n",
    "                #     \"nome_arquivo\": nome_arquivo,\n",
    "                #     \"Batch\": batch_name,\n",
    "                # }\n",
    "                # except Exception as e:\n",
    "                #     print(f\"Erro ao gerar o json: {e}\")\n",
    "                \n",
    "                \n",
    "                # pdf_document.close()\n",
    "\n",
    "# # Salvando as informações em um arquivo JSON (novo formato nome arquivo V2)\n",
    "# with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "#     json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# print(f\"As informações foram salvas em {json_file_path}\")\n",
    "\n",
    "#print(pdf_info)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_prefeitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_cabecalho():\n",
    "\n",
    "    nf_data_cabecalho = {}\n",
    "    model = \"mage_1\"\n",
    "    # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "    filtered_frames_info = frames_info[frames_info['model'] == model]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        frame_model = row_frame['model']\n",
    "        if frame_model == model:\n",
    "            frame_father = row_frame['label']\n",
    "            # ... Select specific frames ...\n",
    "            if frame_father == \"1_frame_prefeitura_nf\" or frame_father == \"1_frame_dados_nf\":\n",
    "                \n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                \n",
    "                seq = row_frame['seq']\n",
    "                #print(f'\\nLoop 1: {frame_model}, seq.: {seq}, row_frame[label]: {frame_father}\\n')\n",
    "                nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "                \n",
    "                for index_field, row_field in sframe_fields_info.iterrows():\n",
    "                    item_son = row_field['father']\n",
    "                    frame_father = row_frame['label']\n",
    "                    if item_son == frame_father:\n",
    "\n",
    "                        model_value = row_field['model']\n",
    "                        type_value = row_field['type']\n",
    "                        label_value = row_field['label']\n",
    "                        reference_value = row_field['reference']\n",
    "                        seq_value = row_field['seq']\n",
    "                        father_value = row_field['father']\n",
    "                        # ... Select specific fields ...\n",
    "                        if label_value == \"nome_prefeitura\" and model_value == frame_model: \n",
    "                            #print(f'  Loop 2: {model_value}, seq.: {seq_value}, type_value: {type_value}, label_value: {label_value}')\n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            for value in values:\n",
    "                                result = process_line(value, reference_value, label_value)\n",
    "                                if result:\n",
    "                                    nf_data_cabecalho.update(result)\n",
    "                                    \n",
    "                        elif label_value == \"secretaria\" and model_value == frame_model: \n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            for value in values:\n",
    "                                result = process_line(value, reference_value, label_value)\n",
    "                                if result:\n",
    "                                    nf_data_cabecalho.update(result)\n",
    "                                    \n",
    "                        elif label_value == \"tipo_nota_fiscal\" and model_value == frame_model:\n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            for value in values:\n",
    "                                result = process_line(value, reference_value, label_value)\n",
    "                                if result:\n",
    "                                    nf_data_cabecalho.update(result)\n",
    "                        \n",
    "                        #Extraçao de Dados da NF            \n",
    "                        elif father_value == \"1_frame_dados_nf\" and model_value == frame_model:\n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            data_list = [item for item in values if item != '']\n",
    "                            \n",
    "                            data_dict = {}\n",
    "                            for i in range(0, len(data_list), 2):\n",
    "                                key = data_list[i]\n",
    "                                value = data_list[i+1]\n",
    "                                data_dict[key] = value\n",
    "\n",
    "                            # You can now access the values using the corresponding labels\n",
    "                            nro_nota_fiscal = data_dict['Número da Nota:']\n",
    "                            nf_data_cabecalho['numero_nota_fiscal'] = data_dict['Número da Nota:']\n",
    "                            nf_data_cabecalho['competencia'] = data_dict['Competência:']\n",
    "                            nf_data_cabecalho['dt_hr_emissao'] = data_dict['ata e Hora da Emissão:']\n",
    "                            nf_data_cabecalho['codigo_verificacao'] = data_dict['Código Verificação:']\n",
    "                            \n",
    "    return nf_data_cabecalho, nro_nota_fiscal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocos de chamada e checagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = Texto_extraido.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_father"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prefeitura(father, model, text):\n",
    "    data_extrated_prefeitura = {}\n",
    "\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == f_father) & (sframe_fields_info['model'] == model)]\n",
    "\n",
    "    for index_sframe, row_sframe in filtered_sframe_fields_info.iterrows():\n",
    "        label_value = row_sframe['label']\n",
    "        if label_value == \"nome_prefeitura\":\n",
    "            reference_value = row_sframe['reference']\n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result)\n",
    "        elif label_value == \"secretaria\":\n",
    "            reference_value = row_sframe['reference']\n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result) \n",
    "        elif label_value == \"tipo_nota_fiscal\":\n",
    "            reference_value = row_sframe['reference']  \n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result)\n",
    "                    \n",
    "    return data_extrated_prefeitura                                      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sframe_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pesquisa_texto(texto):\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', texto)\n",
    "    if nome_prefeitura_match:\n",
    "        is_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        \n",
    "        return  is_prefeitura\n",
    "    else:\n",
    "        raise ValueError(\"Nao consegui pesquisar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sframe_info = {}\n",
    "\n",
    "sframe_fields_info\n",
    "\n",
    "filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == f_father) & (sframe_fields_info['model'] == model)]\n",
    "for index_sframe, row_sframe in filtered_sframe_fields_info.iterrows():\n",
    "    reference = row_sframe['reference']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "if texto_extraido.startswith(label):\n",
    "    text = texto_extraido[len(label):].strip()\n",
    "nf_data_servico['discriminacao_servicos'] = text \n",
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "if texto_extraido.startswith(label):\n",
    "    text = texto_extraido[len(label):].strip()\n",
    "nf_data_servico['discriminacao_servicos'] = text \n",
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(f'\\nseq: {seq} |  label: {label} | reference: {reference} ')\n",
    "    data_sframe_info['seq'] = seq\n",
    "    data_sframe_info['label'] = label\n",
    "    data_sframe_info['reference'] = reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = row_sframe['seq']\n",
    "label = row_sframe['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### novissimas funcoes de extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. funcao: find_value_after_keyword_out_frame_up\n",
    "def find_value_after_keyword_out_frame_up(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "        if text_list[index + 1] not in default_keyword_list:\n",
    "            return text_list[index + 1]\n",
    "        else:\n",
    "            return \"Valor não encontrado\"  # Ou pode retornar None ou uma string vazia, conforme sua necessidade\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            for default_keyword in default_keyword_list:\n",
    "                if default_keyword in text_list:\n",
    "                    # Caso especial para 'Nome/Razão Social:'\n",
    "                    if keyword == 'Nome/Razão Social:':\n",
    "                        return text_list[0]\n",
    "        return \"Keyword não encontrada\"\n",
    "    \n",
    "#2. find_value_after_keyword_out_frame_down  \n",
    "def find_value_after_keyword_out_frame_down(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return \"Keyword não encontrada\"\n",
    "        else:\n",
    "            return \"Keyword não encontrada\"\n",
    "        \n",
    "#3. find_value_after_keyword_fuzz\n",
    "def find_value_after_keyword_fuzz(keyword, text_list, default_keyword_list=None, fuzziness_threshold=80):\n",
    "    closest_match = None\n",
    "    closest_match_score = 0\n",
    "    \n",
    "    for i, text in enumerate(text_list):\n",
    "        score = fuzz.ratio(keyword, text)\n",
    "        \n",
    "        if score > closest_match_score:\n",
    "            closest_match_score = score\n",
    "            closest_match = text\n",
    "        \n",
    "        if closest_match_score > fuzziness_threshold:\n",
    "            break\n",
    "\n",
    "    if closest_match_score > fuzziness_threshold:\n",
    "        index = text_list.index(closest_match)\n",
    "        if index + 1 < len(text_list):\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    else:\n",
    "        return \"Keyword não encontrada\"            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> Relaçao de Frames para funcoes </mar>\n",
    "\n",
    "seq =  0 | 1_frame_prefeitura_nf\n",
    "\n",
    "seq =  1 | 1_frame_dados_nf\n",
    "\n",
    "seq =  2 | 2_frame_cnpj_prestador\n",
    "\n",
    "seq =  3 | 2_frame_inscricao_prestador\n",
    "\n",
    "seq =  4 | 2_frame_dados_prestador\n",
    "\n",
    "seq =  5 | 3_frame_cnpj_tomador\n",
    "\n",
    "seq =  6 | 3_frame_inscricao_tomador\n",
    "\n",
    "seq =  7 | 3_frame_dados_tomador\n",
    "\n",
    "seq =  8 | 4_frame_descricao_totais\n",
    "\n",
    "seq =  9 | 4_frame_valor_total\n",
    "\n",
    "seq = 10 | 4_frame_cnae_itens_servico\n",
    "\n",
    "seq = 11 | 5_frame_valores_impostos\n",
    "\n",
    "seq = 12 | 5_frame_dados_complementares\n",
    "\n",
    "seq = 13 | 5_frame_inf_criticas\n",
    "\n",
    "seq = 14 | 5_frame_observacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Interacao para pesquisar prefeitura\n",
    "def pesquisa_texto(texto):\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', texto)\n",
    "    if nome_prefeitura_match:\n",
    "        is_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        \n",
    "        return  is_prefeitura\n",
    "    else:\n",
    "        raise ValueError(\"Nao consegui pesquisar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"1_frame_dados_nf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splited = texto_extraido()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Número da Nota:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Competência:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Código Verificação:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"2_frame_inscricao_prestador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Inscrição Municipal:', 'Inscrição Estadual:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Municipal:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Estadual:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"2_frame_dados_prestador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Nome/Razão Social:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Nome de Fantasia:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Endereço:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"E-mail:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"3_frame_inscricao_tomador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['RG:', 'Inscrição Estadual:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"RG:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Estadual:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa =\"3_frame_dados_tomador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"Nome/Razão Social:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"Endereço:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"E-mail\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_descricao_totais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "if texto_extraido.startswith(label):\n",
    "    text = texto_extraido[len(label):].strip()\n",
    "nf_data_servico['discriminacao_servicos'] = text \n",
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_valor_total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r'R\\$\\s[\\d,.]+', Texto_extraido)\n",
    "\n",
    "if match:\n",
    "    extracted_value = match.group(0)\n",
    "else:\n",
    "    extracted_value = \"Valor não encontrado\"\n",
    "\n",
    "valor_total = format_number(extracted_value)\n",
    "\n",
    "print(valor_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "                filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "                for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "                    frame_name = row_frame['label']\n",
    "                    frames_pesquisa.append(frame_name)\n",
    "                    data_cabecalho = {}\n",
    "                    section = \"1 - CABECALHO\"\n",
    "                    data_frame = \"1_frame_prefeitura_nf\"\n",
    "                    if frames_pesquisa[i_frame] == data_frame:\n",
    "                        print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                        result = {}\n",
    "                        data_from_pref = {}\n",
    "                        f_father = frames_pesquisa[i_frame]\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        result = extract_prefeitura(f_father, model, Texto_extraido)\n",
    "                        if result:\n",
    "                                data_from_pref.update(result)\n",
    "                                \n",
    "                        if data_from_pref:\n",
    "                            data_cabecalho.update(data_from_pref)      \n",
    "                            \n",
    "                            \n",
    "                elif frames_pesquisa[i_frame] == data_frame:\n",
    "                    print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                    data_frame = \"1_frame_dados_nf\"            \n",
    "                    f_father = frames_pesquisa[i_frame]\n",
    "                    Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                    #result = extract_prefeitura(f_father, model, Texto_extraido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_cnae_itens_servico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mage_cnae_x_item_servico_df = pd.read_excel('pipeline_extracao_documentos/6_geral_administacao/datasets/MAGE_CNAE_X_ITEM_SERVICO_V1.xlsx')\n",
    "\n",
    "# Creating a dictionary for CNAE codes and descriptions\n",
    "cnae_dict = dict(zip(mage_cnae_x_item_servico_df['cnae'], mage_cnae_x_item_servico_df['descricao_cnae']))\n",
    "item_servico_dict = dict(zip(mage_cnae_x_item_servico_df['item_servico'], mage_cnae_x_item_servico_df['descricao_item_servico']))\n",
    "\n",
    "\n",
    "\n",
    "# Função para extrair número da string\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\b\\d+(\\.\\d+)?\\b', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido\n",
    "text_splited = Texto_extraido.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando CNAE\n",
    "cnae_line = [line for line in text_splited if 'CNAE' in line][0]\n",
    "cnae_number = int(extract_number(cnae_line))\n",
    "cnae_value = cnae_dict.get(cnae_number, \"Valor não encontrado\")\n",
    "cnae_value = cnae_value.upper()\n",
    "cnae_value = str(cnae_number) + \" - \" + cnae_value\n",
    "print(cnae_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando Item de Serviço\n",
    "item_servico_line = [line for line in text_splited if 'Item da Lista de Serviços' in line][0]\n",
    "item_servico_number = float(extract_number(item_servico_line))\n",
    "item_servico_value = item_servico_dict.get(item_servico_number, \"Valor não encontrado\")\n",
    "item_servico_value = item_servico_value.upper()\n",
    "item_servico_value = str(item_servico_number) + \" - \" + item_servico_value\n",
    "print(item_servico_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenha Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0297 Raquel.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0299 Luciana.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for color names to RGB values\n",
    "color_mapping = {\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"orange\": (255, 165, 0),\n",
    "    \"green\": (0, 128, 50),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"yellow\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "# Reload the image to start fresh\n",
    "image = Image.open(name_image_2work)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define a font size for the labels using the default PIL font\n",
    "font_size = 100\n",
    "#font = ImageFont.load_default()\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf\", 30, encoding=\"unic\")\n",
    "\n",
    "# Update the draw_box function to use the larger font size with the default font\n",
    "def draw_box(row):\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    color = color_mapping.get(row['color'], (0, 0, 0)) # Default to black if color not found\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
    "    label = str(row['label']) if pd.notnull(row['label']) else None # Check for missing label\n",
    "    if label:\n",
    "        draw.text((x0 + 5, y0 + 5), label, fill=color, font=font)\n",
    "\n",
    "# Draw the boundaries\n",
    "#draw_box(boundaries_info)\n",
    "\n",
    "\n",
    "def draw_box_model(modelo,\n",
    "                   boundaries_info=None,\n",
    "                   sections_info=None,\n",
    "                   frames_info=None,\n",
    "                   field_boxes_info=None,\n",
    "                   draw_boundaries=True,\n",
    "                   draw_sections=True,\n",
    "                   draw_frames=True,\n",
    "                   draw_field_boxes=True):\n",
    "    \n",
    "    # Draw boundaries if requested\n",
    "    if draw_boundaries and boundaries_info is not None:\n",
    "        filtered_boundaries_info = boundaries_info[boundaries_info['model'] == modelo]\n",
    "        for index, row in filtered_boundaries_info.iterrows():\n",
    "            draw_box(row)\n",
    "\n",
    "    # Draw sections if requested\n",
    "    if draw_sections and sections_info is not None:\n",
    "        filtered_sections_info = sections_info[sections_info['model'] == modelo]\n",
    "        for index, row in filtered_sections_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw frames if requested\n",
    "    if draw_frames and frames_info is not None:\n",
    "        filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "        for index, row in filtered_frames_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw field boxes if requested\n",
    "    if draw_field_boxes and field_boxes_info is not None:\n",
    "        filtered_field_boxes_info = field_boxes_info[field_boxes_info['model'] == modelo]\n",
    "        for index, row in filtered_field_boxes_info.iterrows():\n",
    "            draw_box(row)\n",
    "    \n",
    "    # Show the image with selected drawings\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"mage_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw everything\n",
    "draw_box_model(modelo, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames de pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # secao: 1 - CABECALHO\n",
    "                    #seq =  0 | 1_frame_prefeitura_nf\n",
    "                    if frame_pesquisa == \"1_frame_prefeitura_nf\":\n",
    "                        data_cabecalho = {}\n",
    "                        f_father = \"1_frame_prefeitura_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                    #seq =  1 | 1_frame_dados_nf\n",
    "                    elif frame_pesquisa == \"1_frame_dados_nf\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"1_frame_dados_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 2. PRESTADOR DE SERVIÇO\n",
    "                    #seq =  2 | 2_frame_cnpj_prestador\n",
    "                    elif frame_pesquisa == \"2_frame_cnpj_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_cnpj_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                    #seq =  3 | 2_frame_inscricao_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_inscricao_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_inscricao_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)       \n",
    "                    \n",
    "                    #seq =  4 | 2_frame_dados_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_dados_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_dados_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                           \n",
    "                           \n",
    "                    # secao: 3 - TOMADOR       \n",
    "                    #seq =  5 | 3_frame_cnpj_tomador       \n",
    "                    elif frame_pesquisa == \"3_frame_cnpj_tomador\": #TBD\n",
    "                    \n",
    "                    #seq =  6 | 3_frame_inscricao_tomador \n",
    "                    elif frame_pesquisa == \"3_frame_inscricao_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_inscricao_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                    \n",
    "                    #seq =  7 | 3_frame_dados_tomador    \n",
    "                    elif frame_pesquisa == \"3_frame_dados_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_dados_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "                    #seq =  8 | 4_frame_descricao_totais\n",
    "                    elif frame_pesquisa == \"4_frame_descricao_totais\":\n",
    "                        data_servico = {}\n",
    "                        result = {}\n",
    "                        f_father = \"4_frame_descricao_totais\"\n",
    "                        section = \"4. DESCRIMINACAO DOS SERVIÇOS\" \n",
    "                        vx_0 = 125\n",
    "                        vy_0 = 1123\n",
    "                        vx_1 = 1934\n",
    "                        vy_1 = 1720\n",
    "                        data_servico['secao'] = section\n",
    "                        result, texto_extraido = ocr_RasterPDF_free(image_2work, vx_0, vy_0, vx_1, vy_1)\n",
    "                        nf_data_servico = {}\n",
    "                        label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                        if texto_extraido.startswith(label):\n",
    "                            text = texto_extraido[len(label):].strip()\n",
    "                        data_servico['discriminacao_servicos'] = text \n",
    "                        print(data_servico)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 5. VALOR TOTAL\n",
    "                    #seq =  9 | 4_frame_valor_total   \n",
    "                    elif frame_pesquisa == \"4_frame_valor_total\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_valor_total\"\n",
    "                        section = \"5. VALOR TOTAL\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                        \n",
    "                        \n",
    "                    # secao: 6. CNAE e Item da Lista de Serviços\n",
    "                    #seq = 10 | 4_frame_cnae_itens_servico     \n",
    "                    elif frame_pesquisa == \"4_frame_cnae_itens_servico\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_cnae_itens_servico\"\n",
    "                        section = \"6. CNAE e Item da Lista de Serviços\"    \n",
    "                        Texto_extraido = extract_fields_box(model, f_father, section)\n",
    "                        \n",
    "                    \n",
    "                    # secao: 7. VALORES E IMPOSTOS\n",
    "                    #seq = 11 | 5_frame_valores_impostos  \n",
    "                    elif frame_pesquisa == \"5_frame_valores_impostos\":\n",
    "                        data_valores = {}\n",
    "                        result = {}\n",
    "                        father_value = \"5_frame_valores_impostos\"\n",
    "                        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "                        result = extract_fields_box(modelo, father_value, section)\n",
    "                        if result:\n",
    "                            data_valores.update(result)\n",
    "                         \n",
    "\n",
    "                    #seq = 12 | 5_frame_dados_complementares\n",
    "                    elif frame_pesquisa == \"5_frame_dados_complementares\": #TDB\n",
    "                        \n",
    "                    \n",
    "                    #seq = 13 | 5_frame_inf_criticas\n",
    "                    elif frame_pesquisa == \"5_frame_inf_criticas\": #TDB    \n",
    "                    \n",
    "                    \n",
    "                    # secao: 10. OBSERVACOES  \n",
    "                    #seq = 14 | 5_frame_observacao  \n",
    "                    elif frame_pesquisa == \"5_frame_observacao\":\n",
    "                        data_observacao = {}\n",
    "                        f_father = \"5_frame_observacao\"\n",
    "                        section = \"10. OBSERVACOES\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        Texto_extraido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de funcoes de extracao - PDF Pesquisavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "# 0. Pesquisa PDF\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 1. CABECALHO\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['nome_prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['tipo_nota_fiscal'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nr_nro_nf = numero_nota_match.group(1)\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = numero_nota_match.group(1)\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['codigo_verificacao'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "def extract_fields_prestador(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    nf_data_prestador = {}\n",
    "    \n",
    "    nf_data_prestador['secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['inscricao_estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador['telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['razao_social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['nome_fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['email'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['email'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "# 3. TOMADOR DE SERVIÇO\n",
    "def extract_fields_tomador(text):\n",
    "    nf_data_tomador = {}\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['rg'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['rg'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['inscricao_estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['razao_social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['email'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['email'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "def extract_fields_impostos(text):\n",
    "    nf_data_valores = {}\n",
    "    nf_data_valores['secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_servicos'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['valor_servicos'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_deducao'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_deducao'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_incond'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_incond'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['base_calculo'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['base_calculo'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['aliquota'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['aliquota'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss_retido'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss_retido'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_cond'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_cond'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_pis'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_pis'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_cofins'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_cofins'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_ir'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_ir'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_inss'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_inss'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_csll'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_csll'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['outras_retencoes'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['outras_retencoes'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_liquido'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_liquido'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # secao: 5 - VALOR TOTAL\n",
    "        data_valor_total = {}\n",
    "        #data_valor_total = processa_total()\n",
    "        father_value = \"4_frame_valor_total\"\n",
    "        section = \"5. VALOR TOTAL\"\n",
    "        \n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_valor_total.update(result)\n",
    "        \n",
    "        # secao: 6 - CNAE e Item da Lista de Serviços\n",
    "        data_CNAE = {}\n",
    "        data_CNAE = processa_cnae_itens()\n",
    "\n",
    "        # secao: 7 - VALORES E IMPOSTOS & 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "        data_valores = {}\n",
    "        father_value = \"5_frame_valores_impostos\"\n",
    "        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_valores.update(result)\n",
    "            \n",
    "        # secao: 8 - DADOS COMPLEMENTARES\"\n",
    "        data_dados_complementares = {}\n",
    "        f_father = \"5_frame_dados_complementares\"\n",
    "        section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "        data_dados_complementares = extract_dados_comple_obs(modelo, f_father, section)                                           \n",
    "                                \n",
    "                                \n",
    "        # secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "        data_outras_informacoes = {}\n",
    "        father_value = \"5_frame_inf_criticas\"\n",
    "        section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "\n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_outras_informacoes.update(result)                        \n",
    "                            \n",
    "\n",
    "        # secao: 10. OBSERVACOES\n",
    "        data_observacao = {}\n",
    "        f_father = \"5_frame_observacao\"\n",
    "        section = \"10. OBSERVACOES\"\n",
    "\n",
    "        data_observacao = extract_dados_comple_obs(modelo, f_father, section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras funcoes deprecateds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_after_keyword_out_frame(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return \"Keyword não encontrada\"\n",
    "        else:\n",
    "            return \"Keyword não encontrada\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_after_keyword(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return \"Keyword não encontrada\"\n",
    "        else:\n",
    "            return \"Keyword não encontrada\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
