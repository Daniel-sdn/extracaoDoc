{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Extracao Unificada V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "import PyPDF2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "\n",
    "#import modules.ExtracaoPdf as extrac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRESTAR ATENCAO\n",
    "modelo = 'mage_1'\n",
    "\n",
    "\n",
    "#### IMPORTANTE - Nro Batch\n",
    "batch_name = \"Batch_10\"\n",
    "\n",
    "\n",
    "# 1. path para documentos PDF (omelhor se estiverem dentro de um unico diretorio)\n",
    "root_pdf_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 2. path para documentos PDF que podem estar aguardando para serem processados\n",
    "root_pdf_aguardando_path = \"pipeline_extracao_documentos/3_tratamento_excecoes/pdf_aguardando_processar\"\n",
    "\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 3. path para documentos PDF externos para serem processados\n",
    "root_external_pdf_path = \"content_from_pdftool/data/data_pdf/NF_para_processamento/NFRJ_PDF_para _ocr\"\n",
    "# 4. path para documentos PDF PESQUISAVEIS externos para serem processados\n",
    "root_external_pdf_pesquisavel_path = \"content_from_pdftool/data/data_pdf/NF_processadas/NFRJ/fwdnotasfiscaisemitidaslmpadalegal\"\n",
    "\n",
    "# 5. path para imagem padrao\n",
    "image_resized_path = 'pipeline_extracao_documentos/6_geral_administacao/images/processadas'\n",
    "\n",
    "# 6. path para log\n",
    "log_path = 'pipeline_extracao_documentos/6_geral_administacao/logs'\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"pipeline_extracao_documentos/5_documentos_processados/jsons\"\n",
    "\n",
    "# 8. path para NFs processadas\n",
    "nf_processada_path = \"pipeline_extracao_documentos/5_documentos_processados\"\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "# 9. path para modelos\n",
    "nf_model_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/frames_nf_v6.xlsx\"\n",
    "\n",
    "# 10. path para dicionario de modelos\n",
    "model_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/models.csv\"\n",
    "\n",
    "# 11. path para datasets CNAE e Itens de Serviço\n",
    "nf_datasets_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "\n",
    "\n",
    "# VERIFICAR\n",
    "tgt_imagens = \"pipeline_extracao_documentos/6_geral_administacao/images\"\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento template do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le a planilha e cria do DF\n",
    "frames_nf_v3_df = pd.read_excel(nf_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seq</th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>box</th>\n",
       "      <th>t_value</th>\n",
       "      <th>father</th>\n",
       "      <th>label</th>\n",
       "      <th>reference</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>Largura</th>\n",
       "      <th>Altura</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>1</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>2</td>\n",
       "      <td>boundaries</td>\n",
       "      <td>green</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>2567.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>3</td>\n",
       "      <td>section</td>\n",
       "      <td>red</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14.803272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>4</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>5</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>string</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>nome_prefeitura</td>\n",
       "      <td>PREFEITURA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>73</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>issqn_retido</td>\n",
       "      <td>ISSQN RETIDO</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>74</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_pretacao_servico</td>\n",
       "      <td>LOCAL. PRESTAÇÃO SERVIÇO</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>75</td>\n",
       "      <td>field_box</td>\n",
       "      <td>orange</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_incidencia</td>\n",
       "      <td>LOCAL INCIDÊNCIA</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2425.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>76</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>uma observação</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>77</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>observação</td>\n",
       "      <td>OBSERVAÇÃO:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  seq          type   color  box t_value  \\\n",
       "0   mage_1    1      document     NaN  NaN     NaN   \n",
       "1   mage_1    2    boundaries   green  yes     NaN   \n",
       "2   mage_1    3       section     red  yes     NaN   \n",
       "3   mage_1    4         frame  purple  yes     NaN   \n",
       "4   mage_1    5  sframe_field     NaN   no  string   \n",
       "..     ...  ...           ...     ...  ...     ...   \n",
       "72  mage_1   73     field_box  orange  yes  string   \n",
       "73  mage_1   74     field_box  orange  yes  string   \n",
       "74  mage_1   75     field_box  orange  yes  string   \n",
       "75  mage_1   76         frame  purple  NaN     NaN   \n",
       "76  mage_1   77  sframe_field     NaN   no     NaN   \n",
       "\n",
       "                                   father                              label  \\\n",
       "0                                     NaN             modelo_prefeitura_mage   \n",
       "1                  modelo_prefeitura_mage  boundaries_modelo_prefeitura_mage   \n",
       "2       boundaries_modelo_prefeitura_mage             1_section_cabecalho_nf   \n",
       "3                  1_section_cabecalho_nf              1_frame_prefeitura_nf   \n",
       "4                   1_frame_prefeitura_nf                    nome_prefeitura   \n",
       "..                                    ...                                ...   \n",
       "72                   5_frame_inf_criticas                       issqn_retido   \n",
       "73                   5_frame_inf_criticas             local_pretacao_servico   \n",
       "74                   5_frame_inf_criticas                   local_incidencia   \n",
       "75  6_section_inf_complementares_criticas                 5_frame_observacao   \n",
       "76                     5_frame_observacao                         observação   \n",
       "\n",
       "                   reference      x0      y0      x1      y1  Largura  Altura  \\\n",
       "0                        NaN     0.0     0.0  2067.0  2923.0   2067.0  2923.0   \n",
       "1                        NaN   144.0    99.0  1925.0  2666.0   1781.0  2567.0   \n",
       "2                        NaN     0.0     0.0  2067.0   380.0   2067.0   380.0   \n",
       "3                        NaN   406.0     0.0  1540.0   380.0   1030.0   380.0   \n",
       "4                 PREFEITURA     NaN     NaN     NaN     NaN      NaN     NaN   \n",
       "..                       ...     ...     ...     ...     ...      ...     ...   \n",
       "72              ISSQN RETIDO  1066.0  2425.0  1328.0  2521.0    262.0    96.0   \n",
       "73  LOCAL. PRESTAÇÃO SERVIÇO  1328.0  2425.0  1638.0  2521.0    310.0    96.0   \n",
       "74          LOCAL INCIDÊNCIA  1638.0  2425.0  1922.0  2521.0    284.0    96.0   \n",
       "75            uma observação   148.0  2521.0  1922.0  2676.0   1774.0   155.0   \n",
       "76               OBSERVAÇÃO:     NaN     NaN     NaN     NaN      0.0     0.0   \n",
       "\n",
       "             %  \n",
       "0          NaN  \n",
       "1   100.000000  \n",
       "2    14.803272  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "..         ...  \n",
       "72         NaN  \n",
       "73         NaN  \n",
       "74         NaN  \n",
       "75         NaN  \n",
       "76         NaN  \n",
       "\n",
       "[77 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_nf_v3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'section']\n",
    "frames_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seq</th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>box</th>\n",
       "      <th>t_value</th>\n",
       "      <th>father</th>\n",
       "      <th>label</th>\n",
       "      <th>reference</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>Largura</th>\n",
       "      <th>Altura</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>4</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>8</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_dados_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>14</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_cnpj_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>18</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_inscricao_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>21</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_dados_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>27</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_cnpj_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>32</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_inscricao_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>35</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_dados_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>40</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_descricao_totais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>42</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_valor_total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>45</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_cnae_itens_servico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>50</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_section_valores_dados</td>\n",
       "      <td>5_frame_valores_impostos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>67</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_dados_complementares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>69</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>76</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>uma observação</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  seq   type   color  box t_value  \\\n",
       "3   mage_1    4  frame  purple  yes     NaN   \n",
       "7   mage_1    8  frame  purple  yes     NaN   \n",
       "13  mage_1   14  frame  purple  yes     NaN   \n",
       "17  mage_1   18  frame  purple  yes     NaN   \n",
       "20  mage_1   21  frame  purple  yes     NaN   \n",
       "26  mage_1   27  frame  purple  yes     NaN   \n",
       "31  mage_1   32  frame  purple  yes     NaN   \n",
       "34  mage_1   35  frame  purple  yes     NaN   \n",
       "39  mage_1   40  frame  purple  yes     NaN   \n",
       "41  mage_1   42  frame  purple  yes     NaN   \n",
       "44  mage_1   45  frame  purple  yes     NaN   \n",
       "49  mage_1   50  frame  purple  yes     NaN   \n",
       "66  mage_1   67  frame  purple  yes     NaN   \n",
       "68  mage_1   69  frame  purple  yes     NaN   \n",
       "75  mage_1   76  frame  purple  NaN     NaN   \n",
       "\n",
       "                                   father                         label  \\\n",
       "3                  1_section_cabecalho_nf         1_frame_prefeitura_nf   \n",
       "7                  1_section_cabecalho_nf              1_frame_dados_nf   \n",
       "13            2_section_prestador_servico        2_frame_cnpj_prestador   \n",
       "17            2_section_prestador_servico   2_frame_inscricao_prestador   \n",
       "20            2_section_prestador_servico       2_frame_dados_prestador   \n",
       "26              3_section_tomador_servico          3_frame_cnpj_tomador   \n",
       "31              3_section_tomador_servico     3_frame_inscricao_tomador   \n",
       "34              3_section_tomador_servico         3_frame_dados_tomador   \n",
       "39              4_section_servicos_totais      4_frame_descricao_totais   \n",
       "41              4_section_servicos_totais           4_frame_valor_total   \n",
       "44              4_section_servicos_totais    4_frame_cnae_itens_servico   \n",
       "49                5_section_valores_dados      5_frame_valores_impostos   \n",
       "66  6_section_inf_complementares_criticas  5_frame_dados_complementares   \n",
       "68  6_section_inf_complementares_criticas          5_frame_inf_criticas   \n",
       "75  6_section_inf_complementares_criticas            5_frame_observacao   \n",
       "\n",
       "         reference      x0      y0      x1      y1  Largura  Altura   %  \n",
       "3              NaN   406.0     0.0  1540.0   380.0   1030.0   380.0 NaN  \n",
       "7              NaN  1633.0     0.0  2067.0   380.0    434.0   380.0 NaN  \n",
       "13             NaN     0.0   380.0   550.0   555.0    440.0   170.0 NaN  \n",
       "17             NaN   550.0   380.0  1357.0   555.0    917.0   170.0 NaN  \n",
       "20             NaN     0.0   552.0  2067.0   785.0   2067.0   235.0 NaN  \n",
       "26             NaN     0.0   785.0   550.0   983.0    440.0   198.0 NaN  \n",
       "31             NaN   550.0   785.0  1357.0   983.0    917.0   198.0 NaN  \n",
       "34             NaN     0.0   983.0  2067.0  1154.0   2067.0   171.0 NaN  \n",
       "39             NaN     0.0  1150.0  2067.0  1790.0   2067.0   690.0 NaN  \n",
       "41             NaN     0.0  1743.0  2067.0  1852.0   2067.0   104.0 NaN  \n",
       "44             NaN     0.0  1844.0  2067.0  1943.0   2067.0    99.0 NaN  \n",
       "49             NaN   344.0  1950.0  1953.0  2273.0   1609.0   323.0 NaN  \n",
       "66             NaN   148.0  2273.0  1925.0  2377.0   1777.0   104.0 NaN  \n",
       "68             NaN   148.0  2377.0  1925.0  2521.0   1777.0   144.0 NaN  \n",
       "75  uma observação   148.0  2521.0  1922.0  2676.0   1774.0   155.0 NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras funcoes possiveis com frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_model = row_frame['model']\n",
    "    frame_name = row_frame['label']\n",
    "    if frame_model == model:\n",
    "        frame_father = row_frame['label']\n",
    "        # ... Select specific frames ...\n",
    "        if frame_father == \"2_frame_cnpj_prestador\":\n",
    "        \n",
    "            \n",
    "            # Extrai coordenadas para recorte\n",
    "            x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "            extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "            nf_data_prestador = extract_fields_prestador_cnpj(extracted_text_frame)\n",
    "            \n",
    "        elif frame_father == \"2_frame_inscricao_prestador\":\n",
    "            # Extrai coordenadas para recorte\n",
    "            x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "            extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "            # 1. Prrestador de Servico - INSCRICAO ESTADUAL/MUNICIPAL\n",
    "            nf_data_prestador_incricao = {}\n",
    "\n",
    "            # Dividir o texto em linhas\n",
    "            linhas = extracted_text_frame.split('\\n')\n",
    "\n",
    "            # Inicializar variáveis para armazenar os valores\n",
    "            inscricao_municipal = None\n",
    "            inscricao_estadual = None\n",
    "\n",
    "\n",
    "            # Initialize variables\n",
    "            inscricao_municipal = \"\"\n",
    "            inscricao_estadual = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_boxes_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcoes de imagem e extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRIMEIRAS FUNCOES\n",
    "\n",
    "# 1. Interacao para pesquisar prefeitura\n",
    "def pesquisa_texto(texto):\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', texto)\n",
    "    if nome_prefeitura_match:\n",
    "        is_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        \n",
    "        return  is_prefeitura\n",
    "    else:\n",
    "        raise ValueError(\"Nao consegui pesquisar\")\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "# 3. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# Funcao importante - process_line\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Funcao de conversao e resize do documento\n",
    "def convertResize_analise(nome_documento, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(nome_documento)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "# Funcao de pesquisa de modelo\n",
    "def pequisaModel(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "            return  nome_prefeitura\n",
    "        else:\n",
    "            raise ValueError(\"Nao acho nome de prefeitura\")\n",
    "        \n",
    "# 1. Funcao de conversao e resize do documento\n",
    "def convertResize(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "\n",
    "# 2. Pesquisa prefeitura no documento\n",
    "def pequisaModel(image_name):\n",
    "\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1) \n",
    "            return  nome_prefeitura        \n",
    "        \n",
    "\n",
    "\n",
    "# 3. Ajusta o filename tirando caracteres especiais \n",
    "def conv_filename(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão\n",
    "    name, extension = title.rsplit('.', 1) if '.' in title else (title, \"\")\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    # Adicione a extensão de volta, se houver\n",
    "    if extension:\n",
    "        filename += '.' + extension.lower()\n",
    "\n",
    "    return filename\n",
    "\n",
    "# 4. Ajusta o filename tirando caracteres especiais e a\n",
    "def conv_filename_no_ext(title):\n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename  \n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# 5. Verifica se PDF e pesquisavel ou nao e grava metadados dele\n",
    "def is_pdf_searchable_analise(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        pages = pdf_document.page_count\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        dados_pdf = pdf_document.metadata\n",
    "        pdf_document.close()\n",
    "        return is_searchable, dados_pdf, pages\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "# Funcao importante - process_line\n",
    "\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "def convertResizeAnalise_1page(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    resized_pages = []\n",
    "    for page in pages:\n",
    "        resized_page = page.resize((2067, 2923))\n",
    "        resized_pages.append(resized_page)\n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "# 2. Leitura do arquivo CSV e criação do dicionário modelos\n",
    "def create_model_dictionary(model_dict_path):\n",
    "    model_dictionary = {}\n",
    "    with open(model_dict_path, 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            prefeitura_name = row['prefeitura']\n",
    "            model_name = row['model']\n",
    "\n",
    "            if prefeitura_name not in model_dictionary:\n",
    "                model_dictionary[prefeitura_name] = model_name\n",
    "            \n",
    "            #model_dictionary[prefeitura_name].append(model_name)\n",
    "    \n",
    "    return model_dictionary\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_coordinates(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "# secao: 8 - DADOS COMPLEMENTARES & 10. OBSERVACOES\n",
    "def extract_dados_from_frame(modelo, frame_father, section):\n",
    "    \n",
    "    data_dados_frame = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_frame = extract_text_from_coordinates(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        \n",
    "                \n",
    "    return extracted_text_frame         \n",
    "        \n",
    "        \n",
    "def extract_text_from_frame(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "def format_number(number_str):\n",
    "    # Check for percentage and handle it\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # You can multiply by 100 here if needed\n",
    "\n",
    "    # Check if the string contains \"R$\" or a comma, indicating the original format\n",
    "    if 'R$' in number_str or ',' in number_str:\n",
    "        # Original format: Remove 'R$', replace dots with nothing, and replace commas with dots\n",
    "        number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    else:\n",
    "        # New format: Extract only the numeric part using regex\n",
    "        number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)\n",
    "\n",
    "# Funçao de formatacao de numeros\n",
    "def format_number2(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)\n",
    "\n",
    "\n",
    "def extract_fields_box(modelo, father_value, section):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        #print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference'], row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1'] ))\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        if row_field['t_value'] == 'number':\n",
    "            # Formate o valor usando a função format_number\n",
    "            #print(\"vou verificar valor\")\n",
    "            value = format_number2(value)\n",
    "            #print(value)\n",
    "        # Armazene o texto extraído com o rótulo correspondente\n",
    "        label = row_field['label']\n",
    "        data_box_valores[label] = value\n",
    "        \n",
    "    return data_box_valores\n",
    "\n",
    "# move NF processadas ok\n",
    "def move_raster_pdf(document_path, raster_pdf_path, batch_name, doc2convert):\n",
    "    # Determine the destination directory\n",
    "    destination_dir = os.path.join(raster_pdf_path, batch_name)\n",
    "\n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Determine the destination path including the filename\n",
    "    destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "\n",
    "    # Move the file from the source path to the destination path\n",
    "    try:\n",
    "        shutil.move(document_path, destination_path)\n",
    "        print(f\"Sucesso ao mover: {document_path} para: {destination_path}\")\n",
    "        return True, destination_path, None  # Success, destination path, no error\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao mover: {document_path} para: {destination_path}: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return False, None, error_message  # Failure, no destination path, error message\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_page_split(input_pdf_path):\n",
    "    \n",
    "    # Lista para guardar paginas\n",
    "    document_pages = []\n",
    "    # Abre o PDF\n",
    "    pdf = fitz.open(input_pdf_path)\n",
    "\n",
    "    # Número total de páginas no PDF\n",
    "    total_pages = len(pdf)\n",
    "\n",
    "    # Nome base para os arquivos de saída\n",
    "    base_name = input_pdf_path.split('.')[0]  # Remove a extensão do arquivo\n",
    "\n",
    "    # Loop para criar um novo PDF para cada página\n",
    "    for page_num in range(total_pages):\n",
    "        # Cria um novo objeto PDF\n",
    "        new_pdf = fitz.open()\n",
    "        # Adiciona a página atual ao novo PDF\n",
    "        new_pdf.insert_pdf(pdf, from_page=page_num, to_page=page_num)\n",
    "        # Nome do novo arquivo PDF\n",
    "        new_pdf_name = f\"{base_name}_page_{page_num + 1}.pdf\"\n",
    "        #splited_doc_path = os.path.join(destiny_path, new_pdf_name)\n",
    "        # Atualiza lista de paginas\n",
    "        document_pages.append(new_pdf_name)\n",
    "        # Salva o novo PDF\n",
    "        new_pdf.save(new_pdf_name)\n",
    "        # Fecha o novo PDF\n",
    "        new_pdf.close()\n",
    "\n",
    "    # Fecha o PDF original\n",
    "    pdf.close()\n",
    "    return document_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline  <mark>PDF Pesquisavel e Raster PDF</mark> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste <mark>RASTER_PDF</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando ambiente de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANTE - NRO BATCH PARA TESTE    0 = PDF_PESQUISAVEL | 1 = RASTER_PDF\n",
    "\n",
    "i_test = 0\n",
    "\n",
    "modelo = 'mage_1' \n",
    "\n",
    "tipo_pdf = []\n",
    "tipo_pdf.append('PDF_PESQUISAVEL')\n",
    "tipo_pdf.append('RASTER_PDF')\n",
    "tipo_pdf[i_test]\n",
    "\n",
    "\n",
    "# Tratamento do Path de ORIGEM DO DOCUMENTOS PARA TESTE QUE SERAO MOVIDOS\n",
    "list_path_test = []\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/pdf_pesquisavel_4_test\")\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/raster_pdf_4_test\")\n",
    "list_path_test[i_test]\n",
    "\n",
    "# Frame para teste\n",
    "i_frame = 0\n",
    "\n",
    "frames_pesquisa = []\n",
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_name = row_frame['label']\n",
    "    frames_pesquisa.append(frame_name)\n",
    "\n",
    "# Nome Batch\n",
    "batch_name = \"Batch_\" + str(tipo_pdf[i_test]) + \"_\" + str(i_frame)\n",
    "\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "\n",
    "# Listagem dos frames de pesquisa\n",
    "i = 0\n",
    "for frame in frames_pesquisa:\n",
    "    print(f'seq ={i:>3} | {frame}')\n",
    "    i += 1\n",
    "    \n",
    "if frames_pesquisa[i_frame]:\n",
    "    print(f'\\n\\nDados do teste: batch_name: {batch_name} | frame: {frames_pesquisa[i_frame]} | model: {modelo} | tipo_pdf: {tipo_pdf[i_test]}')\n",
    "    \n",
    "    \n",
    "######### PATHS\n",
    "#1. path formado para busca de pdfs recursiva\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "\n",
    "#2. path para documentos teste RASTER PDF (ATRIBIDO DA LISTA)\n",
    "path_test_pdf = list_path_test[1]\n",
    "\n",
    "#3. path formado para nome do arquivo json\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "\n",
    "#Listando paths utilizados\n",
    "print(f'\\nroot_doc_analise: {root_doc_analise}\\npath_test_pdf: {path_test_pdf}\\njson_file_path: {json_file_path}')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório onde você quer salvar os arquivos extraídos\n",
    "output_dir = os.path.join(documentos_extracao_path, batch_name)\n",
    "i = 1\n",
    "for root, dirs, files in os.walk(path_test_pdf):\n",
    "    #print(f'1. | {root}  | {dirs} | {files}\\n')\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "        \n",
    "        doc2test = file\n",
    "        \n",
    "        \n",
    "        doc2test = conv_filename(doc2test)\n",
    "        doc2test_path = os.path.join(root, doc2test)\n",
    "        destination_path = os.path.join(output_dir, doc2test)\n",
    "        #destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "        #print(f'\\n      iter: {i} Documento: {file} | renomeado para: {doc2test}\\n\\n      mover de: output_dir = {doc2test_path}\\n      para: destination_path =  {destination_path}\\n')\n",
    "        if not os.path.exists(output_dir):\n",
    "           os.makedirs(output_dir) # estou criando o diretorio caso nao exista\n",
    "        # Move the file from the source path to the destination path\n",
    "        try:\n",
    "            shutil.move(doc2test_path, destination_path)\n",
    "            print(f\"Sucesso ao mover: {doc2test_path} para: {destination_path}\")\n",
    "        except Exception as e:\n",
    "            error_message = f\"Erro ao mover: {doc2test_path} para: {destination_path}: {str(e)}\"\n",
    "            print(error_message)   \n",
    "\n",
    "    i += 1    \n",
    "print(f'\\ntotal de {i-1} documentos movidos')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_document_pages = simple_page_split(nome_documento)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo atual de call de funcoes Raster PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # secao: 1 - CABECALHO\n",
    "                    #seq =  0 | 1_frame_prefeitura_nf\n",
    "                    if frame_pesquisa == \"1_frame_prefeitura_nf\":\n",
    "                        data_cabecalho = {}\n",
    "                        f_father = \"1_frame_prefeitura_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                    #seq =  1 | 1_frame_dados_nf\n",
    "                    elif frame_pesquisa == \"1_frame_dados_nf\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"1_frame_dados_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 2. PRESTADOR DE SERVIÇO\n",
    "                    #seq =  2 | 2_frame_cnpj_prestador\n",
    "                    elif frame_pesquisa == \"2_frame_cnpj_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_cnpj_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                    #seq =  3 | 2_frame_inscricao_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_inscricao_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_inscricao_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)       \n",
    "                    \n",
    "                    #seq =  4 | 2_frame_dados_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_dados_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_dados_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                           \n",
    "                           \n",
    "                    # secao: 3 - TOMADOR       \n",
    "                    #seq =  5 | 3_frame_cnpj_tomador       \n",
    "                    elif frame_pesquisa == \"3_frame_cnpj_tomador\": #TBD\n",
    "                    \n",
    "                    #seq =  6 | 3_frame_inscricao_tomador \n",
    "                    elif frame_pesquisa == \"3_frame_inscricao_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_inscricao_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                    \n",
    "                    #seq =  7 | 3_frame_dados_tomador    \n",
    "                    elif frame_pesquisa == \"3_frame_dados_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_dados_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "                    #seq =  8 | 4_frame_descricao_totais\n",
    "                    elif frame_pesquisa == \"4_frame_descricao_totais\":\n",
    "                        data_servico = {}\n",
    "                        result = {}\n",
    "                        f_father = \"4_frame_descricao_totais\"\n",
    "                        section = \"4. DESCRIMINACAO DOS SERVIÇOS\" \n",
    "                        vx_0 = 125\n",
    "                        vy_0 = 1123\n",
    "                        vx_1 = 1934\n",
    "                        vy_1 = 1720\n",
    "                        data_servico['secao'] = section\n",
    "                        result, texto_extraido = ocr_RasterPDF_free(image_2work, vx_0, vy_0, vx_1, vy_1)\n",
    "                        nf_data_servico = {}\n",
    "                        label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                        if texto_extraido.startswith(label):\n",
    "                            text = texto_extraido[len(label):].strip()\n",
    "                        data_servico['discriminacao_servicos'] = text \n",
    "                        print(data_servico)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 5. VALOR TOTAL\n",
    "                    #seq =  9 | 4_frame_valor_total   \n",
    "                    elif frame_pesquisa == \"4_frame_valor_total\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_valor_total\"\n",
    "                        section = \"5. VALOR TOTAL\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                        \n",
    "                        \n",
    "                    # secao: 6. CNAE e Item da Lista de Serviços\n",
    "                    #seq = 10 | 4_frame_cnae_itens_servico     \n",
    "                    elif frame_pesquisa == \"4_frame_cnae_itens_servico\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_cnae_itens_servico\"\n",
    "                        section = \"6. CNAE e Item da Lista de Serviços\"    \n",
    "                        Texto_extraido = extract_fields_box(model, f_father, section)\n",
    "                        \n",
    "                    \n",
    "                    # secao: 7. VALORES E IMPOSTOS\n",
    "                    #seq = 11 | 5_frame_valores_impostos  \n",
    "                    elif frame_pesquisa == \"5_frame_valores_impostos\":\n",
    "                        data_valores = {}\n",
    "                        result = {}\n",
    "                        father_value = \"5_frame_valores_impostos\"\n",
    "                        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "                        result = extract_fields_box(modelo, father_value, section)\n",
    "                        if result:\n",
    "                            data_valores.update(result)\n",
    "                         \n",
    "\n",
    "                    #seq = 12 | 5_frame_dados_complementares\n",
    "                    elif frame_pesquisa == \"5_frame_dados_complementares\": #TDB\n",
    "                        \n",
    "                    \n",
    "                    #seq = 13 | 5_frame_inf_criticas\n",
    "                    elif frame_pesquisa == \"5_frame_inf_criticas\": #TDB    \n",
    "                    \n",
    "                    \n",
    "                    # secao: 10. OBSERVACOES  \n",
    "                    #seq = 14 | 5_frame_observacao  \n",
    "                    elif frame_pesquisa == \"5_frame_observacao\":\n",
    "                        data_observacao = {}\n",
    "                        f_father = \"5_frame_observacao\"\n",
    "                        section = \"10. OBSERVACOES\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        Texto_extraido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento multiplas paginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_documento = \"pipeline_extracao_documentos/2_documentos_para_extracao/Batch_10/SPA 15082023/junto toriba (2).pdf\"\n",
    "\n",
    "path_destino = \"pipeline_extracao_documentos/2_documentos_para_extracao/Batch_10/SPA 15082023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_document_pages = simple_page_split(nome_documento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funcoes anteriores de extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "# 0. Pesquisa PDF\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 1. CABECALHO\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['nome_prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['tipo_nota_fiscal'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nr_nro_nf = numero_nota_match.group(1)\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = numero_nota_match.group(1)\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['codigo_verificacao'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "def extract_fields_prestador(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    nf_data_prestador = {}\n",
    "    \n",
    "    nf_data_prestador['secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['inscricao_estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador['telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['razao_social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['nome_fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['email'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['email'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "# 3. TOMADOR DE SERVIÇO\n",
    "def extract_fields_tomador(text):\n",
    "    nf_data_tomador = {}\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['rg'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['rg'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['inscricao_estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['razao_social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['email'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['email'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "def extract_fields_impostos(text):\n",
    "    nf_data_valores = {}\n",
    "    nf_data_valores['secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_servicos'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['valor_servicos'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_deducao'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_deducao'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_incond'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_incond'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['base_calculo'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['base_calculo'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['aliquota'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['aliquota'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss_retido'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss_retido'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_cond'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_cond'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_pis'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_pis'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_cofins'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_cofins'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_ir'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_ir'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_inss'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_inss'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_csll'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_csll'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['outras_retencoes'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['outras_retencoes'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_liquido'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_liquido'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento do Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "nro: 1 | doc: junto 2566 (11)_page_2.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: junto 2612 (10)_page_2.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: junto 2947 (9)_page_2.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: junto 2565 (12)_page_1.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: junto toriba (2)_page_2.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: NFS N° 202315 - DISTRIBUIDORA NYCOLLY.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: Nota Fiscal Eletrônica 20231763.pdf | pdf?: True | pesquisavel?: True | paginas: 2\n",
      "\n",
      "Erro ao verificar o PDF: 'numero_nota_fiscal'\n",
      "\n",
      "nro: 1 | doc: NFS N° 202314 - MARBELA.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: junto 2569 (11)_page_2.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "\n",
      "nro: 1 | doc: Nota Fiscal Eletrônica 20231708.pdf | pdf?: True | pesquisavel?: True | paginas: 2\n",
      "\n",
      "Erro ao verificar o PDF: 'numero_nota_fiscal'\n",
      "\n",
      "nro: 1 | doc: junto 1822 (5)_page_2.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "As informações foram salvas em pipeline_extracao_documentos/5_documentos_processados/jsons/Batch_10.json\n"
     ]
    }
   ],
   "source": [
    "# 1. Leitura recursiva de diretorios e arquivos a partir de root\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "nf_data_servico = {}#VERIFICAR\n",
    "analise_doc_nf = {} #VERIFICAR\n",
    "file_data = [] #VERIFICAR\n",
    "\n",
    "list_document_pages = []\n",
    "#nro_nota = 0\n",
    "# TEMP\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "#3. path formado para nome do arquivo json\n",
    "\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "\n",
    "i = 1\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    \n",
    "    for file in files:\n",
    "        doc2convert = file\n",
    "        document_path_1 = os.path.join(root, file)\n",
    "        file_path = os.path.join(root, file)\n",
    "        dados_pdf = None  # Inicialização fora do try/catch\n",
    "\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            documento_pdf = True\n",
    "            \n",
    "\n",
    "            \n",
    "            pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "            \n",
    "            print(f'\\nnro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                \n",
    "            # 1. Ponto de pesquisa se PDF e pesquisavel ou nao    \n",
    "            if not pesquisavel:\n",
    "\n",
    "                move_raster_pdf(file_path, path_raster_pdf, batch_name, doc2convert)\n",
    "\n",
    "                #if paginas == 1:\n",
    "                if paginas > 1000:\n",
    "                    model = \"mage_1\"\n",
    "                    #1. Converto para imagem\n",
    "                    # 2. Ajusta o nome do arquivo tirando caracteres especiais e a extensao\n",
    "                    #doc2convert_named = conv_filename_no_ext(doc2convert)\n",
    "                    \n",
    "                    print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                    image_2work, name_image_2work = convertResizeAnalise_1page(file, file_path, image_resized_path)\n",
    "                    \n",
    "                    # CHAVES DE PESQUISA\n",
    "                          \n",
    "                    # Aqui vai o codigo dos blocos\n",
    "                    \n",
    " \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    if i == 1000: #Define quantidade de tratamento de documentos raster PDF\n",
    "                        break\n",
    "                    \n",
    "                print(f'\\nRASTER PDF nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                i +=1 \n",
    "              \n",
    "            # 2. Tratamento PDF pesquisavel        \n",
    "            else:\n",
    "                #print(f'\\nPDF PESQUISAVEL nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                status = \"O PDF é pesquisável\"\n",
    "                # Carregar o arquivo PDF\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "\n",
    "                \n",
    "                \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 4\n",
    "                x1 = 600\n",
    "                y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                if text:\n",
    "                    page_number = 0\n",
    "                else:\n",
    "                    page_number = 1\n",
    "                \n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                #pdf_document = fitz.open(file_path)\n",
    "                #page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 115 #era 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                #nf_data_cabecalho = extrac.extract_fields_cabecalho(text)\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                try:\n",
    "                    nro_nota = nf_data_cabecalho['numero_nota_fiscal']\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao verificar o PDF: {e}\")\n",
    "                    \n",
    "                \n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                #nf_data_prestador = extrac.extract_fields_prestador(text)\n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                \n",
    "                #nf_data_tomador = extrac.extract_fields_tomador(text)\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 490  # era 500\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical 550\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 520 # 530\n",
    "                x1 = 600\n",
    "                y1 = 545  # 540 Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 535 #  545\n",
    "                x1 = 600\n",
    "                y1 = 580  # 560 Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                  \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                #nf_data_valores = extrac.extract_fields_impostos(text)\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                #nf_data_outras_informacoes = extrac.extract_fields_outras_info(text)\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                #nr_nro_nf = nro_nota\n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                \n",
    "                try:\n",
    "                    pdf_info[nro_nota] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": dir_name, #os.path.basename(root)\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                    \"Batch\": batch_name,\n",
    "                }\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao gerar o json: {e}\")\n",
    "                    \n",
    "                pdf_document.close()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "# Salvando as informações em um arquivo JSON (novo formato nome arquivo V2)\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blocos de chamada e checagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_servico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. Tratamento da string\n",
    "Texto_extraido\n",
    "text_splited = Texto_extraido.split('\\n')\n",
    "text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "text_splited = [x for x in text_splited if x.strip()]\n",
    "text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "text_splited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### novissimas funcoes de extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. funcao: find_value_after_keyword_out_frame_up\n",
    "def find_value_after_keyword_out_frame_up(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "        if text_list[index + 1] not in default_keyword_list:\n",
    "            return text_list[index + 1]\n",
    "        else:\n",
    "            return \"Valor não encontrado\"  # Ou pode retornar None ou uma string vazia, conforme sua necessidade\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            for default_keyword in default_keyword_list:\n",
    "                if default_keyword in text_list:\n",
    "                    # Caso especial para 'Nome/Razão Social:'\n",
    "                    if keyword == 'Nome/Razão Social:':\n",
    "                        return text_list[0]\n",
    "        return \"Keyword não encontrada\"\n",
    "    \n",
    "#2. find_value_after_keyword_out_frame_down  \n",
    "def find_value_after_keyword_out_frame_down(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return \"Keyword não encontrada\"\n",
    "        else:\n",
    "            return \"Keyword não encontrada\"\n",
    "        \n",
    "#3. find_value_after_keyword_fuzz\n",
    "def find_value_after_keyword_fuzz(keyword, text_list, default_keyword_list=None, fuzziness_threshold=80):\n",
    "    closest_match = None\n",
    "    closest_match_score = 0\n",
    "    \n",
    "    for i, text in enumerate(text_list):\n",
    "        score = fuzz.ratio(keyword, text)\n",
    "        \n",
    "        if score > closest_match_score:\n",
    "            closest_match_score = score\n",
    "            closest_match = text\n",
    "        \n",
    "        if closest_match_score > fuzziness_threshold:\n",
    "            break\n",
    "\n",
    "    if closest_match_score > fuzziness_threshold:\n",
    "        index = text_list.index(closest_match)\n",
    "        if index + 1 < len(text_list):\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    else:\n",
    "        return \"Keyword não encontrada\"            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> Relaçao de Frames para funcoes </mar>\n",
    "\n",
    "seq =  0 | 1_frame_prefeitura_nf\n",
    "\n",
    "seq =  1 | 1_frame_dados_nf\n",
    "\n",
    "seq =  2 | 2_frame_cnpj_prestador\n",
    "\n",
    "seq =  3 | 2_frame_inscricao_prestador\n",
    "\n",
    "seq =  4 | 2_frame_dados_prestador\n",
    "\n",
    "seq =  5 | 3_frame_cnpj_tomador\n",
    "\n",
    "seq =  6 | 3_frame_inscricao_tomador\n",
    "\n",
    "seq =  7 | 3_frame_dados_tomador\n",
    "\n",
    "seq =  8 | 4_frame_descricao_totais\n",
    "\n",
    "seq =  9 | 4_frame_valor_total\n",
    "\n",
    "seq = 10 | 4_frame_cnae_itens_servico\n",
    "\n",
    "seq = 11 | 5_frame_valores_impostos\n",
    "\n",
    "seq = 12 | 5_frame_dados_complementares\n",
    "\n",
    "seq = 13 | 5_frame_inf_criticas\n",
    "\n",
    "seq = 14 | 5_frame_observacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"1_frame_dados_nf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Número da Nota:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Competência:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Código Verificação:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"2_frame_inscricao_prestador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Inscrição Municipal:', 'Inscrição Estadual:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Municipal:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Estadual:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"2_frame_dados_prestador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Nome/Razão Social:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Nome de Fantasia:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"Endereço:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "\n",
    "string_pesquisa = \"E-mail:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"3_frame_inscricao_tomador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['RG:', 'Inscrição Estadual:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"RG:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pesquisa = \"Inscrição Estadual:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa =\"3_frame_dados_tomador\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Itero sobre text_splited (lista)\n",
    "a = 0\n",
    "for texto_spl in text_splited:\n",
    "    print(f'texto_spl linha {a}: {texto_spl}')\n",
    "\n",
    "    a +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"Nome/Razão Social:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"Endereço:\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "\n",
    "string_pesquisa = \"E-mail\"\n",
    "\n",
    "\n",
    "resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "if resultado_extraido_fuzz == \"Keyword não encontrada\":\n",
    "    resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "    if resultado_extraido_frame_up == \"Keyword não encontrada\":\n",
    "        resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "        resultado_extraido = resultado_extraido_frame_down\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_frame_up\n",
    "else:\n",
    "    resultado_extraido = resultado_extraido_fuzz           \n",
    "    \n",
    "print(f'\"{resultado_extraido}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_descricao_totais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "if texto_extraido.startswith(label):\n",
    "    text = texto_extraido[len(label):].strip()\n",
    "nf_data_servico['discriminacao_servicos'] = text \n",
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nf_data_servico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_valor_total\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r'R\\$\\s[\\d,.]+', Texto_extraido)\n",
    "\n",
    "if match:\n",
    "    extracted_value = match.group(0)\n",
    "else:\n",
    "    extracted_value = \"Valor não encontrado\"\n",
    "\n",
    "valor_total = format_number(extracted_value)\n",
    "\n",
    "print(valor_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame_pesquisa = \"4_frame_cnae_itens_servico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mage_cnae_x_item_servico_df = pd.read_excel('pipeline_extracao_documentos/6_geral_administacao/datasets/MAGE_CNAE_X_ITEM_SERVICO_V1.xlsx')\n",
    "\n",
    "# Creating a dictionary for CNAE codes and descriptions\n",
    "cnae_dict = dict(zip(mage_cnae_x_item_servico_df['cnae'], mage_cnae_x_item_servico_df['descricao_cnae']))\n",
    "item_servico_dict = dict(zip(mage_cnae_x_item_servico_df['item_servico'], mage_cnae_x_item_servico_df['descricao_item_servico']))\n",
    "\n",
    "\n",
    "\n",
    "# Função para extrair número da string\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\b\\d+(\\.\\d+)?\\b', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto_extraido\n",
    "text_splited = Texto_extraido.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando CNAE\n",
    "cnae_line = [line for line in text_splited if 'CNAE' in line][0]\n",
    "cnae_number = int(extract_number(cnae_line))\n",
    "cnae_value = cnae_dict.get(cnae_number, \"Valor não encontrado\")\n",
    "cnae_value = cnae_value.upper()\n",
    "cnae_value = str(cnae_number) + \" - \" + cnae_value\n",
    "print(cnae_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando Item de Serviço\n",
    "item_servico_line = [line for line in text_splited if 'Item da Lista de Serviços' in line][0]\n",
    "item_servico_number = float(extract_number(item_servico_line))\n",
    "item_servico_value = item_servico_dict.get(item_servico_number, \"Valor não encontrado\")\n",
    "item_servico_value = item_servico_value.upper()\n",
    "item_servico_value = str(item_servico_number) + \" - \" + item_servico_value\n",
    "print(item_servico_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenha Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0297 Raquel.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0299 Luciana.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for color names to RGB values\n",
    "color_mapping = {\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"orange\": (255, 165, 0),\n",
    "    \"green\": (0, 128, 50),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"yellow\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "# Reload the image to start fresh\n",
    "image = Image.open(name_image_2work)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define a font size for the labels using the default PIL font\n",
    "font_size = 100\n",
    "#font = ImageFont.load_default()\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf\", 30, encoding=\"unic\")\n",
    "\n",
    "# Update the draw_box function to use the larger font size with the default font\n",
    "def draw_box(row):\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    color = color_mapping.get(row['color'], (0, 0, 0)) # Default to black if color not found\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
    "    label = str(row['label']) if pd.notnull(row['label']) else None # Check for missing label\n",
    "    if label:\n",
    "        draw.text((x0 + 5, y0 + 5), label, fill=color, font=font)\n",
    "\n",
    "# Draw the boundaries\n",
    "#draw_box(boundaries_info)\n",
    "\n",
    "\n",
    "def draw_box_model(modelo,\n",
    "                   boundaries_info=None,\n",
    "                   sections_info=None,\n",
    "                   frames_info=None,\n",
    "                   field_boxes_info=None,\n",
    "                   draw_boundaries=True,\n",
    "                   draw_sections=True,\n",
    "                   draw_frames=True,\n",
    "                   draw_field_boxes=True):\n",
    "    \n",
    "    # Draw boundaries if requested\n",
    "    if draw_boundaries and boundaries_info is not None:\n",
    "        filtered_boundaries_info = boundaries_info[boundaries_info['model'] == modelo]\n",
    "        for index, row in filtered_boundaries_info.iterrows():\n",
    "            draw_box(row)\n",
    "\n",
    "    # Draw sections if requested\n",
    "    if draw_sections and sections_info is not None:\n",
    "        filtered_sections_info = sections_info[sections_info['model'] == modelo]\n",
    "        for index, row in filtered_sections_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw frames if requested\n",
    "    if draw_frames and frames_info is not None:\n",
    "        filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "        for index, row in filtered_frames_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw field boxes if requested\n",
    "    if draw_field_boxes and field_boxes_info is not None:\n",
    "        filtered_field_boxes_info = field_boxes_info[field_boxes_info['model'] == modelo]\n",
    "        for index, row in filtered_field_boxes_info.iterrows():\n",
    "            draw_box(row)\n",
    "    \n",
    "    # Show the image with selected drawings\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"mage_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw everything\n",
    "draw_box_model(modelo, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # secao: 5 - VALOR TOTAL\n",
    "        data_valor_total = {}\n",
    "        #data_valor_total = processa_total()\n",
    "        father_value = \"4_frame_valor_total\"\n",
    "        section = \"5. VALOR TOTAL\"\n",
    "        \n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_valor_total.update(result)\n",
    "        \n",
    "        # secao: 6 - CNAE e Item da Lista de Serviços\n",
    "        data_CNAE = {}\n",
    "        data_CNAE = processa_cnae_itens()\n",
    "\n",
    "        # secao: 7 - VALORES E IMPOSTOS & 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "        data_valores = {}\n",
    "        father_value = \"5_frame_valores_impostos\"\n",
    "        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_valores.update(result)\n",
    "            \n",
    "        # secao: 8 - DADOS COMPLEMENTARES\"\n",
    "        data_dados_complementares = {}\n",
    "        f_father = \"5_frame_dados_complementares\"\n",
    "        section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "        data_dados_complementares = extract_dados_comple_obs(modelo, f_father, section)                                           \n",
    "                                \n",
    "                                \n",
    "        # secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "        data_outras_informacoes = {}\n",
    "        father_value = \"5_frame_inf_criticas\"\n",
    "        section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "\n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_outras_informacoes.update(result)                        \n",
    "                            \n",
    "\n",
    "        # secao: 10. OBSERVACOES\n",
    "        data_observacao = {}\n",
    "        f_father = \"5_frame_observacao\"\n",
    "        section = \"10. OBSERVACOES\"\n",
    "\n",
    "        data_observacao = extract_dados_comple_obs(modelo, f_father, section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras funcoes deprecateds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_after_keyword_out_frame(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return \"Keyword não encontrada\"\n",
    "        else:\n",
    "            return \"Keyword não encontrada\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_after_keyword(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return \"Valor não encontrado\"\n",
    "        else:\n",
    "            return \"Keyword é o último elemento, valor não encontrado\"\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return \"Keyword não encontrada\"\n",
    "        else:\n",
    "            return \"Keyword não encontrada\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
