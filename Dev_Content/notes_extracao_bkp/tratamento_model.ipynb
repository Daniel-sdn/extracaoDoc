{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "import PyPDF2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "\n",
    "import modules.extrai_pdf_pesquisavel as Extc\n",
    "import modules.cronometro as cron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRESTAR ATENCAO\n",
    "model = 'pedro_aldeia'\n",
    "\n",
    "\n",
    "#### IMPORTANTE - Nro Batch\n",
    "batch_name = \"Batch_15\"\n",
    "\n",
    "\n",
    "# 1. path para documentos PDF (omelhor se estiverem dentro de um unico diretorio)\n",
    "root_pdf_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 2. path para documentos PDF que podem estar aguardando para serem processados\n",
    "root_pdf_aguardando_path = \"pipeline_extracao_documentos/3_tratamento_excecoes/pdf_aguardando_processar\"\n",
    "\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 3. path para documentos PDF externos para serem processados\n",
    "root_external_pdf_path = \"content_from_pdftool/data/data_pdf/NF_para_processamento/NFRJ_PDF_para _ocr\"\n",
    "# 4. path para documentos PDF PESQUISAVEIS externos para serem processados\n",
    "root_external_pdf_pesquisavel_path = \"content_from_pdftool/data/data_pdf/NF_processadas/NFRJ/fwdnotasfiscaisemitidaslmpadalegal\"\n",
    "\n",
    "# 5. path para imagem padrao\n",
    "image_resized_path = 'pipeline_extracao_documentos/6_geral_administacao/images/processadas'\n",
    "\n",
    "# 6. path para log\n",
    "log_path = 'pipeline_extracao_documentos/6_geral_administacao/logs'\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"pipeline_extracao_documentos/5_documentos_processados/jsons\"\n",
    "\n",
    "# 8. path para NFs processadas\n",
    "nf_processada_path = \"pipeline_extracao_documentos/5_documentos_processados\"\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "# 9. path para models\n",
    "nf_model_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/frames_nf_v9.xlsx\"\n",
    "\n",
    "# 10. path para dicionario de models\n",
    "model_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/models.csv\"\n",
    "\n",
    "# 11. path para datasets CNAE e Itens de Serviço\n",
    "nf_datasets_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "\n",
    "\n",
    "# VERIFICAR\n",
    "tgt_imagens = \"pipeline_extracao_documentos/6_geral_administacao/images\"\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento template do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le a planilha e cria do DF\n",
    "frames_nf_v4_df = pd.read_excel(nf_model_path)\n",
    "\n",
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'section']\n",
    "frames_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>seq</th>\n",
       "      <th>prestador</th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>f_size</th>\n",
       "      <th>box</th>\n",
       "      <th>t_value</th>\n",
       "      <th>father</th>\n",
       "      <th>label</th>\n",
       "      <th>section_json</th>\n",
       "      <th>reference</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>Largura</th>\n",
       "      <th>Altura</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mage</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>document</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mage</td>\n",
       "      <td>2</td>\n",
       "      <td>todos</td>\n",
       "      <td>boundaries</td>\n",
       "      <td>green</td>\n",
       "      <td>120.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modelo_prefeitura_mage</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2666.0</td>\n",
       "      <td>1781.0</td>\n",
       "      <td>2567.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>mage</td>\n",
       "      <td>3</td>\n",
       "      <td>todos</td>\n",
       "      <td>section</td>\n",
       "      <td>orange</td>\n",
       "      <td>110.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boundaries_modelo_prefeitura_mage</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1 - CABECALHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>14.803272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mage</td>\n",
       "      <td>4</td>\n",
       "      <td>todos</td>\n",
       "      <td>frame</td>\n",
       "      <td>red</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>1 - CABECALHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>mage</td>\n",
       "      <td>5</td>\n",
       "      <td>todos</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>string</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>nome_prefeitura</td>\n",
       "      <td>1 - CABECALHO</td>\n",
       "      <td>PREFEITURA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>225</td>\n",
       "      <td>pedro_aldeia</td>\n",
       "      <td>73</td>\n",
       "      <td>todos</td>\n",
       "      <td>field_box</td>\n",
       "      <td>purple</td>\n",
       "      <td>80.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>issqn_retido</td>\n",
       "      <td>9. OUTRAS INFORMAÇOES / CRITICAS</td>\n",
       "      <td>ISSQN RETIDO</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>226</td>\n",
       "      <td>pedro_aldeia</td>\n",
       "      <td>74</td>\n",
       "      <td>todos</td>\n",
       "      <td>field_box</td>\n",
       "      <td>purple</td>\n",
       "      <td>80.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_pretacao_servico</td>\n",
       "      <td>9. OUTRAS INFORMAÇOES / CRITICAS</td>\n",
       "      <td>LOCAL. PRESTAÇÃO SERVIÇO</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>227</td>\n",
       "      <td>pedro_aldeia</td>\n",
       "      <td>75</td>\n",
       "      <td>todos</td>\n",
       "      <td>field_box</td>\n",
       "      <td>purple</td>\n",
       "      <td>80.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>local_incidencia</td>\n",
       "      <td>9. OUTRAS INFORMAÇOES / CRITICAS</td>\n",
       "      <td>LOCAL INCIDÊNCIA</td>\n",
       "      <td>1638.0</td>\n",
       "      <td>2410.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>228</td>\n",
       "      <td>pedro_aldeia</td>\n",
       "      <td>76</td>\n",
       "      <td>todos</td>\n",
       "      <td>frame</td>\n",
       "      <td>red</td>\n",
       "      <td>100.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>10. OBSERVACOES</td>\n",
       "      <td>uma observação</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>229</td>\n",
       "      <td>pedro_aldeia</td>\n",
       "      <td>77</td>\n",
       "      <td>todos</td>\n",
       "      <td>sframe_field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>string</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>observação</td>\n",
       "      <td>10. OBSERVACOES</td>\n",
       "      <td>OBSERVAÇÃO:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         model  seq prestador          type   color  f_size  box  \\\n",
       "0      1          mage    1       NaN      document     NaN     NaN  NaN   \n",
       "1      2          mage    2     todos    boundaries   green   120.0  yes   \n",
       "2      3          mage    3     todos       section  orange   110.0  yes   \n",
       "3      4          mage    4     todos         frame     red   100.0  yes   \n",
       "4      5          mage    5     todos  sframe_field     NaN     NaN   no   \n",
       "..   ...           ...  ...       ...           ...     ...     ...  ...   \n",
       "224  225  pedro_aldeia   73     todos     field_box  purple    80.0  yes   \n",
       "225  226  pedro_aldeia   74     todos     field_box  purple    80.0  yes   \n",
       "226  227  pedro_aldeia   75     todos     field_box  purple    80.0  yes   \n",
       "227  228  pedro_aldeia   76     todos         frame     red   100.0  yes   \n",
       "228  229  pedro_aldeia   77     todos  sframe_field     NaN     NaN   no   \n",
       "\n",
       "    t_value                                 father  \\\n",
       "0       NaN                                    NaN   \n",
       "1       NaN                 modelo_prefeitura_mage   \n",
       "2       NaN      boundaries_modelo_prefeitura_mage   \n",
       "3       NaN                 1_section_cabecalho_nf   \n",
       "4    string                  1_frame_prefeitura_nf   \n",
       "..      ...                                    ...   \n",
       "224  string                   5_frame_inf_criticas   \n",
       "225  string                   5_frame_inf_criticas   \n",
       "226  string                   5_frame_inf_criticas   \n",
       "227     NaN  6_section_inf_complementares_criticas   \n",
       "228  string                     5_frame_observacao   \n",
       "\n",
       "                                 label                      section_json  \\\n",
       "0               modelo_prefeitura_mage                               NaN   \n",
       "1    boundaries_modelo_prefeitura_mage                               NaN   \n",
       "2               1_section_cabecalho_nf                     1 - CABECALHO   \n",
       "3                1_frame_prefeitura_nf                     1 - CABECALHO   \n",
       "4                      nome_prefeitura                     1 - CABECALHO   \n",
       "..                                 ...                               ...   \n",
       "224                       issqn_retido  9. OUTRAS INFORMAÇOES / CRITICAS   \n",
       "225             local_pretacao_servico  9. OUTRAS INFORMAÇOES / CRITICAS   \n",
       "226                   local_incidencia  9. OUTRAS INFORMAÇOES / CRITICAS   \n",
       "227                 5_frame_observacao                   10. OBSERVACOES   \n",
       "228                         observação                   10. OBSERVACOES   \n",
       "\n",
       "                    reference      x0      y0      x1      y1  Largura  \\\n",
       "0                         NaN     0.0     0.0  2067.0  2923.0   2067.0   \n",
       "1                         NaN   144.0    99.0  1925.0  2666.0   1781.0   \n",
       "2                         NaN     0.0     0.0  2067.0   380.0   2067.0   \n",
       "3                         NaN   406.0     0.0  1540.0   380.0   1030.0   \n",
       "4                  PREFEITURA     NaN     NaN     NaN     NaN      NaN   \n",
       "..                        ...     ...     ...     ...     ...      ...   \n",
       "224              ISSQN RETIDO  1066.0  2410.0  1328.0  2521.0    262.0   \n",
       "225  LOCAL. PRESTAÇÃO SERVIÇO  1328.0  2410.0  1638.0  2521.0    310.0   \n",
       "226          LOCAL INCIDÊNCIA  1638.0  2410.0  1922.0  2521.0    284.0   \n",
       "227            uma observação   148.0  2515.0  1922.0  2676.0   1774.0   \n",
       "228               OBSERVAÇÃO:     NaN     NaN     NaN     NaN      0.0   \n",
       "\n",
       "     Altura           %  \n",
       "0    2923.0         NaN  \n",
       "1    2567.0  100.000000  \n",
       "2     380.0   14.803272  \n",
       "3     380.0         NaN  \n",
       "4       NaN         NaN  \n",
       "..      ...         ...  \n",
       "224   111.0         NaN  \n",
       "225   111.0         NaN  \n",
       "226   111.0         NaN  \n",
       "227   155.0         NaN  \n",
       "228     0.0         NaN  \n",
       "\n",
       "[229 rows x 20 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_nf_v4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes de imagem e extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PRIMEIRAS FUNCOES\n",
    "\n",
    "# 1. Interacao para pesquisar prefeitura\n",
    "def pesquisa_texto(texto):\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', texto)\n",
    "    if nome_prefeitura_match:\n",
    "        is_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        \n",
    "        return  is_prefeitura\n",
    "    else:\n",
    "        raise ValueError(\"Nao consegui pesquisar\")\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "# 3. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# Funcao importante - process_line\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Funcao de conversao e resize do documento\n",
    "def convertResize_analise(nome_documento, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(nome_documento)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "# Funcao de pesquisa de modelo\n",
    "def pequisaModel(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "            return  nome_prefeitura\n",
    "        else:\n",
    "            raise ValueError(\"Nao acho nome de prefeitura\")\n",
    "        \n",
    "# 1. Funcao de conversao e resize do documento\n",
    "def convertResize(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "\n",
    "# 2. Pesquisa prefeitura no documento\n",
    "def pequisaModel(image_name):\n",
    "\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1) \n",
    "            return  nome_prefeitura        \n",
    "        \n",
    "\n",
    "\n",
    "# 3. Ajusta o filename tirando caracteres especiais \n",
    "def conv_filename(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão\n",
    "    name, extension = title.rsplit('.', 1) if '.' in title else (title, \"\")\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    # Adicione a extensão de volta, se houver\n",
    "    if extension:\n",
    "        filename += '.' + extension.lower()\n",
    "\n",
    "    return filename\n",
    "\n",
    "# 4. Ajusta o filename tirando caracteres especiais e a\n",
    "def conv_filename_no_ext(title):\n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename  \n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# 5. Verifica se PDF e pesquisavel ou nao e grava metadados dele\n",
    "def is_pdf_searchable_analise(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        pages = pdf_document.page_count\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        dados_pdf = pdf_document.metadata\n",
    "        pdf_document.close()\n",
    "        return is_searchable, dados_pdf, pages\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "# Funcao importante - process_line\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convertResizeAnalise_1page(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    resized_pages = []\n",
    "    for page in pages:\n",
    "        resized_page = page.resize((2067, 2923))\n",
    "        resized_pages.append(resized_page)\n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "# 2. Leitura do arquivo CSV e criação do dicionário modelos\n",
    "def create_model_dictionary(model_dict_path):\n",
    "    model_dictionary = {}\n",
    "    with open(model_dict_path, 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            prefeitura_name = row['prefeitura']\n",
    "            model_name = row['model']\n",
    "\n",
    "            if prefeitura_name not in model_dictionary:\n",
    "                model_dictionary[prefeitura_name] = model_name\n",
    "            \n",
    "            #model_dictionary[prefeitura_name].append(model_name)\n",
    "    \n",
    "    return model_dictionary\n",
    "\n",
    "\n",
    "def format_number(number_str):\n",
    "    # Check for percentage and handle it\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # You can multiply by 100 here if needed\n",
    "\n",
    "    # Check if the string contains \"R$\" or a comma, indicating the original format\n",
    "    if 'R$' in number_str or ',' in number_str:\n",
    "        # Original format: Remove 'R$', replace dots with nothing, and replace commas with dots\n",
    "        number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    else:\n",
    "        # New format: Extract only the numeric part using regex\n",
    "        number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)\n",
    "\n",
    "# Funçao de formatacao de numeros\n",
    "def format_number2(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)\n",
    "\n",
    "\n",
    "def extract_fields_box(modelo, father_value, section):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        #print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference'], row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1'] ))\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        if row_field['t_value'] == 'number':\n",
    "            # Formate o valor usando a função format_number\n",
    "            #print(\"vou verificar valor\")\n",
    "            value = format_number2(value)\n",
    "            #print(value)\n",
    "        # Armazene o texto extraído com o rótulo correspondente\n",
    "        label = row_field['label']\n",
    "        data_box_valores[label] = value\n",
    "        \n",
    "    return data_box_valores\n",
    "\n",
    "# move NF processadas ok\n",
    "def move_raster_pdf(document_path, raster_pdf_path, batch_name, doc2convert):\n",
    "    # Determine the destination directory\n",
    "    destination_dir = os.path.join(raster_pdf_path, batch_name)\n",
    "\n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Determine the destination path including the filename\n",
    "    destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "\n",
    "    # Move the file from the source path to the destination path\n",
    "    try:\n",
    "        shutil.move(document_path, destination_path)\n",
    "        print(f\"Sucesso ao mover: {document_path} para: {destination_path}\")\n",
    "        return True, destination_path, None  # Success, destination path, no error\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao mover: {document_path} para: {destination_path}: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return False, None, error_message  # Failure, no destination path, error message\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cricao dos dados ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq =  0 | 1_frame_prefeitura_nf\n",
      "seq =  1 | 1_frame_dados_nf\n",
      "seq =  2 | 2_frame_cnpj_prestador\n",
      "seq =  3 | 2_frame_inscricao_prestador\n",
      "seq =  4 | 2_frame_dados_prestador\n",
      "seq =  5 | 3_frame_cnpj_tomador\n",
      "seq =  6 | 3_frame_inscricao_tomador\n",
      "seq =  7 | 3_frame_dados_tomador\n",
      "seq =  8 | 4_frame_descricao_totais\n",
      "seq =  9 | 4_frame_valor_total\n",
      "seq = 10 | 4_frame_cnae_itens_servico\n",
      "seq = 11 | 5_frame_valores_impostos\n",
      "seq = 12 | 5_frame_dados_complementares\n",
      "seq = 13 | 5_frame_inf_criticas\n",
      "seq = 14 | 5_frame_observacao\n",
      "\n",
      "\n",
      "Dados do teste: batch_name: Batch_RASTER_PDF_0 | frame: 1_frame_prefeitura_nf | model: pedro_aldeia | tipo_pdf: RASTER_PDF\n"
     ]
    }
   ],
   "source": [
    "#### IMPORTANTE - NRO BATCH PARA TESTE    0 = PDF_PESQUISAVEL | 1 = RASTER_PDF\n",
    "\n",
    "i_test = 1\n",
    "\n",
    "tipo_pdf = []\n",
    "tipo_pdf.append('PDF_PESQUISAVEL')\n",
    "tipo_pdf.append('RASTER_PDF')\n",
    "tipo_pdf[i_test]\n",
    "\n",
    "\n",
    "# Tratamento do Path de ORIGEM DO DOCUMENTOS PARA TESTE QUE SERAO MOVIDOS\n",
    "list_path_test = []\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/pdf_pesquisavel_4_test\")\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/raster_pdf_4_test\")\n",
    "list_path_test[i_test]\n",
    "\n",
    "# Frame para teste\n",
    "i_frame = 0\n",
    "\n",
    "frames_pesquisa = []\n",
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == model]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_name = row_frame['label']\n",
    "    frames_pesquisa.append(frame_name)\n",
    "\n",
    "# Nome Batch\n",
    "batch_name = \"Batch_\" + str(tipo_pdf[i_test]) + \"_\" + str(i_frame)\n",
    "\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "\n",
    "# Listagem dos frames de pesquisa\n",
    "i = 0\n",
    "for frame in frames_pesquisa:\n",
    "    print(f'seq ={i:>3} | {frame}')\n",
    "    i += 1\n",
    "    \n",
    "if frames_pesquisa[i_frame]:\n",
    "    print(f'\\n\\nDados do teste: batch_name: {batch_name} | frame: {frames_pesquisa[i_frame]} | model: {model} | tipo_pdf: {tipo_pdf[i_test]}')\n",
    "    \n",
    "    \n",
    "######### PATHS\n",
    "#1. path formado para busca de pdfs recursiva\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "\n",
    "#2. path para documentos teste RASTER PDF (ATRIBIDO DA LISTA)\n",
    "path_test_pdf = list_path_test[1]\n",
    "\n",
    "#3. path formado para nome do arquivo json\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "\n",
    "#Listando paths utilizados\n",
    "#print(f'\\nroot_doc_analise: {root_doc_analise}\\npath_test_pdf: {path_test_pdf}\\njson_file_path: {json_file_path}')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de iteracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chamadas de funcao de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Cria os valores \n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "secao = \"1 - CABECALHO\"\n",
    "f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "\n",
    "\n",
    "#4. Extrai prefeitura\n",
    "def extract_prefeitura(model, father, values):\n",
    "    \n",
    "    tipo = \"sframe_field\"\n",
    "    data_extrated_prefeitura = {}\n",
    "    #print(tipo)\n",
    "\n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model) & (frames_nf_v4_df['father'] == father) & (frames_nf_v4_df['type'] == tipo)]\n",
    "\n",
    "    for index_sframe, row_sframe in filtered_frames_nf_v4_df.iterrows():\n",
    "        \n",
    "        label_value = row_sframe['label']\n",
    "        \n",
    "        #print(\"label_value\", label_value)\n",
    "        \n",
    "        if label_value == \"nome_prefeitura\":\n",
    "            reference_value = row_sframe['reference']\n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result)\n",
    "        elif label_value == \"secretaria\":\n",
    "            reference_value = row_sframe['reference']\n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result) \n",
    "        elif label_value == \"tipo_nota_fiscal\":\n",
    "            reference_value = row_sframe['reference']  \n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result)\n",
    "                    \n",
    "    return data_extrated_prefeitura\n",
    "\n",
    "# 2. Extracao OCR\n",
    "def extract_text_from_coordinates(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "# 1. funçao basica de modelo \n",
    "def executa_model_frame(model, secao, father_name):\n",
    "\n",
    "    data_dados_frame = {}\n",
    "    \n",
    "    tipo = \"frame\"\n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model) & (frames_nf_v4_df['label'] == f_frame_name) & (frames_nf_v4_df['type'] == tipo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_frame = extract_text_from_coordinates(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        frame_seq = row_frame['seq']\n",
    "        frame_model = row_frame['model']\n",
    "        frame_label = row_frame['label']\n",
    "        frame_type = row_frame['type']\n",
    "        frame_section = row_frame['section_json']\n",
    "        frame_reference = row_frame['reference']\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        #print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "        \n",
    "    return extracted_text_frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sao iguais \n",
    "def extract_text_from_frame(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited\n",
    "\n",
    "\n",
    "#1. funcao: find_value_after_keyword_out_frame_up\n",
    "def find_value_after_keyword_out_frame_up(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "        if text_list[index + 1] not in default_keyword_list:\n",
    "            return text_list[index + 1]\n",
    "        else:\n",
    "            return None\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            for default_keyword in default_keyword_list:\n",
    "                if default_keyword in text_list:\n",
    "                    # Caso especial para 'Nome/Razão Social:'\n",
    "                    if keyword == 'Nome/Razão Social:':\n",
    "                        return text_list[0]\n",
    "        return None\n",
    "    \n",
    "#2. find_value_after_keyword_out_frame_down  \n",
    "def find_value_after_keyword_out_frame_down(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "#3. find_value_after_keyword_fuzz\n",
    "def find_value_after_keyword_fuzz(keyword, text_list, default_keyword_list=None, fuzziness_threshold=80):\n",
    "    closest_match = None\n",
    "    closest_match_score = 0\n",
    "    \n",
    "    for i, text in enumerate(text_list):\n",
    "        score = fuzz.ratio(keyword, text)\n",
    "        \n",
    "        if score > closest_match_score:\n",
    "            closest_match_score = score\n",
    "            closest_match = text\n",
    "        \n",
    "        if closest_match_score > fuzziness_threshold:\n",
    "            break\n",
    "\n",
    "    if closest_match_score > fuzziness_threshold:\n",
    "        index = text_list.index(closest_match)\n",
    "        if index + 1 < len(text_list):\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def pesquisa_keyword(string_pesquisa, text_splited, keyword_list):\n",
    "\n",
    "    resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "\n",
    "    if resultado_extraido_fuzz == None:\n",
    "        resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "        if resultado_extraido_frame_up == None:\n",
    "            resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "            resultado_extraido = resultado_extraido_frame_down\n",
    "        else:\n",
    "            resultado_extraido = resultado_extraido_frame_up\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_fuzz           \n",
    "    #print(resultado_extraido)\n",
    "    return resultado_extraido\n",
    "\n",
    "\n",
    "def cabecalho_prefeitura():\n",
    "    valor_dict = {}\n",
    "    dados_prefeitura = {}\n",
    "    f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "    # 1. funçao basica de modelo \n",
    "    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "    text_splited = texto.split('\\n')\n",
    "    \n",
    "    valor_dict = extract_prefeitura(model, f_frame_name, text_splited)\n",
    "    if valor_dict:\n",
    "        dados_prefeitura.update(valor_dict)\n",
    "        \n",
    "        \n",
    "    return dados_prefeitura \n",
    "                \n",
    "def cabecalho_dados():\n",
    "\n",
    "    valor = {}   \n",
    "    f_frame_name = \"1_frame_dados_nf\"\n",
    "    \n",
    "    dadinho_dados_nf = {}\n",
    "    \n",
    "    # 1. funçao basica de modelo \n",
    "    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "    text_splited = texto_extraido(texto)\n",
    "    keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "\n",
    "    string_pesquisa = \"Número da Nota:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)         \n",
    "    dadinho_dados_nf['numero_nota_fiscal'] = texto\n",
    "\n",
    "\n",
    "    string_pesquisa = \"Competência:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "    dadinho_dados_nf['competencia'] = texto\n",
    "    \n",
    "    \n",
    "    string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "    dadinho_dados_nf['dt_hr_emissao'] = texto\n",
    "    \n",
    "    \n",
    "    string_pesquisa = \"Código Verificação:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "    dadinho_dados_nf['codigo_verificacao'] = texto\n",
    "    \n",
    "    return dadinho_dados_nf      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields_prestador_cnpj(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    \n",
    "    \n",
    "    nf_data_prestador_cnpj = {}\n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador_cnpj['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador_cnpj['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "\n",
    "    # Extrair Telefone\n",
    "    telefone_str = None\n",
    "    \n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador_cnpj['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador_cnpj['telefone'] = None   \n",
    "    \n",
    "    \n",
    "    return nf_data_prestador_cnpj \n",
    "\n",
    "\n",
    "def extract_fields_tomador_cnpj(text):\n",
    "    nf_data_tomador_cnpj = {}\n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador_cnpj['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador_cnpj['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador_cnpj['telefone'] = None  # Valor padrão quando não há correspondência\n",
    "        elif telefone_str == '':\n",
    "            nf_data_tomador_cnpj['telefone'] = None  # Valor padrão quando não há correspondência\n",
    "                    \n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['telefone'] = telefone_match.group(1)\n",
    "            \n",
    "    \n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        inscricao_municipal_str = inscricao_municipal_match.group(1)\n",
    "        if inscricao_municipal_str == \"Telefone:\": \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = inscricao_municipal_str\n",
    "    \n",
    "    insc_municipal_match = re.search(r'INSC:MUNICIPAL:\\s+(.+)', text)\n",
    "    if insc_municipal_match:\n",
    "        insc_municipal_str = insc_municipal_match.group(1)\n",
    "        if insc_municipal_str == \"Telefone:\":\n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = insc_municipal_str\n",
    "    else:\n",
    "        nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "            \n",
    "    \n",
    "    return nf_data_tomador_cnpj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mage_cnae_x_item_servico_df = pd.read_excel('pipeline_extracao_documentos/6_geral_administacao/datasets/MAGE_CNAE_X_ITEM_SERVICO_V1.xlsx')\n",
    "\n",
    "# Creating a dictionary for CNAE codes and descriptions\n",
    "cnae_dict = dict(zip(mage_cnae_x_item_servico_df['cnae'], mage_cnae_x_item_servico_df['descricao_cnae']))\n",
    "item_servico_dict = dict(zip(mage_cnae_x_item_servico_df['item_servico'], mage_cnae_x_item_servico_df['descricao_item_servico']))\n",
    "\n",
    "\n",
    "\n",
    "# Função para extrair número da string\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\b\\d+(\\.\\d+)?\\b', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dados_comple_obs(modelo, frame_father, section):\n",
    "    \n",
    "    data_dados_complementares = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_frame['seq'], row_frame['model'], row_frame['father'], row_frame['label'], row_frame['reference'], row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'] ))\n",
    "        for index_field, row_field in filtered_sframe_fields_info.iterrows():\n",
    "            #print(\"{:<5} {:<10} {:<30} {:<20} {:<20}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference']))\n",
    "            \n",
    "            if frame_father == \"5_frame_dados_complementares\":\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['section'] = section\n",
    "                \n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', extracted_text_box, count=1)\n",
    "                if text == '':\n",
    "                    text = None\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                    \n",
    "                return nf_data_dados_complementares                \n",
    "                \n",
    "            elif frame_father == \"5_frame_observacao\":\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['section'] = section \n",
    "                                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', extracted_text_box, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                return nf_data_observacao   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = \"Batch_15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_doc_analise = \"pipeline_extracao_documentos/2_documentos_para_extracao/Batch_15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_dados_complementares nan                  148.0   2273.0  1925.0  2377.0 \n",
      "76    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_observacao   uma observação       148.0   2515.0  1922.0  2676.0 \n",
      "67    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_dados_complementares nan                  148.0   2273.0  1925.0  2377.0 \n",
      "76    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_observacao   uma observação       148.0   2515.0  1922.0  2676.0 \n",
      "67    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_dados_complementares nan                  148.0   2273.0  1925.0  2377.0 \n",
      "76    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_observacao   uma observação       148.0   2515.0  1922.0  2676.0 \n",
      "67    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_dados_complementares nan                  148.0   2273.0  1925.0  2377.0 \n",
      "76    pedro_aldeia 6_section_inf_complementares_criticas 5_frame_observacao   uma observação       148.0   2515.0  1922.0  2676.0 \n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: '5 714.00'\n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: '420.00 E'\n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: 'ET'\n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: 'Ape'\n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: '&'\n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: ' 0.00 À'\n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: 'RS 504.00'\n",
      "Erro busca cnae: list index out of range\n",
      "Erro valores complementares: could not convert string to float: '?5 0.00'\n",
      "As informações foram salvas em pipeline_extracao_documentos/5_documentos_processados/jsons/Batch_15.json\n"
     ]
    }
   ],
   "source": [
    "erros = {}\n",
    "\n",
    "# 1. Leitura recursiva de diretorios e arquivos a partir de root\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "nf_data_servico = {}#VERIFICAR\n",
    "analise_doc_nf = {} #VERIFICAR\n",
    "file_data = [] #VERIFICAR\n",
    "\n",
    "list_document_pages = []\n",
    "#nro_nota = 0\n",
    "# TEMP\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "#3. path formado para nome do arquivo json\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "#root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "#print(root_doc_analise)\n",
    "i = 1\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    #print(dir_name)\n",
    "    for file in files:\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            doc2convert = file\n",
    "            document_path_1 = os.path.join(root, file)\n",
    "            pdf_document = fitz.open(document_path_1)\n",
    "            #page_number = 0  # Defina o número da página que deseja analisar\n",
    "            #page = pdf_document[page_number]\n",
    "            \n",
    "            documento_pdf = True\n",
    "            pesquisavel, metadados, paginas = is_pdf_searchable_analise(document_path_1)\n",
    "            #print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                \n",
    "            if not pesquisavel:\n",
    "                image_2work, name_image_2work = convertResizeAnalise_1page(file, document_path_1, image_resized_path)\n",
    "                \n",
    "                secao = \"1 - CABECALHO\"\n",
    "                try:\n",
    "                    nro_nota = 0\n",
    "                    data_cabecalho = {}\n",
    "                    data_cabecalho['secao'] = secao\n",
    "                    valor_dict = {}\n",
    "                    dados_prefeitura = {}\n",
    "                    f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "                    # 1. funçao basica de modelo \n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text_splited = texto.split('\\n')\n",
    "                    \n",
    "                    valor_dict = extract_prefeitura(model, f_frame_name, text_splited)\n",
    "                    if valor_dict:\n",
    "                        dados_prefeitura.update(valor_dict)\n",
    "                    valor = {}   \n",
    "                    f_frame_name = \"1_frame_dados_nf\"\n",
    "                    dadinho_dados_nf = {}\n",
    "                    # 1. funçao basica de modelo \n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "\n",
    "                    string_pesquisa = \"Número da Nota:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)         \n",
    "                    dadinho_dados_nf['numero_nota_fiscal'] = texto\n",
    "                    nro_nota = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Competência:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    dadinho_dados_nf['competencia'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    dadinho_dados_nf['dt_hr_emissao'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Código Verificação:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    dadinho_dados_nf['codigo_verificacao'] = texto\n",
    "                    \n",
    "                    data_cabecalho.update(dados_prefeitura)\n",
    "                    data_cabecalho.update(dadinho_dados_nf)\n",
    "                except Exception as e:\n",
    "                    erros_cabecalho = {}\n",
    "                    err_msg = f\"Erro de processo cabecalho: {e}\"\n",
    "                    erros['documento'] = file\n",
    "                    erros_cabecalho['secao'] = secao\n",
    "                    erros_cabecalho['erro'] = err_msg\n",
    "                    erros.update(erros_cabecalho)                \n",
    "               \n",
    "                \n",
    "                \n",
    "                \n",
    "                secao = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                try:\n",
    "                    f_frame_name = \"2_frame_cnpj_prestador\"\n",
    "                    data_prestador = {}\n",
    "                    prestador_inscricao = {}\n",
    "                    data_prestador['secao'] = secao\n",
    "                    prestador_cnpj_value = {}\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    prestador_cnpj_value = extract_fields_prestador_cnpj(texto)\n",
    "                    if prestador_cnpj_value:\n",
    "                        data_prestador.update(prestador_cnpj_value)\n",
    "                except Exception as e:\n",
    "                    erros_cnpj_prestador = {}\n",
    "                    err_msg = (f\"Erro prestador cnpj: {e}\")\n",
    "                    erros_cnpj_prestador['secao'] = secao\n",
    "                    erros_cnpj_prestador['erro'] = err_msg\n",
    "                    erros.update(erros_cnpj_prestador)       \n",
    "                    \n",
    "                try:\n",
    "                    f_frame_name = \"2_frame_inscricao_prestador\" \n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    keyword_list = ['Inscrição Municipal:', 'Inscrição Estadual:']\n",
    "                    string_pesquisa = \"Inscrição Municipal:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_inscricao['prestador_inscricao'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Inscrição Estadual:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_inscricao['inscricao_estadual'] = texto\n",
    "                    data_prestador.update(prestador_inscricao)\n",
    "                except Exception as e:\n",
    "                    erros_inscricao_prestador = {}\n",
    "                    err_msg = (f\"Erro de processo inscricao prestador: {e}\")\n",
    "                    erros_inscricao_prestador['secao'] = secao\n",
    "                    erros_inscricao_prestador['erro'] = err_msg\n",
    "                    erros.update(erros_inscricao_prestador)\n",
    "\n",
    "                try:\n",
    "                    f_frame_name = \"2_frame_dados_prestador\"\n",
    "                    prestador_dados_value = {}\n",
    "                    \n",
    "                    keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "                    string_pesquisa = \"Nome/Razão Social:\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['razao_social'] = texto\n",
    "\n",
    "                    string_pesquisa = \"Nome de Fantasia:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['nome_fantasia'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Endereço:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['endereco'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"E-mail:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['email'] = texto\n",
    "                    data_prestador.update(prestador_dados_value)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Erro prestador dados: {e}\") \n",
    "                    \n",
    "                \n",
    "                secao = \"3. TOMADOR DE SERVIÇO\"\n",
    "                try:\n",
    "                    data_tomador = {}\n",
    "                    tomador_cnpj_value = {}\n",
    "                    data_tomador['secao'] = secao\n",
    "                    f_frame_name = \"3_frame_cnpj_tomador\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto) \n",
    "                    tomador_cnpj_value = extract_fields_tomador_cnpj(texto)\n",
    "                    if tomador_cnpj_value:\n",
    "                        data_tomador.update(tomador_cnpj_value)                  \n",
    "                except Exception as e:\n",
    "                    print(f\"Erro tomador cnpj: {e}\")\n",
    "                    \n",
    "                f_frame_name = \"3_frame_inscricao_tomador\"    \n",
    "                try:\n",
    "                    data_tomador_inscricao = {}\n",
    "                    keyword_list = ['RG:', 'Inscrição Estadual:']\n",
    "                    string_pesquisa = \"RG:\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_inscricao['rg'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Inscrição Estadual:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_inscricao['inscricao_estadual'] = texto\n",
    "                    data_tomador.update(data_tomador_inscricao)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro tomador inscricao: {e}\")\n",
    "                    \n",
    "                f_frame_name = \"3_frame_dados_tomador\"\n",
    "                try: \n",
    "                    data_tomador_dados = {}   \n",
    "                    keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "                    string_pesquisa = \"Nome/Razão Social:\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_dados['razao_social'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Endereço:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_dados['endereco'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"E-mail\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_dados['email'] = texto\n",
    "                    \n",
    "                    data_tomador.update(data_tomador_dados)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro tomador dados: {e}\") \n",
    "                    \n",
    "                secao = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                try:\n",
    "                    data_servico = {}\n",
    "                    data_servico['secao'] = secao\n",
    "                    f_frame_name = \"4_frame_descricao_totais\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text = texto.replace('\\n', ' ')\n",
    "                    label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                    if text.startswith(label):\n",
    "                        text = text[len(label):].strip()\n",
    "                    data_servico['discriminacao_servicos'] = text \n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro descricao servico: {e}\")\n",
    "                     \n",
    "                secao = \"5. VALOR TOTAL\"\n",
    "                try:\n",
    "                    data_valor_total = {}\n",
    "                    data_valor_total['secao'] = secao\n",
    "                    f_frame_name = \"4_frame_valor_total\"   \n",
    "                    text = executa_model_frame(model, secao, f_frame_name)  \n",
    "                    valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                    if valor_total_match:\n",
    "                        valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                        data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro valor total: {e}\")\n",
    "\n",
    "                secao = \"6. CNAE e Item da Lista de Serviços\"\n",
    "                try:\n",
    "                    data_CNAE = {}\n",
    "                    \n",
    "                    data_CNAE['secao'] = secao\n",
    "                    f_frame_name = \"4_frame_cnae_itens_servico\"   \n",
    "                    Texto_extraido = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text_splited = Texto_extraido.split('\\n')\n",
    "                    # Processando CNAE\n",
    "                    cnae_line = [line for line in text_splited if 'CNAE' in line][0]\n",
    "                    cnae_number = int(extract_number(cnae_line))\n",
    "                    cnae_value = cnae_dict.get(cnae_number, \"Valor não encontrado\")\n",
    "                    cnae_value = cnae_value.upper()\n",
    "                    cnae_value = str(cnae_number) + \" - \" + cnae_value\n",
    "                    data_CNAE['cnae'] = cnae_value\n",
    "                    \n",
    "                    item_servico_line = [line for line in text_splited if 'Item da Lista de Serviços' in line][0]\n",
    "                    item_servico_number = float(extract_number(item_servico_line))\n",
    "                    item_servico_value = item_servico_dict.get(item_servico_number, \"Valor não encontrado\")\n",
    "                    item_servico_value = item_servico_value.upper()\n",
    "                    item_servico_value = str(item_servico_number) + \" - \" + item_servico_value\n",
    "                    \n",
    "                    data_CNAE['item_lista_servicos'] = item_servico_value\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro busca cnae: {e}\")                    \n",
    "\n",
    "                \n",
    "                secao = \"8. DADOS COMPLEMENTARES\"\n",
    "                try:\n",
    "                    data_valores = {}\n",
    "                    \n",
    "                    data_valores['secao'] = secao\n",
    "                    f_frame_name = \"5_frame_valores_impostos\"   \n",
    "                    \n",
    "                    result = extract_fields_box(model, f_frame_name, secao)\n",
    "                    if result:\n",
    "                        data_valores.update(result)\n",
    "            \n",
    "                    # secao: 8 - DADOS COMPLEMENTARES\"\n",
    "                    data_dados_complementares = {}\n",
    "                    f_frame_name  = \"5_frame_dados_complementares\"\n",
    "                    section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                    data_dados_complementares = extract_dados_comple_obs(model, f_frame_name, section)                                           \n",
    "                                            \n",
    "                                            \n",
    "                    # secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "                    data_outras_informacoes = {}\n",
    "                    father_value = \"5_frame_inf_criticas\"\n",
    "                    section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "\n",
    "                    result = extract_fields_box(model, father_value, section)\n",
    "                    if result:\n",
    "                        data_outras_informacoes.update(result)                        \n",
    "                                        \n",
    "                    # secao: 10. OBSERVACOES\n",
    "                    data_observacao = {}\n",
    "                    f_father = \"5_frame_observacao\"\n",
    "                    section = \"10. OBSERVACOES\"\n",
    "\n",
    "                    data_observacao = extract_dados_comple_obs(model, f_father, section)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro valores complementares: {e}\")   \n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                try:\n",
    "                    pdf_info[nro_nota] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": data_cabecalho,\n",
    "                        \"data_prestador\": data_prestador,\n",
    "                        \"data_tomador\": data_tomador,\n",
    "                        \"data_servico\": data_servico,\n",
    "                        \"data_valor_total\": data_valor_total,\n",
    "                        \"data_CNAE\": data_CNAE,\n",
    "                        \"data_valores\": data_valores,\n",
    "                        \"data_dados_complementares\": data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": data_outras_informacoes,\n",
    "                        \"data_observacao\": data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": dir_name, #os.path.basename(root)\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                    \"Batch\": batch_name,\n",
    "                }\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao gerar o json: {e}\")\n",
    "                pdf_document.close()\n",
    "                #print(pdf_info)\n",
    "                #if paginas == 1:\n",
    "                if paginas > 1000:\n",
    "                    if i == 1000: #Define quantidade de tratamento de documentos raster PDF\n",
    "                        break\n",
    "            i +=1 \n",
    "                \n",
    "# Salvando as informações em um arquivo JSON (novo formato nome arquivo V2)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")\n",
    "\n",
    "#print(pdf_info)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenha Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0297 Raquel.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for color names to RGB values\n",
    "color_mapping = {\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"orange\": (255, 165, 0),\n",
    "    \"green\": (0, 128, 50),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"yellow\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "# Reload the image to start fresh\n",
    "image = Image.open(name_image_2work)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define a font size for the labels using the default PIL font\n",
    "font_size = 100\n",
    "#font = ImageFont.load_default()\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf\", 30, encoding=\"unic\")\n",
    "\n",
    "# Update the draw_box function to use the larger font size with the default font\n",
    "def draw_box(row):\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    color = color_mapping.get(row['color'], (0, 0, 0)) # Default to black if color not found\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
    "    label = str(row['label']) if pd.notnull(row['label']) else None # Check for missing label\n",
    "    if label:\n",
    "        draw.text((x0 + 5, y0 + 5), label, fill=color, font=font)\n",
    "\n",
    "# Draw the boundaries\n",
    "#draw_box(boundaries_info)\n",
    "\n",
    "\n",
    "def draw_box_model(modelo,\n",
    "                   boundaries_info=None,\n",
    "                   sections_info=None,\n",
    "                   frames_info=None,\n",
    "                   field_boxes_info=None,\n",
    "                   draw_boundaries=True,\n",
    "                   draw_sections=True,\n",
    "                   draw_frames=True,\n",
    "                   draw_field_boxes=True):\n",
    "    \n",
    "    # Draw boundaries if requested\n",
    "    if draw_boundaries and boundaries_info is not None:\n",
    "        filtered_boundaries_info = boundaries_info[boundaries_info['model'] == modelo]\n",
    "        for index, row in filtered_boundaries_info.iterrows():\n",
    "            draw_box(row)\n",
    "\n",
    "    # Draw sections if requested\n",
    "    if draw_sections and sections_info is not None:\n",
    "        filtered_sections_info = sections_info[sections_info['model'] == modelo]\n",
    "        for index, row in filtered_sections_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw frames if requested\n",
    "    if draw_frames and frames_info is not None:\n",
    "        filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "        for index, row in filtered_frames_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw field boxes if requested\n",
    "    if draw_field_boxes and field_boxes_info is not None:\n",
    "        filtered_field_boxes_info = field_boxes_info[field_boxes_info['model'] == modelo]\n",
    "        for index, row in filtered_field_boxes_info.iterrows():\n",
    "            draw_box(row)\n",
    "    \n",
    "    # Show the image with selected drawings\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[25644:25672:0830/033433.312059:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[25644:25687:0830/033437.517783:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[25644:25687:0830/033437.517824:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[25644:25672:0830/033437.558832:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25672:0830/033437.558904:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25672:0830/033437.558917:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25672:0830/033437.558926:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033437.591417:ERROR:policy_logger.cc(154)] :components/enterprise/browser/controller/chrome_browser_cloud_management_controller.cc(163) Cloud management controller initialization aborted as CBCM is not enabled.\n",
      "[25644:25672:0830/033437.705674:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25672:0830/033437.705710:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033437.711755:ERROR:assistance_home_client.cc(32)] File path /home/dani-boy/.config/microsoft-edge-beta/Default\n",
      "[25644:25672:0830/033437.835294:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25672:0830/033437.835332:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033437.962150:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.portal.Settings.Read: object_path= /org/freedesktop/portal/desktop: unknown error type: \n",
      "[25644:25881:0830/033438.044971:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[25644:25881:0830/033438.045075:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[25644:25881:0830/033438.045165:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[25644:25881:0830/033438.045214:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[25644:25881:0830/033438.045256:ERROR:bus.cc(406)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[26034:3:0830/033440.056207:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[26034:3:0830/033440.088081:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[26034:3:0830/033440.088503:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[26034:3:0830/033440.097076:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[26034:3:0830/033440.106077:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[26036:3:0830/033440.114126:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[26036:3:0830/033440.117025:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[25644:25669:0830/033440.976383:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033440.976512:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[25644:25669:0830/033440.976606:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033440.976729:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[25644:25669:0830/033440.976854:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033440.977023:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[25644:25669:0830/033440.977139:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033440.977233:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[25644:25669:0830/033440.977310:ERROR:bus.cc(406)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[25644:25644:0830/033440.977417:ERROR:object_proxy.cc(576)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n"
     ]
    }
   ],
   "source": [
    "# To draw everything\n",
    "draw_box_model(model, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # secao: 1 - CABECALHO\n",
    "                    #seq =  0 | 1_frame_prefeitura_nf\n",
    "                    if frame_pesquisa == \"1_frame_prefeitura_nf\":\n",
    "                        data_cabecalho = {}\n",
    "                        f_father = \"1_frame_prefeitura_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    #seq =  1 | 1_frame_dados_nf\n",
    "                    elif frame_pesquisa == \"1_frame_dados_nf\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"1_frame_dados_nf\"\n",
    "                        section = \"1 - CABECALHO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 2. PRESTADOR DE SERVIÇO\n",
    "                    #seq =  2 | 2_frame_cnpj_prestador\n",
    "                    elif frame_pesquisa == \"2_frame_cnpj_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_cnpj_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                    #seq =  3 | 2_frame_inscricao_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_inscricao_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_inscricao_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)       \n",
    "                    \n",
    "                    #seq =  4 | 2_frame_dados_prestador    \n",
    "                    elif frame_pesquisa == \"2_frame_dados_prestador\":\n",
    "                        data_prestador = {}\n",
    "                        f_father = \"2_frame_dados_prestador\"\n",
    "                        section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                           \n",
    "                           \n",
    "                    # secao: 3 - TOMADOR       \n",
    "                    #seq =  5 | 3_frame_cnpj_tomador       \n",
    "                    elif frame_pesquisa == \"3_frame_cnpj_tomador\": #TBD\n",
    "                    \n",
    "                    #seq =  6 | 3_frame_inscricao_tomador \n",
    "                    elif frame_pesquisa == \"3_frame_inscricao_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_inscricao_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                    \n",
    "                    #seq =  7 | 3_frame_dados_tomador    \n",
    "                    elif frame_pesquisa == \"3_frame_dados_tomador\":\n",
    "                        \n",
    "                        data_tomador = {}\n",
    "                        f_father = \"3_frame_dados_tomador\"\n",
    "                        section = \"3. TOMADOR DE SERVIÇO\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "                    #seq =  8 | 4_frame_descricao_totais\n",
    "                    elif frame_pesquisa == \"4_frame_descricao_totais\":\n",
    "                        data_servico = {}\n",
    "                        result = {}\n",
    "                        f_father = \"4_frame_descricao_totais\"\n",
    "                        section = \"4. DESCRIMINACAO DOS SERVIÇOS\" \n",
    "                        vx_0 = 125\n",
    "                        vy_0 = 1123\n",
    "                        vx_1 = 1934\n",
    "                        vy_1 = 1720\n",
    "                        data_servico['secao'] = section\n",
    "                        result, texto_extraido = ocr_RasterPDF_free(image_2work, vx_0, vy_0, vx_1, vy_1)\n",
    "                        nf_data_servico = {}\n",
    "                        label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                        if texto_extraido.startswith(label):\n",
    "                            text = texto_extraido[len(label):].strip()\n",
    "                        data_servico['discriminacao_servicos'] = text \n",
    "                        print(data_servico)\n",
    "                        \n",
    "                        \n",
    "                    # secao: 5. VALOR TOTAL\n",
    "                    #seq =  9 | 4_frame_valor_total   \n",
    "                    elif frame_pesquisa == \"4_frame_valor_total\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_valor_total\"\n",
    "                        section = \"5. VALOR TOTAL\"    \n",
    "                        Texto_extraido = extract_fields_box_geral(model, f_father, section)\n",
    "                        print(Texto_extraido) \n",
    "                        \n",
    "                        \n",
    "                    # secao: 6. CNAE e Item da Lista de Serviços\n",
    "                    #seq = 10 | 4_frame_cnae_itens_servico     \n",
    "                    elif frame_pesquisa == \"4_frame_cnae_itens_servico\":\n",
    "                        data_CNAE = {}\n",
    "                        f_father = \"4_frame_cnae_itens_servico\"\n",
    "                        section = \"6. CNAE e Item da Lista de Serviços\"    \n",
    "                        Texto_extraido = extract_fields_box(model, f_father, section)\n",
    "                        \n",
    "                    \n",
    "                    # secao: 7. VALORES E IMPOSTOS\n",
    "                    #seq = 11 | 5_frame_valores_impostos  \n",
    "                    elif frame_pesquisa == \"5_frame_valores_impostos\":\n",
    "                        data_valores = {}\n",
    "                        result = {}\n",
    "                        father_value = \"5_frame_valores_impostos\"\n",
    "                        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "                        result = extract_fields_box(modelo, father_value, section)\n",
    "                        if result:\n",
    "                            data_valores.update(result)\n",
    "                         \n",
    "\n",
    "                    #seq = 12 | 5_frame_dados_complementares\n",
    "                    elif frame_pesquisa == \"5_frame_dados_complementares\": #TDB\n",
    "                        \n",
    "                    \n",
    "                    #seq = 13 | 5_frame_inf_criticas\n",
    "                    elif frame_pesquisa == \"5_frame_inf_criticas\": #TDB    \n",
    "                    \n",
    "                    \n",
    "                    # secao: 10. OBSERVACOES  \n",
    "                    #seq = 14 | 5_frame_observacao  \n",
    "                    elif frame_pesquisa == \"5_frame_observacao\":\n",
    "                        data_observacao = {}\n",
    "                        f_father = \"5_frame_observacao\"\n",
    "                        section = \"10. OBSERVACOES\"\n",
    "                        Texto_extraido = extract_dados_from_frame(model, f_father, section)\n",
    "                        Texto_extraido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sao iguais APAGAR ESSA\n",
    "def extract_text_from_frame(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executa_model()\n",
    "i_frame = 0\n",
    "frames_pesquisa = []\n",
    "filtered_frames_nf_v4_df = frames_nf_v4_df[frames_nf_v4_df['model'] == model]\n",
    "for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "    frame_seq = row_frame['seq']\n",
    "    frame_model = row_frame['model']\n",
    "    frame_label = row_frame['label']\n",
    "    frame_type = row_frame['type']\n",
    "    frame_section = row_frame['section_json']\n",
    "    frame_reference = row_frame['reference']\n",
    "    frame_father = row_frame['father']\n",
    "    #if frame_section == \"1 - CABECALHO\" and frame_type == \"frame\":\n",
    "    if frame_section == \"1 - CABECALHO\":\n",
    "        frame_father = row_frame['father']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"1_frame_prefeitura_nf\" and frame_type == \"sframe_field\":\n",
    "        #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            frame_id = row_frame['id']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {}\n",
    "            \n",
    "        elif frame_father == \"1_frame_dados_nf\" and frame_type == \"sframe_field\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {} \n",
    "    elif frame_section == \"2. PRESTADOR DE SERVIÇO\":\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"2_frame_cnpj_prestador\" and frame_type == \"sframe_field\":\n",
    "        #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {}\n",
    "            \n",
    "        elif frame_father == \"2_frame_inscricao_prestador\" and frame_type == \"sframe_field\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {} \n",
    "        elif frame_father == \"2_frame_dados_prestador\" and frame_type == \"sframe_field\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {}\n",
    "            \n",
    "    elif frame_section == \"3. TOMADOR DE SERVIÇO\":\n",
    "            frame_father = row_frame['father']\n",
    "            frame_id = row_frame['id']\n",
    "            data_cabecalho = {}\n",
    "            data_cabecalho['secao'] = frame_section\n",
    "            if frame_father == \"3_frame_cnpj_tomador\" and frame_type == \"sframe_field\":\n",
    "                #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "                frame_father = row_frame['father']\n",
    "                print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "                result = {}\n",
    "            \n",
    "            elif frame_father == \"3_frame_inscricao_tomador\" and frame_type == \"sframe_field\":\n",
    "                frame_father = row_frame['father']\n",
    "                print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "                result = {} \n",
    "            elif frame_father == \"3_frame_dados_tomador\" and frame_type == \"sframe_field\":\n",
    "                frame_father = row_frame['father']\n",
    "                print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "                result = {}\n",
    "                \n",
    "    elif frame_section == \"4. DESCRIMINACAO DOS SERVIÇOS\":\n",
    "            frame_father = row_frame['father']\n",
    "            frame_id = row_frame['id']\n",
    "            data_cabecalho = {}\n",
    "            data_cabecalho['secao'] = frame_section\n",
    "            if frame_father == \"4_frame_descricao_totais\" and frame_type == \"field_box\":\n",
    "                #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "                frame_father = row_frame['father']\n",
    "                print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "                result = {}  \n",
    "                \n",
    "    elif frame_section == \"5. VALOR TOTAL\":\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"4_frame_valor_total\" and frame_type == \"field_box\":\n",
    "            #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {}   \n",
    "            \n",
    "    elif frame_section == \"6. CNAE e Item da Lista de Serviços\":\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"4_frame_cnae_itens_servico\" and frame_type == \"sframe_field\":\n",
    "            #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {}\n",
    "    \n",
    "    elif frame_section == \"8. DADOS COMPLEMENTARES\":\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"5_frame_valores_impostos\" and frame_type == \"field_box\":\n",
    "            #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {}\n",
    "        if frame_father == \"5_frame_dados_complementares\" and frame_type == \"sframe_field\":\n",
    "            #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {} \n",
    "    elif frame_section == \"9. OUTRAS INFORMAÇOES / CRITICAS\":\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"5_frame_inf_criticas\" and frame_type == \"field_box\":\n",
    "            #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {} \n",
    "    elif frame_section == \"10. OBSERVACOES\":\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho['secao'] = frame_section\n",
    "        if frame_father == \"5_frame_observacao\" and frame_type == \"sframe_field\":\n",
    "            #if frame_label == \"1_frame_prefeitura_nf\":\n",
    "            frame_father = row_frame['father']\n",
    "            print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "            result = {}                             \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
