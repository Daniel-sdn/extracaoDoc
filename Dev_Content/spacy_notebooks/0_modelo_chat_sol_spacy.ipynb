{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/dani-boy/extractNF/Dev_Content/spacy_notebooks/0_modelo_chat_sol_spacy.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/Dev_Content/spacy_notebooks/0_modelo_chat_sol_spacy.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/Dev_Content/spacy_notebooks/0_modelo_chat_sol_spacy.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mcopy\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/Dev_Content/spacy_notebooks/0_modelo_chat_sol_spacy.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/Dev_Content/spacy_notebooks/0_modelo_chat_sol_spacy.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Markdown, display\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/dani-boy/extractNF/Dev_Content/spacy_notebooks/0_modelo_chat_sol_spacy.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mhttp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_structs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstruct_type\u001b[39;00m \u001b[39mimport\u001b[39;00m IndexStructType\n\u001b[1;32m     13\u001b[0m \u001b[39m# embeddings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m LangchainEmbedding\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbedding\n\u001b[1;32m     17\u001b[0m \u001b[39m# structured\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/llama_index/embeddings/langchain.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Langchain Embedding Wrapper Module.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m List\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m Embeddings \u001b[39mas\u001b[39;00m LCEmbeddings\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mllama_index\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseEmbedding\n\u001b[1;32m     11\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLangchainEmbedding\u001b[39;00m(BaseEmbedding):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import time, copy\n",
    "\n",
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import http.client\n",
    "import datetime\n",
    "import pymongo\n",
    "import pprint\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from bson import tz_util as tz\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import pydantic\n",
    "from typing import Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://danielAgro:GtqV7UmRMwSBilrS@cluster0.qmjsaat.mongodb.net/?retryWrites=true&w=majority\")\n",
    "db = client.assistant_db #verificar\n",
    "message_log = db.message_log\n",
    "entidades = db.entidades\n",
    "\n",
    "\n",
    "def busca_emitente(remoteJid):\n",
    "    \n",
    "    for entidade in entidades.find({\"remoteJid\": remoteJid}):\n",
    "            nome_entidade = entidade['Nome']\n",
    "            sobrenome_entidade = entidade['Sobrenome']\n",
    "            tipo_entidade = entidade['Tipo']\n",
    "            razao_entidade = entidade['razao']\n",
    "            \n",
    "    return  nome_entidade, sobrenome_entidade, tipo_entidade, razao_entidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia = db.ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_mapping = {\n",
    "    '#Idfazenda': 'Idfazenda',\n",
    "    '#2nomefazenda': 'nomefazenda',\n",
    "    '#3idcultura': 'idcultura',\n",
    "    '#4nomecultura': 'nomecultura',\n",
    "    '#5idcliente': 'idcliente',\n",
    "    '#6nomecliente': 'nomecliente',\n",
    "    '#7idsafra': 'idsafra',\n",
    "    '#8nrocontrato': 'nrocontrato',\n",
    "    '#9qttotalcontrato': 'qttotalcontrato',\n",
    "    '#10qtentreguecontrato': 'qtentreguecontrato',\n",
    "    '#11qtsaldocontrato': 'qtsaldocontrato'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON data from file\n",
    "with open('query.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each row, map the fields, and insert into MongoDB\n",
    "bulk_insert = []\n",
    "for row in data:\n",
    "    mapped_data = {}\n",
    "    for key, value in row.items():\n",
    "        if key == '#7idsafra':\n",
    "            # Convert season_id from \"2023\" to \"20/23\"\n",
    "            mapped_data['idsafra'] = value[:2] + '/' + value[2:]\n",
    "        elif key in field_mapping:\n",
    "            mapped_data[field_mapping[key]] = value\n",
    "    bulk_insert.append(mapped_data)\n",
    "\n",
    "# Insert all documents using bulk insert\n",
    "ia.insert_many(bulk_insert)\n",
    "\n",
    "# Close the MongoDB connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "from spacy.tokens import Span\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antonio\n",
    "\n",
    "    remoteJid = \"5551993130284@s.whatsapp.net\"\n",
    "\n",
    "Emilio\n",
    "\n",
    "    remoteJid = \"5511991710950@s.whatsapp.net\"\n",
    "\n",
    "Valeria\n",
    "\n",
    "    remoteJid = \"5515997067346@s.whatsapp.net\"\n",
    "\n",
    "Daniel\n",
    "\n",
    "    remoteJid = \"5511994954119@s.whatsapp.net\"\n",
    "\n",
    "Carlos\n",
    "\n",
    "    remoteJid = \"5511953094208@s.whatsapp.net\"\n",
    "\n",
    "LD\n",
    "\n",
    "    remoteJid = \"5551953094208@s.whatsapp.net\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Definindo estruturas e consistencias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Set das extensoes dos tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Cultura\n",
    "cutura_getter = lambda token: token.text in (\"milho\", \"café\", \"soja\", \"sorgo\", \"cevada\", \"lúpulo\", \"lentilha\", \"feijão\", \"milheto\")\n",
    "Token.set_extension(\"is_cultura\", getter=cutura_getter, force=True)\n",
    "\n",
    "# 2. Quantidade\n",
    "quantidade_getter = lambda token: token.text in (\"quantos\", \"quanto\", \"saldo\", \"saldos\", \"total\", \"totais\", \"quantidade\", \"quantidades\")\n",
    "Token.set_extension(\"is_quantidade\", getter=quantidade_getter, force=True)\n",
    "\n",
    "# 3. Acoes do negocio\n",
    "acao_getter = lambda token: token.text in (\"entregou\", \"entregue\", \"entreguei\", \"entregados\", \"entregar\", \"entregaram\", \"entregarão\", \"entregariam\")\n",
    "Token.set_extension(\"is_acao\", getter=acao_getter, force=True)\n",
    "\n",
    "# 4. Contrato\n",
    "contrato_getter = lambda token: token.text in (\"contrato\", \"contratos\")\n",
    "Token.set_extension(\"is_contrato\", getter=contrato_getter, force=True)\n",
    "\n",
    "# 5. Safra\n",
    "safra_getter = lambda token: token.text in (\"safra\", \"safras\")\n",
    "Token.set_extension(\"is_safra\", getter=safra_getter, force=True)\n",
    "\n",
    "# 6. Fazenda\n",
    "fazenda_getter = lambda token: token.text in (\"fazenda\", \"fazendas\")\n",
    "Token.set_extension(\"is_fazenda\", getter=fazenda_getter, force=True)\n",
    "\n",
    "# 7. Cliente\n",
    "cliente_getter = lambda token: token.text in (\"cliente\", \"clientes\")\n",
    "Token.set_extension(\"is_cliente\", getter=cliente_getter, force=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Adiciono entity_ruler no pipeline\n",
    "entity_ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "# 4. Adiciono labels em NER\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.add_label(\"CULTURA\")\n",
    "ner.add_label(\"FAZENDA\")\n",
    "ner.add_label(\"CLIENTE\")\n",
    "ner.add_label(\"CONTRATO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Adiciono patterns\n",
    "patterns = [{\"label\": \"FAZENDA\", \"pattern\": [{\"LOWER\": \"passo\"}, {\"LOWER\": \"fundo\"}], \"id\": \"passo-fundo\"},\n",
    "            {\"label\": \"FAZENDA\", \"pattern\": [{\"LOWER\": \"Passo\"}, {\"LOWER\": \"fundo\"}], \"id\": \"passo-fundo\"},\n",
    "            {\"label\": \"FAZENDA\", \"pattern\": [{\"LOWER\": \"bela\"}, {\"LOWER\": \"vista\"}], \"id\": \"bela-vista\"},\n",
    "            {\"label\": \"FAZENDA\", \"pattern\": [{\"LOWER\": \"Bela\"}, {\"LOWER\": \"Vista\"}], \"id\": \"bela-vista\"},\n",
    "            {\"label\": \"FAZENDA\", \"pattern\": [{\"LOWER\": \"BELA\"}, {\"LOWER\": \"VISTA\"}], \"id\": \"bela-vista\"},\n",
    "            {\"label\": \"FAZENDA\", \"pattern\": {\"LOWER\": \"agrobi\"}, \"id\": \"agro-bi\"},\n",
    "            {\"label\": \"FAZENDA\", \"pattern\": {\"LOWER\": \"AgroBI\"}, \"id\": \"agro-bi\"},\n",
    "            {\"label\": \"FAZENDA\", \"pattern\": {\"LOWER\": \"AgroBi\"}, \"id\": \"agro-bi\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"matarazzo\"}, \"id\": \"matarazzo\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"Matarazzo\"}, \"id\": \"matarazzo\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"MATARAZZO\"}, \"id\": \"matarazzo\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"Lopito\"}, \"id\": \"lopito\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"lopito\"}, \"id\": \"lopito\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"LOPITO\"}, \"id\": \"lopito\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"Berdinazi\"}, \"id\": \"berdinazi\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"berdinazi\"}, \"id\": \"berdinazi\"},\n",
    "            {\"label\": \"CLIENTE\", \"pattern\": {\"LOWER\": \"BERDINAZI\"}, \"id\": \"berdinazi\"},\n",
    "            {\"label\": \"CULTURA\", \"pattern\": {\"LOWER\": \"milho\"}, \"id\": \"milho\"},\n",
    "            {\"label\": \"CULTURA\", \"pattern\": {\"LOWER\": \"Milho\"}, \"id\": \"milho\"},\n",
    "            {\"label\": \"CULTURA\", \"pattern\": {\"LOWER\": \"MILHO\"}, \"id\": \"milho\"},\n",
    "            {\"label\": \"CULTURA\", \"pattern\": {\"LOWER\": \"soja\"}, \"id\": \"soja\"},\n",
    "            {\"label\": \"CULTURA\", \"pattern\": {\"LOWER\": \"Soja\"}, \"id\": \"soja\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"campo\"}, {\"LOWER\": \"bom\"}], \"id\": \"campo-bom\"},\n",
    "            {\"label\": \"GPE\", \"pattern\": [{\"LOWER\": \"Campo\"}, {\"LOWER\": \"Bom\"}], \"id\": \"campo-bom\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Atualizo entity_ruler\n",
    "entity_ruler.initialize(lambda: [], nlp=nlp, patterns=patterns)\n",
    "len(entity_ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. doc para teste\n",
    "doc = nlp(\"A fazenda Passo Fundo possui dois contratos: 568S e 634S de soja e milheto a entregar para os clientes Lopito e Berdinazi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.analyze_pipes(pretty=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio do processo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_conversation = \"Qual é o saldo de milho que a fazenda Passo Fundo tem para entregar na safra 22/23?\"\n",
    "\n",
    "meta_conversation_2 = \"Bom dia, gostaria de saber o saldo total de soja que tenho para entregar na safra 22/23?\"\n",
    "\n",
    "meta_conversation_3 = \"Qual é o total de milho que a fazenda Passo Fundo tem para entregar para o cliente BERDINAZI?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DefiniÇao user & Utterance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A. Inicialização conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carlos', 'PRODUTOR', 'BOA ESPERANCA'] 28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "conhecimento = []\n",
    "\n",
    "# Preparaçao da mensagem\n",
    "remoteJid = \"5511953094208@s.whatsapp.net\"\n",
    "\n",
    "nome_entidade, sobrenome_entidade, tipo_entidade, razao_entidade = busca_emitente(remoteJid)\n",
    "\n",
    "meta_conversation_3 = \"Bom dia, gostaria de saber o saldo total de soja que tenho para entregar na safra 22/23?\"\n",
    "\n",
    "example_sentence = \"George Washington foi um líder político americano, \\\n",
    "general militar, estadista e fundador que serviu como \\\n",
    "primeiro presidente dos Estados Unidos de 1789 a 1797.\\n\"\n",
    "\n",
    "\n",
    "conhecimento.append(nome_entidade)\n",
    "conhecimento.append(tipo_entidade)\n",
    "conhecimento.append(razao_entidade)   \n",
    "\n",
    "doc = nlp(example_sentence)\n",
    "\n",
    "total_tokens = len(doc)\n",
    "\n",
    "print(conhecimento, total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo Fundo FAZENDA 2 4 Passo Passo Fundo\n",
      "Lopito LOC 20 20 21 Lopito\n",
      "Berdinazi LOC 22 22 23 Berdinazi\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"FAZENDA\":\n",
    "        print(ent.text, ent.label_, ent.start, ent.end, ent.root,  ent.orth_) # ent.start_char, ent.char_span, ent.n_lefts, ent.n_rights, ent.ent_id, ent.kb_id_,\n",
    "    elif ent.label_ == \"CULTURA\":\n",
    "        print(ent.text, ent.label_, ent.start, ent.end, ent.root, ent.orth_)\n",
    "    elif ent.label_ == \"CLIENTE\":\n",
    "        print(ent.text, ent.label_,  ent.start, ent.end, ent.root, ent.orth_)    \n",
    "    elif ent.label_ == \"GPE\":\n",
    "        print(ent.text, ent.label_,  ent.start, ent.end, ent.root, ent.orth_)\n",
    "    elif ent.label_ == \"LOC\":\n",
    "        print(ent.text, ent.label_, ent.start,  ent.start, ent.end, ent.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"542c32aab5e5434cbbb922ef97cbeb7e-0\" class=\"displacy\" width=\"2690\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">A</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">fazenda</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">Passo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Fundo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">possui</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">dois</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">contratos:</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">568S</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">e</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">634S</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">soja</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">e</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1610\">milheto</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1610\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">entregar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1970\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1970\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2090\">os</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2090\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2210\">clientes</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2210\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2330\">Lopito</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2330\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2450\">e</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2450\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2570\">Berdinazi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2570\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-0\" stroke-width=\"2px\" d=\"M70,302.0 C70,242.0 150.0,242.0 150.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,304.0 L62,292.0 78,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-1\" stroke-width=\"2px\" d=\"M190,302.0 C190,242.0 270.0,242.0 270.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270.0,304.0 L278.0,292.0 262.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-2\" stroke-width=\"2px\" d=\"M430,302.0 C430,242.0 510.0,242.0 510.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,304.0 L422,292.0 438,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-3\" stroke-width=\"2px\" d=\"M670,302.0 C670,242.0 750.0,242.0 750.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,304.0 L662,292.0 678,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-4\" stroke-width=\"2px\" d=\"M550,302.0 C550,182.0 755.0,182.0 755.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M755.0,304.0 L763.0,292.0 747.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-5\" stroke-width=\"2px\" d=\"M790,302.0 C790,242.0 870.0,242.0 870.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870.0,304.0 L878.0,292.0 862.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-6\" stroke-width=\"2px\" d=\"M1030,302.0 C1030,242.0 1110.0,242.0 1110.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030,304.0 L1022,292.0 1038,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-7\" stroke-width=\"2px\" d=\"M910,302.0 C910,182.0 1115.0,182.0 1115.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1115.0,304.0 L1123.0,292.0 1107.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-8\" stroke-width=\"2px\" d=\"M1270,302.0 C1270,242.0 1350.0,242.0 1350.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270,304.0 L1262,292.0 1278,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-9\" stroke-width=\"2px\" d=\"M910,302.0 C910,122.0 1360.0,122.0 1360.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1360.0,304.0 L1368.0,292.0 1352.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-10\" stroke-width=\"2px\" d=\"M1510,302.0 C1510,242.0 1590.0,242.0 1590.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1510,304.0 L1502,292.0 1518,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-11\" stroke-width=\"2px\" d=\"M910,302.0 C910,62.0 1605.0,62.0 1605.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1605.0,304.0 L1613.0,292.0 1597.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-12\" stroke-width=\"2px\" d=\"M1750,302.0 C1750,242.0 1830.0,242.0 1830.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1750,304.0 L1742,292.0 1758,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-13\" stroke-width=\"2px\" d=\"M910,302.0 C910,2.0 1850.0,2.0 1850.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1850.0,304.0 L1858.0,292.0 1842.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-14\" stroke-width=\"2px\" d=\"M1990,302.0 C1990,182.0 2195.0,182.0 2195.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1990,304.0 L1982,292.0 1998,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-15\" stroke-width=\"2px\" d=\"M2110,302.0 C2110,242.0 2190.0,242.0 2190.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2110,304.0 L2102,292.0 2118,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-16\" stroke-width=\"2px\" d=\"M1870,302.0 C1870,122.0 2200.0,122.0 2200.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2200.0,304.0 L2208.0,292.0 2192.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-17\" stroke-width=\"2px\" d=\"M2470,302.0 C2470,242.0 2550.0,242.0 2550.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2470,304.0 L2462,292.0 2478,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-18\" stroke-width=\"2px\" d=\"M2350,302.0 C2350,182.0 2555.0,182.0 2555.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-542c32aab5e5434cbbb922ef97cbeb7e-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2555.0,304.0 L2563.0,292.0 2547.0,292.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='dep',\n",
    "                jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A fazenda \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Passo Fundo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAZENDA</span>\n",
       "</mark>\n",
       " possui dois contratos: 568S e 634S de soja e milheto a entregar para os clientes \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lopito\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " e \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Berdinazi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent',\n",
    "                jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Analises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 - Analise lemma, pos, pos_explained e dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Qual é o total de milho que eu vou receber na safra 22/23?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Tag_explainned</th>\n",
       "      <th>token_POS</th>\n",
       "      <th>POS_explainned</th>\n",
       "      <th>dep</th>\n",
       "      <th>T. Head</th>\n",
       "      <th>dep explained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Qual</td>\n",
       "      <td>qual</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Qual</td>\n",
       "      <td>(Gender=Fem, Number=Sing, PronType=Int)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>é</td>\n",
       "      <td>ser</td>\n",
       "      <td>AUX</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>AUX</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>cop</td>\n",
       "      <td>total</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>det</td>\n",
       "      <td>total</td>\n",
       "      <td>(Definite=Def, Gender=Masc, Number=Sing, PronT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>total</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Qual</td>\n",
       "      <td>(Gender=Masc, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>case</td>\n",
       "      <td>milho</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>milho</td>\n",
       "      <td>milho</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>nmod</td>\n",
       "      <td>total</td>\n",
       "      <td>(Gender=Masc, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>obj</td>\n",
       "      <td>receber</td>\n",
       "      <td>(Gender=Masc, Number=Sing, PronType=Rel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>eu</td>\n",
       "      <td>eu</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>receber</td>\n",
       "      <td>(Case=Nom, Number=Sing, Person=1, PronType=Prs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>vou</td>\n",
       "      <td>ir</td>\n",
       "      <td>AUX</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>AUX</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>aux</td>\n",
       "      <td>receber</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=1, Tense=Pres, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>receber</td>\n",
       "      <td>receber</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>advcl</td>\n",
       "      <td>total</td>\n",
       "      <td>(VerbForm=Inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>na</td>\n",
       "      <td>em o</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>case</td>\n",
       "      <td>safra</td>\n",
       "      <td>(Definite=Def, Gender=Fem, Number=Sing, PronTy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>safra</td>\n",
       "      <td>safra</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>obl</td>\n",
       "      <td>receber</td>\n",
       "      <td>(Gender=Fem, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>22/23</td>\n",
       "      <td>22/23</td>\n",
       "      <td>NUM</td>\n",
       "      <td>numeral</td>\n",
       "      <td>NUM</td>\n",
       "      <td>numeral</td>\n",
       "      <td>appos</td>\n",
       "      <td>safra</td>\n",
       "      <td>(NumType=Card)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>punct</td>\n",
       "      <td>Qual</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    Texto    Lemma    Tag Tag_explainned token_POS POS_explainned   \n",
       "0    0     Qual     qual   PRON        pronoun      PRON        pronoun  \\\n",
       "1    1        é      ser    AUX      auxiliary       AUX      auxiliary   \n",
       "2    2        o        o    DET     determiner       DET     determiner   \n",
       "3    3    total    total   NOUN           noun      NOUN           noun   \n",
       "4    4       de       de    ADP     adposition       ADP     adposition   \n",
       "5    5    milho    milho   NOUN           noun      NOUN           noun   \n",
       "6    6      que      que   PRON        pronoun      PRON        pronoun   \n",
       "7    7       eu       eu   PRON        pronoun      PRON        pronoun   \n",
       "8    8      vou       ir    AUX      auxiliary       AUX      auxiliary   \n",
       "9    9  receber  receber   VERB           verb      VERB           verb   \n",
       "10  10       na     em o    ADP     adposition       ADP     adposition   \n",
       "11  11    safra    safra   NOUN           noun      NOUN           noun   \n",
       "12  12    22/23    22/23    NUM        numeral       NUM        numeral   \n",
       "13  13        ?        ?  PUNCT    punctuation     PUNCT    punctuation   \n",
       "\n",
       "      dep  T. Head                                      dep explained  \n",
       "0    ROOT     Qual            (Gender=Fem, Number=Sing, PronType=Int)  \n",
       "1     cop    total  (Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...  \n",
       "2     det    total  (Definite=Def, Gender=Masc, Number=Sing, PronT...  \n",
       "3   nsubj     Qual                         (Gender=Masc, Number=Sing)  \n",
       "4    case    milho                                                 ()  \n",
       "5    nmod    total                         (Gender=Masc, Number=Sing)  \n",
       "6     obj  receber           (Gender=Masc, Number=Sing, PronType=Rel)  \n",
       "7   nsubj  receber    (Case=Nom, Number=Sing, Person=1, PronType=Prs)  \n",
       "8     aux  receber  (Mood=Ind, Number=Sing, Person=1, Tense=Pres, ...  \n",
       "9   advcl    total                                     (VerbForm=Inf)  \n",
       "10   case    safra  (Definite=Def, Gender=Fem, Number=Sing, PronTy...  \n",
       "11    obl  receber                          (Gender=Fem, Number=Sing)  \n",
       "12  appos    safra                                     (NumType=Card)  \n",
       "13  punct     Qual                                                 ()  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization for tokens \n",
    "lemmatization = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"Texto\",\"Lemma\", \"Tag\", \"Tag_explainned\", \"token_POS\", \"POS_explainned\", \"dep\", \"T. Head\", \"dep explained\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    lemmatization.loc[i,\"id\"] = token.i\n",
    "    lemmatization.loc[i,\"Texto\"] = token.text\n",
    "    lemmatization.loc[i,\"Lemma\"] = token.lemma_\n",
    "    lemmatization.loc[i,\"Tag\"] = token.tag_\n",
    "    lemmatization.loc[i,\"Tag_explainned\"] = spacy.explain(token.tag_)\n",
    "    lemmatization.loc[i,\"token_POS\"] = token.pos_\n",
    "    lemmatization.loc[i,\"POS_explainned\"] = spacy.explain(token.pos_)\n",
    "    lemmatization.loc[i,\"dep\"] = token.dep_\n",
    "    lemmatization.loc[i,\"T. Head\"] = token.head.text\n",
    "    lemmatization.loc[i,\"dep explained\"] = token.morph\n",
    "    \n",
    "    i = i+1\n",
    "\n",
    "lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo Fundo 10 21 FAZENDA\n",
      "Lopito 103 109 LOC\n",
      "Berdinazi 112 121 LOC\n"
     ]
    }
   ],
   "source": [
    "for token in doc.ents:\n",
    "    print(token.text, token.start_char, token.end_char, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A fazenda'}\n",
      "{'Passo'}\n",
      "{'Fundo'}\n",
      "{'dois contratos'}\n",
      "{'soja'}\n",
      "{'milheto'}\n",
      "{'os clientes'}\n",
      "LOC\n",
      "{'Lopito'}\n",
      "LOC\n",
      "{'Berdinazi'}\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "      texto_chunk = chunk.text\n",
    "      \n",
    "      texto_ents = chunk.ents\n",
    "      texto_noun_chunks = chunk.noun_chunks\n",
    "      chunk_start = chunk.start\n",
    "      chunk_end = chunk.end\n",
    "      for c_ent in texto_ents:\n",
    "            print(c_ent.label_)\n",
    "      span = chunk.char_span(chunk_start, chunk_end)\n",
    "      print({texto_chunk})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A fazenda \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Passo Fundo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAZENDA</span>\n",
       "</mark>\n",
       " possui dois contratos: 568S e 634S de soja e milheto a entregar para os clientes \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lopito\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " e \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Berdinazi\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A. Análise de verbos da frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>T_texto</th>\n",
       "      <th>T_pos_</th>\n",
       "      <th>T_lemma_</th>\n",
       "      <th>T_dep_</th>\n",
       "      <th>T_head</th>\n",
       "      <th>T_morph_VerbForm</th>\n",
       "      <th>T_morph_Tense</th>\n",
       "      <th>T_morph_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>possui</td>\n",
       "      <td>VERB</td>\n",
       "      <td>possuir</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>possui</td>\n",
       "      <td>[Fin]</td>\n",
       "      <td>[Pres]</td>\n",
       "      <td>[Sing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>entregar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>entregar</td>\n",
       "      <td>acl</td>\n",
       "      <td>568S</td>\n",
       "      <td>[Inf]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx   T_texto T_pos_  T_lemma_ T_dep_  T_head T_morph_VerbForm   \n",
       "0   4    possui   VERB   possuir   ROOT  possui            [Fin]  \\\n",
       "1  16  entregar   VERB  entregar    acl    568S            [Inf]   \n",
       "\n",
       "  T_morph_Tense T_morph_Number  \n",
       "0        [Pres]         [Sing]  \n",
       "1            []             []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 1. IMPORTANTE - Analise dos verbos da frase\n",
    "\n",
    "user_verbs = []\n",
    "verbs_lemma = []\n",
    "verbs_head = []\n",
    "verbs_id = []\n",
    "for token in doc:\n",
    "    if token.pos_ == \"VERB\":\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            verbs_id.append(token.i)\n",
    "            user_verbs.append(token.i)\n",
    "            verbs_lemma.append(token.i)\n",
    "            verbs_head.append(token.i)\n",
    "            user_verbs.append(token.text)\n",
    "            user_verbs.append(\"ROOT\")\n",
    "            verbs_lemma.append(token.lemma_)\n",
    "            verbs_head.append(token.head)\n",
    "        else:\n",
    "            verbs_id.append(token.i)    \n",
    "            user_verbs.append(token.i)\n",
    "            verbs_lemma.append(token.i)\n",
    "            verbs_head.append(token.i)\n",
    "            user_verbs.append(token.text)\n",
    "            verbs_lemma.append(token.lemma_)\n",
    "            verbs_head.append(token.head)\n",
    "\n",
    "doc_verbs = pd.DataFrame(data=[], \\\n",
    "  columns=[\"idx\", \"T_texto\",\"T_pos_\", \"T_lemma_\", \"T_dep_\", \"T_head\", \"T_morph_VerbForm\", \"T_morph_Tense\", \"T_morph_Number\"])\n",
    "i = 0\n",
    "for idx in verbs_id:\n",
    "    doc_verbs.loc[i,\"idx\"] = doc[idx].i\n",
    "    doc_verbs.loc[i,\"T_texto\"] = doc[idx].text\n",
    "    doc_verbs.loc[i,\"T_pos_\"] = doc[idx].pos_\n",
    "    doc_verbs.loc[i,\"T_lemma_\"] = doc[idx].lemma_\n",
    "    doc_verbs.loc[i,\"T_dep_\"] = doc[idx].dep_\n",
    "    doc_verbs.loc[i,\"T_head\"] = doc[idx].head\n",
    "    doc_verbs.loc[i,\"T_morph_VerbForm\"] = doc[idx].morph.get(\"VerbForm\")\n",
    "    doc_verbs.loc[i,\"T_morph_Tense\"] = doc[idx].morph.get(\"Tense\")\n",
    "    doc_verbs.loc[i,\"T_morph_Number\"] = doc[idx].morph.get(\"Number\")\n",
    "    i = i+1\n",
    "   \n",
    "\n",
    "doc_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 16]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conhecimento' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m token_Root\u001b[39m.\u001b[39mappend(token\u001b[39m.\u001b[39mi)\n\u001b[1;32m      9\u001b[0m token_Root\u001b[39m.\u001b[39mappend(token\u001b[39m.\u001b[39mtext)\n\u001b[0;32m---> 10\u001b[0m conhecimento\u001b[39m.\u001b[39mappend(token\u001b[39m.\u001b[39mi)\n\u001b[1;32m     11\u001b[0m conhecimento\u001b[39m.\u001b[39mappend(token\u001b[39m.\u001b[39mtext)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conhecimento' is not defined"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE Identificar o ROOT da frase\n",
    "\n",
    "seq_tokens_valued = []\n",
    "token_Root = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"ROOT\":\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        token_Root.append(token.i)\n",
    "        token_Root.append(token.text)\n",
    "        conhecimento.append(token.i)\n",
    "        conhecimento.append(token.text)\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conhecimento' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(conhecimento, seq_tokens_valued, total_tokens)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conhecimento' is not defined"
     ]
    }
   ],
   "source": [
    "print(conhecimento, seq_tokens_valued, total_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pensar numa forma de adicionar o verbo de desejo com verbos de acao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "userDesejo_conhecimento = [\"querer\", \"saber\", \"desejar\", \"precisar\", \"questionar\", \"abordar\", \"compreender\", \"entender\", \"gostar\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 possuir\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>T_texto</th>\n",
       "      <th>T_pos_</th>\n",
       "      <th>T_lemma_</th>\n",
       "      <th>T_dep_</th>\n",
       "      <th>T_head</th>\n",
       "      <th>T_morph_VerbForm</th>\n",
       "      <th>T_morph_Tense</th>\n",
       "      <th>T_morph_Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>entregar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>entregar</td>\n",
       "      <td>acl</td>\n",
       "      <td>568S</td>\n",
       "      <td>[Inf]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  idx   T_texto T_pos_  T_lemma_ T_dep_ T_head T_morph_VerbForm T_morph_Tense   \n",
       "0  16  entregar   VERB  entregar    acl   568S            [Inf]            []  \\\n",
       "\n",
       "  T_morph_Number  \n",
       "0             []  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 2. IMPORTANTE - Analise dos verbos da frase x Verbos significantes para negocio\n",
    " \n",
    "verbs_to_check=['ficar', 'gostar', 'ser', 'saber',  'ter', 'solicitar', 'entregar', 'ver', 'pedir', 'conhecer', 'estar', 'devolver']\n",
    "\n",
    "\n",
    "significative_verbs = pd.DataFrame(data=[], \\\n",
    "  columns=[\"idx\", \"T_texto\",\"T_pos_\", \"T_lemma_\", \"T_dep_\", \"T_head\", \"T_morph_VerbForm\", \"T_morph_Tense\", \"T_morph_Number\"])\n",
    "i = 0\n",
    "for idx in verbs_id:\n",
    "    verb_lemma = doc[idx].lemma_\n",
    "    if [n for n, x in enumerate(verbs_to_check) if verb_lemma in x]:\n",
    "        significative_verbs.loc[i,\"idx\"] = doc[idx].i\n",
    "        significative_verbs.loc[i,\"T_texto\"] = doc[idx].text\n",
    "        significative_verbs.loc[i,\"T_pos_\"] = doc[idx].pos_\n",
    "        significative_verbs.loc[i,\"T_lemma_\"] = doc[idx].lemma_\n",
    "        significative_verbs.loc[i,\"T_dep_\"] = doc[idx].dep_\n",
    "        significative_verbs.loc[i,\"T_head\"] = doc[idx].head\n",
    "        significative_verbs.loc[i,\"T_morph_VerbForm\"] = doc[idx].morph.get(\"VerbForm\")\n",
    "        significative_verbs.loc[i,\"T_morph_Tense\"] = doc[idx].morph.get(\"Tense\")\n",
    "        significative_verbs.loc[i,\"T_morph_Number\"] = doc[idx].morph.get(\"Number\")\n",
    "        i = i+1\n",
    "    else:\n",
    "        print(f'{i} {verb_lemma}')\n",
    "\n",
    "significative_verbs    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rever esta estrutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fazenda\n",
      "possui\n",
      "e verbo\n",
      "Lopito\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_i = token.i\n",
    "    token_text = token.text\n",
    "    token_lemma = token.lemma_\n",
    "    token_pos = token.pos_\n",
    "    pos_explained = spacy.explain(token_pos)\n",
    "    token_dep = token.dep_\n",
    "    dep_explained = spacy.explain(token_dep)\n",
    "    token_head = token.head.text\n",
    "    token_tag = token.tag_\n",
    "    token_morph = token.morph\n",
    "    if token_dep == \"ROOT\":\n",
    "        print(token_text)\n",
    "        if token_pos == \"VERB\":\n",
    "            print(\"e verbo\")\n",
    "            if token.lemma_ in userDesejo_conhecimento:\n",
    "                print(\"esta na condicao\")\n",
    "                conhecimento.append(token.i)\n",
    "                conhecimento.append(token.text)\n",
    "                #conhecimento.append(token.head)\n",
    "                # conhecimento.append(token.lemma_)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conhecimento' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m conhecimento\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conhecimento' is not defined"
     ]
    }
   ],
   "source": [
    "conhecimento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analises da frase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Analise sintatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>T_texto</th>\n",
       "      <th>T_shape</th>\n",
       "      <th>T_is_alpha</th>\n",
       "      <th>T_is_digit</th>\n",
       "      <th>T_is_title</th>\n",
       "      <th>T_is_punct</th>\n",
       "      <th>T_is_sent_start</th>\n",
       "      <th>T_is_right_punct</th>\n",
       "      <th>T_is_stop</th>\n",
       "      <th>T_is_quote</th>\n",
       "      <th>T_is_currency</th>\n",
       "      <th>T_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Definite=Def, Gender=Fem, Number=Sing, PronTy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fazenda</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Passo</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Masc, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Fundo</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Masc, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>possui</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>dois</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(NumType=Card)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>contratos</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Masc, Number=Plur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>568S</td>\n",
       "      <td>dddX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(NumType=Card)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>634S</td>\n",
       "      <td>dddX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(NumType=Card)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>de</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>soja</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>milheto</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Masc, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>entregar</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(VerbForm=Inf)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>para</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>os</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Definite=Def, Gender=Masc, Number=Plur, PronT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>clientes</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Masc, Number=Plur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Lopito</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Sing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Berdinazi</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>(Gender=Fem, Number=Sing)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    T_texto T_shape T_is_alpha T_is_digit T_is_title T_is_punct   \n",
       "0    0          A       X       True      False       True      False  \\\n",
       "1    1    fazenda    xxxx       True      False      False      False   \n",
       "2    2      Passo   Xxxxx       True      False       True      False   \n",
       "3    3      Fundo   Xxxxx       True      False       True      False   \n",
       "4    4     possui    xxxx       True      False      False      False   \n",
       "5    5       dois    xxxx       True      False      False      False   \n",
       "6    6  contratos    xxxx       True      False      False      False   \n",
       "7    7          :       :      False      False      False       True   \n",
       "8    8       568S    dddX      False      False       True      False   \n",
       "9    9          e       x       True      False      False      False   \n",
       "10  10       634S    dddX      False      False       True      False   \n",
       "11  11         de      xx       True      False      False      False   \n",
       "12  12       soja    xxxx       True      False      False      False   \n",
       "13  13          e       x       True      False      False      False   \n",
       "14  14    milheto    xxxx       True      False      False      False   \n",
       "15  15          a       x       True      False      False      False   \n",
       "16  16   entregar    xxxx       True      False      False      False   \n",
       "17  17       para    xxxx       True      False      False      False   \n",
       "18  18         os      xx       True      False      False      False   \n",
       "19  19   clientes    xxxx       True      False      False      False   \n",
       "20  20     Lopito   Xxxxx       True      False       True      False   \n",
       "21  21          e       x       True      False      False      False   \n",
       "22  22  Berdinazi   Xxxxx       True      False       True      False   \n",
       "\n",
       "   T_is_sent_start T_is_right_punct T_is_stop T_is_quote T_is_currency   \n",
       "0             True            False      True      False         False  \\\n",
       "1            False            False     False      False         False   \n",
       "2            False            False     False      False         False   \n",
       "3             True            False     False      False         False   \n",
       "4            False            False     False      False         False   \n",
       "5            False            False      True      False         False   \n",
       "6            False            False     False      False         False   \n",
       "7            False            False     False      False         False   \n",
       "8            False            False     False      False         False   \n",
       "9            False            False      True      False         False   \n",
       "10           False            False     False      False         False   \n",
       "11           False            False      True      False         False   \n",
       "12           False            False     False      False         False   \n",
       "13           False            False      True      False         False   \n",
       "14           False            False     False      False         False   \n",
       "15           False            False      True      False         False   \n",
       "16           False            False     False      False         False   \n",
       "17           False            False      True      False         False   \n",
       "18           False            False      True      False         False   \n",
       "19           False            False     False      False         False   \n",
       "20            True            False     False      False         False   \n",
       "21           False            False      True      False         False   \n",
       "22           False            False     False      False         False   \n",
       "\n",
       "                                              T_morph  \n",
       "0   (Definite=Def, Gender=Fem, Number=Sing, PronTy...  \n",
       "1                           (Gender=Fem, Number=Sing)  \n",
       "2                          (Gender=Masc, Number=Sing)  \n",
       "3                          (Gender=Masc, Number=Sing)  \n",
       "4   (Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...  \n",
       "5                                      (NumType=Card)  \n",
       "6                          (Gender=Masc, Number=Plur)  \n",
       "7                                                  ()  \n",
       "8                                      (NumType=Card)  \n",
       "9                                                  ()  \n",
       "10                                     (NumType=Card)  \n",
       "11                                                 ()  \n",
       "12                          (Gender=Fem, Number=Sing)  \n",
       "13                                                 ()  \n",
       "14                         (Gender=Masc, Number=Sing)  \n",
       "15                                                 ()  \n",
       "16                                     (VerbForm=Inf)  \n",
       "17                                                 ()  \n",
       "18  (Definite=Def, Gender=Masc, Number=Plur, PronT...  \n",
       "19                         (Gender=Masc, Number=Plur)  \n",
       "20                          (Gender=Fem, Number=Sing)  \n",
       "21                                                 ()  \n",
       "22                          (Gender=Fem, Number=Sing)  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisys\n",
    "syntatic = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_shape\", \"T_is_alpha\", \"T_is_digit\", \"T_is_title\", \"T_is_punct\", \"T_is_sent_start\", \"T_is_right_punct\", \"T_is_stop\", \"T_is_quote\", \"T_is_currency\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    syntatic.loc[i,\"id\"] = token.i\n",
    "    syntatic.loc[i,\"T_texto\"] = token.text\n",
    "    syntatic.loc[i,\"T_shape\"] = token.shape_\n",
    "    syntatic.loc[i,\"T_is_alpha\"] = token.is_alpha\n",
    "    syntatic.loc[i,\"T_is_digit\"] = token.is_digit\n",
    "    syntatic.loc[i,\"T_is_title\"] = token.is_title\n",
    "    syntatic.loc[i,\"T_is_punct\"] = token.is_punct\n",
    "    syntatic.loc[i,\"T_is_sent_start\"] = token.is_sent_start\n",
    "    syntatic.loc[i,\"T_is_right_punct\"] = token.is_right_punct\n",
    "    syntatic.loc[i,\"T_is_stop\"] = token.is_stop\n",
    "    syntatic.loc[i,\"T_is_quote\"] = token.is_quote\n",
    "    syntatic.loc[i,\"T_is_currency\"] = token.is_currency\n",
    "    syntatic.loc[i,\"T_morph\"] = token.morph\n",
    "    i = i+1\n",
    "\n",
    "syntatic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4A - Analise Tokens Significativos (extensoes, ROOT, verbos siginificativos de acao e desejo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estou repetindo aqui os mesmos set em extensions de tokens - Finalidade: Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tokens_valued = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = []\n",
    "extensions_nro = []\n",
    "extensions_text = []\n",
    "tk_quantidade = []\n",
    "tk_quantidade_head = []\n",
    "\n",
    "\n",
    "for token in doc:\n",
    "    if token._.is_cultura:\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        extensions.append(token.i)\n",
    "        extensions.append('is_cultura')\n",
    "        extensions_nro.append(token.i)\n",
    "        extensions_nro.append('is_cultura')\n",
    "        extensions_nro.append(token.text)\n",
    "        \n",
    "        extensions_text.append(token.i)\n",
    "        extensions_text.append(token.text)\n",
    "    if token._.is_quantidade:\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        extensions.append(token.i)\n",
    "        extensions.append('is_quantidade')\n",
    "        \n",
    "        tk_quantidade.append(token.i)\n",
    "        tk_quantidade.append(token.text)\n",
    "        tk_quantidade_head.append(token.i)\n",
    "        tk_quantidade_head.append(token.head)\n",
    "        \n",
    "\n",
    "        extensions_nro.append(token.i)\n",
    "        extensions_nro.append('is_quantidade')\n",
    "        extensions_nro.append(token.text)\n",
    "        \n",
    "        extensions_text.append(token.i)\n",
    "        extensions_text.append(token.text)\n",
    "        \n",
    "    if token._.is_contrato:\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        extensions.append(token.i)\n",
    "        extensions.append('is_contrato')\n",
    "        \n",
    "        extensions_nro.append(token.i)\n",
    "        extensions_nro.append('is_contrato')\n",
    "        extensions_nro.append(token.text)\n",
    "        \n",
    "        \n",
    "        extensions_text.append(token.i)\n",
    "        extensions_text.append(token.text)\n",
    "        \n",
    "    if token._.is_safra:\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        extensions.append(token.i)\n",
    "        extensions.append('is_safra')\n",
    "        \n",
    "            \n",
    "        extensions_nro.append(token.i)\n",
    "        extensions_nro.append('is_safra')\n",
    "        extensions_nro.append(token.text)\n",
    "        \n",
    "        extensions_text.append(token.i)\n",
    "        extensions_text.append(token.text)\n",
    "        \n",
    "    if token._.is_acao:\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        extensions.append(token.i)\n",
    "        extensions.append('is_acao')\n",
    "        \n",
    "        extensions_nro.append(token.i)\n",
    "        extensions_nro.append('is_acao')\n",
    "        extensions_nro.append(token.text)\n",
    "        \n",
    "        extensions_text.append(token.i)\n",
    "        extensions_text.append(token.text)\n",
    "        \n",
    "        \n",
    "    if token._.is_fazenda:\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        extensions.append(token.i)\n",
    "        extensions.append('is_fazenda')\n",
    "        \n",
    "        extensions_nro.append(token.i)\n",
    "        extensions_nro.append('is_fazenda')\n",
    "        extensions_nro.append(token.text)\n",
    "        \n",
    "        extensions_text.append(token.i)\n",
    "        extensions_text.append(token.text)\n",
    "    if token._.is_cliente:\n",
    "        seq_tokens_valued.append(token.i)\n",
    "        extensions.append(token.i)\n",
    "        extensions.append('is_cliente')\n",
    "        \n",
    "        extensions_nro.append(token.i)\n",
    "        extensions_nro.append('is_cliente')\n",
    "        extensions_nro.append(token.text) \n",
    "        \n",
    "        extensions_text.append(token.i)\n",
    "        extensions_text.append(token.text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seq_tokens_valued' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m significative_tokens \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39m[], \\\n\u001b[1;32m      3\u001b[0m   columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39midx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_texto\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mT_pos_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_lemma_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_dep_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_head\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_morph_VerbForm\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_morph_Tense\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_morph_Number\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mT_type\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m seq_tokens_valued:\n\u001b[1;32m      6\u001b[0m     significative_tokens\u001b[39m.\u001b[39mloc[i,\u001b[39m\"\u001b[39m\u001b[39midx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m doc[idx]\u001b[39m.\u001b[39mi\n\u001b[1;32m      7\u001b[0m     significative_tokens\u001b[39m.\u001b[39mloc[i,\u001b[39m\"\u001b[39m\u001b[39mT_texto\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m doc[idx]\u001b[39m.\u001b[39mtext\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seq_tokens_valued' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extensions\n",
    "significative_tokens = pd.DataFrame(data=[], \\\n",
    "  columns=[\"idx\", \"T_texto\",\"T_pos_\", \"T_lemma_\", \"T_dep_\", \"T_head\", \"T_morph_VerbForm\", \"T_morph_Tense\", \"T_morph_Number\", \"T_type\"])\n",
    "i = 0\n",
    "for idx in seq_tokens_valued:\n",
    "    significative_tokens.loc[i,\"idx\"] = doc[idx].i\n",
    "    significative_tokens.loc[i,\"T_texto\"] = doc[idx].text\n",
    "    significative_tokens.loc[i,\"T_pos_\"] = doc[idx].pos_\n",
    "    significative_tokens.loc[i,\"T_lemma_\"] = doc[idx].lemma_\n",
    "    significative_tokens.loc[i,\"T_dep_\"] = doc[idx].dep_\n",
    "    significative_tokens.loc[i,\"T_head\"] = doc[idx].head\n",
    "    significative_tokens.loc[i,\"T_morph_VerbForm\"] = doc[idx].morph.get(\"VerbForm\")\n",
    "    significative_tokens.loc[i,\"T_morph_Tense\"] = doc[idx].morph.get(\"Tense\")\n",
    "    significative_tokens.loc[i,\"T_morph_Number\"] = doc[idx].morph.get(\"Number\")\n",
    "    extension = doc[idx].get_extension\n",
    "    if extension == \"is_cultura\":\n",
    "      print(extension)\n",
    "    # for token in doc:\n",
    "    #   if token.i == idx:\n",
    "    #     if token._.is_cultura:\n",
    "    #       significative_tokens.loc[i,\"T_type\"] = \"is_cultura\"\n",
    "    \n",
    "\n",
    "    i = i+1\n",
    "\n",
    "significative_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_texto</th>\n",
       "      <th>T_pos_</th>\n",
       "      <th>T_dep_</th>\n",
       "      <th>T_is_cultura</th>\n",
       "      <th>T_is_quantidade</th>\n",
       "      <th>T_is_contrato</th>\n",
       "      <th>T_is_contrato</th>\n",
       "      <th>T_is_safra</th>\n",
       "      <th>T_is_fazenda</th>\n",
       "      <th>T_is_cliente</th>\n",
       "      <th>T_is_acao</th>\n",
       "      <th>T_type</th>\n",
       "      <th>T_morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fazenda</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Significativo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>possui</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Significativo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contratos</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>obj</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[is_contrato, is_verb]</td>\n",
       "      <td>(Gender=Masc, Number=Plur)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>soja</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nmod</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_cultura</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>milheto</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>conj</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>is_cultura</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lopito</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Significativo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_texto T_pos_ T_dep_ T_is_cultura T_is_quantidade T_is_contrato   \n",
       "1     fazenda   NOUN   ROOT        False           False         False  \\\n",
       "4      possui   VERB   ROOT        False           False         False   \n",
       "6   contratos   NOUN    obj        False           False          True   \n",
       "12       soja   NOUN   nmod         True           False         False   \n",
       "14    milheto   NOUN   conj         True           False         False   \n",
       "20     Lopito  PROPN   ROOT        False           False         False   \n",
       "\n",
       "   T_is_contrato T_is_safra T_is_fazenda T_is_cliente T_is_acao   \n",
       "1          False      False         True        False     False  \\\n",
       "4          False      False        False        False     False   \n",
       "6           True      False        False        False     False   \n",
       "12         False      False        False        False     False   \n",
       "14         False      False        False        False     False   \n",
       "20         False      False        False        False     False   \n",
       "\n",
       "                    T_type                     T_morph  \n",
       "1            Significativo                         NaN  \n",
       "4            Significativo                         NaN  \n",
       "6   [is_contrato, is_verb]  (Gender=Masc, Number=Plur)  \n",
       "12              is_cultura                         NaN  \n",
       "14              is_cultura                         NaN  \n",
       "20           Significativo                         NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_to_check=['ficar', 'gostar', 'ser', 'saber',  'ter', 'solicitar', 'entregar', 'ver', 'pedir', 'conhecer', 'estar', 'devolver']\n",
    "\n",
    "\n",
    "# Extensions\n",
    "extension = pd.DataFrame(data=[], \\\n",
    "  columns=[\"T_texto\",\"T_pos_\", \"T_dep_\", \"T_is_cultura\", \"T_is_quantidade\", \"T_is_contrato\", \"T_is_contrato\", \"T_is_safra\", \"T_is_fazenda\", \"T_is_cliente\", \"T_is_acao\", \"T_type\", \"T_morph\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "  if token.dep_ == \"ROOT\":\n",
    "      extension.loc[i,\"T_texto\"] = token.text\n",
    "      extension.loc[i,\"T_pos_\"] = token.pos_\n",
    "      extension.loc[i,\"T_dep_\"] = token.dep_\n",
    "      extension.loc[i,\"T_is_cultura\"] = token._.is_cultura\n",
    "      extension.loc[i,\"T_is_quantidade\"] = token._.is_quantidade\n",
    "      extension.loc[i,\"T_is_contrato\"] = token._.is_contrato\n",
    "      extension.loc[i,\"T_is_safra\"] = token._.is_safra\n",
    "      extension.loc[i,\"T_is_fazenda\"] = token._.is_fazenda\n",
    "      extension.loc[i,\"T_is_cliente\"] = token._.is_cliente\n",
    "      extension.loc[i,\"T_is_acao\"] = token._.is_acao\n",
    "      extension.loc[i,\"T_type\"] = \"Significativo\"\n",
    "  elif token._.is_cultura:\n",
    "      #extension.loc[i,\"id\"] = token.i\n",
    "      extension.loc[i,\"T_texto\"] = token.text\n",
    "      extension.loc[i,\"T_pos_\"] = token.pos_\n",
    "      extension.loc[i,\"T_dep_\"] = token.dep_\n",
    "      extension.loc[i,\"T_is_cultura\"] = token._.is_cultura\n",
    "      extension.loc[i,\"T_is_quantidade\"] = token._.is_quantidade\n",
    "      extension.loc[i,\"T_is_contrato\"] = token._.is_contrato\n",
    "      extension.loc[i,\"T_is_safra\"] = token._.is_safra\n",
    "      extension.loc[i,\"T_is_fazenda\"] = token._.is_fazenda\n",
    "      extension.loc[i,\"T_is_cliente\"] = token._.is_cliente\n",
    "      extension.loc[i,\"T_is_acao\"] = token._.is_acao\n",
    "      extension.loc[i,\"T_type\"] = \"is_cultura\"\n",
    "  elif token._.is_quantidade:\n",
    "      #extension.loc[i,\"id\"] = token.i\n",
    "      extension.loc[i,\"T_texto\"] = token.text\n",
    "      extension.loc[i,\"T_pos_\"] = token.pos_\n",
    "      extension.loc[i,\"T_dep_\"] = token.dep_\n",
    "      extension.loc[i,\"T_is_cultura\"] = token._.is_cultura\n",
    "      extension.loc[i,\"T_is_quantidade\"] = token._.is_quantidade\n",
    "      extension.loc[i,\"T_is_contrato\"] = token._.is_contrato\n",
    "      extension.loc[i,\"T_is_safra\"] = token._.is_safra\n",
    "      extension.loc[i,\"T_is_fazenda\"] = token._.is_fazenda\n",
    "      extension.loc[i,\"T_is_cliente\"] = token._.is_cliente\n",
    "      extension.loc[i,\"T_is_acao\"] = token._.is_acao\n",
    "      extension.loc[i,\"T_type\"] = [\"is_quantidade\", \"is_verb\"]       \n",
    "      extension.loc[i,\"T_morph\"] = token.morph\n",
    "  elif token._.is_contrato:   \n",
    "      extension.loc[i,\"T_texto\"] = token.text\n",
    "      extension.loc[i,\"T_pos_\"] = token.pos_\n",
    "      extension.loc[i,\"T_dep_\"] = token.dep_\n",
    "      extension.loc[i,\"T_is_cultura\"] = token._.is_cultura\n",
    "      extension.loc[i,\"T_is_quantidade\"] = token._.is_quantidade\n",
    "      extension.loc[i,\"T_is_contrato\"] = token._.is_contrato\n",
    "      extension.loc[i,\"T_is_safra\"] = token._.is_safra\n",
    "      extension.loc[i,\"T_is_fazenda\"] = token._.is_fazenda\n",
    "      extension.loc[i,\"T_is_cliente\"] = token._.is_cliente\n",
    "      extension.loc[i,\"T_is_acao\"] = token._.is_acao\n",
    "      extension.loc[i,\"T_type\"] = [\"is_contrato\",\"is_verb\"]      \n",
    "      extension.loc[i,\"T_morph\"] = token.morph\n",
    "  #elif [n for n, x in enumerate(verbs_to_check) if verb_lemma in x]:    \n",
    "      \n",
    "      \n",
    "      \n",
    "\n",
    "  i = i+1\n",
    "\n",
    "extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o saldo total\n",
      "soja\n",
      "que\n",
      "safra\n"
     ]
    }
   ],
   "source": [
    "for chunk in nlp(\"Bom dia, gostaria de saber o saldo total de soja que tenho para entregar na safra 22/23?\").noun_chunks:\n",
    "      print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington foi um líder político americano, general militar, estadista e fundador que serviu como primeiro presidente dos Estados Unidos de 1789 a 1797\n",
      "Text Start End Label\n",
      "George Washington 0 17 PER\n",
      "Estados Unidos 129 143 LOC\n"
     ]
    }
   ],
   "source": [
    "# Print NER results\n",
    "example_sentence = \"George Washington foi um líder político americano, \\\n",
    "general militar, estadista e fundador que serviu como \\\n",
    "primeiro presidente dos Estados Unidos de 1789 a 1797\"\n",
    "\n",
    "print(example_sentence)\n",
    "\n",
    "print(\"Text Start End Label\")\n",
    "doc = nlp(example_sentence)\n",
    "for token in doc.ents:\n",
    "    print(token.text, token.start_char, token.end_char, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    George Washington\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " foi um líder político americano, general militar, estadista e fundador que serviu como primeiro presidente dos \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Estados Unidos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " de 1789 a 1797</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize NER results\n",
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington was an American political leader, military general, statesman, and Founding Father who served as the first president of the United States from 1789 to 1797.\n",
      "\n",
      "Text Start End Label\n",
      "George Washington 0 17 PER\n",
      "Founding Father who served 85 111 MISC\n",
      "the first president of the United States from 1789 to 1797 115 173 ORG\n"
     ]
    }
   ],
   "source": [
    "# Print NER results\n",
    "example_sentence_en = \"George Washington was an American political leader, \\\n",
    "military general, statesman, and Founding Father who served as the \\\n",
    "first president of the United States from 1789 to 1797.\\n\"\n",
    "\n",
    "print(example_sentence_en)\n",
    "\n",
    "print(\"Text Start End Label\")\n",
    "doc = nlp(example_sentence_en)\n",
    "for token in doc.ents:\n",
    "    print(token.text, token.start_char, token.end_char, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    George Washington\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " was an American political leader, military general, statesman, and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Founding Father who served\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " as \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the first president of the United States from 1789 to 1797\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize NER results\n",
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7, 8, 10, 14, 16, 7, 8, 10, 14, 16]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tokens_valued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GARANTIR que a ordem dos Tokens esteja correta (ascendente)\n",
    "seq_tokens_valued.sort()\n",
    "seq_tokens_valued\n",
    "\n",
    "\n",
    "## tokens_ids + Lista de todos os Tokens da frase\n",
    "tokens_ids = []\n",
    "for token in doc:\n",
    "    tokens_ids.append(token.i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 7, 8, 10, 14, 16, 7, 8, 10, 14, 16]\n"
     ]
    }
   ],
   "source": [
    "print(seq_tokens_valued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 'is_quantidade', 'saldo', 8, 'is_quantidade', 'total', 10, 'is_cultura', 'soja', 14, 'is_acao', 'entregar', 16, 'is_safra', 'safra']\n"
     ]
    }
   ],
   "source": [
    "print(extensions_nro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 'saldo', 8, 'total', 10, 'soja', 14, 'entregar', 16, 'safra']\n"
     ]
    }
   ],
   "source": [
    "print(extensions_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "exten_dep = pd.DataFrame(data=[], \\\n",
    "  columns=[\"id\", \"T_texto\",\"T_n_lefts\", \"T_n_rights\", \"T_dep_\", \"T_is_sent_end\", \"T_head\"])\n",
    "i = 0\n",
    "for token in doc:\n",
    "    exten_dep.loc[i,\"id\"] = token.i\n",
    "    exten_dep.loc[i,\"T_texto\"] = token.text\n",
    "    exten_dep.loc[i,\"T_n_lefts\"] = token.n_lefts\n",
    "    exten_dep.loc[i,\"T_n_rights\"] = token.n_rights\n",
    "    exten_dep.loc[i,\"T_dep_\"] = token.dep_\n",
    "    exten_dep.loc[i,\"T_is_sent_end\"] = token.is_sent_end\n",
    "    exten_dep.loc[i,\"T_head\"] = token.head\n",
    "\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "exten_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[17].shape_.format(\"dddx\")\n",
    "doc[134].shape_ == \"dddx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doc[17].shape_ == \"dd/dd\":\n",
    "    nro_safra = doc[17].text\n",
    "print(nro_safra)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_safra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de tokens extentsions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carlos', 'PRODUTOR', 'BOA ESPERANCA', 3, 'gostaria', 3, 'gostaria']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions\n",
    "\n",
    "verbs_to_check=['ficar', 'gostar', 'ser', 'saber',  'ter', 'solicitar', 'entregar', 'ver', 'pedir', 'conhecer', 'estar', 'devolver']\n",
    "\n",
    "\n",
    "significative_verbs = pd.DataFrame(data=[], \\\n",
    "  columns=[\"idx\", \"T_texto\",\"T_pos_\", \"T_lemma_\", \"T_dep_\", \"T_head\", \"T_morph_VerbForm\", \"T_morph_Tense\", \"T_morph_Number\"])\n",
    "i = 0\n",
    "for idx in verbs_id:\n",
    "    verb_lemma = doc[idx].lemma_\n",
    "    if [n for n, x in enumerate(verbs_to_check) if verb_lemma in x]:\n",
    "        significative_verbs.loc[i,\"idx\"] = doc[idx].i\n",
    "        significative_verbs.loc[i,\"T_texto\"] = doc[idx].text\n",
    "        significative_verbs.loc[i,\"T_pos_\"] = doc[idx].pos_\n",
    "        significative_verbs.loc[i,\"T_lemma_\"] = doc[idx].lemma_\n",
    "        significative_verbs.loc[i,\"T_dep_\"] = doc[idx].dep_\n",
    "        significative_verbs.loc[i,\"T_head\"] = doc[idx].head\n",
    "        significative_verbs.loc[i,\"T_morph_VerbForm\"] = doc[idx].morph.get(\"VerbForm\")\n",
    "        significative_verbs.loc[i,\"T_morph_Tense\"] = doc[idx].morph.get(\"Tense\")\n",
    "        significative_verbs.loc[i,\"T_morph_Number\"] = doc[idx].morph.get(\"Number\")\n",
    "        i = i+1\n",
    "    else:\n",
    "        print(f'{i} {verb_lemma}')\n",
    "\n",
    "significative_verbs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_to_check=['ficar', 'gostar', 'ser', 'saber',  'ter', 'solicitar', 'entregar', 'ver', 'pedir', 'conhecer', 'estar', 'devolver']\n",
    "\n",
    "for i in verbs_id:\n",
    "    verb_lemma = doc[i].lemma_\n",
    "    if [n for n, x in enumerate(verbs_to_check) if verb_lemma in x]:\n",
    "        print(f'\\n{doc[i].i} | valor: {doc[i].text} | {doc[i].pos_} | {doc[i].lemma_} | {doc[i].dep_} | {doc[i].head} || {doc[i].morph.get(\"VerbForm\")} | {doc[i].morph.get(\"Tense\")} | {doc[i].morph.get(\"Number\")}')\n",
    "    else:\n",
    "        print(f'{i} {verb_lemma}')\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 'is_quantidade',\n",
       " 'saldo',\n",
       " 8,\n",
       " 'is_quantidade',\n",
       " 'total',\n",
       " 10,\n",
       " 'is_cultura',\n",
       " 'soja',\n",
       " 14,\n",
       " 'is_acao',\n",
       " 'entregar',\n",
       " 16,\n",
       " 'is_safra',\n",
       " 'safra']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extensions_nro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_quantidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_tk_quant = len(tk_quantidade)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de item quantidades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso especifico para quantidade\n",
    "nro_tk_quant = len(tk_quantidade)\n",
    "if nro_tk_quant > 2:\n",
    "    if (tk_quantidade[nro_tk_quant-2] - tk_quantidade[nro_tk_quant-4]) <= 2:\n",
    "        palavra_quantidade = tk_quantidade[nro_tk_quant-3] + \" \" + tk_quantidade[nro_tk_quant-1]\n",
    "        if \"saldo\" in palavra_quantidade:\n",
    "            palavra_quantidade = \"quantidade de saldo do contrato\"\n",
    "            key_quantidade = \"11-qt saldo contrato\"\n",
    "            confirm_question = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavra_quantidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_tk_quant-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_quantidade_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tk_quantidade_head[3] == tk_quantidade[1]:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_quantidade_head[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_quantidade_head[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_to_check=['ficar', 'gostar', 'ser', 'saber',  'ter', 'solicitar', 'entregar', 'ver', 'pedir', 'conhecer', 'estar', 'devolver']\n",
    "verbs_id\n",
    "total_tokens = len(doc)\n",
    "userDesejo_conhecimento = [\"querer\", \"saber\", \"desejar\", \"precisar\", \"questionar\", \"abordar\", \"compreender\", \"entender\", \"gostar\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesquisa SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'7045','PASSO FUNDO','2','MILHO','303','BERDINAZI','2021','826V','155550','155550'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlagro.get_query_results(fields=['NM_FAZENDA', 'ID_SAFRA', 'QT_TOTAL_CONTRATO', 'QT_ENTREGUE_CONTRATO', 'QT_SALDO_CONTRATO'], filters={'NR_CONTRATO': '955T','NM_CLIENTE': 'BERDINAZI', 'NM_FAZENDA': 'AGROBI', 'NM_CULTURA': 'FEIJÃO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tk_quant in tk_quantidade:\n",
    "    if type(tk_quant) == int:\n",
    "        id1 = tk_quant\n",
    "        if tk\n",
    "        print(tk_quant)\n",
    "    #print(tk_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "\n",
    "print([(token.text, token.dep_, token.pos_) for token in doc])\n",
    "\n",
    "resultados = [True if c else False for c in condicoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(token.text, token.dep_, token.pos_) for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = [True if c else False for c in condicoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_true = [i for i, palavra in enumerate(palavras_chave) if doc._.has_token(palavra)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_quantidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for valor in extensions:\n",
    "    if valor == \"is_quantidade\":\n",
    "        print(\"falou de quantidade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if extensions[0] == \"is_quantidade\" and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"A fazenda Passo Fundo possui dois contratos: 568S e 634S. No primeiro, entregou 30000 quilos de soja e no segundo, entregou 15000 qulios de  30.000 quilos de milho nas safras 20/22 e 21/23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Avaliando cultura\n",
    "doc = nlp(\"A fazenda Passo Fundo produz milho e soja para as safras de 20/22 e 21/23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Quantos quilos de milho já foram entregues pela fazenda Passo Fundo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the similarity of the spans\n",
    "similarity = span1.similarity(span2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.analyze_pipes(pretty=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Matchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechando a questao do nro do contrato\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
    "matcher.add(\"CONTRATO\", [nlp(\"000A\"), nlp(\"999Z\")])\n",
    "\n",
    "doc = nlp(\"Meu contrato 532S da fazenda FAZENDA PASSO FUNDO da safra 2023\")\n",
    "for match_id, start, end in matcher(doc):\n",
    "    doc_matches = doc[start:end]\n",
    "    print(doc_matches)\n",
    "matches = matcher(doc, as_spans=True)\n",
    "for span in matches:\n",
    "    print(f'Mostrando o span: {span.text}, e o label: {span.label_}\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechando a questao do nro do contrato - com exibicao do span como ent\n",
    "from spacy import displacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "# Fechando a questao do nro do contrato\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
    "matcher.add(\"CONTRATO\", [nlp(\"000A\"), nlp(\"999Z\")])\n",
    "\n",
    "doc = nlp(\"Meu contrato 532S da fazenda FAZENDA PASSO FUNDO da safra 2023\")\n",
    "for match_id, start, end in matcher(doc):\n",
    "    doc_matches = doc[start:end]\n",
    "    print(doc_matches)\n",
    "matches = matcher(doc, as_spans=True)\n",
    "for span in matches:\n",
    "    span_start = span.start\n",
    "    span_end = span.end\n",
    "    doc.spans[\"sc\"] = [\n",
    "        Span(doc, span_start, span_end, \"CONTRATO\")]\n",
    "    print(f'Mostrando o span: {span.text}, e o label: {span.label_} {span_start} {span_end}\\n')\n",
    "\n",
    "displacy.render(doc, style=\"span\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando emojos para analise de sentimentos\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pos_emoji = [\"😀\", \"😃\", \"😂\", \"🤣\", \"😊\", \"😍\"]  # Positive emoji\n",
    "neg_emoji = [\"😞\", \"😠\", \"😩\", \"😢\", \"😭\", \"😒\"]  # Negative emoji\n",
    "\n",
    "# Add patterns to match one or more emoji tokens\n",
    "pos_patterns = [[{\"ORTH\": emoji}] for emoji in pos_emoji]\n",
    "neg_patterns = [[{\"ORTH\": emoji}] for emoji in neg_emoji]\n",
    "\n",
    "# Function to label the sentiment\n",
    "def label_sentiment(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    if doc.vocab.strings[match_id] == \"FELIZ\":\n",
    "        doc.sentiment += 0.1  \n",
    "    elif doc.vocab.strings[match_id] == \"TRISTE\":\n",
    "        doc.sentiment -= 0.1  \n",
    "\n",
    "matcher.add(\"FELIZ\", pos_patterns, on_match=label_sentiment) \n",
    "matcher.add(\"TRISTE\", neg_patterns, on_match=label_sentiment) \n",
    "\n",
    "# Add pattern for valid hashtag, i.e. '#' plus any ASCII token\n",
    "matcher.add(\"HASHTAG\", [[{\"ORTH\": \"#\"}, {\"IS_ASCII\": True}]])\n",
    "\n",
    "doc = nlp(\"Bom dia 😀 #AtendimentoTop\")\n",
    "\n",
    "#doc = nlp(\"Nao funcionou 😞\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = doc.vocab.strings[match_id]  \n",
    "    span = doc[start:end]\n",
    "    print(string_id, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando matcher para IP\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
    "matcher.add(\"IP\", [nlp(\"127.0.0.1\"), nlp(\"127.127.0.0\")])\n",
    "\n",
    "doc = nlp(\"Often the router will have an IP address such as 192.168.1.1 or 192.168.2.1.\")\n",
    "for match_id, start, end in matcher(doc):\n",
    "    print(\"Matched based on token shape:\", doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Outras estruturas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[2].morph.get(\"VerbForm\")\n",
    "doc[4].morph.get(\"Number\")\n",
    "doc[2].morph.get(\"Tense\")\n",
    "doc[14].shape_.format(\"dddx\")\n",
    "doc[134].shape_ == \"dddx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes gerais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pipelines Agro "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando componentes ao pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionamos um tokenizador\n",
    "nlp.add_pipe(\"tok2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionamos um tagger\n",
    "nlp.add_pipe(\"tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionamos um parser\n",
    "nlp.add_pipe(\"parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionamos um ner\n",
    "nlp.add_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(\"entity_linker\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando o pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.analyze_pipes(pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelo de configuraçao - soluçao"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo predeterminado, templetizado e <mark>parametrizavel</mark> para o andamento do processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import Config\n",
    "config_agro = Config().from_disk(\"/home/dani-boy/nlpdoc/config/config_agro.cfg\")\n",
    "config_agro = config_agro.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config_agro[\"mega\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_agro[\"mega\"][\"context_category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_agro[\"mega\"][\"stages\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_agro[\"mega\"][\"stages\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_agro[\"timing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_agro[\"timing\"][\"wait_for_next_message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_agro[\"timing\"][\"time_to_log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_agro[\"mega\"][\"stages\"][2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Criando os docs para OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Import the Doc class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Desired text: \"spaCy is cool!\"\n",
    "words = [\"spaCy\", \"is\", \"cool\", \"!\"]\n",
    "spaces = [True, True, False, False]\n",
    "\n",
    "# Create a Doc from the words and spaces\n",
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "print(doc.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
