{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Processa pipeline models</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "\n",
    "import platform\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "\n",
    "\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "import fitz  # Módulo PyMuPDF\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "import PyPDF2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import locale\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time, copy\n",
    "\n",
    "\n",
    "from outlook_msg import Message\n",
    "import extract_msg\n",
    "import zipfile\n",
    "from pyunpack import Archive\n",
    "import py7zr\n",
    "\n",
    "\n",
    "from pytz import timezone\n",
    "from urllib import response\n",
    "\n",
    "\n",
    "\n",
    "import modules.extrai_pdf_pesquisavel as Extc\n",
    "import modules.cronometro as cron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_test = 16\n",
    "\n",
    "### PRESTAR ATENCAO\n",
    "#model = 'mage'\n",
    "model = 'mesquita'\n",
    "#model = 'pedro_aldeia'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Nome Batch\n",
    "batch_name = \"Batch_\" + str(i_test)\n",
    "\n",
    "root_doc_analise = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "image_resized_path = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas\"\n",
    "\n",
    "######### PATHS\n",
    "#1. path formado para busca de pdfs recursiva\n",
    "root_doc_analise = os.path.join(root_doc_analise, batch_name)\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"pipeline_extracao_documentos/5_documentos_processados/jsons\"\n",
    "\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. path para documentos PDF (omelhor se estiverem dentro de um unico diretorio)\n",
    "root_pdf_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 2. path para documentos PDF que podem estar aguardando para serem processados\n",
    "root_pdf_aguardando_path = \"pipeline_extracao_documentos/3_tratamento_excecoes/pdf_aguardando_processar\"\n",
    "\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 3. path para documentos PDF externos para serem processados\n",
    "root_external_pdf_path = \"content_from_pdftool/data/data_pdf/NF_para_processamento/NFRJ_PDF_para _ocr\"\n",
    "# 4. path para documentos PDF PESQUISAVEIS externos para serem processados\n",
    "root_external_pdf_pesquisavel_path = \"content_from_pdftool/data/data_pdf/NF_processadas/NFRJ/fwdnotasfiscaisemitidaslmpadalegal\"\n",
    "\n",
    "# 5. path para imagem padrao\n",
    "image_resized_path = 'pipeline_extracao_documentos/6_geral_administacao/images/processadas'\n",
    "\n",
    "# 6. path para log\n",
    "log_path = 'pipeline_extracao_documentos/6_geral_administacao/logs'\n",
    "\n",
    "# 8. path para NFs processadas\n",
    "nf_processada_path = \"pipeline_extracao_documentos/5_documentos_processados\"\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "cnae_dict_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets/MAGE_CNAE_X_ITEM_SERVICO_V1.xlsx\"\n",
    "\n",
    "# VERIFICAR\n",
    "tgt_imagens = \"pipeline_extracao_documentos/6_geral_administacao/images\"\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.utf8'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 1. Caminho do arquivo uma mensagem especifica\n",
    "msg_dir_path = 'pipeline_extracao_documentos/1_emails'\n",
    "\n",
    "# 2. Path para arquivos atachados compactados\n",
    "msg_attachment_zip = 'pipeline_extracao_documentos/1_emails/attachments'\n",
    "\n",
    "# 3. Path para documentos atachados:\n",
    "documentos_extracao_path = 'pipeline_extracao_documentos/2_documentos_para_extracao'\n",
    "\n",
    "\n",
    "# definindo localizadcao para pt_BR\n",
    "locale.setlocale(locale.LC_TIME, \"pt_BR.utf8\")\n",
    "\n",
    "# Nosso timezone\n",
    "#local_tz = pytz.timezone('America/Sao_Paulo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "i_test: 13 | model: mage | batch_name: Batch_13 | root_doc_analise: pipeline_extracao_documentos/2_documentos_para_extracao/Batch_13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'\\ni_test: {i_test} | model: {model} | batch_name: {batch_name} | root_doc_analise: {root_doc_analise}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tratando nome de carga do df_processamento\n",
    "dataset_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "df_processamento_file = \"df_processamento_\"\n",
    "\n",
    "df_processamento_file_read = df_processamento_file + str(i_test - 1) + \".xlsx\"\n",
    "\n",
    "# 2. Tratando nome de carga do df_extracao_files_Batch\n",
    "df_extracao_files_Batch_file = \"df_extracao_files_Batch_\"\n",
    "\n",
    "df_extracao_files_Batch_file_read = df_extracao_files_Batch_file + str(i_test - 1) + \".xlsx\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pipeline_extracao_documentos/6_geral_administacao/datasets/df_processamento_15.xlsx'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processamento_file_read_path = os.path.join(dataset_path, df_processamento_file_read)\n",
    "\n",
    "df_processamento_file_read_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pipeline_extracao_documentos/6_geral_administacao/datasets/df_extracao_files_Batch_15.xlsx'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracao_files_Batch_file_read_path = os.path.join(dataset_path, df_extracao_files_Batch_file_read)\n",
    "\n",
    "df_extracao_files_Batch_file_read_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt_hora</th>\n",
       "      <th>Assunto</th>\n",
       "      <th>Quantidade de Documentos</th>\n",
       "      <th>De</th>\n",
       "      <th>batch</th>\n",
       "      <th>email</th>\n",
       "      <th>Arquivos_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/08/2023 16:11:50</td>\n",
       "      <td>Notas Magé</td>\n",
       "      <td>[115]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17/08/2023 15:49:21</td>\n",
       "      <td>Notas Sao Pedro da Aldeia</td>\n",
       "      <td>[28]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/08/2023 11:56:51</td>\n",
       "      <td>Notas São Pedro da Aldeia</td>\n",
       "      <td>[10]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/08/2023 12:01:16</td>\n",
       "      <td>Notas Mesquita</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>na</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/08/2023 11:25:42</td>\n",
       "      <td>Fwd: Notas Magé</td>\n",
       "      <td>[9]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_5</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-10-08 23:20:56</td>\n",
       "      <td>Fwd: Notas Magé 2</td>\n",
       "      <td>[11]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_6</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/08/2023 23:20:56</td>\n",
       "      <td>Fwd: Notas Magé 2</td>\n",
       "      <td>[75]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_6_Atualizado</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/08/2023 17:54:14</td>\n",
       "      <td>Fwd: Notas Magé 1</td>\n",
       "      <td>[21, 8, 18, 3]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_7</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>['07-2023 (1).7z', 'fwdrenotafiscal.zip', 'fwd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12/08/2023 11:25:42</td>\n",
       "      <td>Fwd: Notas Magé</td>\n",
       "      <td>[9]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_8</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31/08/2023 22:27:59</td>\n",
       "      <td>Notas Magé</td>\n",
       "      <td>[2, 17]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31/08/2023 22:27:59</td>\n",
       "      <td>Notas Magé</td>\n",
       "      <td>[17]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>['notas mage 31082023.zip']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31/08/2023 22:31:10</td>\n",
       "      <td>Nota SPA</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_13</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31/08/2023 23:00:27</td>\n",
       "      <td>Notas Magé 2</td>\n",
       "      <td>[3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, ...</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_14</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31/08/2023 23:00:54</td>\n",
       "      <td>Notas SPA 2</td>\n",
       "      <td>[1, 1, 1, 3, 2, 1, 8, 2, 1, 1, 1, 1]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_15</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dt_hora                    Assunto  \\\n",
       "0   17/08/2023 16:11:50                 Notas Magé   \n",
       "1   17/08/2023 15:49:21  Notas Sao Pedro da Aldeia   \n",
       "2   17/08/2023 11:56:51  Notas São Pedro da Aldeia   \n",
       "3   17/08/2023 12:01:16             Notas Mesquita   \n",
       "4   12/08/2023 11:25:42            Fwd: Notas Magé   \n",
       "5   2023-10-08 23:20:56          Fwd: Notas Magé 2   \n",
       "6   10/08/2023 23:20:56          Fwd: Notas Magé 2   \n",
       "7   10/08/2023 17:54:14          Fwd: Notas Magé 1   \n",
       "8   12/08/2023 11:25:42            Fwd: Notas Magé   \n",
       "9   31/08/2023 22:27:59                 Notas Magé   \n",
       "10  31/08/2023 22:27:59                 Notas Magé   \n",
       "11  31/08/2023 22:31:10                   Nota SPA   \n",
       "12  31/08/2023 23:00:27               Notas Magé 2   \n",
       "13  31/08/2023 23:00:54                Notas SPA 2   \n",
       "\n",
       "                             Quantidade de Documentos                  De  \\\n",
       "0                                               [115]  Bruna Maciel Adame   \n",
       "1                                                [28]  Bruna Maciel Adame   \n",
       "2                                                [10]  Bruna Maciel Adame   \n",
       "3                                                 [2]  Bruna Maciel Adame   \n",
       "4                                                 [9]   Verlânio Gallindo   \n",
       "5                                                [11]   Verlânio Gallindo   \n",
       "6                                                [75]   Verlânio Gallindo   \n",
       "7                                      [21, 8, 18, 3]   Verlânio Gallindo   \n",
       "8                                                 [9]   Verlânio Gallindo   \n",
       "9                                             [2, 17]  Bruna Maciel Adame   \n",
       "10                                               [17]  Bruna Maciel Adame   \n",
       "11                                                [1]  Bruna Maciel Adame   \n",
       "12  [3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, ...  Bruna Maciel Adame   \n",
       "13               [1, 1, 1, 3, 2, 1, 8, 2, 1, 1, 1, 1]  Bruna Maciel Adame   \n",
       "\n",
       "                 batch                             email  \\\n",
       "0              Batch_1  bruna@modernizacaopublica.com.br   \n",
       "1              Batch_2  bruna@modernizacaopublica.com.br   \n",
       "2              Batch_3  bruna@modernizacaopublica.com.br   \n",
       "3                   na  bruna@modernizacaopublica.com.br   \n",
       "4              Batch_5                verlanio@gmail.com   \n",
       "5              Batch_6                verlanio@gmail.com   \n",
       "6   Batch_6_Atualizado                verlanio@gmail.com   \n",
       "7              Batch_7                verlanio@gmail.com   \n",
       "8              Batch_8                verlanio@gmail.com   \n",
       "9             Batch_12  bruna@modernizacaopublica.com.br   \n",
       "10            Batch_12  bruna@modernizacaopublica.com.br   \n",
       "11            Batch_13  bruna@modernizacaopublica.com.br   \n",
       "12            Batch_14  bruna@modernizacaopublica.com.br   \n",
       "13            Batch_15  bruna@modernizacaopublica.com.br   \n",
       "\n",
       "                                         Arquivos_zip  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7   ['07-2023 (1).7z', 'fwdrenotafiscal.zip', 'fwd...  \n",
       "8                                                  []  \n",
       "9                                                  []  \n",
       "10                        ['notas mage 31082023.zip']  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                                 []  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processamento = pd.read_excel(df_processamento_file_read_path) \n",
    "\n",
    "df_processamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Batch</th>\n",
       "      <th>diretorio_origem</th>\n",
       "      <th>nome_arquivo_origem</th>\n",
       "      <th>nome_arquivo_destino</th>\n",
       "      <th>data_processamento</th>\n",
       "      <th>tipo_pdf</th>\n",
       "      <th>qut_paginas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>NF 689- PMMacae- 8ª Med CO-22-22 TB Contrato 0...</td>\n",
       "      <td>nf_689__pmmacae__8a_med_co_22_22_tb_contrato_0...</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>nfse 4414.pdf</td>\n",
       "      <td>nfse_4414.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>nfse 4409.pdf</td>\n",
       "      <td>nfse_4409.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>NF 688 - ConsoR Zadar- Engetecnica (ENZA) (1).pdf</td>\n",
       "      <td>nf_688___consor_zadar__engetecnica_enza_1.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>12225 COFIM -.pdf</td>\n",
       "      <td>12225_cofim__.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>10</td>\n",
       "      <td>Batch_15</td>\n",
       "      <td>11778003</td>\n",
       "      <td>NFSe-e 23.pdf</td>\n",
       "      <td>nfse_e_23.pdf</td>\n",
       "      <td>01/09/2023 15:22:11</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>11</td>\n",
       "      <td>Batch_15</td>\n",
       "      <td>11674905</td>\n",
       "      <td>5CBB9967-367A-42EE-BCD8-A25F161906E3.PDF</td>\n",
       "      <td>5cbb9967_367a_42ee_bcd8_a25f161906e3.pdf</td>\n",
       "      <td>01/09/2023 15:22:11</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>12</td>\n",
       "      <td>Batch_15</td>\n",
       "      <td>11777556</td>\n",
       "      <td>NF 202315- SJDI 35 JUL 23.pdf</td>\n",
       "      <td>nf_202315__sjdi_35_jul_23.pdf</td>\n",
       "      <td>01/09/2023 15:22:11</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>13</td>\n",
       "      <td>Batch_15</td>\n",
       "      <td>11779053</td>\n",
       "      <td>resposta.PDF</td>\n",
       "      <td>resposta.pdf</td>\n",
       "      <td>01/09/2023 15:22:11</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>14</td>\n",
       "      <td>Batch_15</td>\n",
       "      <td>11779531</td>\n",
       "      <td>Heidelberg 21 07 2023 NOTA FISCAL.pdf</td>\n",
       "      <td>heidelberg_21_07_2023_nota_fiscal.pdf</td>\n",
       "      <td>01/09/2023 15:22:11</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     Batch     diretorio_origem  \\\n",
       "0       2  Batch_12  notas_mage_31082023   \n",
       "1       2  Batch_12  notas_mage_31082023   \n",
       "2       2  Batch_12  notas_mage_31082023   \n",
       "3       2  Batch_12  notas_mage_31082023   \n",
       "4       2  Batch_12  notas_mage_31082023   \n",
       "..    ...       ...                  ...   \n",
       "67     10  Batch_15             11778003   \n",
       "68     11  Batch_15             11674905   \n",
       "69     12  Batch_15             11777556   \n",
       "70     13  Batch_15             11779053   \n",
       "71     14  Batch_15             11779531   \n",
       "\n",
       "                                  nome_arquivo_origem  \\\n",
       "0   NF 689- PMMacae- 8ª Med CO-22-22 TB Contrato 0...   \n",
       "1                                       nfse 4414.pdf   \n",
       "2                                       nfse 4409.pdf   \n",
       "3   NF 688 - ConsoR Zadar- Engetecnica (ENZA) (1).pdf   \n",
       "4                                   12225 COFIM -.pdf   \n",
       "..                                                ...   \n",
       "67                                      NFSe-e 23.pdf   \n",
       "68           5CBB9967-367A-42EE-BCD8-A25F161906E3.PDF   \n",
       "69                      NF 202315- SJDI 35 JUL 23.pdf   \n",
       "70                                       resposta.PDF   \n",
       "71              Heidelberg 21 07 2023 NOTA FISCAL.pdf   \n",
       "\n",
       "                                 nome_arquivo_destino   data_processamento  \\\n",
       "0   nf_689__pmmacae__8a_med_co_22_22_tb_contrato_0...  01/09/2023 14:22:44   \n",
       "1                                       nfse_4414.pdf  01/09/2023 14:22:44   \n",
       "2                                       nfse_4409.pdf  01/09/2023 14:22:44   \n",
       "3       nf_688___consor_zadar__engetecnica_enza_1.pdf  01/09/2023 14:22:44   \n",
       "4                                   12225_cofim__.pdf  01/09/2023 14:22:44   \n",
       "..                                                ...                  ...   \n",
       "67                                      nfse_e_23.pdf  01/09/2023 15:22:11   \n",
       "68           5cbb9967_367a_42ee_bcd8_a25f161906e3.pdf  01/09/2023 15:22:11   \n",
       "69                      nf_202315__sjdi_35_jul_23.pdf  01/09/2023 15:22:11   \n",
       "70                                       resposta.pdf  01/09/2023 15:22:11   \n",
       "71              heidelberg_21_07_2023_nota_fiscal.pdf  01/09/2023 15:22:11   \n",
       "\n",
       "    tipo_pdf  qut_paginas  \n",
       "0      False            1  \n",
       "1       True            1  \n",
       "2       True            1  \n",
       "3      False            1  \n",
       "4       True            1  \n",
       "..       ...          ...  \n",
       "67      True            1  \n",
       "68      True            7  \n",
       "69      True            1  \n",
       "70      True            1  \n",
       "71      True            1  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracao_files = pd.read_excel(df_extracao_files_Batch_file_read_path) \n",
    "\n",
    "df_extracao_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trata dicionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. path para models\n",
    "nf_model_path = \"pipeline_extracao_documentos/6_geral_administacao/modelos/frames_nf_v9.xlsx\"\n",
    "\n",
    "# 11. path para datasets CNAE e Itens de Serviço\n",
    "nf_datasets_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "\n",
    "#Le a planilha e cria do DF\n",
    "frames_nf_v4_df = pd.read_excel(nf_model_path)\n",
    "\n",
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'section']\n",
    "frames_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v4_df[frames_nf_v4_df['type'] == 'field_box']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mage_cnae_x_item_servico_df = pd.read_excel(cnae_dict_path)\n",
    "\n",
    "# Creating a dictionary for CNAE codes and descriptions\n",
    "cnae_dict = dict(zip(mage_cnae_x_item_servico_df['cnae'], mage_cnae_x_item_servico_df['descricao_cnae']))\n",
    "item_servico_dict = dict(zip(mage_cnae_x_item_servico_df['item_servico'], mage_cnae_x_item_servico_df['descricao_item_servico']))\n",
    "\n",
    "\n",
    "    \n",
    "# 2. Leitura do arquivo CSV e criação do dicionário modelos\n",
    "def create_model_dictionary(model_dict_path):\n",
    "    model_dictionary = {}\n",
    "    with open(model_dict_path, 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            prefeitura_name = row['prefeitura']\n",
    "            model_name = row['model']\n",
    "\n",
    "            if prefeitura_name not in model_dictionary:\n",
    "                model_dictionary[prefeitura_name] = model_name\n",
    "            \n",
    "            #model_dictionary[prefeitura_name].append(model_name)\n",
    "    \n",
    "    return model_dictionary    \n",
    "    \n",
    "    frames_nf_v4_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trata e-mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_BR.utf8'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documentos_extracao_path = \"pipeline_extracao_documentos/2_documentos_para_extracao\"\n",
    "\n",
    "# 1. Caminho do arquivo uma mensagem especifica\n",
    "msg_dir_path = 'pipeline_extracao_documentos/1_emails'\n",
    "\n",
    "# 2. Path para arquivos atachados compactados\n",
    "msg_attachment_zip = 'pipeline_extracao_documentos/1_emails/attachments'\n",
    "\n",
    "# 3. Path para documentos atachados:\n",
    "documentos_extracao_path = 'pipeline_extracao_documentos/2_documentos_para_extracao'\n",
    "\n",
    "\n",
    "# definindo localizadcao para pt_BR\n",
    "locale.setlocale(locale.LC_TIME, \"pt_BR.utf8\")\n",
    "\n",
    "# Nosso timezone\n",
    "#local_tz = pytz.timezone('America/Sao_Paulo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista para armazenar as linhas\n",
    "rows_list = []\n",
    "\n",
    "# Função recursiva para adicionar linha\n",
    "def add_row_recursively(rows_list, \n",
    "                        index, \n",
    "                        Batch, \n",
    "                        diretorio_ori, \n",
    "                        arquivo_origem, \n",
    "                        arquivo_destino, \n",
    "                        data_hora, \n",
    "                        tipo_doc_pdf, \n",
    "                        qtd_paginas\n",
    "                        ):\n",
    "    if index == 0:\n",
    "        return rows_list\n",
    "    else:\n",
    "        new_row = {\n",
    "                    'index': index,\n",
    "                    'Batch': Batch,\n",
    "                    'diretorio_origem': diretorio_ori,\n",
    "                    'nome_arquivo_origem': arquivo_origem,\n",
    "                    'nome_arquivo_destino': arquivo_destino,\n",
    "                    'data_processamento': data_hora,\n",
    "                    'tipo_pdf': tipo_doc_pdf,\n",
    "                    'qut_paginas': qtd_paginas\n",
    "                    }\n",
    "        rows_list.append(new_row)\n",
    "        \n",
    "        return add_row_recursively(rows_list, index-1, Batch, diretorio_ori, arquivo_origem, arquivo_destino, data_hora, tipo_doc_pdf, qtd_paginas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Funcoes necessarias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. converte nome do arquivo\n",
    "def conv_filename(title):\n",
    "    \n",
    "    # Divide o título em nome e extensão\n",
    "    name, extension = title.rsplit('.', 1) if '.' in title else (title, \"\")\n",
    "\n",
    "    # Remove acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substiti espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remove quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converte para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    # Adiciona a extensão de volta, se houver\n",
    "    if extension:\n",
    "        filename += '.' + extension.lower()\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "\n",
    "def conv_filename_no_ext(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename \n",
    "\n",
    "\n",
    "# 3. move NF processadas ok\n",
    "def move_raster_pdf(document_path, raster_pdf_path, batch_name, doc2convert):\n",
    "    # Determine the destination directory\n",
    "    destination_dir = os.path.join(raster_pdf_path, batch_name)\n",
    "\n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Determine the destination path including the filename\n",
    "    destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "\n",
    "    # Move the file from the source path to the destination path\n",
    "    try:\n",
    "        shutil.move(document_path, destination_path)\n",
    "        print(f\"Sucesso ao mover: {document_path} para: {destination_path}\")\n",
    "        return True, destination_path, None  # Success, destination path, no error\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao mover: {document_path} para: {destination_path}: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return False, None, error_message  # Failure, no destination path, error message\n",
    "\n",
    "# 5. Verifica se PDF e pesquisavel ou nao e grava metadados dele\n",
    "def is_pdf_searchable_analise(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        pages = pdf_document.page_count\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        dados_pdf = pdf_document.metadata\n",
    "        pdf_document.close()\n",
    "        return is_searchable, dados_pdf, pages\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Lendo o email e anexos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "email: Nota mesquita.msg, email_path: pipeline_extracao_documentos/1_emails/Nota mesquita.msg\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(msg_dir_path):\n",
    "    #print(f'{root}  | {dirs} | {document} | {files}\\n')\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        if file.lower().endswith('.msg'):\n",
    "            email_message = file\n",
    "            email_path = os.path.join(root, file)\n",
    "            print(f'email: {email_message}, email_path: {email_path}')\n",
    "            \n",
    "            \n",
    "msg = extract_msg.Message(email_path)\n",
    "\n",
    "msg_raw_sender = msg.sender\n",
    "\n",
    "parts = msg_raw_sender.rsplit('<', 1)\n",
    "\n",
    "msg_email_address = parts[1].strip('<>')\n",
    "\n",
    "msg_sender = parts[0].strip(' ')\n",
    "\n",
    "msg_subject = msg.subject\n",
    "\n",
    "\n",
    "msg_body = msg.body\n",
    "\n",
    "# Defina a localização para pt_BR\n",
    "locale.setlocale(locale.LC_TIME, \"pt_BR.utf8\")\n",
    "\n",
    "# String original\n",
    "original_date_str = msg.date\n",
    "\n",
    "date_email = cron.convert_email_date(original_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_email = cron.convert_email_date(original_date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo anexos e gravando em attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "pipeline_extracao_documentos/1_emails/attachments/MESQUITA_PDF_31282023_2258.zip\n"
     ]
    }
   ],
   "source": [
    "# Caminho da pasta onde você quer salvar os anexos\n",
    "pasta_destino = msg_attachment_zip\n",
    "\n",
    "# Verifica se a pasta existe; se não, cria ela\n",
    "if not os.path.exists(pasta_destino):\n",
    "    os.makedirs(pasta_destino)\n",
    "\n",
    "with open(email_path) as msg_file:\n",
    "    msg = Message(msg_file)\n",
    "\n",
    "# Contents are the plaintext body of the email\n",
    "#contents = msg.body\n",
    "\n",
    "\n",
    "total_attch = len(msg.attachments)\n",
    "\n",
    "print(total_attch)\n",
    "\n",
    "arquivos_zip = []\n",
    "arquivos = []\n",
    "i = 0\n",
    "# Loop para salvar cada anexo\n",
    "for i in range(total_attch):\n",
    "    attachment = msg.attachments[i]\n",
    "    caminho_completo_anexo = os.path.join(pasta_destino, attachment.filename)\n",
    "    if file.lower().endswith('.zip') or file.lower().endswith('.rar') or file.lower().endswith('.7z'):\n",
    "        arquivos_zip.append(attachment.filename)\n",
    "    else:\n",
    "        arquivos.append(attachment.filename)\n",
    "      \n",
    "    print(caminho_completo_anexo)\n",
    "    with attachment.open() as attachment_fp, open(caminho_completo_anexo, 'wb') as output_fp:\n",
    "        output_fp.write(attachment_fp.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 Salvando os attachments do e-mail </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> Extraindo documentos do ZIP </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório onde você quer salvar os arquivos extraídos\n",
    "output_dir = os.path.join(documentos_extracao_path, batch_name)\n",
    "\n",
    "folder_file_dict = {}\n",
    "\n",
    "for root, dirs, files in os.walk(msg_attachment_zip):\n",
    "    #print(f'{root}  | {dirs} | {document} | {files}\\n')\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        if file.lower().endswith('.zip'):\n",
    "            zip_file = file\n",
    "            zip_file_path = os.path.join(root, file)\n",
    "            # Obtém o nome base do arquivo ZIP para usar como subdiretório\n",
    "            zip_base_name = os.path.splitext(os.path.basename(zip_file_path))[0]\n",
    "            zip_basename = conv_filename(zip_base_name)\n",
    "            \n",
    "            # Cria o subdiretório com base no nome do arquivo ZIP\n",
    "            root_output_dir = os.path.join(output_dir, zip_basename)\n",
    "            \n",
    "            if not os.path.exists(root_output_dir):\n",
    "                os.makedirs(root_output_dir) # estou criando o diretorio caso nao exista\n",
    "\n",
    "            # Abre o arquivo ZIP\n",
    "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "                for member in zip_ref.namelist():\n",
    "                    # Separa o nome da pasta e o nome do arquivo usando barra invertida como delimitador\n",
    "                    parts = member.rsplit('\\\\', 1)\n",
    "                    folder_name = parts[0] if len(parts) > 1 else ''\n",
    "                    #folder_name = conv_filename(folder_temp)\n",
    "                    filename = parts[-1]\n",
    "                    if filename:  # ignora diretórios\n",
    "                        # Adiciona ao dicionário\n",
    "                        #filename = conv_filename(filename)\n",
    "                        # Cria um subdiretório se ele não existir\n",
    "                        sub_dir = os.path.join(root_output_dir, folder_name)\n",
    "                        if not os.path.exists(sub_dir):\n",
    "                            os.makedirs(sub_dir)\n",
    "\n",
    "                        # Salva o arquivo no subdiretório especificado\n",
    "                        source = zip_ref.open(member)\n",
    "                        target_path = os.path.join(sub_dir, filename)\n",
    "                        \n",
    "                        with open(target_path, \"wb\") as target:\n",
    "                            target.write(source.read())\n",
    "                            dir_path = os.path.dirname(filename)\n",
    "                            \n",
    "        elif file.lower().endswith('.rar'):\n",
    "            rar_file = file\n",
    "            rar_file = conv_filename_no_ext(rar_file)\n",
    "            rar_file_path = os.path.join(root, file) \n",
    "            root_output_dir = os.path.join(output_dir, rar_file)\n",
    "            if not os.path.exists(root_output_dir):\n",
    "                os.makedirs(root_output_dir)\n",
    "            Archive(rar_file_path).extractall(root_output_dir)  \n",
    "            \n",
    "        elif file.lower().endswith('.7z'):\n",
    "            sevenz_file = file\n",
    "            sevenz_file = conv_filename_no_ext(sevenz_file)\n",
    "            sevenz_file_path = os.path.join(root, file)\n",
    "            root_output_dir = os.path.join(output_dir, sevenz_file)                      \n",
    "                            \n",
    "            with py7zr.SevenZipFile(sevenz_file_path, mode='r') as z:\n",
    "                z.extractall(root_output_dir)\n",
    "                \n",
    "        elif file.lower().endswith('.pdf'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            new_path_name = os.path.join(output_dir, file)\n",
    "            if not os.path.exists(output_dir):\n",
    "                            os.makedirs(output_dir)\n",
    "            shutil.move(file_path, new_path_name)\n",
    "            \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ajustando o filename e criando o dicionario\n",
    "folder_file_dict = {}\n",
    "rows_list = []\n",
    "output_dir = os.path.join(documentos_extracao_path, batch_name)\n",
    "i = 0\n",
    "for root, dirs, files in os.walk(\"pipeline_extracao_documentos/2_documentos_para_extracao\"):\n",
    "    folder_name = os.path.basename(root)\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        pesquisavel, metadados, paginas = is_pdf_searchable_analise(file_path)\n",
    "\n",
    "        new_name = conv_filename(file)\n",
    "        new_path_name = os.path.join(root, new_name)\n",
    "        #print(f'\\nfile: {file} | new_name: {new_name} ')\n",
    "        shutil.move(file_path, new_path_name)\n",
    "        folder_file_dict.setdefault(folder_name, []).append(new_name)\n",
    "        time_now = cron.timenow_pt_BR()\n",
    "        new_row = {\n",
    "                    'index': i,\n",
    "                    'Batch': batch_name,\n",
    "                    'diretorio_origem': folder_name,\n",
    "                    'nome_arquivo_origem': file,\n",
    "                    'nome_arquivo_destino': new_name,\n",
    "                    'data_processamento': time_now,\n",
    "                    'tipo_pdf': pesquisavel,\n",
    "                    'qut_paginas': paginas\n",
    "                    }\n",
    "        rows_list.append(new_row)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9286/2817542823.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_extracao_files = df_extracao_files.append(df_files, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Anexando o novo DataFrame ao original\n",
    "df_extracao_files = df_extracao_files.append(df_files, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Batch</th>\n",
       "      <th>diretorio_origem</th>\n",
       "      <th>nome_arquivo_origem</th>\n",
       "      <th>nome_arquivo_destino</th>\n",
       "      <th>data_processamento</th>\n",
       "      <th>tipo_pdf</th>\n",
       "      <th>qut_paginas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>NF 689- PMMacae- 8ª Med CO-22-22 TB Contrato 0...</td>\n",
       "      <td>nf_689__pmmacae__8a_med_co_22_22_tb_contrato_0...</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>nfse 4414.pdf</td>\n",
       "      <td>nfse_4414.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>nfse 4409.pdf</td>\n",
       "      <td>nfse_4409.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>NF 688 - ConsoR Zadar- Engetecnica (ENZA) (1).pdf</td>\n",
       "      <td>nf_688___consor_zadar__engetecnica_enza_1.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>notas_mage_31082023</td>\n",
       "      <td>12225 COFIM -.pdf</td>\n",
       "      <td>12225_cofim__.pdf</td>\n",
       "      <td>01/09/2023 14:22:44</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4</td>\n",
       "      <td>Batch_16</td>\n",
       "      <td>159871</td>\n",
       "      <td>2023 -8.pdf</td>\n",
       "      <td>2023__8.pdf</td>\n",
       "      <td>01/09/2023 15:28:23</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5</td>\n",
       "      <td>Batch_16</td>\n",
       "      <td>160014</td>\n",
       "      <td>31-07.pdf</td>\n",
       "      <td>31_07.pdf</td>\n",
       "      <td>01/09/2023 15:28:23</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5</td>\n",
       "      <td>Batch_16</td>\n",
       "      <td>160014</td>\n",
       "      <td>ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...</td>\n",
       "      <td>acfrogblgyewspqaweud3qjkpdqn5kp2dfiynq7d6wjcry...</td>\n",
       "      <td>01/09/2023 15:28:23</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>6</td>\n",
       "      <td>Batch_16</td>\n",
       "      <td>126623</td>\n",
       "      <td>41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF</td>\n",
       "      <td>41c46d8f_73ab_4906_a4c6_c7dc92c05828.pdf</td>\n",
       "      <td>01/09/2023 15:28:23</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>7</td>\n",
       "      <td>Batch_16</td>\n",
       "      <td>138565</td>\n",
       "      <td>B4066C58-F309-42E4-A992-55EB8961211E.PDF</td>\n",
       "      <td>b4066c58_f309_42e4_a992_55eb8961211e.pdf</td>\n",
       "      <td>01/09/2023 15:28:23</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     Batch     diretorio_origem  \\\n",
       "0       2  Batch_12  notas_mage_31082023   \n",
       "1       2  Batch_12  notas_mage_31082023   \n",
       "2       2  Batch_12  notas_mage_31082023   \n",
       "3       2  Batch_12  notas_mage_31082023   \n",
       "4       2  Batch_12  notas_mage_31082023   \n",
       "..    ...       ...                  ...   \n",
       "78      4  Batch_16               159871   \n",
       "79      5  Batch_16               160014   \n",
       "80      5  Batch_16               160014   \n",
       "81      6  Batch_16               126623   \n",
       "82      7  Batch_16               138565   \n",
       "\n",
       "                                  nome_arquivo_origem  \\\n",
       "0   NF 689- PMMacae- 8ª Med CO-22-22 TB Contrato 0...   \n",
       "1                                       nfse 4414.pdf   \n",
       "2                                       nfse 4409.pdf   \n",
       "3   NF 688 - ConsoR Zadar- Engetecnica (ENZA) (1).pdf   \n",
       "4                                   12225 COFIM -.pdf   \n",
       "..                                                ...   \n",
       "78                                        2023 -8.pdf   \n",
       "79                                          31-07.pdf   \n",
       "80  ACFrOgBLgYewSPQAweUd3QJkpDqN5Kp2dFIyNq7d6wJCRY...   \n",
       "81           41C46D8F-73AB-4906-A4C6-C7DC92C05828.PDF   \n",
       "82           B4066C58-F309-42E4-A992-55EB8961211E.PDF   \n",
       "\n",
       "                                 nome_arquivo_destino   data_processamento  \\\n",
       "0   nf_689__pmmacae__8a_med_co_22_22_tb_contrato_0...  01/09/2023 14:22:44   \n",
       "1                                       nfse_4414.pdf  01/09/2023 14:22:44   \n",
       "2                                       nfse_4409.pdf  01/09/2023 14:22:44   \n",
       "3       nf_688___consor_zadar__engetecnica_enza_1.pdf  01/09/2023 14:22:44   \n",
       "4                                   12225_cofim__.pdf  01/09/2023 14:22:44   \n",
       "..                                                ...                  ...   \n",
       "78                                        2023__8.pdf  01/09/2023 15:28:23   \n",
       "79                                          31_07.pdf  01/09/2023 15:28:23   \n",
       "80  acfrogblgyewspqaweud3qjkpdqn5kp2dfiynq7d6wjcry...  01/09/2023 15:28:23   \n",
       "81           41c46d8f_73ab_4906_a4c6_c7dc92c05828.pdf  01/09/2023 15:28:23   \n",
       "82           b4066c58_f309_42e4_a992_55eb8961211e.pdf  01/09/2023 15:28:23   \n",
       "\n",
       "    tipo_pdf  qut_paginas  \n",
       "0      False            1  \n",
       "1       True            1  \n",
       "2       True            1  \n",
       "3      False            1  \n",
       "4       True            1  \n",
       "..       ...          ...  \n",
       "78      True            1  \n",
       "79      True            1  \n",
       "80      True            1  \n",
       "81      True            1  \n",
       "82      True            1  \n",
       "\n",
       "[83 rows x 8 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracao_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'115964': ['livro_de_registro_do_issqn.pdf'],\n",
       " '159871': ['2023__5.pdf',\n",
       "  '2023__7.pdf',\n",
       "  '2023__4.pdf',\n",
       "  '2023__6.pdf',\n",
       "  '2023__3.pdf',\n",
       "  '2023__8.pdf'],\n",
       " '160014': ['31_07.pdf',\n",
       "  'acfrogblgyewspqaweud3qjkpdqn5kp2dfiynq7d6wjcrymgxkby0xaq7m2xyrrh8asjkxsfk1z9f4bsqat1di5gppkc3ahrhnhavaawbjuamkpiluuxpydd2ovrxzk.pdf'],\n",
       " '126623': ['41c46d8f_73ab_4906_a4c6_c7dc92c05828.pdf'],\n",
       " '138565': ['b4066c58_f309_42e4_a992_55eb8961211e.pdf']}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_file_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dicionarios e Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho de folder_names: 5\n",
      "Tamanho de file_counts: 5\n",
      "Tamanho de file_names: 5\n"
     ]
    }
   ],
   "source": [
    "folder_names = []\n",
    "file_counts = []\n",
    "file_names = []\n",
    "\n",
    "# Iterar sobre o dicionário para coletar informações\n",
    "for folder, files in folder_file_dict.items():\n",
    "    folder_names.append(folder)\n",
    "    file_counts.append(len(files))\n",
    "    file_names.append(files)\n",
    "    \n",
    "    \n",
    "# Suponha que folder_file_dict é algo como {'pasta1': 'arquivo1.pdf', 'pasta2': 'arquivo2.pdf'}\n",
    "folder_names = list(folder_file_dict.keys())\n",
    "file_names = list(folder_file_dict.values())    \n",
    "\n",
    "\n",
    "print(\"Tamanho de folder_names:\", len(folder_names))\n",
    "print(\"Tamanho de file_counts:\", len(file_counts))\n",
    "print(\"Tamanho de file_names:\", len(file_names))\n",
    "# ... e assim por diante para as demais variáveis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nome dos arquivos para salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tratando nome de carga do df_processamento\n",
    "dataset_path = \"pipeline_extracao_documentos/6_geral_administacao/datasets\"\n",
    "\n",
    "df_processamento_file = \"df_processamento_\"\n",
    "\n",
    "df_processamento_file_write = df_processamento_file + str(i_test) + \".xlsx\"\n",
    "\n",
    "# 2. Tratando nome de carga do df_extracao_files_Batch\n",
    "df_extracao_files_Batch_file = \"df_extracao_files_Batch_\"\n",
    "\n",
    "df_extracao_files_Batch_file_write = df_extracao_files_Batch_file + str(i_test) + \".xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 2, 1, 1]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {} \n",
    "# Criar o DataFrame do batch\n",
    "df_batch = pd.DataFrame({\n",
    "    \"Dt_hora\": [date_email],\n",
    "    \"Assunto\": [msg_subject],\n",
    "    \"Arquivos_zip\": [arquivos_zip],\n",
    "    \"Quantidade de Documentos\": [file_counts],\n",
    "    \"De\": [msg_sender],\n",
    "    \"batch\": [batch_name],\n",
    "    \"email\": [msg_email_address],\n",
    "\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9286/1808731608.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_processamento = df_processamento.append(df_batch, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Anexando o novo DataFrame ao original\n",
    "df_processamento = df_processamento.append(df_batch, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dt_hora</th>\n",
       "      <th>Assunto</th>\n",
       "      <th>Quantidade de Documentos</th>\n",
       "      <th>De</th>\n",
       "      <th>batch</th>\n",
       "      <th>email</th>\n",
       "      <th>Arquivos_zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/08/2023 16:11:50</td>\n",
       "      <td>Notas Magé</td>\n",
       "      <td>[115]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_1</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17/08/2023 15:49:21</td>\n",
       "      <td>Notas Sao Pedro da Aldeia</td>\n",
       "      <td>[28]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_2</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/08/2023 11:56:51</td>\n",
       "      <td>Notas São Pedro da Aldeia</td>\n",
       "      <td>[10]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_3</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/08/2023 12:01:16</td>\n",
       "      <td>Notas Mesquita</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>na</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/08/2023 11:25:42</td>\n",
       "      <td>Fwd: Notas Magé</td>\n",
       "      <td>[9]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_5</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-10-08 23:20:56</td>\n",
       "      <td>Fwd: Notas Magé 2</td>\n",
       "      <td>[11]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_6</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10/08/2023 23:20:56</td>\n",
       "      <td>Fwd: Notas Magé 2</td>\n",
       "      <td>[75]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_6_Atualizado</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10/08/2023 17:54:14</td>\n",
       "      <td>Fwd: Notas Magé 1</td>\n",
       "      <td>[21, 8, 18, 3]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_7</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>['07-2023 (1).7z', 'fwdrenotafiscal.zip', 'fwd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12/08/2023 11:25:42</td>\n",
       "      <td>Fwd: Notas Magé</td>\n",
       "      <td>[9]</td>\n",
       "      <td>Verlânio Gallindo</td>\n",
       "      <td>Batch_8</td>\n",
       "      <td>verlanio@gmail.com</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31/08/2023 22:27:59</td>\n",
       "      <td>Notas Magé</td>\n",
       "      <td>[2, 17]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31/08/2023 22:27:59</td>\n",
       "      <td>Notas Magé</td>\n",
       "      <td>[17]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_12</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>['notas mage 31082023.zip']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31/08/2023 22:31:10</td>\n",
       "      <td>Nota SPA</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_13</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31/08/2023 23:00:27</td>\n",
       "      <td>Notas Magé 2</td>\n",
       "      <td>[3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, ...</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_14</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31/08/2023 23:00:54</td>\n",
       "      <td>Notas SPA 2</td>\n",
       "      <td>[1, 1, 1, 3, 2, 1, 8, 2, 1, 1, 1, 1]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_15</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31/08/2023 23:01:14</td>\n",
       "      <td>Nota mesquita</td>\n",
       "      <td>[1, 6, 2, 1, 1]</td>\n",
       "      <td>Bruna Maciel Adame</td>\n",
       "      <td>Batch_16</td>\n",
       "      <td>bruna@modernizacaopublica.com.br</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dt_hora                    Assunto  \\\n",
       "0   17/08/2023 16:11:50                 Notas Magé   \n",
       "1   17/08/2023 15:49:21  Notas Sao Pedro da Aldeia   \n",
       "2   17/08/2023 11:56:51  Notas São Pedro da Aldeia   \n",
       "3   17/08/2023 12:01:16             Notas Mesquita   \n",
       "4   12/08/2023 11:25:42            Fwd: Notas Magé   \n",
       "5   2023-10-08 23:20:56          Fwd: Notas Magé 2   \n",
       "6   10/08/2023 23:20:56          Fwd: Notas Magé 2   \n",
       "7   10/08/2023 17:54:14          Fwd: Notas Magé 1   \n",
       "8   12/08/2023 11:25:42            Fwd: Notas Magé   \n",
       "9   31/08/2023 22:27:59                 Notas Magé   \n",
       "10  31/08/2023 22:27:59                 Notas Magé   \n",
       "11  31/08/2023 22:31:10                   Nota SPA   \n",
       "12  31/08/2023 23:00:27               Notas Magé 2   \n",
       "13  31/08/2023 23:00:54                Notas SPA 2   \n",
       "14  31/08/2023 23:01:14              Nota mesquita   \n",
       "\n",
       "                             Quantidade de Documentos                  De  \\\n",
       "0                                               [115]  Bruna Maciel Adame   \n",
       "1                                                [28]  Bruna Maciel Adame   \n",
       "2                                                [10]  Bruna Maciel Adame   \n",
       "3                                                 [2]  Bruna Maciel Adame   \n",
       "4                                                 [9]   Verlânio Gallindo   \n",
       "5                                                [11]   Verlânio Gallindo   \n",
       "6                                                [75]   Verlânio Gallindo   \n",
       "7                                      [21, 8, 18, 3]   Verlânio Gallindo   \n",
       "8                                                 [9]   Verlânio Gallindo   \n",
       "9                                             [2, 17]  Bruna Maciel Adame   \n",
       "10                                               [17]  Bruna Maciel Adame   \n",
       "11                                                [1]  Bruna Maciel Adame   \n",
       "12  [3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, ...  Bruna Maciel Adame   \n",
       "13               [1, 1, 1, 3, 2, 1, 8, 2, 1, 1, 1, 1]  Bruna Maciel Adame   \n",
       "14                                    [1, 6, 2, 1, 1]  Bruna Maciel Adame   \n",
       "\n",
       "                 batch                             email  \\\n",
       "0              Batch_1  bruna@modernizacaopublica.com.br   \n",
       "1              Batch_2  bruna@modernizacaopublica.com.br   \n",
       "2              Batch_3  bruna@modernizacaopublica.com.br   \n",
       "3                   na  bruna@modernizacaopublica.com.br   \n",
       "4              Batch_5                verlanio@gmail.com   \n",
       "5              Batch_6                verlanio@gmail.com   \n",
       "6   Batch_6_Atualizado                verlanio@gmail.com   \n",
       "7              Batch_7                verlanio@gmail.com   \n",
       "8              Batch_8                verlanio@gmail.com   \n",
       "9             Batch_12  bruna@modernizacaopublica.com.br   \n",
       "10            Batch_12  bruna@modernizacaopublica.com.br   \n",
       "11            Batch_13  bruna@modernizacaopublica.com.br   \n",
       "12            Batch_14  bruna@modernizacaopublica.com.br   \n",
       "13            Batch_15  bruna@modernizacaopublica.com.br   \n",
       "14            Batch_16  bruna@modernizacaopublica.com.br   \n",
       "\n",
       "                                         Arquivos_zip  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7   ['07-2023 (1).7z', 'fwdrenotafiscal.zip', 'fwd...  \n",
       "8                                                  []  \n",
       "9                                                  []  \n",
       "10                        ['notas mage 31082023.zip']  \n",
       "11                                                 []  \n",
       "12                                                 []  \n",
       "13                                                 []  \n",
       "14                                                 []  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processamento_file_write_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pipeline_extracao_documentos/6_geral_administacao/datasets/df_processamento_16.xlsx'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processamento_file_write_path = os.path.join(dataset_path, df_processamento_file_write)\n",
    "\n",
    "df_processamento_file_write_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pipeline_extracao_documentos/6_geral_administacao/datasets/df_extracao_files_Batch_16.xlsx'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracao_files_Batch_file_write_path = os.path.join(dataset_path, df_extracao_files_Batch_file_write)\n",
    "\n",
    "df_extracao_files_Batch_file_write_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o DF para excel\n",
    "df_extracao_files.to_excel(df_extracao_files_Batch_file_write_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o DF para excel\n",
    "df_processamento.to_excel(df_processamento_file_write_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funcoes modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Funcao de conversao e resize do documento\n",
    "def convertResize(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "def convertResizeAnalise_1page(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    resized_pages = []\n",
    "    for page in pages:\n",
    "        resized_page = page.resize((2067, 2923))\n",
    "        resized_pages.append(resized_page)\n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "# Funcao de conversao e resize do documento\n",
    "def convertResize_analise(nome_documento, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(nome_documento)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "\n",
    "\n",
    "# Trata Ocr\n",
    "def extract_fields_box(modelo, father_value, section):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        #print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference'], row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1'] ))\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        if row_field['t_value'] == 'number':\n",
    "            # Formate o valor usando a função format_number\n",
    "            #print(\"vou verificar valor\")\n",
    "            value = format_number2(value)\n",
    "            #print(value)\n",
    "        # Armazene o texto extraído com o rótulo correspondente\n",
    "        label = row_field['label']\n",
    "        data_box_valores[label] = value\n",
    "        \n",
    "    return data_box_valores\n",
    "\n",
    "\n",
    "# 3. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF(image_name):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "\n",
    "# 2. Efetua OCR no documento (area parao do texto da NF)\n",
    "def ocr_RasterPDF_free(image_name, vx0, vy0, vx1, vy1):\n",
    "    \n",
    "    analise_pesquisa_nf = {}\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = vx0\n",
    "    y0 = vy0\n",
    "    x1= vx1\n",
    "    y1 = vy1\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "    return values, extracted_text_frame \n",
    "\n",
    "\n",
    "# 2. Pesquisa prefeitura no documento\n",
    "def pequisaModel(image_name):\n",
    "\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1) \n",
    "            return  nome_prefeitura        \n",
    "     \n",
    "\n",
    "# 1. Interacao para pesquisar prefeitura\n",
    "def pesquisa_texto(texto):\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', texto)\n",
    "    if nome_prefeitura_match:\n",
    "        is_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        \n",
    "        return  is_prefeitura\n",
    "    else:\n",
    "        raise ValueError(\"Nao consegui pesquisar\")\n",
    "    \n",
    "    \n",
    "    # 5. Verifica se PDF e pesquisavel ou nao e grava metadados dele\n",
    "def is_pdf_searchable_analise(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        pages = pdf_document.page_count\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        dados_pdf = pdf_document.metadata\n",
    "        pdf_document.close()\n",
    "        return is_searchable, dados_pdf, pages\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "    \n",
    "    \n",
    "# 2. Extracao OCR\n",
    "def extract_text_from_coordinates(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "# 1. funçao basica de modelo \n",
    "def executa_model_frame(model, secao, father_name):\n",
    "\n",
    "    data_dados_frame = {}\n",
    "    \n",
    "    tipo = \"frame\"\n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model) & (frames_nf_v4_df['label'] == f_frame_name) & (frames_nf_v4_df['type'] == tipo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_nf_v4_df.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_frame = extract_text_from_coordinates(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        frame_seq = row_frame['seq']\n",
    "        frame_model = row_frame['model']\n",
    "        frame_label = row_frame['label']\n",
    "        frame_type = row_frame['type']\n",
    "        frame_section = row_frame['section_json']\n",
    "        frame_reference = row_frame['reference']\n",
    "        frame_father = row_frame['father']\n",
    "        frame_id = row_frame['id']\n",
    "        #print(f'\\fid: {frame_id:>3} | seq: {frame_seq:>3} | model: {frame_model:>8} | type: {frame_type:>15} | Father: {frame_father} label: {frame_label:>30} | section: {frame_section:>20} {frame_reference:>30}')\n",
    "        \n",
    "    return extracted_text_frame\n",
    "\n",
    "\n",
    "\n",
    "# Sao iguais \n",
    "def extract_text_from_frame(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text \n",
    "\n",
    "\n",
    "\n",
    "# Trata files\n",
    "# 3. Ajusta o filename tirando caracteres especiais \n",
    "def conv_filename(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão\n",
    "    name, extension = title.rsplit('.', 1) if '.' in title else (title, \"\")\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    # Adicione a extensão de volta, se houver\n",
    "    if extension:\n",
    "        filename += '.' + extension.lower()\n",
    "\n",
    "    return filename\n",
    "\n",
    "# 4. Ajusta o filename tirando caracteres especiais e a\n",
    "def conv_filename_no_ext(title):\n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename  \n",
    "\n",
    "\n",
    "# move NF processadas ok\n",
    "def move_raster_pdf(document_path, raster_pdf_path, batch_name, doc2convert):\n",
    "    # Determine the destination directory\n",
    "    destination_dir = os.path.join(raster_pdf_path, batch_name)\n",
    "\n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Determine the destination path including the filename\n",
    "    destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "\n",
    "    # Move the file from the source path to the destination path\n",
    "    try:\n",
    "        shutil.move(document_path, destination_path)\n",
    "        print(f\"Sucesso ao mover: {document_path} para: {destination_path}\")\n",
    "        return True, destination_path, None  # Success, destination path, no error\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao mover: {document_path} para: {destination_path}: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return False, None, error_message  # Failure, no destination path, error message  \n",
    "    \n",
    "    \n",
    "    # Trata texto extraido\n",
    "    # Função para extrair número da string\n",
    "def extract_number(text):\n",
    "    match = re.search(r'\\b\\d+(\\.\\d+)?\\b', text)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "# Funcao importante - process_line\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "\n",
    "def format_number(number_str):\n",
    "    # Check for percentage and handle it\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # You can multiply by 100 here if needed\n",
    "\n",
    "    # Check if the string contains \"R$\" or a comma, indicating the original format\n",
    "    if 'R$' in number_str or ',' in number_str:\n",
    "        # Original format: Remove 'R$', replace dots with nothing, and replace commas with dots\n",
    "        number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    else:\n",
    "        # New format: Extract only the numeric part using regex\n",
    "        number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)\n",
    "\n",
    "# Funçao de formatacao de numeros\n",
    "def format_number2(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)\n",
    "\n",
    "\n",
    "\n",
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited\n",
    "\n",
    "\n",
    "#1. funcao: find_value_after_keyword_out_frame_up\n",
    "def find_value_after_keyword_out_frame_up(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "        if text_list[index + 1] not in default_keyword_list:\n",
    "            return text_list[index + 1]\n",
    "        else:\n",
    "            return None\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            for default_keyword in default_keyword_list:\n",
    "                if default_keyword in text_list:\n",
    "                    # Caso especial para 'Nome/Razão Social:'\n",
    "                    if keyword == 'Nome/Razão Social:':\n",
    "                        return text_list[0]\n",
    "        return None\n",
    "    \n",
    "#2. find_value_after_keyword_out_frame_down  \n",
    "def find_value_after_keyword_out_frame_down(keyword, text_list, default_keyword_list=None):\n",
    "    try:\n",
    "        index = text_list.index(keyword)\n",
    "        # Verifica se o índice seguinte está dentro da lista\n",
    "        if index + 1 < len(text_list):\n",
    "            # Verifica se o valor seguinte não é outra keyword da lista default_keyword_list\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    except ValueError:\n",
    "        if default_keyword_list:\n",
    "            try:\n",
    "                index = text_list.index(default_keyword_list[-1])\n",
    "                return text_list[index - 1]\n",
    "            except ValueError:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "#3. find_value_after_keyword_fuzz\n",
    "def find_value_after_keyword_fuzz(keyword, text_list, default_keyword_list=None, fuzziness_threshold=80):\n",
    "    closest_match = None\n",
    "    closest_match_score = 0\n",
    "    \n",
    "    for i, text in enumerate(text_list):\n",
    "        score = fuzz.ratio(keyword, text)\n",
    "        \n",
    "        if score > closest_match_score:\n",
    "            closest_match_score = score\n",
    "            closest_match = text\n",
    "        \n",
    "        if closest_match_score > fuzziness_threshold:\n",
    "            break\n",
    "\n",
    "    if closest_match_score > fuzziness_threshold:\n",
    "        index = text_list.index(closest_match)\n",
    "        if index + 1 < len(text_list):\n",
    "            if text_list[index + 1] not in default_keyword_list:\n",
    "                return text_list[index + 1]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return None  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def pesquisa_keyword(string_pesquisa, text_splited, keyword_list):\n",
    "\n",
    "    resultado_extraido_fuzz = find_value_after_keyword_fuzz(string_pesquisa, text_splited, keyword_list)\n",
    "\n",
    "    if resultado_extraido_fuzz == None:\n",
    "        resultado_extraido_frame_up = find_value_after_keyword_out_frame_up(string_pesquisa, text_splited, keyword_list)\n",
    "        if resultado_extraido_frame_up == None:\n",
    "            resultado_extraido_frame_down = find_value_after_keyword_out_frame_down(string_pesquisa, text_splited, keyword_list)\n",
    "            resultado_extraido = resultado_extraido_frame_down\n",
    "        else:\n",
    "            resultado_extraido = resultado_extraido_frame_up\n",
    "    else:\n",
    "        resultado_extraido = resultado_extraido_fuzz           \n",
    "    #print(resultado_extraido)\n",
    "    return resultado_extraido\n",
    "\n",
    "\n",
    "def cabecalho_prefeitura():\n",
    "    valor_dict = {}\n",
    "    dados_prefeitura = {}\n",
    "    f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "    # 1. funçao basica de modelo \n",
    "    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "    text_splited = texto.split('\\n')\n",
    "    \n",
    "    valor_dict = extract_prefeitura(model, f_frame_name, text_splited)\n",
    "    if valor_dict:\n",
    "        dados_prefeitura.update(valor_dict)\n",
    "        \n",
    "        \n",
    "    return dados_prefeitura \n",
    "                \n",
    "def cabecalho_dados():\n",
    "\n",
    "    valor = {}   \n",
    "    f_frame_name = \"1_frame_dados_nf\"\n",
    "    \n",
    "    dadinho_dados_nf = {}\n",
    "    \n",
    "    # 1. funçao basica de modelo \n",
    "    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "    text_splited = texto_extraido(texto)\n",
    "    keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "\n",
    "    string_pesquisa = \"Número da Nota:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)         \n",
    "    dadinho_dados_nf['numero_nota_fiscal'] = texto\n",
    "\n",
    "\n",
    "    string_pesquisa = \"Competência:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "    dadinho_dados_nf['competencia'] = texto\n",
    "    \n",
    "    \n",
    "    string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "    dadinho_dados_nf['dt_hr_emissao'] = texto\n",
    "    \n",
    "    \n",
    "    string_pesquisa = \"Código Verificação:\"\n",
    "    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "    dadinho_dados_nf['codigo_verificacao'] = texto\n",
    "    \n",
    "    return dadinho_dados_nf   \n",
    "\n",
    "\n",
    "def extract_fields_prestador_cnpj(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    \n",
    "    \n",
    "    nf_data_prestador_cnpj = {}\n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador_cnpj['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador_cnpj['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "\n",
    "    # Extrair Telefone\n",
    "    telefone_str = None\n",
    "    \n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador_cnpj['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador_cnpj['telefone'] = None   \n",
    "    \n",
    "    \n",
    "    return nf_data_prestador_cnpj \n",
    "\n",
    "\n",
    "def extract_fields_tomador_cnpj(text):\n",
    "    nf_data_tomador_cnpj = {}\n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador_cnpj['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador_cnpj['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador_cnpj['telefone'] = None  # Valor padrão quando não há correspondência\n",
    "        elif telefone_str == '':\n",
    "            nf_data_tomador_cnpj['telefone'] = None  # Valor padrão quando não há correspondência\n",
    "                    \n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['telefone'] = telefone_match.group(1)\n",
    "            \n",
    "    \n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        inscricao_municipal_str = inscricao_municipal_match.group(1)\n",
    "        if inscricao_municipal_str == \"Telefone:\": \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = inscricao_municipal_str\n",
    "    \n",
    "    insc_municipal_match = re.search(r'INSC:MUNICIPAL:\\s+(.+)', text)\n",
    "    if insc_municipal_match:\n",
    "        insc_municipal_str = insc_municipal_match.group(1)\n",
    "        if insc_municipal_str == \"Telefone:\":\n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = insc_municipal_str\n",
    "    else:\n",
    "        nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "            \n",
    "    \n",
    "    return nf_data_tomador_cnpj \n",
    "\n",
    "def texto_extraido(texto):\n",
    "    #0. Tratamento da string\n",
    "    text_splited = texto.split('\\n')\n",
    "    text_splited = [s.replace(\":\", \"\") for s in text_splited]\n",
    "    text_splited = [x for x in text_splited if x.strip()]\n",
    "    text_splited = [s.replace(\";\", \"\").strip() for s in text_splited] #depende da situaçao\n",
    "    return text_splited\n",
    "\n",
    "\n",
    "def extract_dados_comple_obs(modelo, frame_father, section):\n",
    "    \n",
    "    data_dados_complementares = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_frame['seq'], row_frame['model'], row_frame['father'], row_frame['label'], row_frame['reference'], row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'] ))\n",
    "        for index_field, row_field in filtered_sframe_fields_info.iterrows():\n",
    "            #print(\"{:<5} {:<10} {:<30} {:<20} {:<20}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference']))\n",
    "            \n",
    "            if frame_father == \"5_frame_dados_complementares\":\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['section'] = section\n",
    "                \n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', extracted_text_box, count=1)\n",
    "                if text == '':\n",
    "                    text = None\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                    \n",
    "                return nf_data_dados_complementares                \n",
    "                \n",
    "            elif frame_father == \"5_frame_observacao\":\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['section'] = section \n",
    "                                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', extracted_text_box, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                return nf_data_observacao \n",
    "            \n",
    "            \n",
    "secao = \"1 - CABECALHO\"\n",
    "f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "\n",
    "\n",
    "#4. Extrai prefeitura\n",
    "def extract_prefeitura(model, father, values):\n",
    "    \n",
    "    tipo = \"sframe_field\"\n",
    "    data_extrated_prefeitura = {}\n",
    "    #print(tipo)\n",
    "\n",
    "    filtered_frames_nf_v4_df = frames_nf_v4_df[(frames_nf_v4_df['model'] == model) & (frames_nf_v4_df['father'] == father) & (frames_nf_v4_df['type'] == tipo)]\n",
    "\n",
    "    for index_sframe, row_sframe in filtered_frames_nf_v4_df.iterrows():\n",
    "        \n",
    "        label_value = row_sframe['label']\n",
    "        \n",
    "        #print(\"label_value\", label_value)\n",
    "        \n",
    "        if label_value == \"nome_prefeitura\":\n",
    "            reference_value = row_sframe['reference']\n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result)\n",
    "        elif label_value == \"secretaria\":\n",
    "            reference_value = row_sframe['reference']\n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result) \n",
    "        elif label_value == \"tipo_nota_fiscal\":\n",
    "            reference_value = row_sframe['reference']  \n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    data_extrated_prefeitura.update(result)\n",
    "                    \n",
    "    return data_extrated_prefeitura\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def processa_cnae_outros(text):\n",
    "    nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "    if nf_data_CNAE_match:\n",
    "        try:\n",
    "            # Remove a primeira ocorrência de \"CNAE:\"\n",
    "            nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "            # Remover quebras de linha\n",
    "            nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "            return nf_data_CNAE_str \n",
    "        except Exception as e:\n",
    "            print(f\"Erro busca cnae: {e}\") \n",
    "        \n",
    "    return None   \n",
    "\n",
    "\n",
    "\n",
    "def extract_fb_outras_inf(modelo, father_value, section):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == model)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        \n",
    "        string_pesquisa = row_field['reference']\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        label = row_field['label']\n",
    "        #print(f'extracted_text_box {extracted_text_box}, label {label}')\n",
    "        text = extracted_text_box.replace('\\n', '')\n",
    "        if text.startswith(string_pesquisa):\n",
    "            #print(\"aqui:\", text)\n",
    "            text = text[len(label):].strip()\n",
    "            data_box_valores[label] = text\n",
    "    \n",
    "    return   data_box_valores      \n",
    "                 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## | REALMENTE O PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirma_pdf_pequisavel(file, file_path):\n",
    "    \n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 4\n",
    "    x1 = 600\n",
    "    y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    \n",
    "    print(text)\n",
    "    \n",
    "  \n",
    "    if text:\n",
    "       page_number = 0\n",
    "       print(page_number)\n",
    "    else:\n",
    "       page_number = 1\n",
    "       print(page_number)\n",
    "    \n",
    "   \n",
    "    try:\n",
    "        page = pdf_document[page_number]\n",
    "        x0 = 0\n",
    "        y0 = 0\n",
    "        x1 = 600\n",
    "        y1 = 110\n",
    "\n",
    "        text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "        nf_data_cabecalho = Extc.extract_fields_cabecalho(text)\n",
    "        \n",
    "\n",
    "        pdf_realmente_pequisavel = True\n",
    "        \n",
    "        return pdf_realmente_pequisavel\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao abrir pagina do PDF: {e}\")\n",
    "        \n",
    "        pdf_realmente_pequisavel = False\n",
    "                \n",
    "        return pdf_realmente_pequisavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_raster_pdf(image_2work):\n",
    "    \n",
    "    secao = \"1 - CABECALHO\"\n",
    "    try:\n",
    "        nro_nota = 0\n",
    "        nd_data_cabecalho = {}\n",
    "        nd_data_cabecalho['secao'] = secao\n",
    "        valor_dict = {}\n",
    "        dados_prefeitura = {}\n",
    "        f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "        # 1. funçao basica de modelo \n",
    "        texto = executa_model_frame(model, secao, f_frame_name)\n",
    "        text_splited = texto.split('\\n')\n",
    "        \n",
    "        valor_dict = extract_prefeitura(model, f_frame_name, text_splited)\n",
    "        if valor_dict:\n",
    "            dados_prefeitura.update(valor_dict)\n",
    "        valor = {}   \n",
    "        f_frame_name = \"1_frame_dados_nf\"\n",
    "        dadinho_dados_nf = {}\n",
    "        # 1. funçao basica de modelo \n",
    "        texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        text_splited = texto_extraido(texto)\n",
    "        keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "\n",
    "        string_pesquisa = \"Número da Nota:\"\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)         \n",
    "        dadinho_dados_nf['numero_nota_fiscal'] = texto\n",
    "        nro_nota = texto\n",
    "        \n",
    "        string_pesquisa = \"Competência:\"\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        dadinho_dados_nf['competencia'] = texto\n",
    "        \n",
    "        string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        dadinho_dados_nf['dt_hr_emissao'] = texto\n",
    "        \n",
    "        string_pesquisa = \"Código Verificação:\"\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        dadinho_dados_nf['codigo_verificacao'] = texto\n",
    "        \n",
    "        nd_data_cabecalho.update(dados_prefeitura)\n",
    "        nd_data_cabecalho.update(dadinho_dados_nf)\n",
    "    except Exception as e:\n",
    "        # erros_cabecalho = {}\n",
    "        err_msg = f\"Erro de processo cabecalho: {e}\"\n",
    "        print(err_msg)\n",
    "        # erros['documento'] = file\n",
    "        # erros_cabecalho['secao'] = secao\n",
    "        # erros_cabecalho['erro'] = err_msg\n",
    "        # erros.update(erros_cabecalho)                \n",
    "    \n",
    "    secao = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    try:\n",
    "        f_frame_name = \"2_frame_cnpj_prestador\"\n",
    "        nd_data_prestador = {}\n",
    "        prestador_inscricao = {}\n",
    "        nd_data_prestador['secao'] = secao\n",
    "        prestador_cnpj_value = {}\n",
    "        texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        #text_splited = texto_extraido(texto)\n",
    "        prestador_cnpj_value = extract_fields_prestador_cnpj(texto)\n",
    "        if prestador_cnpj_value:\n",
    "            nd_data_prestador.update(prestador_cnpj_value)\n",
    "    except Exception as e:\n",
    "        # erros_cnpj_prestador = {}\n",
    "        err_msg = (f\"Erro prestador cnpj: {e}\")\n",
    "        print(err_msg)\n",
    "        \n",
    "        # erros_cnpj_prestador['secao'] = secao\n",
    "        # erros_cnpj_prestador['erro'] = err_msg\n",
    "        # erros.update(erros_cnpj_prestador)       \n",
    "        \n",
    "    try:\n",
    "        f_frame_name = \"2_frame_inscricao_prestador\" \n",
    "        texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        text_splited = texto_extraido(texto)\n",
    "        keyword_list = ['Inscrição Municipal:', 'Inscrição Estadual:']\n",
    "        string_pesquisa = \"Inscrição Municipal:\"\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        prestador_inscricao['prestador_inscricao'] = texto\n",
    "        \n",
    "        string_pesquisa = \"Inscrição Estadual:\"\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        prestador_inscricao['inscricao_estadual'] = texto\n",
    "        nd_data_prestador.update(prestador_inscricao)\n",
    "    except Exception as e:\n",
    "        # erros_inscricao_prestador = {}\n",
    "        err_msg = (f\"Erro de processo inscricao prestador: {e}\")\n",
    "        print(err_msg)\n",
    "        # erros_inscricao_prestador['secao'] = secao\n",
    "        # erros_inscricao_prestador['erro'] = err_msg\n",
    "        # erros.update(erros_inscricao_prestador)\n",
    "\n",
    "    try:\n",
    "        f_frame_name = \"2_frame_dados_prestador\"\n",
    "        prestador_dados_value = {}\n",
    "        \n",
    "        keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "        string_pesquisa = \"Nome/Razão Social:\"\n",
    "        texto = executa_model_frame(model, secao, f_frame_name)\n",
    "        text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        prestador_dados_value['razao_social'] = texto\n",
    "\n",
    "        string_pesquisa = \"Nome de Fantasia:\"\n",
    "        #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "        #text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        prestador_dados_value['nome_fantasia'] = texto\n",
    "        \n",
    "        string_pesquisa = \"Endereço:\"\n",
    "        #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "        #text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        prestador_dados_value['endereco'] = texto\n",
    "        \n",
    "        string_pesquisa = \"E-mail:\"\n",
    "        #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "        #text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        prestador_dados_value['email'] = texto\n",
    "        nd_data_prestador.update(prestador_dados_value)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro prestador dados: {e}\") \n",
    "        \n",
    "    \n",
    "    secao = \"3. TOMADOR DE SERVIÇO\"\n",
    "    try:\n",
    "        nd_data_tomador = {}\n",
    "        tomador_cnpj_value = {}\n",
    "        nd_data_tomador['secao'] = secao\n",
    "        f_frame_name = \"3_frame_cnpj_tomador\"\n",
    "        texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        text_splited = texto_extraido(texto) \n",
    "        tomador_cnpj_value = extract_fields_tomador_cnpj(texto)\n",
    "        if tomador_cnpj_value:\n",
    "            nd_data_tomador.update(tomador_cnpj_value)                  \n",
    "    except Exception as e:\n",
    "        print(f\"Erro tomador cnpj: {e}\")\n",
    "        \n",
    "    f_frame_name = \"3_frame_inscricao_tomador\"    \n",
    "    try:\n",
    "        data_tomador_inscricao = {}\n",
    "        keyword_list = ['RG:', 'Inscrição Estadual:']\n",
    "        string_pesquisa = \"RG:\"\n",
    "        texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        data_tomador_inscricao['rg'] = texto\n",
    "        \n",
    "        string_pesquisa = \"Inscrição Estadual:\"\n",
    "        #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        #text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        data_tomador_inscricao['inscricao_estadual'] = texto\n",
    "        nd_data_tomador.update(data_tomador_inscricao)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro tomador inscricao: {e}\")\n",
    "        \n",
    "    f_frame_name = \"3_frame_dados_tomador\"\n",
    "    try: \n",
    "        data_tomador_dados = {}   \n",
    "        keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "        string_pesquisa = \"Nome/Razão Social:\"\n",
    "        texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        data_tomador_dados['razao_social'] = texto\n",
    "        \n",
    "        string_pesquisa = \"Endereço:\"\n",
    "        #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        #text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        data_tomador_dados['endereco'] = texto\n",
    "        \n",
    "        string_pesquisa = \"E-mail\"\n",
    "        #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "        #text_splited = texto_extraido(texto)\n",
    "        texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "        data_tomador_dados['email'] = texto\n",
    "        \n",
    "        nd_data_tomador.update(data_tomador_dados)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro tomador dados: {e}\") \n",
    "        \n",
    "    secao = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "    try:\n",
    "        nd_data_servico = {}\n",
    "        nd_data_servico['secao'] = secao\n",
    "        f_frame_name = \"4_frame_descricao_totais\"\n",
    "        texto = executa_model_frame(model, secao, f_frame_name)\n",
    "        text = texto.replace('\\n', ' ')\n",
    "        label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "        if text.startswith(label):\n",
    "            text = text[len(label):].strip()\n",
    "        nd_data_servico['discriminacao_servicos'] = text \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro descricao servico: {e}\")\n",
    "            \n",
    "    secao = \"5. VALOR TOTAL\"\n",
    "    try:\n",
    "        nd_data_valor_total = {}\n",
    "        data_valor_total['secao'] = secao\n",
    "        f_frame_name = \"4_frame_valor_total\"   \n",
    "        text = executa_model_frame(model, secao, f_frame_name)  \n",
    "        valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "        if valor_total_match:\n",
    "            valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "            nd_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro valor total: {e}\")\n",
    "\n",
    "    secao = \"6. CNAE e Item da Lista de Serviços\"\n",
    "    try:\n",
    "        nd_data_CNAE = {}\n",
    "        nd_data_CNAE['secao'] = secao\n",
    "        f_frame_name = \"4_frame_cnae_itens_servico\"   \n",
    "        Texto_extraido = executa_model_frame(model, secao, f_frame_name)\n",
    "        text_splited = Texto_extraido.split('\\n')\n",
    "        # Processando CNAE\n",
    "        cnae_line = [line for line in text_splited if 'CNAE' in line][0]\n",
    "        cnae_number = int(extract_number(cnae_line))\n",
    "        cnae_value = cnae_dict.get(cnae_number, \"Valor não encontrado\")\n",
    "        if cnae_value == 'Valor não encontrado':\n",
    "            cnae_value = processa_cnae_outros(cnae_line)\n",
    "            cnae_value = cnae_value.upper()\n",
    "            nd_data_CNAE['cnae'] = cnae_value\n",
    "        else:\n",
    "            cnae_value = cnae_value.upper()\n",
    "            cnae_value = str(cnae_number) + \" - \" + cnae_value\n",
    "            nd_data_CNAE['cnae'] = cnae_value\n",
    "            nd_data_CNAE['item_lista_servicos'] = item_servico_value\n",
    "    except Exception as e:\n",
    "        print(f\"Erro busca cnae: {e}\")    \n",
    "\n",
    "    try:\n",
    "        item_servico_line = [line for line in text_splited if 'Item da Lista de Serviços' in line][0]\n",
    "        item_servico_number = float(extract_number(item_servico_line))\n",
    "        item_servico_value = item_servico_dict.get(item_servico_number, \"Valor não encontrado\")\n",
    "        item_servico_value = item_servico_value.upper()\n",
    "        item_servico_value = str(item_servico_number) + \" - \" + item_servico_value\n",
    "        nd_data_CNAE['item_lista_servicos'] = item_servico_value\n",
    "    except Exception as e:\n",
    "        print(f\"Erro busca Itens de servico: {e}\")  \n",
    "\n",
    "    secao = \"8. DADOS COMPLEMENTARES\"\n",
    "    try:\n",
    "        nd_data_valores = {}\n",
    "        nd_data_valores['secao'] = secao\n",
    "        f_frame_name = \"5_frame_valores_impostos\"   \n",
    "        \n",
    "        result = extract_fields_box(model, f_frame_name, secao)\n",
    "        if result:\n",
    "            nd_data_valores.update(result)\n",
    "\n",
    "        # secao: 8 - DADOS COMPLEMENTARES\"\n",
    "        nd_data_dados_complementares = {}\n",
    "        f_frame_name  = \"5_frame_dados_complementares\"\n",
    "        section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "        nd_data_dados_complementares = extract_dados_comple_obs(model, f_frame_name, section)                                           \n",
    "                                \n",
    "                                \n",
    "        # secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "        nd_data_outras_informacoes = {}\n",
    "        father_value = \"5_frame_inf_criticas\"\n",
    "        section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "        \n",
    "        result = extract_fb_outras_inf(model, father_value, section)\n",
    "        if result:\n",
    "            nd_data_outras_informacoes.update(result)                        \n",
    "                            \n",
    "        # secao: 10. OBSERVACOES\n",
    "        nd_data_observacao = {}\n",
    "        f_father = \"5_frame_observacao\"\n",
    "        section = \"10. OBSERVACOES\"\n",
    "\n",
    "        nd_data_observacao = extract_dados_comple_obs(model, f_father, section)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro valores complementares:\")  \n",
    "        \n",
    "    \n",
    "    return nro_nota, nd_data_cabecalho, nd_data_prestador, nd_data_tomador, nd_data_servico, nd_data_valor_total, nd_data_CNAE, nd_data_valores, nd_data_dados_complementares, nd_data_outras_informacoes, nd_data_observacao      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa_pdf_pesquisavel(file_path):\n",
    "    \n",
    "   \n",
    "    status = \"O PDF é pesquisável\"\n",
    "    # Carregar o arquivo PDF\n",
    "    pdf_document = fitz.open(file_path)\n",
    "\n",
    "    # Página do PDF  ATENCAO  (UNICA PAGINA)\n",
    "    page_number = 0  # Defina o número da página que deseja analisar\n",
    "    page = pdf_document[page_number]\n",
    "\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 4\n",
    "    x1 = 600\n",
    "    y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    \n",
    "    print(text)\n",
    "    \n",
    "  \n",
    "    if text:\n",
    "       page_number = 0\n",
    "       print(page_number)\n",
    "    else:\n",
    "       page_number = 1\n",
    "       print(page_number)\n",
    "    \n",
    "    nf_data_cabecalho = {}\n",
    "    \n",
    "    page = pdf_document[page_number]\n",
    "    x0 = 0\n",
    "    y0 = 0\n",
    "    x1 = 600\n",
    "    y1 = 110\n",
    "\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    nf_data_cabecalho = Extc.extract_fields_cabecalho(text)\n",
    "    #nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "    \n",
    "    nro_nota = nf_data_cabecalho['numero_nota_fiscal']\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 2. PRESTADOR DE SERVIÇO\n",
    "    # Definir retângulo de interesse\n",
    "    nf_data_prestador = {}\n",
    "    x0 = 0\n",
    "    y0 = 100\n",
    "    x1 = 600\n",
    "    y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    \n",
    "    nf_data_prestador = Extc.extract_fields_prestador(text)\n",
    "    #nf_data_prestador = extract_fields_prestador(text)\n",
    "    \n",
    "    # 3. TOMADOR DE SERVIÇO\n",
    "    # Definir retângulo de interesse\n",
    "    nf_data_tomador = {}\n",
    "    x0 = 0\n",
    "    y0 = 210\n",
    "    x1 = 600\n",
    "    y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    \n",
    "    \n",
    "    nf_data_tomador = Extc.extract_fields_tomador(text)\n",
    "    #nf_data_tomador = extract_fields_tomador(text)\n",
    "    \n",
    "    \n",
    "    # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "    nf_data_servico = {}\n",
    "    nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 330\n",
    "    x1 = 600\n",
    "    y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "    # Remover quebras de linha e rótulo\n",
    "    text = text.replace('\\n', ' ')\n",
    "    label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "    if text.startswith(label):\n",
    "        text = text[len(label):].strip()\n",
    "\n",
    "    # Atribuir texto ao dicionário\n",
    "    nf_data_servico['discriminacao_servicos'] = text\n",
    "    \n",
    "    \n",
    "    # 5. VALOR TOTAL\n",
    "    nf_data_valor_total = {}\n",
    "    nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 500\n",
    "    x1 = 600\n",
    "    y1 = 550  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "    # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "    valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "    if valor_total_match:\n",
    "        valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "        nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # 6. CNAE e Item da Lista de Serviços\n",
    "    nf_data_CNAE = {}\n",
    "    nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "    # Definir retângulo de interesse CNAE\n",
    "    x0 = 0\n",
    "    y0 = 530\n",
    "    x1 = 600\n",
    "    y1 = 540  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "    # Extrair CNAE\n",
    "    nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "    if nf_data_CNAE_match:\n",
    "        # Remove a primeira ocorrência de \"CNAE:\"\n",
    "        nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "        # Remover quebras de linha\n",
    "        nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "        nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Item da Lista de Serviços    \n",
    "    # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "    x0 = 0\n",
    "    y0 = 545\n",
    "    x1 = 600\n",
    "    y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "        \n",
    "    # Extrair Item da Lista de Serviços\n",
    "    nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "    if nf_item_lista_servicos_match:\n",
    "        nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "        # Remover quebras de linha\n",
    "        #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "        nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "        nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "        \n",
    "    \n",
    "    # 7. VALORES E IMPOSTOS\n",
    "    # Definir retângulo de interesse\n",
    "    nf_data_valores = {}\n",
    "    \n",
    "    x0 = 0\n",
    "    y0 = 550\n",
    "    x1 = 600\n",
    "    y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "    # Extrair campos e valores\n",
    "    nf_data_valores = Extc.extract_fields_impostos(text)\n",
    "    #nf_data_valores = extract_fields_impostos(text)\n",
    "    \n",
    "    # 8. DADOS COMPLEMENTARES\n",
    "    nf_data_dados_complementares = {}\n",
    "    nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 650\n",
    "    x1 = 600\n",
    "    y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "    # Remove a primeira ocorrência de \"Observação:\"\n",
    "    text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "    if text == \" \":\n",
    "        text = \"NONE\"\n",
    "        nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "    else:    \n",
    "        # Extrair texto dentro do retângulo\n",
    "        nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "    # Definir retângulo de interesse\n",
    "    nf_data_outras_informacoes = {}\n",
    "    x0 = 0\n",
    "    y0 = 680\n",
    "    x1 = 600\n",
    "    y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "    # Extrair campos e valores\n",
    "    nf_data_outras_informacoes = Extc.extract_fields_outras_info(text)\n",
    "    #nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "    \n",
    "    \n",
    "    # 10. OBSERVACOES\n",
    "    nf_data_observacao = {}\n",
    "    nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "    # Definir retângulo de interesse\n",
    "    x0 = 0\n",
    "    y0 = 725\n",
    "    x1 = 600\n",
    "    y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "    # Remove a primeira ocorrência de \"Observação:\"\n",
    "    text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "    # Remover quebras de linha\n",
    "    text = text.replace('\\n', ' ')\n",
    "\n",
    "    # Extrair texto dentro do retângulo\n",
    "    nf_data_observacao['observacao'] = text.strip()\n",
    "    \n",
    "    # try:\n",
    "    #     nr_nro_nf = nro_nota\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Nao encontrado nro da NF: {e}\")       \n",
    "    \n",
    "\n",
    "    return nro_nota, nf_data_cabecalho, nf_data_prestador, nf_data_tomador, nf_data_servico, nf_data_valor_total, nf_data_CNAE, nf_data_valores, nf_data_dados_complementares, nf_data_outras_informacoes, nf_data_observacao       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Processo RASTER PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que contém \n",
      "numeradas eletronicamente da Nº 1 à \n",
      "serviu para o:\n",
      "TERMO DE ABERTURA\n",
      "EXERCÍCIO: 2023\n",
      "LIV\n",
      "2\n",
      "2 folhas\n",
      "Este Livro da PREFEITURA MUNICIPAL DE MESQUITA/RJ\n",
      "\n",
      "0\n",
      "27/07/2023, 15:05\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20233\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:04:00\n",
      "Código Verificação:\n",
      "178964118\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "27/07/2023, 15:12\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20234\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:11:00\n",
      "Código Verificação:\n",
      "4FDA9FBAE\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "27/07/2023, 15:20\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20237\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:19:00\n",
      "Código Verificação:\n",
      "C45A7FCE4\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "27/07/2023, 15:25\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20238\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:21:00\n",
      "Código Verificação:\n",
      "3C86CC2F2\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "27/07/2023, 15:14\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20235\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:13:00\n",
      "Código Verificação:\n",
      "92ED36652\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "27/07/2023, 15:18\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20236\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:16:00\n",
      "Código Verificação:\n",
      "3650A24CE\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "01/08/2023 20:03\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20232\n",
      "Competência:\n",
      "Agosto/2023\n",
      "Data e Hora da Emissão:\n",
      "01/08/2023 20:00:00\n",
      "Código Verificação:\n",
      "DAD4C3BCC\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 51.156.898/0001-22\n",
      "Inscrição Municipal:\n",
      "952681\n",
      "Telefone:\n",
      " 21995883745.\n",
      "Inscrição Estadual:\n",
      "Nome/Razão Social:\n",
      "51.156.898 EDVALDO DA COSTA NASCIMENTO\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "31/07/2023 13:03\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20231\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "31/07/2023 12:54:00\n",
      "Código Verificação:\n",
      "42BC784C8\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 51.156.898/0001-22\n",
      "Inscrição Municipal:\n",
      "952681\n",
      "Telefone:\n",
      " 21995883745.\n",
      "Inscrição Estadual:\n",
      "Nome/Razão Social:\n",
      "51.156.898 EDVALDO DA COSTA NASCIMENTO\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "Rua Arthur Oliveira Vecchi, 0120 - CEP:26553-080\n",
      "Mesquita\n",
      "RJ\n",
      "Centro\n",
      "Listagem de Notas \n",
      "Inscrição/C.G.A........:\n",
      "Nome / Razão Social:\n",
      "Endereço..................: \n",
      "CNPJ/CPF:\n",
      "Resp Contábil:\n",
      "N° da Nota\n",
      "Data Emissão\n",
      "Tomador\n",
      "Situação\n",
      "Nº da Guia\n",
      "Status da Guia\n",
      "Item 116\n",
      "CNAE:\n",
      "N° RPS\n",
      "\n",
      "0\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "Rua Arthur Oliveira Vecchi, 0120 - CEP:26553-080\n",
      "Mesquita\n",
      "RJ\n",
      "Centro\n",
      "Listagem de Notas Emitida\n",
      "951271\n",
      "Inscrição/C.G.A........:\n",
      "Nome / Razão Social:\n",
      "Endereço..................: \n",
      "RUA OTAVIO BRAGA Nº 146 BAIRRO: CHATUBA CEP: 26587260             COMPLEMENTO: \n",
      "CNPJ/CPF: 45.849.286/0001-12\n",
      "Resp Contábil:\n",
      "N° da Nota\n",
      "Data Emissão\n",
      "Tomador\n",
      "Situação\n",
      "Nº da Guia\n",
      "Status da Guia\n",
      "Item 116\n",
      "CNAE:\n",
      "N° RPS\n",
      "EMITIDA/ATIVA\n",
      "202313\n",
      "02/08/2023\n",
      "(47785676000100) - BRAVUS ENTREGAS RAPIDAS LTDA\n",
      "Pendente: NÃO EMI\n",
      "26.01\n",
      "5320201\n",
      "\n",
      "0\n",
      "As informações foram salvas em pipeline_extracao_documentos/5_documentos_processados/jsons/Batch_16_PDF_Pesquisavel.json\n"
     ]
    }
   ],
   "source": [
    "erros = {}\n",
    "\n",
    "# 1. Leitura recursiva de diretorios e arquivos a partir de root\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "nf_data_servico = {}#VERIFICAR\n",
    "analise_doc_nf = {} #VERIFICAR\n",
    "file_data = [] #VERIFICAR\n",
    "\n",
    "list_document_pages = []\n",
    "#nro_nota = 0\n",
    "# TEMP\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "#3. path formado para nome do arquivo json\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "#root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "#print(root_doc_analise)\n",
    "i = 1\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    #print(dir_name)\n",
    "    for file in files:\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            doc2convert = file\n",
    "            document_path_1 = os.path.join(root, file)\n",
    "            pdf_document = fitz.open(document_path_1)\n",
    "            #page_number = 0  # Defina o número da página que deseja analisar\n",
    "            #page = pdf_document[page_number]\n",
    "            \n",
    "            documento_pdf = True\n",
    "            pesquisavel, metadados, paginas = is_pdf_searchable_analise(document_path_1)\n",
    "            \n",
    "            \n",
    "            pdf_realmente_pequisavel = confirma_pdf_pequisavel(file, document_path_1)\n",
    "            \n",
    "            if not pdf_realmente_pequisavel:\n",
    "                print(f'\\nTeste nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                processo = \"PDF_Raster\"\n",
    "                \n",
    "                image_2work, name_image_2work = convertResizeAnalise_1page(file, document_path_1, image_resized_path)\n",
    "                \n",
    "                secao = \"1 - CABECALHO\"\n",
    "                try:\n",
    "                    nro_nota = 0\n",
    "                    data_cabecalho = {}\n",
    "                    data_cabecalho['secao'] = secao\n",
    "                    valor_dict = {}\n",
    "                    dados_prefeitura = {}\n",
    "                    f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "                    # 1. funçao basica de modelo \n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text_splited = texto.split('\\n')\n",
    "                    \n",
    "                    valor_dict = extract_prefeitura(model, f_frame_name, text_splited)\n",
    "                    if valor_dict:\n",
    "                        dados_prefeitura.update(valor_dict)\n",
    "                    valor = {}   \n",
    "                    f_frame_name = \"1_frame_dados_nf\"\n",
    "                    dadinho_dados_nf = {}\n",
    "                    # 1. funçao basica de modelo \n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "\n",
    "                    string_pesquisa = \"Número da Nota:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)         \n",
    "                    dadinho_dados_nf['numero_nota_fiscal'] = texto\n",
    "                    nro_nota = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Competência:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    dadinho_dados_nf['competencia'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    dadinho_dados_nf['dt_hr_emissao'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Código Verificação:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    dadinho_dados_nf['codigo_verificacao'] = texto\n",
    "                    \n",
    "                    data_cabecalho.update(dados_prefeitura)\n",
    "                    data_cabecalho.update(dadinho_dados_nf)\n",
    "                except Exception as e:\n",
    "                    erros_cabecalho = {}\n",
    "                    err_msg = f\"Erro de processo cabecalho: {e}\"\n",
    "                    erros['documento'] = file\n",
    "                    erros_cabecalho['secao'] = secao\n",
    "                    erros_cabecalho['erro'] = err_msg\n",
    "                    erros.update(erros_cabecalho)                \n",
    "               \n",
    "                \n",
    "                \n",
    "                \n",
    "                secao = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                try:\n",
    "                    f_frame_name = \"2_frame_cnpj_prestador\"\n",
    "                    data_prestador = {}\n",
    "                    prestador_inscricao = {}\n",
    "                    data_prestador['secao'] = secao\n",
    "                    prestador_cnpj_value = {}\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    prestador_cnpj_value = extract_fields_prestador_cnpj(texto)\n",
    "                    if prestador_cnpj_value:\n",
    "                        data_prestador.update(prestador_cnpj_value)\n",
    "                except Exception as e:\n",
    "                    erros_cnpj_prestador = {}\n",
    "                    err_msg = (f\"Erro prestador cnpj: {e}\")\n",
    "                    erros_cnpj_prestador['secao'] = secao\n",
    "                    erros_cnpj_prestador['erro'] = err_msg\n",
    "                    erros.update(erros_cnpj_prestador)       \n",
    "                    \n",
    "                try:\n",
    "                    f_frame_name = \"2_frame_inscricao_prestador\" \n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    keyword_list = ['Inscrição Municipal:', 'Inscrição Estadual:']\n",
    "                    string_pesquisa = \"Inscrição Municipal:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_inscricao['prestador_inscricao'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Inscrição Estadual:\"\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_inscricao['inscricao_estadual'] = texto\n",
    "                    data_prestador.update(prestador_inscricao)\n",
    "                except Exception as e:\n",
    "                    erros_inscricao_prestador = {}\n",
    "                    err_msg = (f\"Erro de processo inscricao prestador: {e}\")\n",
    "                    erros_inscricao_prestador['secao'] = secao\n",
    "                    erros_inscricao_prestador['erro'] = err_msg\n",
    "                    erros.update(erros_inscricao_prestador)\n",
    "\n",
    "                try:\n",
    "                    f_frame_name = \"2_frame_dados_prestador\"\n",
    "                    prestador_dados_value = {}\n",
    "                    \n",
    "                    keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "                    string_pesquisa = \"Nome/Razão Social:\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['razao_social'] = texto\n",
    "\n",
    "                    string_pesquisa = \"Nome de Fantasia:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['nome_fantasia'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Endereço:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['endereco'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"E-mail:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    prestador_dados_value['email'] = texto\n",
    "                    data_prestador.update(prestador_dados_value)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Erro prestador dados: {e}\") \n",
    "                    \n",
    "                \n",
    "                secao = \"3. TOMADOR DE SERVIÇO\"\n",
    "                try:\n",
    "                    data_tomador = {}\n",
    "                    tomador_cnpj_value = {}\n",
    "                    data_tomador['secao'] = secao\n",
    "                    f_frame_name = \"3_frame_cnpj_tomador\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto) \n",
    "                    tomador_cnpj_value = extract_fields_tomador_cnpj(texto)\n",
    "                    if tomador_cnpj_value:\n",
    "                        data_tomador.update(tomador_cnpj_value)                  \n",
    "                except Exception as e:\n",
    "                    print(f\"Erro tomador cnpj: {e}\")\n",
    "                    \n",
    "                f_frame_name = \"3_frame_inscricao_tomador\"    \n",
    "                try:\n",
    "                    data_tomador_inscricao = {}\n",
    "                    keyword_list = ['RG:', 'Inscrição Estadual:']\n",
    "                    string_pesquisa = \"RG:\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_inscricao['rg'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Inscrição Estadual:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_inscricao['inscricao_estadual'] = texto\n",
    "                    data_tomador.update(data_tomador_inscricao)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro tomador inscricao: {e}\")\n",
    "                    \n",
    "                f_frame_name = \"3_frame_dados_tomador\"\n",
    "                try: \n",
    "                    data_tomador_dados = {}   \n",
    "                    keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "                    string_pesquisa = \"Nome/Razão Social:\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_dados['razao_social'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"Endereço:\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_dados['endereco'] = texto\n",
    "                    \n",
    "                    string_pesquisa = \"E-mail\"\n",
    "                    #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #text_splited = texto_extraido(texto)\n",
    "                    texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    data_tomador_dados['email'] = texto\n",
    "                    \n",
    "                    data_tomador.update(data_tomador_dados)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro tomador dados: {e}\") \n",
    "                    \n",
    "                secao = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                try:\n",
    "                    data_servico = {}\n",
    "                    data_servico['secao'] = secao\n",
    "                    f_frame_name = \"4_frame_descricao_totais\"\n",
    "                    texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text = texto.replace('\\n', ' ')\n",
    "                    label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                    if text.startswith(label):\n",
    "                        text = text[len(label):].strip()\n",
    "                    data_servico['discriminacao_servicos'] = text \n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro descricao servico: {e}\")\n",
    "                     \n",
    "                secao = \"5. VALOR TOTAL\"\n",
    "                try:\n",
    "                    data_valor_total = {}\n",
    "                    data_valor_total['secao'] = secao\n",
    "                    f_frame_name = \"4_frame_valor_total\"   \n",
    "                    text = executa_model_frame(model, secao, f_frame_name)  \n",
    "                    valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                    if valor_total_match:\n",
    "                        valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                        data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro valor total: {e}\")\n",
    "\n",
    "                secao = \"6. CNAE e Item da Lista de Serviços\"\n",
    "                try:\n",
    "                    data_CNAE = {}\n",
    "                    data_CNAE['secao'] = secao\n",
    "                    f_frame_name = \"4_frame_cnae_itens_servico\"   \n",
    "                    Texto_extraido = executa_model_frame(model, secao, f_frame_name)\n",
    "                    text_splited = Texto_extraido.split('\\n')\n",
    "                    # Processando CNAE\n",
    "                    cnae_line = [line for line in text_splited if 'CNAE' in line][0]\n",
    "                    cnae_number = int(extract_number(cnae_line))\n",
    "                    cnae_value = cnae_dict.get(cnae_number, \"Valor não encontrado\")\n",
    "                    if cnae_value == 'Valor não encontrado':\n",
    "                        cnae_value = processa_cnae_outros(cnae_line)\n",
    "                        cnae_value = cnae_value.upper()\n",
    "                        data_CNAE['cnae'] = cnae_value\n",
    "                    else:\n",
    "                        cnae_value = cnae_value.upper()\n",
    "                        cnae_value = str(cnae_number) + \" - \" + cnae_value\n",
    "                        data_CNAE['cnae'] = cnae_value\n",
    "                        data_CNAE['item_lista_servicos'] = item_servico_value\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro busca cnae: {e}\")    \n",
    "          \n",
    "                try:\n",
    "                    item_servico_line = [line for line in text_splited if 'Item da Lista de Serviços' in line][0]\n",
    "                    item_servico_number = float(extract_number(item_servico_line))\n",
    "                    item_servico_value = item_servico_dict.get(item_servico_number, \"Valor não encontrado\")\n",
    "                    item_servico_value = item_servico_value.upper()\n",
    "                    item_servico_value = str(item_servico_number) + \" - \" + item_servico_value\n",
    "                    data_CNAE['item_lista_servicos'] = item_servico_value\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro busca Itens de servico: {e}\")  \n",
    "\n",
    "                secao = \"8. DADOS COMPLEMENTARES\"\n",
    "                try:\n",
    "                    data_valores = {}\n",
    "                    data_valores['secao'] = secao\n",
    "                    f_frame_name = \"5_frame_valores_impostos\"   \n",
    "                    \n",
    "                    result = extract_fields_box(model, f_frame_name, secao)\n",
    "                    if result:\n",
    "                        data_valores.update(result)\n",
    "            \n",
    "                    # secao: 8 - DADOS COMPLEMENTARES\"\n",
    "                    data_dados_complementares = {}\n",
    "                    f_frame_name  = \"5_frame_dados_complementares\"\n",
    "                    section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                    data_dados_complementares = extract_dados_comple_obs(model, f_frame_name, section)                                           \n",
    "                                            \n",
    "                                            \n",
    "                    # secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "                    data_outras_informacoes = {}\n",
    "                    father_value = \"5_frame_inf_criticas\"\n",
    "                    section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "                    \n",
    "                    result = extract_fb_outras_inf(model, father_value, section)\n",
    "                    if result:\n",
    "                        data_outras_informacoes.update(result)                        \n",
    "                                        \n",
    "                    # secao: 10. OBSERVACOES\n",
    "                    data_observacao = {}\n",
    "                    f_father = \"5_frame_observacao\"\n",
    "                    section = \"10. OBSERVACOES\"\n",
    "\n",
    "                    data_observacao = extract_dados_comple_obs(model, f_father, section)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro valores complementares: {e}\")   \n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                try:\n",
    "                    pdf_info[nro_nota] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": data_cabecalho,\n",
    "                        \"data_prestador\": data_prestador,\n",
    "                        \"data_tomador\": data_tomador,\n",
    "                        \"data_servico\": data_servico,\n",
    "                        \"data_valor_total\": data_valor_total,\n",
    "                        \"data_CNAE\": data_CNAE,\n",
    "                        \"data_valores\": data_valores,\n",
    "                        \"data_dados_complementares\": data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": data_outras_informacoes,\n",
    "                        \"data_observacao\": data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": dir_name, #os.path.basename(root)\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                    \"Batch\": batch_name,\n",
    "                    \"modelo\": model,\n",
    "                    \"processo\": processo,\n",
    "                }\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao gerar o json: {e}\")\n",
    "                pdf_document.close()\n",
    "                \n",
    "                #print(pdf_info)\n",
    "                #if paginas == 1:\n",
    "                if paginas > 1000:\n",
    "                    if i == 1000: #Define quantidade de tratamento de documentos raster PDF\n",
    "                        break\n",
    "            i +=1 \n",
    "                \n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name + \"_\" + processo + \".json\"\n",
    "\n",
    "json_file_path = os.path.join(json_path, nome_formado_json )\n",
    "\n",
    "\n",
    "# Salvando as informações em um arquivo JSON (novo formato nome arquivo V2)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Processo PDF Pesquisavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "diretorio: 115964 nro: 1 | doc: livro_de_registro_do_issqn.pdf | pdf?: True | pesquisavel?: True | paginas: 4\n",
      "\n",
      "que contém \n",
      "numeradas eletronicamente da Nº 1 à \n",
      "serviu para o:\n",
      "TERMO DE ABERTURA\n",
      "EXERCÍCIO: 2023\n",
      "LIV\n",
      "2\n",
      "2 folhas\n",
      "Este Livro da PREFEITURA MUNICIPAL DE MESQUITA/RJ\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 115964 nro: 1 | doc: livro_de_registro_do_issqn.pdf | pdf?: True | pesquisavel?: True | paginas: 4\n",
      "\n",
      "que contém \n",
      "numeradas eletronicamente da Nº 1 à \n",
      "serviu para o:\n",
      "TERMO DE ABERTURA\n",
      "EXERCÍCIO: 2023\n",
      "LIV\n",
      "2\n",
      "2 folhas\n",
      "Este Livro da PREFEITURA MUNICIPAL DE MESQUITA/RJ\n",
      "\n",
      "0\n",
      "Erro ao gerar dict nf: 'numero_nota_fiscal'\n",
      "i:  2\n",
      "\n",
      "diretorio: 159871 nro: 2 | doc: 2023__3.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:05\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20233\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:04:00\n",
      "Código Verificação:\n",
      "178964118\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 159871 nro: 2 | doc: 2023__3.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:05\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20233\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:04:00\n",
      "Código Verificação:\n",
      "178964118\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  3\n",
      "\n",
      "diretorio: 159871 nro: 3 | doc: 2023__4.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:12\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20234\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:11:00\n",
      "Código Verificação:\n",
      "4FDA9FBAE\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 159871 nro: 3 | doc: 2023__4.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:12\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20234\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:11:00\n",
      "Código Verificação:\n",
      "4FDA9FBAE\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  4\n",
      "\n",
      "diretorio: 159871 nro: 4 | doc: 2023__7.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:20\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20237\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:19:00\n",
      "Código Verificação:\n",
      "C45A7FCE4\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 159871 nro: 4 | doc: 2023__7.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:20\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20237\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:19:00\n",
      "Código Verificação:\n",
      "C45A7FCE4\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  5\n",
      "\n",
      "diretorio: 159871 nro: 5 | doc: 2023__8.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:25\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20238\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:21:00\n",
      "Código Verificação:\n",
      "3C86CC2F2\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 159871 nro: 5 | doc: 2023__8.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:25\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20238\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:21:00\n",
      "Código Verificação:\n",
      "3C86CC2F2\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  6\n",
      "\n",
      "diretorio: 159871 nro: 6 | doc: 2023__5.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:14\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20235\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:13:00\n",
      "Código Verificação:\n",
      "92ED36652\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 159871 nro: 6 | doc: 2023__5.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:14\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20235\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:13:00\n",
      "Código Verificação:\n",
      "92ED36652\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  7\n",
      "\n",
      "diretorio: 159871 nro: 7 | doc: 2023__6.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:18\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20236\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:16:00\n",
      "Código Verificação:\n",
      "3650A24CE\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 159871 nro: 7 | doc: 2023__6.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "27/07/2023, 15:18\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20236\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "27/07/2023 15:16:00\n",
      "Código Verificação:\n",
      "3650A24CE\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 50.921.369/0001-05\n",
      "Inscrição Municipal:\n",
      " 952538\n",
      "Telefone:\n",
      " 2297268232..\n",
      "Inscrição Estadual:\n",
      " \n",
      "Nome/Razão Social:\n",
      "MEDSORIA CLINICA DE AVALIACAO MEDICA E PSICOLOGICA DO TRAFEGO DE MESQUITA LTDA\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  8\n",
      "\n",
      "diretorio: 160014 nro: 8 | doc: acfrogblgyewspqaweud3qjkpdqn5kp2dfiynq7d6wjcrymgxkby0xaq7m2xyrrh8asjkxsfk1z9f4bsqat1di5gppkc3ahrhnhavaawbjuamkpiluuxpydd2ovrxzk.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "01/08/2023 20:03\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20232\n",
      "Competência:\n",
      "Agosto/2023\n",
      "Data e Hora da Emissão:\n",
      "01/08/2023 20:00:00\n",
      "Código Verificação:\n",
      "DAD4C3BCC\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 51.156.898/0001-22\n",
      "Inscrição Municipal:\n",
      "952681\n",
      "Telefone:\n",
      " 21995883745.\n",
      "Inscrição Estadual:\n",
      "Nome/Razão Social:\n",
      "51.156.898 EDVALDO DA COSTA NASCIMENTO\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 160014 nro: 8 | doc: acfrogblgyewspqaweud3qjkpdqn5kp2dfiynq7d6wjcrymgxkby0xaq7m2xyrrh8asjkxsfk1z9f4bsqat1di5gppkc3ahrhnhavaawbjuamkpiluuxpydd2ovrxzk.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "01/08/2023 20:03\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20232\n",
      "Competência:\n",
      "Agosto/2023\n",
      "Data e Hora da Emissão:\n",
      "01/08/2023 20:00:00\n",
      "Código Verificação:\n",
      "DAD4C3BCC\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 51.156.898/0001-22\n",
      "Inscrição Municipal:\n",
      "952681\n",
      "Telefone:\n",
      " 21995883745.\n",
      "Inscrição Estadual:\n",
      "Nome/Razão Social:\n",
      "51.156.898 EDVALDO DA COSTA NASCIMENTO\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  9\n",
      "\n",
      "diretorio: 160014 nro: 9 | doc: 31_07.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "31/07/2023 13:03\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20231\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "31/07/2023 12:54:00\n",
      "Código Verificação:\n",
      "42BC784C8\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 51.156.898/0001-22\n",
      "Inscrição Municipal:\n",
      "952681\n",
      "Telefone:\n",
      " 21995883745.\n",
      "Inscrição Estadual:\n",
      "Nome/Razão Social:\n",
      "51.156.898 EDVALDO DA COSTA NASCIMENTO\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 160014 nro: 9 | doc: 31_07.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "31/07/2023 13:03\n",
      "Nota Fiscal de Serviços Eletrônica (NFSe)\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "SECRETARIA MUNICIPAL DA FAZENDA\n",
      "NOTA FISCAL DE SERVIÇOS ELETRÔNICA - NFS-e\n",
      "Número da Nota:\n",
      "20231\n",
      "Competência:\n",
      "Julho/2023\n",
      "Data e Hora da Emissão:\n",
      "31/07/2023 12:54:00\n",
      "Código Verificação:\n",
      "42BC784C8\n",
      "PRESTADOR DE SERVIÇOS\n",
      "CPF/CNPJ:\n",
      " 51.156.898/0001-22\n",
      "Inscrição Municipal:\n",
      "952681\n",
      "Telefone:\n",
      " 21995883745.\n",
      "Inscrição Estadual:\n",
      "Nome/Razão Social:\n",
      "51.156.898 EDVALDO DA COSTA NASCIMENTO\n",
      "Nome de Fantasia:\n",
      "Endereço:\n",
      "\n",
      "0\n",
      "i:  10\n",
      "\n",
      "diretorio: 126623 nro: 10 | doc: 41c46d8f_73ab_4906_a4c6_c7dc92c05828.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "Rua Arthur Oliveira Vecchi, 0120 - CEP:26553-080\n",
      "Mesquita\n",
      "RJ\n",
      "Centro\n",
      "Listagem de Notas \n",
      "Inscrição/C.G.A........:\n",
      "Nome / Razão Social:\n",
      "Endereço..................: \n",
      "CNPJ/CPF:\n",
      "Resp Contábil:\n",
      "N° da Nota\n",
      "Data Emissão\n",
      "Tomador\n",
      "Situação\n",
      "Nº da Guia\n",
      "Status da Guia\n",
      "Item 116\n",
      "CNAE:\n",
      "N° RPS\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 126623 nro: 10 | doc: 41c46d8f_73ab_4906_a4c6_c7dc92c05828.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "Rua Arthur Oliveira Vecchi, 0120 - CEP:26553-080\n",
      "Mesquita\n",
      "RJ\n",
      "Centro\n",
      "Listagem de Notas \n",
      "Inscrição/C.G.A........:\n",
      "Nome / Razão Social:\n",
      "Endereço..................: \n",
      "CNPJ/CPF:\n",
      "Resp Contábil:\n",
      "N° da Nota\n",
      "Data Emissão\n",
      "Tomador\n",
      "Situação\n",
      "Nº da Guia\n",
      "Status da Guia\n",
      "Item 116\n",
      "CNAE:\n",
      "N° RPS\n",
      "\n",
      "0\n",
      "Erro ao gerar dict nf: 'numero_nota_fiscal'\n",
      "i:  11\n",
      "\n",
      "diretorio: 138565 nro: 11 | doc: b4066c58_f309_42e4_a992_55eb8961211e.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "Rua Arthur Oliveira Vecchi, 0120 - CEP:26553-080\n",
      "Mesquita\n",
      "RJ\n",
      "Centro\n",
      "Listagem de Notas Emitida\n",
      "951271\n",
      "Inscrição/C.G.A........:\n",
      "Nome / Razão Social:\n",
      "Endereço..................: \n",
      "RUA OTAVIO BRAGA Nº 146 BAIRRO: CHATUBA CEP: 26587260             COMPLEMENTO: \n",
      "CNPJ/CPF: 45.849.286/0001-12\n",
      "Resp Contábil:\n",
      "N° da Nota\n",
      "Data Emissão\n",
      "Tomador\n",
      "Situação\n",
      "Nº da Guia\n",
      "Status da Guia\n",
      "Item 116\n",
      "CNAE:\n",
      "N° RPS\n",
      "EMITIDA/ATIVA\n",
      "202313\n",
      "02/08/2023\n",
      "(47785676000100) - BRAVUS ENTREGAS RAPIDAS LTDA\n",
      "Pendente: NÃO EMI\n",
      "26.01\n",
      "5320201\n",
      "\n",
      "0\n",
      "pdf_realmente_pequisavel:  True\n",
      "\n",
      "PDF Pesquisavel diretorio: 138565 nro: 11 | doc: b4066c58_f309_42e4_a992_55eb8961211e.pdf | pdf?: True | pesquisavel?: True | paginas: 1\n",
      "\n",
      "PREFEITURA MUNICIPAL DE MESQUITA\n",
      "Rua Arthur Oliveira Vecchi, 0120 - CEP:26553-080\n",
      "Mesquita\n",
      "RJ\n",
      "Centro\n",
      "Listagem de Notas Emitida\n",
      "951271\n",
      "Inscrição/C.G.A........:\n",
      "Nome / Razão Social:\n",
      "Endereço..................: \n",
      "RUA OTAVIO BRAGA Nº 146 BAIRRO: CHATUBA CEP: 26587260             COMPLEMENTO: \n",
      "CNPJ/CPF: 45.849.286/0001-12\n",
      "Resp Contábil:\n",
      "N° da Nota\n",
      "Data Emissão\n",
      "Tomador\n",
      "Situação\n",
      "Nº da Guia\n",
      "Status da Guia\n",
      "Item 116\n",
      "CNAE:\n",
      "N° RPS\n",
      "EMITIDA/ATIVA\n",
      "202313\n",
      "02/08/2023\n",
      "(47785676000100) - BRAVUS ENTREGAS RAPIDAS LTDA\n",
      "Pendente: NÃO EMI\n",
      "26.01\n",
      "5320201\n",
      "\n",
      "0\n",
      "Erro ao gerar dict nf: 'numero_nota_fiscal'\n",
      "i:  12\n",
      "As informações foram salvas em pipeline_extracao_documentos/5_documentos_processados/jsons/Batch_16_PDF_Pesquisavel.json\n"
     ]
    }
   ],
   "source": [
    "erros = {}\n",
    "# 1. Leitura recursiva de diretorios e arquivos a partir de root\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "\n",
    "data_cabecalho_final = {}\n",
    "data_prestador_final = {}\n",
    "data_tomador_final = {}\n",
    "data_servico_final = {}\n",
    "data_valor_total_final = {}\n",
    "data_CNAE_final = {}\n",
    "data_valores_final = {}\n",
    "data_dados_complementares_final = {}\n",
    "data_outras_informacoes_final = {}\n",
    "data_observacao_final = {}\n",
    "\n",
    "result_1 = {}\n",
    "result_2 = {}\n",
    "result_3 = {}\n",
    "result_4 = {}\n",
    "result_5 = {}\n",
    "result_6 = {}\n",
    "result_7 = {}\n",
    "result_8 = {}\n",
    "result_9 = {}\n",
    "result_10 = {}\n",
    "\n",
    "i = 1\n",
    "for root, dirs, files in os.walk(root_doc_analise):\n",
    "    dir_name = os.path.basename(root)\n",
    "    #print(dir_name)\n",
    "    for file in files:\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            doc2convert = file\n",
    "            document_path_1 = os.path.join(root, file)\n",
    "            pdf_document = fitz.open(document_path_1)\n",
    "            #page_number = 0  # Defina o número da página que deseja analisar\n",
    "            #page = pdf_document[page_number]\n",
    "\n",
    "            \n",
    "            documento_pdf = True\n",
    "            pesquisavel, metadados, paginas = is_pdf_searchable_analise(document_path_1)\n",
    "            print(f'\\ndiretorio: {dir_name} nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "            \n",
    "            pdf_realmente_pequisavel = confirma_pdf_pequisavel(file, document_path_1)\n",
    "            \n",
    "            print(\"pdf_realmente_pequisavel: \", pdf_realmente_pequisavel)\n",
    "            \n",
    "            if not pdf_realmente_pequisavel:\n",
    "                print(f'\\nRaster PDF diretorio: {dir_name} nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "               \n",
    " \n",
    "            else:\n",
    "                print(f'\\nPDF Pesquisavel diretorio: {dir_name} nro: {i} | doc: {file} | pdf?: {documento_pdf} | pesquisavel?: {pesquisavel} | paginas: {paginas}\\n')\n",
    "                try:\n",
    "                    processo = \"PDF_Pesquisavel\"\n",
    "\n",
    "\n",
    "                    nro_nota, result_1, result_2, result_3, result_4, result_5, result_6, result_7, result_8, result_9, result_10 = processa_pdf_pesquisavel(document_path_1)\n",
    "                    \n",
    "                    if result_1:\n",
    "                        data_cabecalho_final.update(result_1)\n",
    "                    if result_2:\n",
    "                        data_prestador_final.update(result_2)   \n",
    "                    if result_3:\n",
    "                        data_tomador_final.update(result_3)\n",
    "                    if result_4:\n",
    "                        data_servico_final.update(result_4)\n",
    "                    if result_5:\n",
    "                        data_valor_total_final.update(result_5)\n",
    "                    if result_6:\n",
    "                        data_CNAE_final.update(result_6)\n",
    "                    if result_7:\n",
    "                        data_valores_final.update(result_7)\n",
    "                    if result_8:\n",
    "                        data_dados_complementares_final.update(result_8)                                                                   \n",
    "                    if result_9:\n",
    "                        data_outras_informacoes_final.update(result_9)   \n",
    "                    if result_10:\n",
    "                        data_observacao_final.update(result_10)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao gerar dict nf: {e}\")         \n",
    "                \n",
    "            nome_arquivo = file\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                pdf_info[nro_nota] = {\n",
    "                        \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": data_cabecalho_final,\n",
    "                        \"data_prestador\": data_prestador_final,\n",
    "                        \"data_tomador\": data_tomador_final,\n",
    "                        \"data_servico\": data_servico_final,\n",
    "                        \"data_valor_total\": data_valor_total_final,\n",
    "                        \"data_CNAE\": data_CNAE_final,\n",
    "                        \"data_valores\": data_valores_final,\n",
    "                        \"data_dados_complementares\": data_dados_complementares_final,\n",
    "                        \"data_outras_informacoes\": data_outras_informacoes_final,\n",
    "                        \"data_observacao\": data_observacao_final,\n",
    "                    },\n",
    "                    \"diretorio\": dir_name, #os.path.basename(root)\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                    \"Batch\": batch_name,\n",
    "                    \"modelo\": model,\n",
    "                    \"pdf_realmente_pequisavel\": pdf_realmente_pequisavel,\n",
    "                    \"processo\": processo,\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao gerar o json: {e}\")\n",
    "                        #print(pdf_info) \n",
    "                    \n",
    "                                                 \n",
    "            pdf_document.close()    \n",
    "                    \n",
    "            i += 1\n",
    "            \n",
    "            print(\"i: \", i) \n",
    "     \n",
    "     \n",
    "     \n",
    "     \n",
    "                \n",
    "\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name + \"_\" + processo + \".json\"\n",
    "\n",
    "json_file_path = os.path.join(json_path, nome_formado_json )\n",
    "\n",
    "\n",
    "# Salvando as informações em um arquivo JSON (novo formato nome arquivo V2)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenha Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_image_2work = \"pipeline_extracao_documentos/6_geral_administacao/images/processadas/Doria Marinho 0297 Raquel.pdf.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw everything\n",
    "trattempl. draw_box_model(model, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nf_data_servico = {}#VERIFICAR\n",
    "# analise_doc_nf = {} #VERIFICAR\n",
    "# file_data = [] #VERIFICAR\n",
    "list_document_pages = []\n",
    "#nro_nota = 0\n",
    "# # TEMP\n",
    "# # Nome do arquivo json\n",
    "# nome_formado_json = batch_name +\".json\"\n",
    "#3. path formado para nome do arquivo json\n",
    "# json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "#root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "#print(root_doc_analise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.extrai_pdf_pesquisavel as Extc\n",
    "import modules.cronometro as cron\n",
    "import modules.trata_dicionarios as tratdic\n",
    "import modules.trata_imagem as tratimg\n",
    "import modules.trata_files as tratfiles\n",
    "import modules.trata_texto_extraido as trattext\n",
    "import modules.trata_template as trattemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # secao = \"1 - CABECALHO\"\n",
    "                    # try:\n",
    "                    #     nro_nota = 0\n",
    "                    #     data_cabecalho = {}\n",
    "                    #     data_cabecalho['secao'] = secao\n",
    "                    #     valor_dict = {}\n",
    "                    #     dados_prefeitura = {}\n",
    "                    #     f_frame_name = \"1_frame_prefeitura_nf\"\n",
    "                    #     # 1. funçao basica de modelo \n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #     text_splited = texto.split('\\n')\n",
    "                        \n",
    "                    #     valor_dict = extract_prefeitura(model, f_frame_name, text_splited)\n",
    "                    #     if valor_dict:\n",
    "                    #         dados_prefeitura.update(valor_dict)\n",
    "                    #     valor = {}   \n",
    "                    #     f_frame_name = \"1_frame_dados_nf\"\n",
    "                    #     dadinho_dados_nf = {}\n",
    "                    #     # 1. funçao basica de modelo \n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     text_splited = texto_extraido(texto)\n",
    "                    #     keyword_list = ['Número da Nota:', 'Competência:', 'Data e Hora da Emissão:', 'Código Verificação:']\n",
    "\n",
    "                    #     string_pesquisa = \"Número da Nota:\"\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)         \n",
    "                    #     dadinho_dados_nf['numero_nota_fiscal'] = texto\n",
    "                    #     nro_nota = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"Competência:\"\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     dadinho_dados_nf['competencia'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"ata e Hora da Emissão:\"\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     dadinho_dados_nf['dt_hr_emissao'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"Código Verificação:\"\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     dadinho_dados_nf['codigo_verificacao'] = texto\n",
    "                        \n",
    "                    #     data_cabecalho.update(dados_prefeitura)\n",
    "                    #     data_cabecalho.update(dadinho_dados_nf)\n",
    "                    # except Exception as e:\n",
    "                    #     erros_cabecalho = {}\n",
    "                    #     err_msg = f\"Erro de processo cabecalho: {e}\"\n",
    "                    #     erros['documento'] = file\n",
    "                    #     erros_cabecalho['secao'] = secao\n",
    "                    #     erros_cabecalho['erro'] = err_msg\n",
    "                    #     erros.update(erros_cabecalho)                \n",
    "                \n",
    "                    # secao = \"2. PRESTADOR DE SERVIÇO\"\n",
    "                    # try:\n",
    "                    #     f_frame_name = \"2_frame_cnpj_prestador\"\n",
    "                    #     data_prestador = {}\n",
    "                    #     prestador_inscricao = {}\n",
    "                    #     data_prestador['secao'] = secao\n",
    "                    #     prestador_cnpj_value = {}\n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     #text_splited = texto_extraido(texto)\n",
    "                    #     prestador_cnpj_value = extract_fields_prestador_cnpj(texto)\n",
    "                    #     if prestador_cnpj_value:\n",
    "                    #         data_prestador.update(prestador_cnpj_value)\n",
    "                    # except Exception as e:\n",
    "                    #     erros_cnpj_prestador = {}\n",
    "                    #     err_msg = (f\"Erro prestador cnpj: {e}\")\n",
    "                    #     erros_cnpj_prestador['secao'] = secao\n",
    "                    #     erros_cnpj_prestador['erro'] = err_msg\n",
    "                    #     erros.update(erros_cnpj_prestador)       \n",
    "                        \n",
    "                    # try:\n",
    "                    #     f_frame_name = \"2_frame_inscricao_prestador\" \n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     text_splited = texto_extraido(texto)\n",
    "                    #     keyword_list = ['Inscrição Municipal:', 'Inscrição Estadual:']\n",
    "                    #     string_pesquisa = \"Inscrição Municipal:\"\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     prestador_inscricao['prestador_inscricao'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"Inscrição Estadual:\"\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     prestador_inscricao['inscricao_estadual'] = texto\n",
    "                    #     data_prestador.update(prestador_inscricao)\n",
    "                    # except Exception as e:\n",
    "                    #     erros_inscricao_prestador = {}\n",
    "                    #     err_msg = (f\"Erro de processo inscricao prestador: {e}\")\n",
    "                    #     erros_inscricao_prestador['secao'] = secao\n",
    "                    #     erros_inscricao_prestador['erro'] = err_msg\n",
    "                    #     erros.update(erros_inscricao_prestador)\n",
    "\n",
    "                    # try:\n",
    "                    #     f_frame_name = \"2_frame_dados_prestador\"\n",
    "                    #     prestador_dados_value = {}\n",
    "                        \n",
    "                    #     keyword_list = ['Nome/Razão Social:', 'Nome de Fantasia:', 'Endereço:', 'E-mail:']\n",
    "                    #     string_pesquisa = \"Nome/Razão Social:\"\n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #     text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     prestador_dados_value['razao_social'] = texto\n",
    "\n",
    "                    #     string_pesquisa = \"Nome de Fantasia:\"\n",
    "                    #     #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #     #text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     prestador_dados_value['nome_fantasia'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"Endereço:\"\n",
    "                    #     #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #     #text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     prestador_dados_value['endereco'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"E-mail:\"\n",
    "                    #     #texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #     #text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     prestador_dados_value['email'] = texto\n",
    "                    #     data_prestador.update(prestador_dados_value)\n",
    "                        \n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro prestador dados: {e}\") \n",
    "                        \n",
    "                    \n",
    "                    # secao = \"3. TOMADOR DE SERVIÇO\"\n",
    "                    # try:\n",
    "                    #     data_tomador = {}\n",
    "                    #     tomador_cnpj_value = {}\n",
    "                    #     data_tomador['secao'] = secao\n",
    "                    #     f_frame_name = \"3_frame_cnpj_tomador\"\n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     text_splited = texto_extraido(texto) \n",
    "                    #     tomador_cnpj_value = extract_fields_tomador_cnpj(texto)\n",
    "                    #     if tomador_cnpj_value:\n",
    "                    #         data_tomador.update(tomador_cnpj_value)                  \n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro tomador cnpj: {e}\")\n",
    "                        \n",
    "                    # f_frame_name = \"3_frame_inscricao_tomador\"    \n",
    "                    # try:\n",
    "                    #     data_tomador_inscricao = {}\n",
    "                    #     keyword_list = ['RG:', 'Inscrição Estadual:']\n",
    "                    #     string_pesquisa = \"RG:\"\n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     data_tomador_inscricao['rg'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"Inscrição Estadual:\"\n",
    "                    #     #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     #text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     data_tomador_inscricao['inscricao_estadual'] = texto\n",
    "                    #     data_tomador.update(data_tomador_inscricao)\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro tomador inscricao: {e}\")\n",
    "                        \n",
    "                    # f_frame_name = \"3_frame_dados_tomador\"\n",
    "                    # try: \n",
    "                    #     data_tomador_dados = {}   \n",
    "                    #     keyword_list = ['Nome/Razão Social:', 'Endereço:', 'E-mail']\n",
    "                    #     string_pesquisa = \"Nome/Razão Social:\"\n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     data_tomador_dados['razao_social'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"Endereço:\"\n",
    "                    #     #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     #text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     data_tomador_dados['endereco'] = texto\n",
    "                        \n",
    "                    #     string_pesquisa = \"E-mail\"\n",
    "                    #     #texto = executa_model_frame(model, secao, f_frame_name)    \n",
    "                    #     #text_splited = texto_extraido(texto)\n",
    "                    #     texto = pesquisa_keyword(string_pesquisa, text_splited, keyword_list)\n",
    "                    #     data_tomador_dados['email'] = texto\n",
    "                        \n",
    "                    #     data_tomador.update(data_tomador_dados)\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro tomador dados: {e}\") \n",
    "                        \n",
    "                    # secao = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                    # try:\n",
    "                    #     data_servico = {}\n",
    "                    #     data_servico['secao'] = secao\n",
    "                    #     f_frame_name = \"4_frame_descricao_totais\"\n",
    "                    #     texto = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #     text = texto.replace('\\n', ' ')\n",
    "                    #     label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                    #     if text.startswith(label):\n",
    "                    #         text = text[len(label):].strip()\n",
    "                    #     data_servico['discriminacao_servicos'] = text \n",
    "\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro descricao servico: {e}\")\n",
    "                        \n",
    "                    # secao = \"5. VALOR TOTAL\"\n",
    "                    # try:\n",
    "                    #     data_valor_total = {}\n",
    "                    #     data_valor_total['secao'] = secao\n",
    "                    #     f_frame_name = \"4_frame_valor_total\"   \n",
    "                    #     text = executa_model_frame(model, secao, f_frame_name)  \n",
    "                    #     valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                    #     if valor_total_match:\n",
    "                    #         valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    #         data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro valor total: {e}\")\n",
    "\n",
    "                    # secao = \"6. CNAE e Item da Lista de Serviços\"\n",
    "                    # try:\n",
    "                    #     data_CNAE = {}\n",
    "                    #     data_CNAE['secao'] = secao\n",
    "                    #     f_frame_name = \"4_frame_cnae_itens_servico\"   \n",
    "                    #     Texto_extraido = executa_model_frame(model, secao, f_frame_name)\n",
    "                    #     text_splited = Texto_extraido.split('\\n')\n",
    "                    #     # Processando CNAE\n",
    "                    #     cnae_line = [line for line in text_splited if 'CNAE' in line][0]\n",
    "                    #     cnae_number = int(extract_number(cnae_line))\n",
    "                    #     cnae_value = cnae_dict.get(cnae_number, \"Valor não encontrado\")\n",
    "                    #     if cnae_value == 'Valor não encontrado':\n",
    "                    #         cnae_value = processa_cnae_outros(cnae_line)\n",
    "                    #         cnae_value = cnae_value.upper()\n",
    "                    #         data_CNAE['cnae'] = cnae_value\n",
    "                    #     else:\n",
    "                    #         cnae_value = cnae_value.upper()\n",
    "                    #         cnae_value = str(cnae_number) + \" - \" + cnae_value\n",
    "                    #         data_CNAE['cnae'] = cnae_value\n",
    "                    #         data_CNAE['item_lista_servicos'] = item_servico_value\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro busca cnae: {e}\")    \n",
    "            \n",
    "                    # try:\n",
    "                    #     item_servico_line = [line for line in text_splited if 'Item da Lista de Serviços' in line][0]\n",
    "                    #     item_servico_number = float(extract_number(item_servico_line))\n",
    "                    #     item_servico_value = item_servico_dict.get(item_servico_number, \"Valor não encontrado\")\n",
    "                    #     item_servico_value = item_servico_value.upper()\n",
    "                    #     item_servico_value = str(item_servico_number) + \" - \" + item_servico_value\n",
    "                    #     data_CNAE['item_lista_servicos'] = item_servico_value\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro busca Itens de servico: {e}\")  \n",
    "\n",
    "                    # secao = \"8. DADOS COMPLEMENTARES\"\n",
    "                    # try:\n",
    "                    #     data_valores = {}\n",
    "                    #     data_valores['secao'] = secao\n",
    "                    #     f_frame_name = \"5_frame_valores_impostos\"   \n",
    "                        \n",
    "                    #     result = extract_fields_box(model, f_frame_name, secao)\n",
    "                    #     if result:\n",
    "                    #         data_valores.update(result)\n",
    "                \n",
    "                    #     # secao: 8 - DADOS COMPLEMENTARES\"\n",
    "                    #     data_dados_complementares = {}\n",
    "                    #     f_frame_name  = \"5_frame_dados_complementares\"\n",
    "                    #     section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                    #     data_dados_complementares = extract_dados_comple_obs(model, f_frame_name, section)                                           \n",
    "                                                \n",
    "                                                \n",
    "                    #     # secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "                    #     data_outras_informacoes = {}\n",
    "                    #     father_value = \"5_frame_inf_criticas\"\n",
    "                    #     section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "                        \n",
    "                    #     result = extract_fb_outras_inf(model, father_value, section)\n",
    "                    #     if result:\n",
    "                    #         data_outras_informacoes.update(result)                        \n",
    "                                            \n",
    "                    #     # secao: 10. OBSERVACOES\n",
    "                    #     data_observacao = {}\n",
    "                    #     f_father = \"5_frame_observacao\"\n",
    "                    #     section = \"10. OBSERVACOES\"\n",
    "\n",
    "                    #     data_observacao = extract_dados_comple_obs(model, f_father, section)\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro valores complementares: {e}\")   \n",
    "                    \n",
    "                    # nome_arquivo = file\n",
    "                    # #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                    # try:\n",
    "                    #     pdf_info[nro_nota] = {\n",
    "                    #     \"dados_NF_PDF\": {\n",
    "                    #         \"data_cabecalho\": data_cabecalho,\n",
    "                    #         \"data_prestador\": data_prestador,\n",
    "                    #         \"data_tomador\": data_tomador,\n",
    "                    #         \"data_servico\": data_servico,\n",
    "                    #         \"data_valor_total\": data_valor_total,\n",
    "                    #         \"data_CNAE\": data_CNAE,\n",
    "                    #         \"data_valores\": data_valores,\n",
    "                    #         \"data_dados_complementares\": data_dados_complementares,\n",
    "                    #         \"data_outras_informacoes\": data_outras_informacoes,\n",
    "                    #         \"data_observacao\": data_observacao,\n",
    "                    #     },\n",
    "                    #     \"diretorio\": dir_name, #os.path.basename(root)\n",
    "                    #     \"nome_arquivo\": nome_arquivo,\n",
    "                    #     \"Batch\": batch_name,\n",
    "                    #     \"modelo\": model,\n",
    "                    # }\n",
    "                    # except Exception as e:\n",
    "                    #     print(f\"Erro ao gerar o json: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IMPORTANTE - NRO BATCH PARA TESTE    0 = PDF_PESQUISAVEL | 1 = RASTER_PDF\n",
    "\n",
    "i_test = 1\n",
    "\n",
    "tipo_pdf = []\n",
    "tipo_pdf.append('PDF_PESQUISAVEL')\n",
    "tipo_pdf.append('RASTER_PDF')\n",
    "tipo_pdf[i_test]\n",
    "\n",
    "\n",
    "# Tratamento do Path de ORIGEM DO DOCUMENTOS PARA TESTE QUE SERAO MOVIDOS\n",
    "list_path_test = []\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/pdf_pesquisavel_4_test\")\n",
    "list_path_test.append(\"pipeline_extracao_documentos/4_area_testes/raster_pdf_4_test\")\n",
    "list_path_test[i_test]\n",
    "\n",
    "# Frame para teste\n",
    "i_frame = 0\n",
    "\n",
    "frames_pesquisa = []\n",
    "# Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "filtered_frames_info = frames_info[frames_info['model'] == model]\n",
    "for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "    frame_name = row_frame['label']\n",
    "    frames_pesquisa.append(frame_name)\n",
    "\n",
    "# Nome Batch\n",
    "batch_name = \"Batch_\" + str(tipo_pdf[i_test]) + \"_\" + str(i_frame)\n",
    "\n",
    "# Nome do arquivo json\n",
    "nome_formado_json = batch_name +\".json\"\n",
    "\n",
    "# Listagem dos frames de pesquisa\n",
    "i = 0\n",
    "for frame in frames_pesquisa:\n",
    "    print(f'seq ={i:>3} | {frame}')\n",
    "    i += 1\n",
    "    \n",
    "if frames_pesquisa[i_frame]:\n",
    "    print(f'\\n\\nDados do teste: batch_name: {batch_name} | frame: {frames_pesquisa[i_frame]} | model: {model} | tipo_pdf: {tipo_pdf[i_test]}')\n",
    "    \n",
    "    \n",
    "######### PATHS\n",
    "#1. path formado para busca de pdfs recursiva\n",
    "root_doc_analise = os.path.join(documentos_extracao_path, batch_name)\n",
    "\n",
    "#2. path para documentos teste RASTER PDF (ATRIBIDO DA LISTA)\n",
    "path_test_pdf = list_path_test[1]\n",
    "\n",
    "#3. path formado para nome do arquivo json\n",
    "json_file_path = os.path.join(json_path, nome_formado_json)\n",
    "\n",
    "#Listando paths utilizados\n",
    "#print(f'\\nroot_doc_analise: {root_doc_analise}\\npath_test_pdf: {path_test_pdf}\\njson_file_path: {json_file_path}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import modules.trata_dicionarios as tratdic\n",
    "\n",
    "import modules.trata_files as tratfiles\n",
    "import modules.trata_texto_extraido as trattext\n",
    "import modules.trata_template as trattemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_info[nr_nro_nf] = {\n",
    "    \"dados_NF_PDF\": {\n",
    "        \"data_cabecalho\": nf_data_cabecalho,\n",
    "        \"data_prestador\": nf_data_prestador,\n",
    "        \"data_tomador\": nf_data_tomador,\n",
    "        \"data_servico\": nf_data_servico,\n",
    "        \"data_valor_total\": nf_data_valor_total,\n",
    "        \"data_CNAE\": nf_data_CNAE,\n",
    "        \"data_valores\": nf_data_valores,\n",
    "        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "        \"data_observacao\": nf_data_observacao,\n",
    "    },\n",
    "    \"diretorio\": os.path.basename(root),\n",
    "    \"nome_arquivo\": nome_arquivo,\n",
    "}\n",
    "\n",
    "\n",
    "pdf_document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nome_arquivo = \"teste\"\n",
    "\n",
    "    pdf_info[\"diretorio\"] = dir_name\n",
    "\n",
    "    pdf_info[nro_nota] = {\n",
    "        \"dados_NF_PDF\": {\n",
    "            \"data_cabecalho\": data_cabecalho_final,\n",
    "            \"data_prestador\": data_prestador_final,\n",
    "            \"data_tomador\": data_tomador_final,\n",
    "            \"data_servico\": data_servico_final,\n",
    "            \"data_valor_total\": data_valor_total_final,\n",
    "            \"data_CNAE\": data_CNAE_final,\n",
    "            \"data_valores\": data_valores_final,\n",
    "            \"data_dados_complementares\": data_dados_complementares_final,\n",
    "            \"data_outras_informacoes\": data_outras_informacoes_final,\n",
    "            \"data_observacao\": data_observacao_final,\n",
    "        },\n",
    "        \"diretorio\": dir_name, #os.path.basename(root)\n",
    "        \"nome_arquivo\": nome_arquivo,\n",
    "        \"Batch\": batch_name,\n",
    "        \"modelo\": model,\n",
    "        \"pdf_realmente_pequisavel\": pdf_realmente_pequisavel,\n",
    "        \"processo\": processo,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "            \n",
    "\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pdf_info[nro_nota] = {\n",
    "            \"dados_NF_PDF\": {\n",
    "            \"data_cabecalho\": data_cabecalho_final,\n",
    "            \"data_prestador\": data_prestador_final,\n",
    "            \"data_tomador\": data_tomador_final,\n",
    "            \"data_servico\": data_servico_final,\n",
    "            \"data_valor_total\": data_valor_total_final,\n",
    "            \"data_CNAE\": data_CNAE_final,\n",
    "            \"data_valores\": data_valores_final,\n",
    "            \"data_dados_complementares\": data_dados_complementares_final,\n",
    "            \"data_outras_informacoes\": data_outras_informacoes_final,\n",
    "            \"data_observacao\": data_observacao_final,\n",
    "        },\n",
    "        \"diretorio\": dir_name, #os.path.basename(root)\n",
    "        \"nome_arquivo\": nome_arquivo,\n",
    "        \"Batch\": batch_name,\n",
    "        \"modelo\": model,\n",
    "        \"pdf_realmente_pequisavel\": pdf_realmente_pequisavel,\n",
    "        \"processo\": processo,\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao gerar o json: {e}\")\n",
    "            #print(pdf_info) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
