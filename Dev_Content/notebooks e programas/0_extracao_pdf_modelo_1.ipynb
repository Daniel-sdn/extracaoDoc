{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracao PDFs - NFs de Servico MI - V1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detalhamento das funcionalidades ajustadas para documentos PDF pesquisaveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modelo Geraçao multiplos Arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Modulos e paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "import json\n",
    "import PyPDF2\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Path - Documentos PDF para Extracao e geracao de JSONS - <mark>producao</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Diretório raiz para documentos PDF pesquisaveis\n",
    "root_directory = '.\\\\data\\data_pdf\\NF_para_processamento'  # Diretório raiz \n",
    "\n",
    "\n",
    "#Diretório raiz para documentos geracao de JSON\n",
    "target_directory = '.\\\\data\\data_pdf\\Gravacao_json'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 <mark>TESTE</mark> - Path - Documentos PDF para Extracao e geracao de JSONS - <mark>TESTE</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretório TESTE raiz para documentos PDF pesquisaveis\n",
    "root_directory = '.\\\\data\\data_teste\\documentos_pdf_teste'  # Diretório raiz TESTE\n",
    "\n",
    "\n",
    "#Diretório raiz para documentos geracao de JSON TESTE\n",
    "target_directory = '.\\\\data\\data_teste\\documentos_pdf_teste'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretório raiz para documentos geracao de JSON TESTE\n",
    "root_directory = '.\\\\data\\data_teste\\documentos_pdf_teste\\mage'  # Diretório raiz TESTE\n",
    "\n",
    "target_directory = '.\\\\data\\data_teste\\documentos_pdf_teste\\mage'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Analise de arquivos e quantidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Analise de PDF Pesquisavel </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 1124 fogo em 20-07-23 cancelada.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 1127 fogo em 20-07-23.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 1128 desmonte em 01-08-23.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 1130.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 1131 fogo em 03-08-23.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 13 Nota Fiscal Eletrônica - Supermercado Santo Antônio - JUNHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 15 Nota Fiscal Eletrônica - CUNHA Julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 16 Nota Fiscal Eletrônica -KARYNE - JULHO (2).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 17 Nota Fiscal Eletrônica - Diogo Adv Julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 18 Nota Fiscal Eletrônica - MedLaser - JULHO (1).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 19 Nota Fiscal Eletrônica - Moema - JULHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 20 Nota Fiscal Eletrônica - PGL BIKES - jULHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 21 Nota Fiscal Eletrônica - HUB ODONTO - JULHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 218_VERDANT IMPERMEABILIZAÇÃO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 219_verdant pintura.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 22 Nota Fiscal Eletrônica - Da Cor Tintas - Julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 24 Nota Fiscal Eletrônica - Vivendo do Grão - JULHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 25 Nota Fiscal Eletrônica - Dom Papito - Julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 26 Nota Fiscal Eletrônica - LD IPHONE - JULHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 27 Nota Fiscal Eletrônica - Céu Doce - Julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 30 Nota Fiscal Eletrônica -Aldir Advogado.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 31 Nota Fiscal Eletrônica - Auto Escola Neumam - JULHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 32 Nota Fiscal Eletrônica - Evandro Santanna - Julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 4303E62C-D357-42B5-A505-F71494066BF0.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 47A11ADC-E2CC-4EDB-9329-875101A9D5F2.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 542.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 7A17914B-27E8-423B-AE9E-7EFD67971272.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 7B651105-D58E-4DFC-8577-D5B8257199F1.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 89BD77C8-2A1D-4927-AD08-AD12B1A7CA2A.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 8C85164D-E8F4-4DA2-98DD-BEBD5B463C49.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: 9FC379AB-6237-4AD1-A963-7C9BD4E51C60.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: A6AA65EC-839D-490B-BCA6-84552314D042.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Asap 0175 Ka Solution.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Asap 0175 Wilson Sons.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: C967E513-8C3F-4C63-9D7D-68154327FFFF.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: CFA1A4B7-9E7B-451D-96CA-72FAB107ED4B.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Doria Marinho 0295 Carlos Leandro.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Doria Marinho 0297 Raquel.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Doria Marinho 0298 Marcelo.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Doria Marinho 0299 Luciana.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Doria Marinho 0300 Vanisa.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Doria Marinho 0301 Ultrascan.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: F2C738D5-5E50-4A09-A12B-A1FF5161AF84.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Ftl 0028 Prestcon.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Helpful 0236 Intercompany.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Isi 0057 Itera.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: JULH-2023-NotaFiscal 2.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Listagem de NFS-e - Sintético IM 237881_104871 (1).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Listagem de NFS-e - Sintético IM 237881_104871.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Listagem de NFS-e - Sintético.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Listagem de notas fiscais pendentes.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Marina Pinheiro 0314 Elizabeth Sul.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Meta 0051 Globality.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: MI NF julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: MSV NF  julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: nf 1129.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 31 IBF.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 32 Arapar.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 33 Arapar.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6225.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6226.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6227.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6228.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6229.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6230.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6231.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6232.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6233.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6234.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6235.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6236.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6237.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6238.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6239.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6240.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6241.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6242.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 6243.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 688 - ConsoR Zadar- Engetecnica (ENZA).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 689- PMMacae- 8ª Med CO-22-22 TB Contrato 045-22.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 774 - BIOPLUS.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 775 - NOVA PINHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF 825 - PC-455 - PO 45-33079 - CTR 3724-23-TENDAS ESCRIT.SP.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NF-825 - EVENTO DOCE MARAVILHA - CTR-131723 - PROJETO-1883-23 - 60%.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NFe INSTALAÇÃO DE CFTV PATIO PRODUÇÃO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NFE MAGE MIN 20230730.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NFS-E 114.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NFS-E 115.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NFSE 232 - 28JULHO2023 - FIORAVANTE ARTES.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NFSe JL CONSTRUIR - 010 (PIABETA SPE LTDA).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NN NF julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: nota agosto (1).PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: nota fiscal 141 emissao 26 de julho (1).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NOTA FISCAL 15.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NOTA FISCAL 16.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: nota fiscal 37420230815_11212276.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: nota fiscal 37520230815_11272926.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NOTA FISCAL 376 CULTIVADORES.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NOTA FISCAL 377 DANIEL.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NOTA FISCAL 378.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: nota fiscal 37920230815_11235122.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: nota fiscal 38020230815_11244882.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Nota Fiscal Eletrônica (1).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Nota Fiscal Eletrônica - Alfa Cópias Julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Nota Fiscal Eletrônica N425 CONTRATUAL.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Nota Fiscal Eletrônica- Grupo Sophia - JULHO.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Nota Fiscal Eletrônica-INICIO-AGO-23.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Nota Fiscal Eletrônica.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: NOTA MATRIZ SERVIÇO ELETRICA (2).pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: notas medical maua.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: RELATÓRIO DE NOTAS FISCAIS.PDF, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Simec NF julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Somente 0065 Alymente.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: Techmuniz 0032 Sys Manager.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF não é pesquisável\n",
      "----------------------------------------\n",
      "Subdiretório: . \n",
      "\n",
      "Nome do arquivo: TN NF  julho.pdf, Tipo: PDF\n",
      "\n",
      "Status: O PDF é pesquisável\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "pdf_image_info = []  # Lista para armazenar informações sobre PDFs e imagens\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                pdf_image_info.append({\n",
    "                    \"subdiretorio\": os.path.relpath(root, root_directory),\n",
    "                    \"nome_arquivo\": file,\n",
    "                    \"tipo\": \"PDF\",\n",
    "                    \"status\": \"O PDF é pesquisável\"\n",
    "                })\n",
    "            else:\n",
    "                pdf_image_info.append({\n",
    "                    \"subdiretorio\": os.path.relpath(root, root_directory),\n",
    "                    \"nome_arquivo\": file,\n",
    "                    \"tipo\": \"PDF\",\n",
    "                    \"status\": \"O PDF não é pesquisável\"\n",
    "                })\n",
    "        elif any(file.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "            pdf_image_info.append({\n",
    "                \"subdiretorio\": os.path.relpath(root, root_directory),\n",
    "                \"nome_arquivo\": file,\n",
    "                \"tipo\": \"IMAGEM\"\n",
    "            })\n",
    "\n",
    "# Iterando e exibindo as informações coletadas\n",
    "for item in pdf_image_info:\n",
    "    print(f\"Subdiretório: {item['subdiretorio']} \\n\\nNome do arquivo: {item['nome_arquivo']}, Tipo: {item['tipo']}\")\n",
    "    if 'status' in item:\n",
    "        print(f\"\\nStatus: {item['status']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Analise de Quantitativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 0}\n",
      "{'total': 1, 'pdf_pesquisavel': 0, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 1, 'pdf_pesquisavel': 1, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 2, 'pdf_pesquisavel': 1, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 2, 'pdf_pesquisavel': 2, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 3, 'pdf_pesquisavel': 2, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 3, 'pdf_pesquisavel': 3, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 4, 'pdf_pesquisavel': 3, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 4, 'pdf_pesquisavel': 4, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 5, 'pdf_pesquisavel': 4, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 5, 'pdf_pesquisavel': 5, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 6, 'pdf_pesquisavel': 5, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 6, 'pdf_pesquisavel': 6, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 7, 'pdf_pesquisavel': 6, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 7, 'pdf_pesquisavel': 7, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 8, 'pdf_pesquisavel': 7, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 8, 'pdf_pesquisavel': 8, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 9, 'pdf_pesquisavel': 8, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 9, 'pdf_pesquisavel': 9, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 10, 'pdf_pesquisavel': 9, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 10, 'pdf_pesquisavel': 10, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 11, 'pdf_pesquisavel': 10, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 11, 'pdf_pesquisavel': 11, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 12, 'pdf_pesquisavel': 11, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 12, 'pdf_pesquisavel': 12, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 13, 'pdf_pesquisavel': 12, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 13, 'pdf_pesquisavel': 13, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 14, 'pdf_pesquisavel': 13, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 14, 'pdf_pesquisavel': 14, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 15, 'pdf_pesquisavel': 14, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 15, 'pdf_pesquisavel': 15, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 16, 'pdf_pesquisavel': 15, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 16, 'pdf_pesquisavel': 16, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 17, 'pdf_pesquisavel': 16, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 17, 'pdf_pesquisavel': 17, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 18, 'pdf_pesquisavel': 17, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 18, 'pdf_pesquisavel': 18, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 19, 'pdf_pesquisavel': 18, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 19, 'pdf_pesquisavel': 19, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 20, 'pdf_pesquisavel': 19, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 20, 'pdf_pesquisavel': 20, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 21, 'pdf_pesquisavel': 20, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 21, 'pdf_pesquisavel': 21, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 22, 'pdf_pesquisavel': 21, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 22, 'pdf_pesquisavel': 22, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 23, 'pdf_pesquisavel': 22, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 23, 'pdf_pesquisavel': 23, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 24, 'pdf_pesquisavel': 23, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 24, 'pdf_pesquisavel': 24, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 25, 'pdf_pesquisavel': 24, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 25, 'pdf_pesquisavel': 25, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 26, 'pdf_pesquisavel': 25, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 26, 'pdf_pesquisavel': 26, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 27, 'pdf_pesquisavel': 26, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 27, 'pdf_pesquisavel': 27, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 28, 'pdf_pesquisavel': 27, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 28, 'pdf_pesquisavel': 28, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 29, 'pdf_pesquisavel': 28, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 29, 'pdf_pesquisavel': 29, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 30, 'pdf_pesquisavel': 29, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 30, 'pdf_pesquisavel': 30, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 31, 'pdf_pesquisavel': 30, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 31, 'pdf_pesquisavel': 31, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 32, 'pdf_pesquisavel': 31, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 32, 'pdf_pesquisavel': 32, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 33, 'pdf_pesquisavel': 32, 'pdf_nao_pesquisavel': 0}\n",
      "{'total': 34, 'pdf_pesquisavel': 32, 'pdf_nao_pesquisavel': 1}\n",
      "{'total': 35, 'pdf_pesquisavel': 32, 'pdf_nao_pesquisavel': 2}\n",
      "{'total': 35, 'pdf_pesquisavel': 33, 'pdf_nao_pesquisavel': 2}\n",
      "{'total': 36, 'pdf_pesquisavel': 33, 'pdf_nao_pesquisavel': 2}\n",
      "{'total': 36, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 2}\n",
      "{'total': 37, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 2}\n",
      "{'total': 38, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 3}\n",
      "{'total': 39, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 4}\n",
      "{'total': 40, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 5}\n",
      "{'total': 41, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 6}\n",
      "{'total': 42, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 7}\n",
      "{'total': 43, 'pdf_pesquisavel': 34, 'pdf_nao_pesquisavel': 8}\n",
      "{'total': 43, 'pdf_pesquisavel': 35, 'pdf_nao_pesquisavel': 8}\n",
      "{'total': 44, 'pdf_pesquisavel': 35, 'pdf_nao_pesquisavel': 8}\n",
      "{'total': 45, 'pdf_pesquisavel': 35, 'pdf_nao_pesquisavel': 9}\n",
      "{'total': 46, 'pdf_pesquisavel': 35, 'pdf_nao_pesquisavel': 10}\n",
      "{'total': 47, 'pdf_pesquisavel': 35, 'pdf_nao_pesquisavel': 11}\n",
      "{'total': 48, 'pdf_pesquisavel': 35, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 48, 'pdf_pesquisavel': 36, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 49, 'pdf_pesquisavel': 36, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 49, 'pdf_pesquisavel': 37, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 50, 'pdf_pesquisavel': 37, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 50, 'pdf_pesquisavel': 38, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 51, 'pdf_pesquisavel': 38, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 51, 'pdf_pesquisavel': 39, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 52, 'pdf_pesquisavel': 39, 'pdf_nao_pesquisavel': 12}\n",
      "{'total': 53, 'pdf_pesquisavel': 39, 'pdf_nao_pesquisavel': 13}\n",
      "{'total': 54, 'pdf_pesquisavel': 39, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 54, 'pdf_pesquisavel': 40, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 55, 'pdf_pesquisavel': 40, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 55, 'pdf_pesquisavel': 41, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 56, 'pdf_pesquisavel': 41, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 56, 'pdf_pesquisavel': 42, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 57, 'pdf_pesquisavel': 42, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 57, 'pdf_pesquisavel': 43, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 58, 'pdf_pesquisavel': 43, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 58, 'pdf_pesquisavel': 44, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 59, 'pdf_pesquisavel': 44, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 59, 'pdf_pesquisavel': 45, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 60, 'pdf_pesquisavel': 45, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 60, 'pdf_pesquisavel': 46, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 61, 'pdf_pesquisavel': 46, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 61, 'pdf_pesquisavel': 47, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 62, 'pdf_pesquisavel': 47, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 62, 'pdf_pesquisavel': 48, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 63, 'pdf_pesquisavel': 48, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 63, 'pdf_pesquisavel': 49, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 64, 'pdf_pesquisavel': 49, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 64, 'pdf_pesquisavel': 50, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 65, 'pdf_pesquisavel': 50, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 65, 'pdf_pesquisavel': 51, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 66, 'pdf_pesquisavel': 51, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 66, 'pdf_pesquisavel': 52, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 67, 'pdf_pesquisavel': 52, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 67, 'pdf_pesquisavel': 53, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 68, 'pdf_pesquisavel': 53, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 68, 'pdf_pesquisavel': 54, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 69, 'pdf_pesquisavel': 54, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 69, 'pdf_pesquisavel': 55, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 70, 'pdf_pesquisavel': 55, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 70, 'pdf_pesquisavel': 56, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 71, 'pdf_pesquisavel': 56, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 71, 'pdf_pesquisavel': 57, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 72, 'pdf_pesquisavel': 57, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 72, 'pdf_pesquisavel': 58, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 73, 'pdf_pesquisavel': 58, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 73, 'pdf_pesquisavel': 59, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 74, 'pdf_pesquisavel': 59, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 74, 'pdf_pesquisavel': 60, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 75, 'pdf_pesquisavel': 60, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 75, 'pdf_pesquisavel': 61, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 76, 'pdf_pesquisavel': 61, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 76, 'pdf_pesquisavel': 62, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 77, 'pdf_pesquisavel': 62, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 77, 'pdf_pesquisavel': 63, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 78, 'pdf_pesquisavel': 63, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 78, 'pdf_pesquisavel': 64, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 79, 'pdf_pesquisavel': 64, 'pdf_nao_pesquisavel': 14}\n",
      "{'total': 80, 'pdf_pesquisavel': 64, 'pdf_nao_pesquisavel': 15}\n",
      "{'total': 81, 'pdf_pesquisavel': 64, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 81, 'pdf_pesquisavel': 65, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 82, 'pdf_pesquisavel': 65, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 82, 'pdf_pesquisavel': 66, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 83, 'pdf_pesquisavel': 66, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 83, 'pdf_pesquisavel': 67, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 84, 'pdf_pesquisavel': 67, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 84, 'pdf_pesquisavel': 68, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 85, 'pdf_pesquisavel': 68, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 85, 'pdf_pesquisavel': 69, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 86, 'pdf_pesquisavel': 69, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 86, 'pdf_pesquisavel': 70, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 87, 'pdf_pesquisavel': 70, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 87, 'pdf_pesquisavel': 71, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 88, 'pdf_pesquisavel': 71, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 88, 'pdf_pesquisavel': 72, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 89, 'pdf_pesquisavel': 72, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 89, 'pdf_pesquisavel': 73, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 90, 'pdf_pesquisavel': 73, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 90, 'pdf_pesquisavel': 74, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 91, 'pdf_pesquisavel': 74, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 91, 'pdf_pesquisavel': 75, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 92, 'pdf_pesquisavel': 75, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 92, 'pdf_pesquisavel': 76, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 93, 'pdf_pesquisavel': 76, 'pdf_nao_pesquisavel': 16}\n",
      "{'total': 94, 'pdf_pesquisavel': 76, 'pdf_nao_pesquisavel': 17}\n",
      "{'total': 94, 'pdf_pesquisavel': 77, 'pdf_nao_pesquisavel': 17}\n",
      "{'total': 95, 'pdf_pesquisavel': 77, 'pdf_nao_pesquisavel': 17}\n",
      "{'total': 95, 'pdf_pesquisavel': 78, 'pdf_nao_pesquisavel': 17}\n",
      "{'total': 96, 'pdf_pesquisavel': 78, 'pdf_nao_pesquisavel': 17}\n",
      "{'total': 97, 'pdf_pesquisavel': 78, 'pdf_nao_pesquisavel': 18}\n",
      "{'total': 98, 'pdf_pesquisavel': 78, 'pdf_nao_pesquisavel': 19}\n",
      "{'total': 98, 'pdf_pesquisavel': 79, 'pdf_nao_pesquisavel': 19}\n",
      "{'total': 99, 'pdf_pesquisavel': 79, 'pdf_nao_pesquisavel': 19}\n",
      "{'total': 99, 'pdf_pesquisavel': 80, 'pdf_nao_pesquisavel': 19}\n",
      "{'total': 100, 'pdf_pesquisavel': 80, 'pdf_nao_pesquisavel': 19}\n",
      "{'total': 100, 'pdf_pesquisavel': 81, 'pdf_nao_pesquisavel': 19}\n",
      "{'total': 101, 'pdf_pesquisavel': 81, 'pdf_nao_pesquisavel': 19}\n",
      "{'total': 102, 'pdf_pesquisavel': 81, 'pdf_nao_pesquisavel': 20}\n",
      "{'total': 103, 'pdf_pesquisavel': 81, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 103, 'pdf_pesquisavel': 82, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 104, 'pdf_pesquisavel': 82, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 104, 'pdf_pesquisavel': 83, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 105, 'pdf_pesquisavel': 83, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 105, 'pdf_pesquisavel': 84, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 106, 'pdf_pesquisavel': 84, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 106, 'pdf_pesquisavel': 85, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 107, 'pdf_pesquisavel': 85, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 107, 'pdf_pesquisavel': 86, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 108, 'pdf_pesquisavel': 86, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 108, 'pdf_pesquisavel': 87, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 109, 'pdf_pesquisavel': 87, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 109, 'pdf_pesquisavel': 88, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 110, 'pdf_pesquisavel': 88, 'pdf_nao_pesquisavel': 21}\n",
      "{'total': 111, 'pdf_pesquisavel': 88, 'pdf_nao_pesquisavel': 22}\n",
      "{'total': 111, 'pdf_pesquisavel': 89, 'pdf_nao_pesquisavel': 22}\n",
      "{'total': 112, 'pdf_pesquisavel': 89, 'pdf_nao_pesquisavel': 22}\n",
      "{'total': 112, 'pdf_pesquisavel': 90, 'pdf_nao_pesquisavel': 22}\n",
      "{'total': 113, 'pdf_pesquisavel': 90, 'pdf_nao_pesquisavel': 22}\n",
      "{'total': 114, 'pdf_pesquisavel': 90, 'pdf_nao_pesquisavel': 23}\n",
      "{'total': 115, 'pdf_pesquisavel': 90, 'pdf_nao_pesquisavel': 24}\n",
      "{'total': 115, 'pdf_pesquisavel': 91, 'pdf_nao_pesquisavel': 24}\n"
     ]
    }
   ],
   "source": [
    "# Analise de PDFs \n",
    "import os\n",
    "import fitz  # Módulo PyMuPDF\n",
    "\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "pdf_image_info = {}  # Dicionário para armazenar informações sobre PDFs e imagens\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    dir_name = os.path.basename(root)  # Nome do diretório no último nível\n",
    "    pdf_image_info[dir_name] = pdf_image_info.get(dir_name, {\"total\": 0})\n",
    "    print(pdf_image_info[dir_name])\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                status = \"O PDF é pesquisável\"\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"\n",
    "                \n",
    "            pdf_image_info[dir_name][\"total\"] += 1\n",
    "            pdf_image_info[dir_name].setdefault(\"pdf_pesquisavel\", 0)\n",
    "            pdf_image_info[dir_name].setdefault(\"pdf_nao_pesquisavel\", 0)\n",
    "            print(pdf_image_info[dir_name])\n",
    "            \n",
    "            if status == \"O PDF é pesquisável\":\n",
    "                pdf_image_info[dir_name][\"pdf_pesquisavel\"] += 1\n",
    "                print(pdf_image_info[dir_name])\n",
    "            else:\n",
    "                pdf_image_info[dir_name][\"pdf_nao_pesquisavel\"] += 1\n",
    "        elif any(file.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "            pdf_image_info[dir_name].setdefault(\"total\", 0)\n",
    "            pdf_image_info[dir_name].setdefault(\"imagens\", 0)\n",
    "            pdf_image_info[dir_name][\"total\"] += 1\n",
    "            pdf_image_info[dir_name].setdefault(\"imagens\", 0)\n",
    "            pdf_image_info[dir_name][\"imagens\"] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#json_file_path = os.path.join(target_directory, f\"{os.path.splitext(file)[0]}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf in pdf_image_info.items():\n",
    "    print(pdf[0])\n",
    "    #diretorio = key\n",
    "    #print(diretorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in pdf_image_info.items():\n",
    "    \n",
    "    diretorio = key\n",
    "    print(diretorio)\n",
    "    #if key == \"SPA 15082023\":\n",
    "    #    print(key, value)\n",
    "        \n",
    "    #print(key, value)\n",
    "    #print(f\"Subdiretório: {item('dir_name')} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As informações foram salvas em .\\data\\data_teste\\documentos_pdf_teste\\mage\\pdf_image_info.json\n"
     ]
    }
   ],
   "source": [
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"pdf_image_info.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(pdf_image_info, json_file, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_image_info.items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Processo gravando um unico arquivo <mark>leioute geral</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_impostos(text):\n",
    "    nf_data_valores = {}\n",
    "    nf_data_valores['secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_servicos'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['valor_servicos'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_deducao'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_deducao'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_incond'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_incond'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['base_calculo'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['base_calculo'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['aliquota'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['aliquota'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss_retido'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss_retido'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_cond'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_cond'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_pis'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_pis'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_cofins'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_cofins'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_ir'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_ir'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_inss'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_inss'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_csll'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_csll'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['outras_retencoes'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['outras_retencoes'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_liquido'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_liquido'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Pesquisa e gravacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As informações foram salvas em .\\data\\data_teste\\documentos_pdf_teste\\mage\\mage.json\n"
     ]
    }
   ],
   "source": [
    "nf_data_servico = {}\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                nro_nota = 0\n",
    "                nr_nro_nf = 0\n",
    "                \n",
    "                #Definindo a pagina\n",
    "                # Carregar o arquivo PDF\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                # Página do PDF\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 4\n",
    "                x1 = 600\n",
    "                y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                if text:\n",
    "                    page_number = 0\n",
    "                else:\n",
    "                    page_number = 1\n",
    "                \n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                #pdf_document = fitz.open(file_path)\n",
    "                #page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho, nro_nota = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 530\n",
    "                x1 = 600\n",
    "                y1 = 540  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 545\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                nr_nro_nf = nro_nota\n",
    "                \n",
    "                nome_arquivo_json = os.path.basename(root) + \".json\"\n",
    "                \n",
    "                #json_file_path = os.path.join(target_directory, diretorio, \".json\")\n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[nr_nro_nf] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, nome_arquivo_json)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNAE demais notas\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outras funçoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"data\\data_teste\\documentos_pdf_teste\\SPA 15082023\\junto 1822 (5).pdf\"\n",
    "\n",
    "# Carregar o arquivo PDF\n",
    "pdf_document = fitz.open(file)\n",
    "\n",
    "# Página do PDF\n",
    "page_number = 1  # Defina o número da página que deseja analisar\n",
    "page = pdf_document[page_number]\n",
    "\n",
    "# Definir retângulo de interesse\n",
    "x0 = 0\n",
    "y0 = 4\n",
    "x1 = 600\n",
    "y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "# Extrair texto dentro do retângulo\n",
    "text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "if text:\n",
    "    print(text)\n",
    "else:\n",
    "    print(\"nao tem nada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"pdf_info_novissimo.json\")\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leioute Modernizacao Informatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 1. CABECALHO\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['nome_prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['tipo_nota_fiscal'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nr_nro_nf = numero_nota_match.group(1)\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = numero_nota_match.group(1)\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['codigo_verificacao'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "def extract_fields_prestador(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    nf_data_prestador = {}\n",
    "    \n",
    "    nf_data_prestador['secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['inscricao_estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador['telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['razao_social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['nome_fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['email'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['email'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_tomador(text):\n",
    "    nf_data_tomador = {}\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['rg'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['rg'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['inscricao_estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['razao_social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['email'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['email'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_impostos(text):\n",
    "    nf_data_valores = {}\n",
    "    nf_data_valores['secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_servicos'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['valor_servicos'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_deducao'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_deducao'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_incond'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_incond'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['base_calculo'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['base_calculo'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['aliquota'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['aliquota'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss_retido'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss_retido'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_cond'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_cond'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_pis'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_pis'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_cofins'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_cofins'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_ir'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_ir'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_inss'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_inss'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_csll'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_csll'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['outras_retencoes'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['outras_retencoes'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_liquido'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_liquido'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes\n",
    "\n",
    "\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 5\n",
    "                x1 = 600\n",
    "                y1 = 400\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                # 6. CNAE\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['secao'] = \"6. CNAE\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                text = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_CNAE['cnae'] = text.strip()\n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 545  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 540\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"MAGEfwdnotasfiscaiscarrier.json\")\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretório TESTE raiz para documentos PDF pesquisaveis\n",
    "root_directory = '.\\\\data\\data_teste'  # Diretório raiz TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"data\\data_teste\\documentos_pdf_teste\\SPA 15082023\\junto 1822 (5).pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\".\\data\\data_teste\\documentos_pdf_teste\\272519EC-959B-4460-BBE6-D80D272B9ACD.PDF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"data\\data_teste\\documentos_pdf_teste\\SPA 15082023\\junto 1822 (5).pdf\"\n",
    "\n",
    "# Carregar o arquivo PDF\n",
    "pdf_document = fitz.open(file)\n",
    "\n",
    "# Página do PDF\n",
    "page_number = 1  # Defina o número da página que deseja analisar\n",
    "page = pdf_document[page_number]\n",
    "\n",
    "# Definir retângulo de interesse\n",
    "x0 = 0\n",
    "y0 = 4\n",
    "x1 = 600\n",
    "y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "# Extrair texto dentro do retângulo\n",
    "text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "if text:\n",
    "    print(text)\n",
    "else:\n",
    "    print(\"nao tem nada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processo gravando multiplos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Funcoes de extracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analise PDF + extracao + gravaÇao arquivos JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                \n",
    "                #pdf_info = {}  # Crie um novo dicionário para cada PDF\n",
    "                \n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                # 6. CNAE\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['secao'] = \"6. CNAE\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                text = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_CNAE['cnae'] = text.strip()\n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 545  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 540\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                \n",
    "                #nome_arquivo = pdf_info[file]\n",
    "                \n",
    "                \n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "                \n",
    "                \n",
    "                # Salvando as informações em um arquivo JSON\n",
    "                #json_file_path = os.path.join(root_directory, \"pdf_info4.json\")\n",
    "                #with open(target_directory, \"w\", encoding='utf-8') as json_file:\n",
    "                #    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "                #print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            \n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"      \n",
    "                \n",
    "                \n",
    "                \n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"pdf_data_3.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(pdf_image_info, json_file, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")                \n",
    "          \n",
    "               \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                pdf_info[file] = {\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(root_directory, \"pdf_info.json\")\n",
    "\n",
    "\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotina para salvar em varios arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Remover caracteres especiais e substituir espaços por underscores\n",
    "                cleaned_filename = unidecode(file)\n",
    "                cleaned_filename = re.sub(r'\\W+', '_', cleaned_filename)\n",
    "                cleaned_filename = cleaned_filename.replace(\"_\", \" \").strip()\n",
    "                cleaned_filename = \"_\".join(cleaned_filename.split())\n",
    "                \n",
    "                json_file_path = os.path.join(target_directory, f\"{os.path.splitext(cleaned_filename)[0]}.json\")\n",
    "                \n",
    "                with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "                    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "                \n",
    "                print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funcoes de arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_json(pdf_path, text):\n",
    "    json_data = {\n",
    "        \"pdf_name\": os.path.basename(pdf_path),\n",
    "        \"text\": text\n",
    "    }\n",
    "    json_filename = pdf_path.with_suffix(\".json\")\n",
    "    with open(json_filename, \"w\") as json_file:\n",
    "        json.dump(json_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def process_pdfs_in_directory(directory_path):\n",
    "    pdf_paths = Path(directory_path).glob(\"*.pdf\")\n",
    "    for pdf_path in pdf_paths:\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        save_as_json(pdf_path, text)\n",
    "        print(f\"Created JSON for {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codigos anteriores (AVALIAR REDUNDANCIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "import json\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "\n",
    "\n",
    "nf_data_servico = {}\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['Origem'] = \"reserrosistemaprefeituranf.zip\"\n",
    "    nf_data_cabecalho['Secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['Nome da Prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['Tipo de NF'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nf_data_cabecalho['Número da Nota'] = numero_nota_match.group(1)\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['Competência'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['Data e Hora de Emissão'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['Código Verificação'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "nf_data_prestador = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_prestador(text):\n",
    "    \n",
    "    nf_data_prestador['Secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['CPF/CNPJ Formatado'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['CPF/CNPJ Sem Máscara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['Inscrição Municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['Inscrição Estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['Inscrição Estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match:\n",
    "        nf_data_prestador['Telefone'] = telefone_match.group(1)\n",
    "    else:\n",
    "        nf_data_prestador['Telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['Nome/Razão Social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['Nome de Fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['Endereço '] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['E-mail'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['E-mail'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "nf_data_tomador = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_tomador(text):\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['Secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['1-CPF/CNPJ Formatado'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['2-CPF/CNPJ Sem Máscara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['RG'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['RG'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['Telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['Telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['Inscrição Municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['Inscrição Estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['Inscrição Estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['Nome/Razão Social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['Endereço '] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['E-mail'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['E-mail'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "nf_data_valores = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_impostos(text):\n",
    "    \n",
    "    \n",
    "    nf_data_valores['Secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR SERVIÇOS'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['VALOR SERVIÇOS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR DEDUÇÃO'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR DEDUÇÃO'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['DESC. INCOND'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['DESC. INCOND'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['BASE DE CÁLCULO'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['BASE DE CÁLCULO'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['ALÍQUOTA'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['ALÍQUOTA'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR ISS'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR ISS'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR ISS RETIDO'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR ISS RETIDO'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['DESC. COND'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['DESC. COND'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR PIS'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR PIS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR COFINS'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR COFINS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR IR'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR IR'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR INSS'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR INSS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR CSLL'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR CSLL'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['OUTRAS RETENÇÕES'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['OUTRAS RETENÇÕES'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR LÍQUIDO'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR LÍQUIDO'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "nf_data_outras_informacoes = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_outras_info(text):\n",
    "    \n",
    "    nf_data_outras_informacoes['Secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['EXIGIBILIDADE ISS'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['REGIME TRIBUTAÇÃO'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['SIMPLES NACIONAL'] = simples_nacional_value\n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['LOCAL PRESTAÇÃO SERVIÇO'] = local_prestacao_servico_value\n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['LOCAL INCIDÊNCIA'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root_directory = '.\\\\Extracao_PDF_NF'  # Diretório raiz\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['Secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_servico['DISCRIMINAÇÃO DOS SERVIÇOS'] = text.strip()\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['Secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['VALOR TOTAL DA NOTA'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                # 6. CNAE\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                text = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_CNAE['CNAE'] = text.strip()    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['Secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['DADOS COMPLEMENTARES'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['DADOS COMPLEMENTARES'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['Secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['Observação'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                pdf_info[file] = {\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "                # Monta o caminho para o arquivo JSON com base no nome do arquivo da NF\n",
    "                json_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.json\")\n",
    "                \n",
    "                with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "                    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "                \n",
    "                print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root_directory = '.\\\\Extracao_PDF_NF'  # Diretório raiz\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "# Função para verificar se o PDF é pesquisável (você deve implementar isso)\n",
    "def is_pdf_searchable(file_path):\n",
    "    # Implemente a lógica para verificar se o PDF é pesquisável\n",
    "    # Retorne True se for pesquisável, False caso contrário\n",
    "    pass\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                # Aqui você pode continuar com o restante do seu código\n",
    "                # Preencha os dados que deseja extrair do PDF e armazene no dicionário pdf_info\n",
    "                \n",
    "                pdf_info[file] = {\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        # ... Preencha os dados da nota fiscal aqui ...\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "                # Monta o caminho para o arquivo JSON com base no nome do arquivo da NF\n",
    "                json_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.json\")\n",
    "                \n",
    "                with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "                    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "                \n",
    "                print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdftool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
