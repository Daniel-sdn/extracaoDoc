{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucao Extracao pdf v2\n",
    "\n",
    "0_solucao_extracao_pdf_v2.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modulos, config e dicionarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from unicodedata import normalize\n",
    "import PyPDF2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import ImageFont\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. path para documentos PDF (omelhor se estiverem dentro de um unico diretorio)\n",
    "root_pdf_path = \"novo_modelo/data_pdf\"\n",
    "\n",
    "# 2. path para documentos PDF que podem estar aguardando para serem processados\n",
    "root_pdf_aguardando_path = \"novo_modelo/pdf_aguardando_processar\"\n",
    "\n",
    "# 3. path para documentos PDF externos para serem processados\n",
    "root_external_pdf_path = \"content_from_pdftool/data/data_pdf/NF_para_processamento/NFRJ_PDF_para _ocr\"\n",
    "\n",
    "# 4. path para documentos PDF PESQUISAVEIS externos para serem processados\n",
    "root_external_pdf_pesquisavel_path = \"content_from_pdftool/data/data_pdf/NF_processadas/NFRJ/fwdnotasfiscaisemitidaslmpadalegal\"\n",
    "\n",
    "\n",
    "# 5. path para imagem padrao\n",
    "image_resized_path = 'novo_modelo/images/processadas'\n",
    "\n",
    "# 6. path para log\n",
    "log_path = 'novo_modelo/logs'\n",
    "\n",
    "\n",
    "# 7. path para arquivos json\n",
    "json_path = \"novo_modelo/jsons\"\n",
    "\n",
    "# 8. path para NFs processadas\n",
    "nf_processada_path = \"novo_modelo/pdf_processado\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### paths de objetos para criacao/gestao (dicionarios/datasets)\n",
    "\n",
    "# 9. path para modelos\n",
    "nf_model_path = \"novo_modelo/modelos/frames_nf_v5_mage1.xlsx\"\n",
    "\n",
    "# 10. path para dicionario de modelos\n",
    "model_dict_path = \"novo_modelo/modelos/models.csv\"\n",
    "\n",
    "# 11. path para datasets CNAE e Itens de Serviço\n",
    "nf_datasets_path = \"novo_modelo/datasets\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# VERIFICAR\n",
    "tgt_imagens = \"novo_modelo/images\"\n",
    "\n",
    "# 12. poppler path\n",
    "poppler_path = \"/home/dani-boy/miniconda3/envs/tables-detr/bin\"\n",
    "\n",
    "# 13. path para config Tesseract\n",
    "tessdata_dir_config = '--tessdata-dir \"/home/dani-boy/miniconda3/envs/tables-detr/share/tessdata/\" --user-patterns \"novo_modelo/modelos/user-patterns2.txt\" --dpi 600 --oem 3 --psm 6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "\n",
    "# Get the current date for filename\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "log_filename = f\"log_{current_date}.txt\"\n",
    "\n",
    "log_file_path = os.path.join(log_path, log_filename)\n",
    "\n",
    "\n",
    "# Configure the logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%d/%m/%Y %H:%M:%S',  \n",
    "    filename=log_file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dicionarios de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Leitura do arquivo CSV e criação do dicionário modelos\n",
    "def create_model_dictionary(model_dict_path):\n",
    "    model_dictionary = {}\n",
    "    with open(model_dict_path, 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "        for row in csvreader:\n",
    "            prefeitura_name = row['prefeitura']\n",
    "            model_name = row['model']\n",
    "\n",
    "            if prefeitura_name not in model_dictionary:\n",
    "                model_dictionary[prefeitura_name] = model_name\n",
    "            \n",
    "            #model_dictionary[prefeitura_name].append(model_name)\n",
    "    \n",
    "    return model_dictionary\n",
    "\n",
    "\n",
    "# 3. Cria o dict de modelos\n",
    "model_dict = create_model_dictionary(model_dict_path) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Le a planilha e cria do DF\n",
    "frames_nf_v3_df = pd.read_excel(nf_model_path)\n",
    "\n",
    "# Cria dicionários para armazenar diferentes tipos de elementos do modelo\n",
    "document_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'document'].iloc[0]\n",
    "boundaries_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'boundaries']\n",
    "sections_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'section']\n",
    "frames_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'frame']\n",
    "sframe_fields_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'sframe_field']\n",
    "field_boxes_info = frames_nf_v3_df[frames_nf_v3_df['type'] == 'field_box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seq</th>\n",
       "      <th>type</th>\n",
       "      <th>color</th>\n",
       "      <th>box</th>\n",
       "      <th>t_value</th>\n",
       "      <th>father</th>\n",
       "      <th>label</th>\n",
       "      <th>reference</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>Largura</th>\n",
       "      <th>Altura</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>4</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_prefeitura_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>8</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1_section_cabecalho_nf</td>\n",
       "      <td>1_frame_dados_nf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>14</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_cnpj_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>18</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_inscricao_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>21</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_section_prestador_servico</td>\n",
       "      <td>2_frame_dados_prestador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>27</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_cnpj_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>32</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_inscricao_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>550.0</td>\n",
       "      <td>785.0</td>\n",
       "      <td>1357.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>35</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3_section_tomador_servico</td>\n",
       "      <td>3_frame_dados_tomador</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1154.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>40</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_descricao_totais</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>42</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_valor_total</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1743.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1852.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>44</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_section_servicos_totais</td>\n",
       "      <td>4_frame_cnae_itens_servico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2067.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>48</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5_section_valores_dados</td>\n",
       "      <td>5_frame_valores_impostos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1609.0</td>\n",
       "      <td>323.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>65</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_dados_complementares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>67</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_inf_criticas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>mage_1</td>\n",
       "      <td>74</td>\n",
       "      <td>frame</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6_section_inf_complementares_criticas</td>\n",
       "      <td>5_frame_observacao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148.0</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>1922.0</td>\n",
       "      <td>2676.0</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  seq   type   color  box t_value  \\\n",
       "3   mage_1    4  frame  purple  yes     NaN   \n",
       "7   mage_1    8  frame  purple  yes     NaN   \n",
       "13  mage_1   14  frame  purple  yes     NaN   \n",
       "17  mage_1   18  frame  purple  yes     NaN   \n",
       "20  mage_1   21  frame  purple  yes     NaN   \n",
       "26  mage_1   27  frame  purple  yes     NaN   \n",
       "31  mage_1   32  frame  purple  yes     NaN   \n",
       "34  mage_1   35  frame  purple  yes     NaN   \n",
       "39  mage_1   40  frame  purple  yes     NaN   \n",
       "41  mage_1   42  frame  purple  yes     NaN   \n",
       "43  mage_1   44  frame  purple  yes     NaN   \n",
       "47  mage_1   48  frame  purple  yes     NaN   \n",
       "64  mage_1   65  frame  purple  yes     NaN   \n",
       "66  mage_1   67  frame  purple  yes     NaN   \n",
       "73  mage_1   74  frame  purple  NaN     NaN   \n",
       "\n",
       "                                   father                         label  \\\n",
       "3                  1_section_cabecalho_nf         1_frame_prefeitura_nf   \n",
       "7                  1_section_cabecalho_nf              1_frame_dados_nf   \n",
       "13            2_section_prestador_servico        2_frame_cnpj_prestador   \n",
       "17            2_section_prestador_servico   2_frame_inscricao_prestador   \n",
       "20            2_section_prestador_servico       2_frame_dados_prestador   \n",
       "26              3_section_tomador_servico          3_frame_cnpj_tomador   \n",
       "31              3_section_tomador_servico     3_frame_inscricao_tomador   \n",
       "34              3_section_tomador_servico         3_frame_dados_tomador   \n",
       "39              4_section_servicos_totais      4_frame_descricao_totais   \n",
       "41              4_section_servicos_totais           4_frame_valor_total   \n",
       "43              4_section_servicos_totais    4_frame_cnae_itens_servico   \n",
       "47                5_section_valores_dados      5_frame_valores_impostos   \n",
       "64  6_section_inf_complementares_criticas  5_frame_dados_complementares   \n",
       "66  6_section_inf_complementares_criticas          5_frame_inf_criticas   \n",
       "73  6_section_inf_complementares_criticas            5_frame_observacao   \n",
       "\n",
       "   reference      x0      y0      x1      y1  Largura  Altura   %  \n",
       "3        NaN   406.0     0.0  1540.0   380.0   1030.0   380.0 NaN  \n",
       "7        NaN  1633.0     0.0  2067.0   380.0    434.0   380.0 NaN  \n",
       "13       NaN     0.0   380.0   550.0   555.0    440.0   170.0 NaN  \n",
       "17       NaN   550.0   380.0  1357.0   555.0    917.0   170.0 NaN  \n",
       "20       NaN     0.0   552.0  2067.0   785.0   2067.0   235.0 NaN  \n",
       "26       NaN     0.0   785.0   550.0   983.0    440.0   198.0 NaN  \n",
       "31       NaN   550.0   785.0  1357.0   983.0    917.0   198.0 NaN  \n",
       "34       NaN     0.0   983.0  2067.0  1154.0   2067.0   171.0 NaN  \n",
       "39       NaN     0.0  1150.0  2067.0  1790.0   2067.0   690.0 NaN  \n",
       "41       NaN     0.0  1743.0  2067.0  1852.0   2067.0   104.0 NaN  \n",
       "43       NaN     0.0  1844.0  2067.0  1943.0   2067.0    99.0 NaN  \n",
       "47       NaN   344.0  1950.0  1953.0  2273.0   1609.0   323.0 NaN  \n",
       "64       NaN   148.0  2273.0  1925.0  2377.0   1777.0   104.0 NaN  \n",
       "66       NaN   148.0  2377.0  1925.0  2521.0   1777.0   144.0 NaN  \n",
       "73       NaN   148.0  2521.0  1922.0  2676.0   1774.0   155.0 NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CNAE Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mage_cnae_x_item_servico_df = pd.read_excel('novo_modelo/datasets/MAGE_CNAE_X_ITEM_SERVICO_V1.xlsx')\n",
    "\n",
    "# Creating a dictionary for CNAE codes and descriptions\n",
    "cnae_dict = dict(zip(mage_cnae_x_item_servico_df['cnae'], mage_cnae_x_item_servico_df['descricao_cnae']))\n",
    "item_servico_dict = dict(zip(mage_cnae_x_item_servico_df['item_servico'], mage_cnae_x_item_servico_df['descricao_item_servico']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OBRAS DE TERRAPLENAGEM                                                                                                                                                                                                                                                                                      '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_servico_dict[7.02].upper()\n",
    "cnae_dict[4313400].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnae_dict[4313400].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnae_dict[3812200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mage_cnae_x_item_servico_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize a default dictionary with list as the default factory\n",
    "cnae_to_item_servico_dict = defaultdict(list)\n",
    "\n",
    "# Iterate through the DataFrame and populate the dictionary\n",
    "for index, row in mage_cnae_x_item_servico_df.iterrows():\n",
    "    cnae = row['cnae']\n",
    "    cnae_cod = row['cnae_cod']\n",
    "    descricao_cnae = row['descricao_cnae']\n",
    "    item_servico = row['item_servico']\n",
    "    descricao_item_servico = row['descricao_item_servico']\n",
    "    cnae_to_item_servico_dict[cnae_cod].append(item_servico)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnae_to_item_servico_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cnae_to_item_servico_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Funçoes gerais de imagem e consistencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Funcoes de tratamento de imagem e  PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Funcao de conversao e resize do documento\n",
    "def convertResize(doc2convert, document_path, image_resized_path):\n",
    "    \n",
    "    \"\"\"# 1. remocao do sufixo .pdf\n",
    "    if doc2convert.split(\".\")[1].islower():\n",
    "        nameImage= doc2convert.removesuffix(\".pdf\")\n",
    "    else:\n",
    "        nameImage= doc2convert.removesuffix(\".PDF\")\"\"\"\n",
    "    \n",
    "    # 2. construo um novo nome para o documento imagem\n",
    "    image_resized_name = os.path.join(f'{image_resized_path}/{str(doc2convert)}.jpg')\n",
    "    \n",
    "    # 3. Conversao para imagem\n",
    "    pages = convert_from_path(document_path, 500, poppler_path=poppler_path)\n",
    "    \n",
    "    # 4. Verifica se ha mais que uma pagina\n",
    "    if len(pages) > 1:\n",
    "        raise ValueError(\"Erro, documento com mais de uma página\")\n",
    "    else:\n",
    "        # 5. Iterar pelas páginas e redimensionar\n",
    "        resized_pages = []\n",
    "        for page in pages:\n",
    "            resized_page = page.resize((2067, 2923))\n",
    "            resized_pages.append(resized_page)\n",
    "            \n",
    "        resized_pages[0].save(image_resized_name, 'JPEG')\n",
    "        \n",
    "    return resized_pages[0], image_resized_name\n",
    "\n",
    "# 2. Pesquisa prefeitura no documento\n",
    "def pequisaModel(image_name):\n",
    "\n",
    "    # 1. Definindo as coordenadas do frame\n",
    "    x0 = 406\n",
    "    y0 = 0\n",
    "    x1= 1540\n",
    "    y1 = 380\n",
    "\n",
    "    # 2. Definir frame_image\n",
    "    frame_image = image_name.crop((x0, y0, x1, y1))\n",
    "\n",
    "    # 3. Extraia texto usando OCR com configuração de idioma padrão para este frame\n",
    "    extracted_text_frame = pytesseract.image_to_string(frame_image, lang='por', config=tessdata_dir_config).strip()\n",
    "\n",
    "    # 4. Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "    values = extracted_text_frame.split('\\n')\n",
    "\n",
    "    # 5. Interacao para pesquisar prefeitura\n",
    "    for value in values:\n",
    "        nome_prefeitura_match = re.search(r'PREFEITURA (.+)', value)\n",
    "        if nome_prefeitura_match:\n",
    "            nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1) \n",
    "            return  nome_prefeitura\n",
    "   \n",
    "# 3. Ajusta o filename tirando caracteres especiais \n",
    "def conv_filename(title):\n",
    "    \n",
    "    # Divida o título em nome e extensão\n",
    "    name, extension = title.rsplit('.', 1) if '.' in title else (title, \"\")\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    # Adicione a extensão de volta, se houver\n",
    "    if extension:\n",
    "        filename += '.' + extension.lower()\n",
    "\n",
    "    return filename\n",
    "\n",
    "# 4. Ajusta o filename tirando caracteres especiais e a\n",
    "def conv_filename_no_ext(title):\n",
    "    # Divida o título em nome e extensão (mas ignore a extensão)\n",
    "    name = title.rsplit('.', 1)[0] if '.' in title else title\n",
    "\n",
    "    # Remova acentos e caracteres especiais do nome\n",
    "    name = normalize('NFKD', name).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    \n",
    "    # Substitua espaços e hífens por sublinhados\n",
    "    filename = name.replace(' ', '_').replace('-', '_')\n",
    "\n",
    "    # Remova quaisquer outros caracteres não alfanuméricos, exceto sublinhados\n",
    "    filename = re.sub(r'[^\\w_]', '', filename)\n",
    "\n",
    "    # Converter para minúsculas\n",
    "    filename = filename.lower()\n",
    "\n",
    "    return filename     \n",
    "\n",
    "# 5. Verifica se PDF e pesquisavel ou nao e grava metadados dele\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        dados_pdf = pdf_document.metadata\n",
    "        pdf_document.close()\n",
    "        return is_searchable, dados_pdf\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Funcoes de suporte e extracao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funçao de formatacao de numeros\n",
    "\"\"\"def format_number(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para fields %\n",
    "    return float(number_str)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Funcoes suporte para extracao\n",
    "\n",
    "def extract_text_from_frame(image, coordinates, config):\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    frame_image = image.crop((x0, y0, x1, y1))\n",
    "    extracted_text = pytesseract.image_to_string(frame_image, lang='por', config=config).strip()\n",
    "    return extracted_text\n",
    "\n",
    "def process_line(value, reference, label):\n",
    "    name_match = re.search(fr'{reference} (.+)', value)\n",
    "    if name_match:\n",
    "        extracted_value = reference + \" \" + name_match.group(1)\n",
    "        return {label: extracted_value}\n",
    "    return None\n",
    "\n",
    "def format_number(number_str):\n",
    "    # Check for percentage and handle it\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # You can multiply by 100 here if needed\n",
    "\n",
    "    # Check if the string contains \"R$\" or a comma, indicating the original format\n",
    "    if 'R$' in number_str or ',' in number_str:\n",
    "        # Original format: Remove 'R$', replace dots with nothing, and replace commas with dots\n",
    "        number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    else:\n",
    "        # New format: Extract only the numeric part using regex\n",
    "        number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)\n",
    "\n",
    "    # Dicionário para armazenar o texto final processado para cada field\n",
    "    final_extracted_data = {}\n",
    "\n",
    "    # Itere pelos dados de texto extraídos e processe o texto para manter apenas os valores\n",
    "    for reference, extracted_text in extracted_text_data_default_lang.items():\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        # Formate o valor usando a função format_number\n",
    "        value = format_number(value)\n",
    "        # Armazene o valor processado no dicionário final\n",
    "        final_extracted_data[reference] = value\n",
    "\n",
    "    # Display the final extracted data for the first few fields\n",
    "    list(final_extracted_data.items())[:15]\n",
    "    \n",
    "    \n",
    "def extract_fields_prestador_cnpj(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    nf_data_prestador_cnpj = {}\n",
    "    \n",
    "    nf_data_prestador_cnpj['secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador_cnpj['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador_cnpj['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "\n",
    "    # Extrair Telefone\n",
    "    telefone_str = None\n",
    "    \n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador_cnpj['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador_cnpj['telefone'] = None   \n",
    "    \n",
    "    \n",
    "    return nf_data_prestador_cnpj \n",
    "\n",
    "\n",
    "def extract_fields_tomador_cnpj(text):\n",
    "    nf_data_tomador_cnpj = {}\n",
    "    \n",
    "    \n",
    "    nf_data_tomador_cnpj['secao'] = \"3.TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador_cnpj['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador_cnpj['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador_cnpj['telefone'] = None  # Valor padrão quando não há correspondência\n",
    "        elif telefone_str == '':\n",
    "            nf_data_tomador_cnpj['telefone'] = None  # Valor padrão quando não há correspondência\n",
    "                    \n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['telefone'] = telefone_match.group(1)\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        inscricao_municipal_str = inscricao_municipal_match.group(1)\n",
    "        if inscricao_municipal_str == \"Telefone:\": \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = inscricao_municipal_str\n",
    "    \n",
    "    insc_municipal_match = re.search(r'INSC:MUNICIPAL:\\s+(.+)', text)\n",
    "    if insc_municipal_match:\n",
    "        insc_municipal_str = insc_municipal_match.group(1)\n",
    "        if insc_municipal_str == \"Telefone:\":\n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "        else:    \n",
    "            nf_data_tomador_cnpj['inscricao_municipal'] = insc_municipal_str\n",
    "    else:\n",
    "        nf_data_tomador_cnpj['inscricao_municipal'] = None\n",
    "            \n",
    "    \n",
    "    return nf_data_tomador_cnpj\n",
    "\n",
    "\n",
    "def extract_fields_tomador_inscricao(text):\n",
    "    nf_data_tomador_inscricao = {}\n",
    "    \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador_inscricao['rg'] = None  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador_inscricao['rg'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == '':\n",
    "            nf_data_tomador_inscricao['inscricao_estadual'] = None\n",
    "        else:    \n",
    "            nf_data_tomador_inscricao['inscricao_estadual'] = inscricao_estadual_match.group(1)   \n",
    "    else: \n",
    "        nf_data_tomador_inscricao['inscricao_estadual'] = None           \n",
    "\n",
    "    return nf_data_tomador_inscricao\n",
    "\n",
    "\n",
    "def extract_fields_tomador_dados(text):\n",
    "    \n",
    "    nf_data_tomador = {}\n",
    "\n",
    "    # Dividir o texto em linhas\n",
    "    linhas = text.split('\\n')\n",
    "\n",
    "    # Inicializar variáveis para armazenar os valores\n",
    "    nome_razao_social = None\n",
    "    endereco = None\n",
    "    email = None\n",
    "\n",
    "    # Iterar pelas linhas para identificar os campos e valores\n",
    "    i = 0\n",
    "    while i < len(linhas):\n",
    "        linha = linhas[i]\n",
    "        if \"Nome/Razão Social:\" in linha:\n",
    "            nome_razao_social = linhas[i + 1].strip()\n",
    "            i += 2\n",
    "        elif \"Endereço:\" in linha:\n",
    "            endereco = linhas[i + 1].strip()\n",
    "            i += 2\n",
    "        elif \"E-mail:\" in linha:\n",
    "            email = linhas[i + 1].strip()\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    nf_data_tomador['razao_social'] = nome_razao_social\n",
    "    nf_data_tomador['endereco'] = endereco\n",
    "    nf_data_tomador['email'] = email\n",
    "    \n",
    "    return nf_data_tomador\n",
    "\n",
    "###################Funcoes Modelo e Frames\n",
    "\n",
    "# 1 - CABECALHO\n",
    "def processa_cabecalho():\n",
    "\n",
    "    nf_data_cabecalho = {}\n",
    "    model = \"mage_1\"\n",
    "    # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "    filtered_frames_info = frames_info[frames_info['model'] == model]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        frame_model = row_frame['model']\n",
    "        if frame_model == model:\n",
    "            frame_father = row_frame['label']\n",
    "            # ... Select specific frames ...\n",
    "            if frame_father == \"1_frame_prefeitura_nf\" or frame_father == \"1_frame_dados_nf\":\n",
    "                \n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                \n",
    "                seq = row_frame['seq']\n",
    "                #print(f'\\nLoop 1: {frame_model}, seq.: {seq}, row_frame[label]: {frame_father}\\n')\n",
    "                nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "                \n",
    "                for index_field, row_field in sframe_fields_info.iterrows():\n",
    "                    item_son = row_field['father']\n",
    "                    frame_father = row_frame['label']\n",
    "                    if item_son == frame_father:\n",
    "\n",
    "                        model_value = row_field['model']\n",
    "                        type_value = row_field['type']\n",
    "                        label_value = row_field['label']\n",
    "                        reference_value = row_field['reference']\n",
    "                        seq_value = row_field['seq']\n",
    "                        father_value = row_field['father']\n",
    "                        # ... Select specific fields ...\n",
    "                        if label_value == \"nome_prefeitura\" and model_value == frame_model: \n",
    "                            #print(f'  Loop 2: {model_value}, seq.: {seq_value}, type_value: {type_value}, label_value: {label_value}')\n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            for value in values:\n",
    "                                result = process_line(value, reference_value, label_value)\n",
    "                                if result:\n",
    "                                    nf_data_cabecalho.update(result)\n",
    "                                    \n",
    "                        elif label_value == \"secretaria\" and model_value == frame_model: \n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            for value in values:\n",
    "                                result = process_line(value, reference_value, label_value)\n",
    "                                if result:\n",
    "                                    nf_data_cabecalho.update(result)\n",
    "                                    \n",
    "                        elif label_value == \"tipo_nota_fiscal\" and model_value == frame_model:\n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            for value in values:\n",
    "                                result = process_line(value, reference_value, label_value)\n",
    "                                if result:\n",
    "                                    nf_data_cabecalho.update(result)\n",
    "                        \n",
    "                        #Extraçao de Dados da NF            \n",
    "                        elif father_value == \"1_frame_dados_nf\" and model_value == frame_model:\n",
    "                            values = extracted_text_frame.split('\\n')\n",
    "                            data_list = [item for item in values if item != '']\n",
    "                            \n",
    "                            data_dict = {}\n",
    "                            for i in range(0, len(data_list), 2):\n",
    "                                key = data_list[i]\n",
    "                                value = data_list[i+1]\n",
    "                                data_dict[key] = value\n",
    "\n",
    "                            # You can now access the values using the corresponding labels\n",
    "                            nro_nota_fiscal = data_dict['Número da Nota:']\n",
    "                            nf_data_cabecalho['numero_nota_fiscal'] = data_dict['Número da Nota:']\n",
    "                            nf_data_cabecalho['competencia'] = data_dict['Competência:']\n",
    "                            nf_data_cabecalho['dt_hr_emissao'] = data_dict['ata e Hora da Emissão:']\n",
    "                            nf_data_cabecalho['codigo_verificacao'] = data_dict['Código Verificação:']\n",
    "                            \n",
    "    return nf_data_cabecalho, nro_nota_fiscal \n",
    "\n",
    "# 2 - PRESTADOR DE SERVIÇO\n",
    "def processa_prestador():\n",
    "\n",
    "    nf_data_prestador = {}\n",
    "    \n",
    "    warning = {}\n",
    "\n",
    "    # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "    filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        frame_model = row_frame['model']\n",
    "        if frame_model == model:\n",
    "            frame_father = row_frame['label']\n",
    "            # ... Select specific frames ...\n",
    "            if frame_father == \"2_frame_cnpj_prestador\":\n",
    "                \n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                nf_data_prestador = extract_fields_prestador_cnpj(extracted_text_frame)\n",
    "                \n",
    "            elif frame_father == \"2_frame_inscricao_prestador\":\n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                # 1. Prrestador de Servico - INSCRICAO ESTADUAL/MUNICIPAL\n",
    "                nf_data_prestador_incricao = {}\n",
    "\n",
    "                # Dividir o texto em linhas\n",
    "                linhas = extracted_text_frame.split('\\n')\n",
    "\n",
    "                # Inicializar variáveis para armazenar os valores\n",
    "                inscricao_municipal = None\n",
    "                inscricao_estadual = None\n",
    "\n",
    "\n",
    "                # Initialize variables\n",
    "                inscricao_municipal = \"\"\n",
    "                inscricao_estadual = \"\"\n",
    "\n",
    "                # Iterar pelas linhas para identificar os campos e valores\n",
    "                i = 0\n",
    "                while i < len(linhas):\n",
    "                    linha = linhas[i]\n",
    "                    try:\n",
    "                        if \"Inscrição Municipal:\" in linha:\n",
    "                            inscricao_municipal = linhas[i + 1].strip()\n",
    "                            i += 2\n",
    "                        elif \"Inscrição Estadual:\" in linha: \n",
    "                            inscricao_estadual = linhas[i + 1].strip()   \n",
    "                            i += 2\n",
    "                        else:\n",
    "                            i += 1\n",
    "                    except IndexError as e:\n",
    "                        # Log the error or print a warning\n",
    "                        print(f\"Aviso: Não é possível processar a linha {i}. {str(e)}\")\n",
    "                        warning = True\n",
    "                        warning_message = f\"Aviso: Não é possível processar a linha {i}. {str(e)}\"\n",
    "                        \n",
    "                        break # Exit the loop or continue based on your needs\n",
    "\n",
    "                if inscricao_municipal == \"\":\n",
    "                    inscricao_municipal = \"None\"        \n",
    "                if inscricao_estadual == \"\":\n",
    "                    inscricao_estadual = \"None\"\n",
    "\n",
    "                nf_data_prestador['inscricao_municipal'] = inscricao_municipal\n",
    "                nf_data_prestador['inscricao_estadual'] = inscricao_estadual\n",
    "\n",
    "\n",
    "                \n",
    "            elif frame_father == \"2_frame_dados_prestador\":\n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                tipo = None\n",
    "\n",
    "                if \"\\n\\n\" in extracted_text_frame:\n",
    "                    linhas = extracted_text_frame.split('\\n\\n')\n",
    "                    tipo = 2\n",
    "                    \n",
    "                else:\n",
    "                    linhas = extracted_text_frame.split('\\n')    \n",
    "                    tipo = 1\n",
    "                \n",
    "                # Inicializar variáveis para armazenar os valores\n",
    "                nome_razao_social = None\n",
    "                nome_fantasia = None\n",
    "                endereco = None\n",
    "                email = None\n",
    "\n",
    "                # Iterar pelas linhas para identificar os campos e valores\n",
    "                i = 0\n",
    "                while i < len(linhas):\n",
    "                    linha = linhas[i]\n",
    "                    if \"Nome/Razão Social:\" in linha:\n",
    "                        if tipo == 2:\n",
    "                            texto1 = linhas[i + 1].strip()\n",
    "                            texto2 = texto1.split('\\n')\n",
    "                            nome_razao_social = texto2[i].strip()\n",
    "                        else:\n",
    "                            nome_razao_social = linhas[i + 1].strip()   \n",
    "\n",
    "                        i += 2\n",
    "                    elif \"Nome de Fantasia:\" in linha:\n",
    "                        nome_fantasia = linhas[i + 1].strip()\n",
    "                        i += 2\n",
    "                    elif \"Endereço:\" in linha:\n",
    "    \n",
    "                        if tipo == 2:\n",
    "                            texto3 = linhas[i + 1].strip()\n",
    "                            texto4 = texto3.split('\\n')\n",
    "                            \n",
    "                            endereco = texto4[0].strip()\n",
    "                        else:\n",
    "                            endereco = linhas[i + 1].strip()      \n",
    "                        i += 2\n",
    "                    elif \"E-mail:\" in linha:\n",
    "                        email = linhas[i + 1].strip()\n",
    "                        i += 2\n",
    "                    else:\n",
    "                        i += 1\n",
    "\n",
    "                nf_data_prestador['razao_social'] = nome_razao_social\n",
    "                nf_data_prestador['nome_fantasia'] = nome_fantasia\n",
    "                nf_data_prestador['endereco'] = endereco\n",
    "                nf_data_prestador['email'] = email\n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "# 3 - TOMADOR DE SERVIÇO\n",
    "def processa_tomador():\n",
    "    nf_data_tomador = {}\n",
    "\n",
    "    # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "    filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        frame_model = row_frame['model']\n",
    "        if frame_model == model:\n",
    "            frame_father = row_frame['label']\n",
    "            # ... Select specific frames ...\n",
    "            if frame_father == \"3_frame_cnpj_tomador\":\n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                nf_data_tomador_cnpj = extract_fields_tomador_cnpj(extracted_text_frame)\n",
    "                \n",
    "            elif frame_father == \"3_frame_inscricao_tomador\":\n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                nf_data_tomador_inscricao = extract_fields_tomador_inscricao(extracted_text_frame)\n",
    "            \n",
    "            elif frame_father == \"3_frame_dados_tomador\":\n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                nf_data_tomador = extract_fields_tomador_dados(extracted_text_frame)\n",
    "                \n",
    "    nf_data_tomador.update(nf_data_tomador_cnpj) \n",
    "    nf_data_tomador.update(nf_data_tomador_inscricao)\n",
    "    nf_data_tomador.update(nf_data_tomador)\n",
    "    \n",
    "    return nf_data_tomador     \n",
    "\n",
    "# 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "def processa_servico():\n",
    "    \n",
    "    nf_data_servico = {}\n",
    "\n",
    "    # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "    filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        frame_model = row_frame['model']\n",
    "        if frame_model == model:\n",
    "            frame_father = row_frame['label']\n",
    "            # ... Select specific frames ...\n",
    "            if frame_father == \"4_frame_descricao_totais\":\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                text = extracted_text_frame.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "                nf_data_servico['discriminacao_servicos'] = text \n",
    "            \n",
    "    return nf_data_servico\n",
    "\n",
    "# 5 - VALOR TOTAL\n",
    "def processa_total():\n",
    "    \n",
    "    nf_data_valor_total = {}\n",
    "    # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "    filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        frame_model = row_frame['model']\n",
    "        if frame_model == model:\n",
    "            frame_father = row_frame['label']\n",
    "            # ... Select specific frames ...\n",
    "            if frame_father == \"4_frame_descricao_totais\":\n",
    "                nf_data_valor_total['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Extrai coordenadas para recorte\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                text = extracted_text_frame.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "                nf_data_valor_total['discriminacao_servicos'] = text\n",
    "                 \n",
    "    return nf_data_valor_total  \n",
    "\n",
    "# 6 - CNAE e Item da Lista de Serviços\n",
    "def processa_cnae_itens():\n",
    "    \n",
    "    nf_data_cnae = {}\n",
    "\n",
    "\n",
    "    # Filtrar o DataFrame para incluir apenas linhas onde a coluna \"model\" oriundo de: modelo\n",
    "    filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        frame_model = row_frame['model']\n",
    "        if frame_model == model:\n",
    "            frame_father = row_frame['label']\n",
    "            # ... Select specific frames ...\n",
    "            if frame_father == \"4_frame_cnae_itens_servico\":\n",
    "                nf_data_cnae['secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "                x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "                extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "                \n",
    "                linhas = extracted_text_frame.split('\\n')\n",
    "                i = len(linhas)\n",
    "                texto_cnae = linhas[0].replace(' . .', '')\n",
    "                cnae = re.sub(r'^CNAE - ', '', texto_cnae, count=1)\n",
    "\n",
    "                # Item da Lista de Serviços \n",
    "                texto_novo = linhas[1]\n",
    "                texto_novo = texto_novo.replace('\\n', '')\n",
    "\n",
    "                item_lista_servico = re.sub(r'^Item da Lista de Serviços - ', '', texto_novo, count=1)\n",
    "\n",
    "                nf_data_cnae['cnae'] = cnae\n",
    "                nf_data_cnae['item_lista_servicos'] = item_lista_servico\n",
    "                \n",
    "    return nf_data_cnae  \n",
    "\n",
    "# 7 - VALORES E IMPOSTOS\n",
    "def extract_fields_box(modelo, father_value, section):\n",
    "\n",
    "    data_box_valores = {}\n",
    "    data_box_valores['secao'] = section\n",
    "    filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]\n",
    "    # Iterate nas informações dos boxes de fields e extraia o texto de cada field\n",
    "    for index_field, row_field in filtered_boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        #print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference'], row_field['x0'], row_field['y0'], row_field['x1'], row_field['y1'] ))\n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        value = value.strip()\n",
    "        if row_field['t_value'] == 'number':\n",
    "            # Formate o valor usando a função format_number\n",
    "            #print(\"vou verificar valor\")\n",
    "            value = format_number(value)\n",
    "            #print(value)\n",
    "        # Armazene o texto extraído com o rótulo correspondente\n",
    "        label = row_field['label']\n",
    "        data_box_valores[label] = value\n",
    "        \n",
    "    return data_box_valores\n",
    "\n",
    "# secao: 8 - DADOS COMPLEMENTARES & 10. OBSERVACOES\n",
    "def extract_dados_comple_obs(modelo, frame_father, section):\n",
    "    \n",
    "    data_dados_complementares = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_frame['seq'], row_frame['model'], row_frame['father'], row_frame['label'], row_frame['reference'], row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'] ))\n",
    "        for index_field, row_field in filtered_sframe_fields_info.iterrows():\n",
    "            #print(\"{:<5} {:<10} {:<30} {:<20} {:<20}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference']))\n",
    "            \n",
    "            if frame_father == \"5_frame_dados_complementares\":\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['section'] = section\n",
    "                \n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', extracted_text_box, count=1)\n",
    "                if text == '':\n",
    "                    text = None\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                    \n",
    "                return nf_data_dados_complementares                \n",
    "                \n",
    "            elif frame_father == \"5_frame_observacao\":\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['section'] = section \n",
    "                                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', extracted_text_box, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                return nf_data_observacao        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'VALOR TOTAL DA NOTA:  11817.63'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11817.63"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_number(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_number_3(number_str):\n",
    "    # Extract only the numeric part of the string using regex\n",
    "    number_str = re.findall(r'[\\d\\.]+', number_str)[-1]\n",
    "\n",
    "    return float(number_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 7 - VALORES E IMPOSTOS & 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "data_valores = {}\n",
    "father_value = \"5_frame_valores_impostos\"\n",
    "section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "result = extract_fields_box(modelo, father_value, section)\n",
    "if result:\n",
    "    data_valores.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'secao': '7. VALORES E IMPOSTOS',\n",
       " 'valor_servicos': 11817.63,\n",
       " 'valor_deducao': 0.0,\n",
       " 'desc_incond': 0.0,\n",
       " 'base_calculo': 11817.63,\n",
       " 'aliquota': 5.0,\n",
       " 'valor_iss': 590.88,\n",
       " 'valor_iss_retido': 0.0,\n",
       " 'desc_cond': 0.0,\n",
       " 'valor_pis': 0.0,\n",
       " 'valor_cofins': 0.0,\n",
       " 'valor_ir': 0.0,\n",
       " 'valor_inss': 0.0,\n",
       " 'valor_csll': 0.0,\n",
       " 'outras_retencoes': 0.0,\n",
       " 'valor_liquido': 11817.63}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7. VALORES E IMPOSTOS'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valor_total = {}\n",
    "#data_valor_total = processa_total()\n",
    "father_value = \"4_frame_valor_total\"\n",
    "section = \"5. VALOR TOTAL\"\n",
    "\n",
    "result = extract_fields_box(modelo, father_value, section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes de manejo de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move NF processadas ok\n",
    "def move_pdf_processed_ok(document_path, nf_processada_path, batch_name, doc2convert):\n",
    "    # Determine the destination directory\n",
    "    destination_dir = os.path.join(nf_processada_path, batch_name)\n",
    "\n",
    "    # Check if the destination directory exists; if not, create it\n",
    "    if not os.path.exists(destination_dir):\n",
    "        os.makedirs(destination_dir)\n",
    "\n",
    "    # Determine the destination path including the filename\n",
    "    destination_path = os.path.join(destination_dir, os.path.basename(document_path))\n",
    "\n",
    "    # Move the file from the source path to the destination path\n",
    "    try:\n",
    "        shutil.move(document_path, destination_path)\n",
    "        print(f\"Sucesso ao mover: {document_path} para: {destination_path}\")\n",
    "        return True, destination_path, None  # Success, destination path, no error\n",
    "    except Exception as e:\n",
    "        error_message = f\"Erro ao mover: {document_path} para: {destination_path}: {str(e)}\"\n",
    "        print(error_message)\n",
    "        return False, None, error_message  # Failure, no destination path, error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling this function    \n",
    "success, dest_path, error_message = move_pdf_processed_ok(document_path, nf_processada_path, doc2convert)\n",
    "if success:\n",
    "    print(f\"Falha ao mover {dest_path}\")\n",
    "else:\n",
    "    print(f\"Um erro ocorreu: {error_message}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_prefeitura = pequisaModel(image_2work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFEITURA MUNICIPAL DE MAGE'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_prefeitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_dict[name_prefeitura]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = model_dict[name_prefeitura]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_dict[name_prefeitura]:\n",
    "    modelo = model_dict[name_prefeitura]\n",
    "    model = model_dict[name_prefeitura]\n",
    "    message_log = f\"Nome de prefeitura: {name_prefeitura} encontrada para: {doc2convert} modelo a ser utilizado: {modelo}\"\n",
    "    print(message_log)\n",
    "    #logging.info(message_log) \n",
    "else:\n",
    "    modelo = model_padrao\n",
    "    message_log = f'\\nmodelo nao encontrado para prefeitura {name_prefeitura}, sera utilizado o modelo {modelo}'   \n",
    "    print(message_log)\n",
    "    #logging.info(message_log)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novo_modelo/data_pdf/lote_teste  | Batch: lote_teste | doc2convert: 2407-106 TERE SÃO PEDRO.pdf | document_path_1: novo_modelo/data_pdf/lote_teste/2407-106 TERE SÃO PEDRO.pdf\n",
      "\n",
      "Aviso: Não é possível processar a linha 3. list index out of range\n",
      "65    mage_1     6_section_inf_complementares_criticas 5_frame_dados_complementares nan                  148.0   2273.0  1925.0  2377.0 \n",
      "74    mage_1     6_section_inf_complementares_criticas 5_frame_observacao   nan                  148.0   2521.0  1922.0  2676.0 \n",
      "Sucesso ao mover: novo_modelo/data_pdf/lote_teste/2407-106 TERE SÃO PEDRO.pdf para: novo_modelo/pdf_processado/lote_teste/2407-106 TERE SÃO PEDRO.pdf\n",
      "Sucesso: novo_modelo/pdf_processado/lote_teste/2407-106 TERE SÃO PEDRO.pdf\n",
      "As informações foram salvas em novo_modelo/jsons/lote_teste.json\n"
     ]
    }
   ],
   "source": [
    "# 1. Leitura recursiva de diretorios e arquivos a partir de root\n",
    "#logging.info(\"Processo iniciado.\")\n",
    "#warning_messages = {}\n",
    "nf_data_servico = {}\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for roots, directories, documents in os.walk(root_pdf_path):\n",
    "    batch_name = os.path.basename(roots)\n",
    "    source_path = roots\n",
    "    for document in documents:\n",
    "        doc2convert = document\n",
    "        document_path_1 = os.path.join(roots, document)\n",
    "        message_log = f\"Processo iniciado para lote: {directories}\"\n",
    "        #logging.info(message_log)\n",
    "        print(f'{roots}  | Batch: {batch_name} | doc2convert: {doc2convert} | document_path_1: {document_path_1}\\n')\n",
    "        #logging.info(\"Processando arquivo: %s\", document_path_1)\n",
    "        message_log = is_pdf_searchable(document_path_1)\n",
    "        #logging.info(message_log)\n",
    "        \n",
    "\n",
    "        \n",
    "        message_log = f\"Processo de extraçao iniciado para documento: {doc2convert}\"\n",
    "        #logging.info(message_log)\n",
    "        \n",
    "        root = roots\n",
    "        \n",
    "        # 2. Ajusta o nome do arquivo tirando caracteres especiais e a extensao\n",
    "        doc2convert_named = conv_filename_no_ext(doc2convert)\n",
    "        \n",
    "        message_log = f\"Processado nome para documento: {doc2convert} -> {doc2convert_named}\"\n",
    "        #logging.info(message_log)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # 3. Converte e resize da imagem \"on the fly\"\n",
    "        image_2work, name_image_2work = convertResize(doc2convert_named, document_path_1, image_resized_path) #Utilizado como origem: document_path_1\n",
    "\n",
    "        #print(name_image_2work)\n",
    "        message_log = f\"Documento {doc2convert} convertido e ajustado para tamanho arquivo: {name_image_2work}\"\n",
    "        #logging.info(message_log) \n",
    "\n",
    "\n",
    "        # 4. Busco nome da prefeitura e modelo\n",
    "        name_prefeitura = pequisaModel(image_2work)\n",
    "\n",
    "        modelo = model_dict[name_prefeitura]\n",
    "\n",
    "        if model_dict[name_prefeitura]:\n",
    "            modelo = model_dict[name_prefeitura]\n",
    "            model = model_dict[name_prefeitura]\n",
    "            message_log = f\"Nome de prefeitura: {name_prefeitura} encontrada para: {doc2convert} modelo a ser utilizado: {modelo}\"\n",
    "            #logging.info(message_log) \n",
    "        else:\n",
    "            modelo = model_padrao\n",
    "            message_log = f'\\nmodelo nao encontrado para prefeitura {name_prefeitura}, sera utilizado o modelo {modelo}'   \n",
    "            print(message_log)\n",
    "            #logging.info(message_log)   \n",
    "        \n",
    "        nro_nota = None\n",
    "            \n",
    "        # secao: 1 - CABECALHO\n",
    "        data_cabecalho = {}\n",
    "        data_cabecalho, nro_nota = processa_cabecalho() \n",
    "        \n",
    "        # secao: 2 - PRESTADOR DE SERVIÇO\n",
    "        data_prestador = {}\n",
    "        data_prestador = processa_prestador()  \n",
    "        \n",
    "        # secao: 3 - TOMADOR DE SERVIÇO\n",
    "        data_tomador = {}\n",
    "        data_tomador = processa_tomador()  \n",
    "        \n",
    "        # secao: 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "        data_servico = {}\n",
    "        data_servico = processa_servico()\n",
    "        \n",
    "        # secao: 5 - VALOR TOTAL\n",
    "        data_valor_total = {}\n",
    "        #data_valor_total = processa_total()\n",
    "        father_value = \"4_frame_valor_total\"\n",
    "        section = \"5. VALOR TOTAL\"\n",
    "        \n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        \n",
    "        # secao: 6 - CNAE e Item da Lista de Serviços\n",
    "        data_CNAE = {}\n",
    "        data_CNAE = processa_cnae_itens()\n",
    "\n",
    "        # secao: 7 - VALORES E IMPOSTOS & 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "        data_valores = {}\n",
    "        father_value = \"5_frame_valores_impostos\"\n",
    "        section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_valores.update(result)\n",
    "            \n",
    "        # secao: 8 - DADOS COMPLEMENTARES\"\n",
    "        data_dados_complementares = {}\n",
    "        f_father = \"5_frame_dados_complementares\"\n",
    "        section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "        data_dados_complementares = extract_dados_comple_obs(modelo, f_father, section)                                           \n",
    "                                \n",
    "                                \n",
    "        # secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "        data_outras_informacoes = {}\n",
    "        father_value = \"5_frame_inf_criticas\"\n",
    "        section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "\n",
    "        result = extract_fields_box(modelo, father_value, section)\n",
    "        if result:\n",
    "            data_outras_informacoes.update(result)                        \n",
    "                            \n",
    "\n",
    "        # secao: 10. OBSERVACOES\n",
    "        data_observacao = {}\n",
    "        f_father = \"5_frame_observacao\"\n",
    "        section = \"10. OBSERVACOES\"\n",
    "\n",
    "        data_observacao = extract_dados_comple_obs(modelo, f_father, section)\n",
    "        \n",
    "        \n",
    "        #nr_nro_nf = nro_nota\n",
    "        \n",
    "        # calling this function    \n",
    "        success, dest_path, error_message = move_pdf_processed_ok(document_path_1, nf_processada_path, batch_name, doc2convert)\n",
    "        if success:\n",
    "            print(f\"Sucesso: {dest_path}\")\n",
    "        else:\n",
    "            print(f\"Um erro ocorreu: {error_message}\") \n",
    "        \n",
    "            \n",
    "        nome_arquivo_json = os.path.basename(root) + \".json\"\n",
    "        nome_arquivo = doc2convert\n",
    "                                    \n",
    "        pdf_info[nro_nota] = {\n",
    "            \"dados_NF_PDF\": {\n",
    "                \"data_cabecalho\": data_cabecalho,\n",
    "                \"data_prestador\": data_prestador,\n",
    "                \"data_tomador\": data_tomador,\n",
    "                \"data_servico\": data_servico,\n",
    "                \"data_valor_total\": data_valor_total,\n",
    "                \"data_CNAE\": data_CNAE,\n",
    "                \"data_valores\": data_valores,\n",
    "                \"data_dados_complementares\": data_dados_complementares,\n",
    "                \"data_outras_informacoes\": data_outras_informacoes,\n",
    "                \"data_observacao\": data_observacao,\n",
    "                },\n",
    "            \"diretorio\": os.path.basename(root),\n",
    "            \"nome_arquivo\": nome_arquivo,    \n",
    "        }            \n",
    "            \n",
    "                        \n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(json_path, nome_arquivo_json)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " Define a mapping for color names to RGB values\n",
    "color_mapping = {\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"orange\": (255, 165, 0),\n",
    "    \"green\": (0, 128, 50),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"yellow\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "# Reload the image to start fresh\n",
    "image = Image.open(name_image_2work)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define a font size for the labels using the default PIL font\n",
    "font_size = 100\n",
    "#font = ImageFont.load_default()\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf\", 30, encoding=\"unic\")\n",
    "\n",
    "# Update the draw_box function to use the larger font size with the default font\n",
    "def draw_box(row):\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    color = color_mapping.get(row['color'], (0, 0, 0)) # Default to black if color not found\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
    "    label = str(row['label']) if pd.notnull(row['label']) else None # Check for missing label\n",
    "    if label:\n",
    "        draw.text((x0 + 5, y0 + 5), label, fill=color, font=font)\n",
    "\n",
    "# Draw the boundaries\n",
    "#draw_box(boundaries_info)\n",
    "\n",
    "\n",
    "def draw_box_model(modelo,\n",
    "                   boundaries_info=None,\n",
    "                   sections_info=None,\n",
    "                   frames_info=None,\n",
    "                   field_boxes_info=None,\n",
    "                   draw_boundaries=True,\n",
    "                   draw_sections=True,\n",
    "                   draw_frames=True,\n",
    "                   draw_field_boxes=True):\n",
    "    \n",
    "    # Draw boundaries if requested\n",
    "    if draw_boundaries and boundaries_info is not None:\n",
    "        filtered_boundaries_info = boundaries_info[boundaries_info['model'] == modelo]\n",
    "        for index, row in filtered_boundaries_info.iterrows():\n",
    "            draw_box(row)\n",
    "\n",
    "    # Draw sections if requested\n",
    "    if draw_sections and sections_info is not None:\n",
    "        filtered_sections_info = sections_info[sections_info['model'] == modelo]\n",
    "        for index, row in filtered_sections_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw frames if requested\n",
    "    if draw_frames and frames_info is not None:\n",
    "        filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "        for index, row in filtered_frames_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw field boxes if requested\n",
    "    if draw_field_boxes and field_boxes_info is not None:\n",
    "        filtered_field_boxes_info = field_boxes_info[field_boxes_info['model'] == modelo]\n",
    "        for index, row in filtered_field_boxes_info.iterrows():\n",
    "            draw_box(row)\n",
    "    \n",
    "    # Show the image with selected drawings\n",
    "    image.show()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22502:22529:0825/121410.114387:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22502:22533:0825/121410.156121:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22502:22533:0825/121410.156223:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22502:22529:0825/121410.162307:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22529:0825/121410.162343:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22529:0825/121410.162381:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22529:0825/121410.162406:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22502:0825/121410.167805:ERROR:chrome_browser_cloud_management_controller.cc(163)] Cloud management controller initialization aborted as CBCM is not enabled.\n",
      "[22502:22502:0825/121410.183208:ERROR:assistance_home_client.cc(32)] File path /home/dani-boy/.config/microsoft-edge-beta/Default\n",
      "[22502:22529:0825/121410.194933:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22529:0825/121410.194971:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22529:0825/121410.212889:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22529:0825/121410.212930:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22502:0825/121410.271130:ERROR:object_proxy.cc(590)] Failed to call method: org.freedesktop.portal.Settings.Read: object_path= /org/freedesktop/portal/desktop: unknown error type: \n",
      "[22502:22676:0825/121410.351686:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22502:22676:0825/121410.351743:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22502:22676:0825/121410.351782:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22502:22676:0825/121410.351823:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22502:22676:0825/121410.351841:ERROR:bus.cc(399)] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n",
      "[22852:3:0825/121415.333590:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[22852:3:0825/121415.352665:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[22852:3:0825/121415.354331:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n",
      "[22502:22526:0825/121416.313242:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22502:0825/121416.313450:ERROR:object_proxy.cc(590)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[22502:22526:0825/121416.313565:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22502:0825/121416.313701:ERROR:object_proxy.cc(590)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[22502:22526:0825/121416.313767:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22502:0825/121416.313845:ERROR:object_proxy.cc(590)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[22502:22526:0825/121416.313952:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22502:0825/121416.314031:ERROR:object_proxy.cc(590)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "[22502:22526:0825/121416.314115:ERROR:bus.cc(399)] Failed to connect to the bus: Could not parse server address: Unknown address type (examples of valid types are \"tcp\" and on UNIX \"unix\")\n",
      "[22502:22502:0825/121416.314240:ERROR:object_proxy.cc(590)] Failed to call method: org.freedesktop.DBus.NameHasOwner: object_path= /org/freedesktop/DBus: unknown error type: \n",
      "Deserialization failed!\n",
      "[23420:3:0825/121710.242626:ERROR:persistent_asset_storage_impl.cc(111)] Initialize succeeded with already open DB\n"
     ]
    }
   ],
   "source": [
    "# To draw everything\n",
    "draw_box_model(modelo, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamada de funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Ajusta o nome do arquivo tirando caracteres especiais e a extensao\n",
    "doc2convert_named = conv_filename_no_ext(doc2convert)\n",
    "\n",
    "\n",
    "# 3. Converte e resize da imagem \"on the fly\"\n",
    "image_2work, name_image_2work = convertResize(doc2convert_named, document_path_1, image_resized_path) #Utilizado como origem: document_path_1\n",
    "\n",
    "#print(name_image_2work) \n",
    "\n",
    "\n",
    "# 4. Busco nome da prefeitura e modelo\n",
    "name_prefeitura = pequisaModel(image_2work)\n",
    "\n",
    "modelo = model_dict[name_prefeitura]\n",
    "\n",
    "if model_dict[name_prefeitura]:\n",
    "    modelo = model_dict[name_prefeitura]\n",
    "    print(f'\\nNome Prefeitura: {name_prefeitura},  modelo: {modelo}') \n",
    "else:\n",
    "    modelo = model_padrao\n",
    "    message = f'\\nmodelo nao encontrado para prefeitura {name_prefeitura}, sera utilizado o modelo {modelo}'   \n",
    "    print(message)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines Atuais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final - tratamento dos arquivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_pdf = \"pequisavel\"\n",
    "tipo_pdf = \"nao pequisavel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 Definir o tipo de PDF a buscar  (TESTE APENAS)\n",
    "#source_directory = root_external_pdf_path\n",
    "\n",
    "#print(source_directory )\n",
    "destination_directory = root_pdf_path\n",
    "if tipo_pdf == \"pequisavel\":\n",
    "    source_directory = root_external_pdf_pesquisavel_path\n",
    "    print(f'\\nTipo PDF a utilizar: {tipo_pdf} | source_directory: {source_directory} \\n\\nDocumento que sera movido: {document_path_1}\\n')\n",
    "    \n",
    "else:\n",
    "    source_directory = root_external_pdf_path\n",
    "\n",
    "#print(f'\\nTipo PDF a utilizar: {tipo_pdf} | source_directory: {source_directory} \\n\\nDocumento que sera movido: {document_path_1}\\n')   \n",
    "\n",
    "\n",
    "# 5. MOVER PDF para diretorio de processados\n",
    "source_path = document_path_1\n",
    "destination_path = os.path.join(f'{nf_processada_path}/{str(doc2convert)}')\n",
    "\n",
    "print(f'\\nsource_path: {source_path} | destination_path: {destination_path} \\n') \n",
    "\n",
    "\n",
    "shutil.move(source_path, destination_path)\n",
    "\n",
    "# 6. ***DELETAR**** o arquivo de imagem gerado\n",
    "image_path_to_delete = name_image_2work\n",
    "os.remove(image_path_to_delete)\n",
    "\n",
    "\n",
    "# Verifique se o diretório de destino está vazio\n",
    "if os.listdir(destination_directory):\n",
    "    raise Exception(\"O diretório de destino não está vazio!\")\n",
    "\n",
    "for roots, directories, documents in os.walk(source_directory):\n",
    "    # Filtre os documentos para incluir apenas aqueles com extensão .pdf\n",
    "    pdf_files = [doc for doc in documents if doc.lower().endswith('.pdf')]\n",
    "    \n",
    "    if pdf_files: # Verifique se há algum arquivo PDF no diretório\n",
    "        first_pdf_file = pdf_files[0] # Obtenha o primeiro arquivo PDF\n",
    "        source_path = os.path.join(roots, first_pdf_file) # Construa o caminho completo para o primeiro arquivo PDF\n",
    "        print(f\"Found the first PDF file: {source_path}\")\n",
    "        \n",
    "        # Mova o arquivo para o diretório de destino\n",
    "        shutil.move(source_path, destination_directory)\n",
    "        \n",
    "        break # Saia do loop após encontrar o primeiro arquivo PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outros itens do Processo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVISAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "               # Iterar pelas linhas para identificar os campos e valores\n",
    "                i = 0\n",
    "                while i < len(linhas):\n",
    "                    linha = linhas[i]\n",
    "                    if \"Inscrição Municipal:\" in linha:\n",
    "                        inscricao_municipal = linhas[i + 1].strip()\n",
    "                        i += 2\n",
    "                    elif \"Inscrição Estadual:\" in linha: \n",
    "                        inscricao_estadual = linhas[i + 1].strip()   \n",
    "                        i += 2\n",
    "                    else:\n",
    "                        i += 1\n",
    "                        \n",
    "                if inscricao_municipal == \"\":\n",
    "                    inscricao_municipal = \"None\"        \n",
    "                if inscricao_estadual == \"\":\n",
    "                    inscricao_estadual = \"None\"\n",
    "\n",
    "                nf_data_prestador['inscricao_municipal'] = inscricao_municipal\n",
    "                nf_data_prestador['inscricao_estadual'] = inscricao_estadual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de pipelines utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(root_pdf_path):\n",
    "    print(f'{root}  | {dirs} | {document} | {files}\\n')\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        #if file.lower().endswith('.pdf'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo iniciado com funçoes do model\n",
    "\n",
    "nf_model = \"mage_1\"\n",
    "\n",
    "nf_data_servico = {}\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        if file.lower().endswith('.pdf'):\n",
    "            #print(file_path)\n",
    "                \n",
    "            # 1. Conversao para imagem e resize\n",
    "            converte2image(file_path)\n",
    "                \n",
    "            # 2. Resize\n",
    "            resizeImage(image_src)\n",
    "                \n",
    "            # 3. Executar cortes\n",
    "            #file_path = img_resi_path\n",
    "            #image_to_crop = Image.open(img_resi_path).convert(\"RGB\")\n",
    "            #width, height = image_to_crop.size\n",
    "\n",
    "            cropSections(nf_model, img_resi_path)\n",
    "                \n",
    "            for roots, directories, images in os.walk(root_dir_section_images):\n",
    "                for image in images:\n",
    "                    #print(f'\\n{roots}, {directories}, {images}')\n",
    "                    print(image)\n",
    "                    image_path = os.path.join(roots, image)\n",
    "                    #print(image_path, image)\n",
    "                    frame = image\n",
    "                    if frame == \"0_frame_dados_nf.jpg\":\n",
    "                        nro_nota = 0\n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_dados, nro_nota = extract_fields_dados(text)\n",
    "\n",
    "                    if frame == \"0_frame_prefeitura_nf.jpg\":\n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_prefeitura, nome_prefeitura  = extract_fields_prefeitura(text)    \n",
    "                        \n",
    "                    if frame == \"1_frame_prestador_cnpj.jpg\": \n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_prestador = extract_fields_prestador(text)\n",
    "                        \n",
    "                               \n",
    "                    if frame == \"1_frame_prestador_inscricao.jpgg\": \n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_prestador = extract_fields_prestador(text)    \n",
    "                            \n",
    "                    if frame == \"1_frame_prestador_servico.jpg\": \n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_prestador = extract_fields_prestador(text)      \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    if frame == \"2_frame_tomador_cnpj.jpg\": \n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_tomador_cnpj = extract_fields_tomador_cnpj(text)                                                       \n",
    "                    \n",
    "                    \n",
    "                    if frame == \"2_frame_tomador_inscricao.jpg\": \n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_tomador_inscricao = extract_fields_tomador_inscricao(text)                            \n",
    "                        \n",
    "                        \n",
    "                    if frame == \"2_frame_tomador_servico.jpg\": \n",
    "                        image_to_ocr = Image.open(image_path).convert('RGB')\n",
    "                        text = pytesseract.image_to_string(image_to_ocr, lang='por', config=tessdata_dir_config)\n",
    "                        nf_data_tomador = extract_fields_tomador(text)  \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            # 6. Processa analise de tabela\n",
    "                            #results = processaTabela(image_path)\n",
    "                            \n",
    "                            # 7. Processa OCR\n",
    "                            #dados_da_tabela = processaOcrTable(image_path, results)\n",
    "                            \n",
    "                            #for i in dados_da_tabela:\n",
    "                                #if dados_da_tabela[i]['label'] == \"table column\":\n",
    "                                    #text = dados_da_tabela[i]['texto']\n",
    "                                    #print(f\"\\n{i}: \\n{dados_da_tabela[i]['texto']}\")\n",
    "                                    \n",
    "                    nr_nro_nf = nro_nota\n",
    "                        \n",
    "                    nome_arquivo_json = os.path.basename(root) + \".json\"\n",
    "                    nome_arquivo = file\n",
    "                                                \n",
    "                    pdf_info[nr_nro_nf] = {\n",
    "                        \"dados_NF_PDF\": {\n",
    "                            \"data_nf\": nf_data_dados,\n",
    "                            \"data_prefeitura\": nf_data_prefeitura,\n",
    "                            \"data_prestador\": nf_data_prestador,\n",
    "                            \"data_tomador_cnpj\": nf_data_tomador_cnpj,\n",
    "                            \"data_tomador_inscricao\": nf_data_tomador_inscricao,\n",
    "                            \"data_tomador\": nf_data_tomador,\n",
    "                            },\n",
    "                        \"diretorio\": os.path.basename(root),\n",
    "                        \"nome_arquivo\": nome_arquivo,    \n",
    "                    }            \n",
    "                        \n",
    "                        \n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, nome_arquivo_json)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo anterior do pipeline\n",
    "\n",
    "nf_data_servico = {}\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                nro_nota = 0\n",
    "                nr_nro_nf = 0\n",
    "                \n",
    "                #Definindo a pagina\n",
    "                # Carregar o arquivo PDF\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                # Página do PDF\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 4\n",
    "                x1 = 600\n",
    "                y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                if text:\n",
    "                    page_number = 0\n",
    "                else:\n",
    "                    page_number = 1\n",
    "                \n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                #pdf_document = fitz.open(file_path)\n",
    "                #page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho, nro_nota = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 530\n",
    "                x1 = 600\n",
    "                y1 = 540  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 545\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                nr_nro_nf = nro_nota\n",
    "                \n",
    "                nome_arquivo_json = os.path.basename(root) + \".json\"\n",
    "                \n",
    "                #json_file_path = os.path.join(target_directory, diretorio, \".json\")\n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[nr_nro_nf] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, nome_arquivo_json)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamada das funcoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 1 - CABECALHO\n",
    "data_cabecalho = {}\n",
    "data_cabecalho = processa_cabecalho()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 2 - PRESTADOR DE SERVIÇO\n",
    "data_prestador = {}\n",
    "data_prestador = processa_prestador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 3 - TOMADOR DE SERVIÇO\n",
    "data_tomador = {}\n",
    "data_tomador = processa_tomador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 4 - DESCRIMINACAO DOS SERVIÇOS\n",
    "data_servico = {}\n",
    "data_servico = processa_servico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 5 - VALOR TOTAL\n",
    "data_valor_total = {}\n",
    "data_valor_total = processa_total()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 6 - CNAE e Item da Lista de Serviços\n",
    "data_CNAE = {}\n",
    "data_CNAE = processa_cnae_itens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 7 - VALORES E IMPOSTOS & 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "data_valores = {}\n",
    "father_value = \"5_frame_valores_impostos\"\n",
    "section = \"7. VALORES E IMPOSTOS\"\n",
    "\n",
    "result = extract_fields_box(modelo, father_value, section)\n",
    "if result:\n",
    "    data_valores.update(result)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 8 - DADOS COMPLEMENTARES\"\n",
    "data_dados_complementares = {}\n",
    "f_father = \"5_frame_dados_complementares\"\n",
    "section = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "data_dados_complementares = extract_dados_comple_obs(modelo, f_father, section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 9 - OUTRAS INFORMAÇOES / CRITICAS\n",
    "data_outras_informacoes = {}\n",
    "father_value = \"5_frame_inf_criticas\"\n",
    "section = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "\n",
    "result = extract_fields_box(modelo, father_value, section)\n",
    "if result:\n",
    "    data_outras_informacoes.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# secao: 10. OBSERVACOES\n",
    "data_observacao = {}\n",
    "f_father = \"5_frame_observacao\"\n",
    "section = \"10. OBSERVACOES\"\n",
    "\n",
    "data_observacao = extract_dados_comple_obs(modelo, f_father, section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for color names to RGB values\n",
    "color_mapping = {\n",
    "    \"red\": (255, 0, 0),\n",
    "    \"purple\": (128, 0, 128),\n",
    "    \"orange\": (255, 165, 0),\n",
    "    \"green\": (0, 128, 50),\n",
    "    \"blue\": (0, 0, 255),\n",
    "    \"yellow\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "# Reload the image to start fresh\n",
    "image = Image.open(name_image_2work)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define a font size for the labels using the default PIL font\n",
    "font_size = 100\n",
    "#font = ImageFont.load_default()\n",
    "\n",
    "font = ImageFont.truetype(\"/usr/share/fonts/truetype/ubuntu/Ubuntu-M.ttf\", 30, encoding=\"unic\")\n",
    "\n",
    "# Update the draw_box function to use the larger font size with the default font\n",
    "def draw_box(row):\n",
    "    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "    color = color_mapping.get(row['color'], (0, 0, 0)) # Default to black if color not found\n",
    "    draw.rectangle([x0, y0, x1, y1], outline=color, width=3)\n",
    "    label = str(row['label']) if pd.notnull(row['label']) else None # Check for missing label\n",
    "    if label:\n",
    "        draw.text((x0 + 5, y0 + 5), label, fill=color, font=font)\n",
    "\n",
    "# Draw the boundaries\n",
    "#draw_box(boundaries_info)\n",
    "\n",
    "\n",
    "def draw_box_model(modelo,\n",
    "                   boundaries_info=None,\n",
    "                   sections_info=None,\n",
    "                   frames_info=None,\n",
    "                   field_boxes_info=None,\n",
    "                   draw_boundaries=True,\n",
    "                   draw_sections=True,\n",
    "                   draw_frames=True,\n",
    "                   draw_field_boxes=True):\n",
    "    \n",
    "    # Draw boundaries if requested\n",
    "    if draw_boundaries and boundaries_info is not None:\n",
    "        filtered_boundaries_info = boundaries_info[boundaries_info['model'] == modelo]\n",
    "        for index, row in filtered_boundaries_info.iterrows():\n",
    "            draw_box(row)\n",
    "\n",
    "    # Draw sections if requested\n",
    "    if draw_sections and sections_info is not None:\n",
    "        filtered_sections_info = sections_info[sections_info['model'] == modelo]\n",
    "        for index, row in filtered_sections_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw frames if requested\n",
    "    if draw_frames and frames_info is not None:\n",
    "        filtered_frames_info = frames_info[frames_info['model'] == modelo]\n",
    "        for index, row in filtered_frames_info.iterrows():\n",
    "            draw_box(row)\n",
    "            \n",
    "    # Draw field boxes if requested\n",
    "    if draw_field_boxes and field_boxes_info is not None:\n",
    "        filtered_field_boxes_info = field_boxes_info[field_boxes_info['model'] == modelo]\n",
    "        for index, row in filtered_field_boxes_info.iterrows():\n",
    "            draw_box(row)\n",
    "    \n",
    "    # Show the image with selected drawings\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only boundaries and sections:\n",
    "draw_box_model(modelo, boundaries_info, sections_info, draw_frames=False, draw_field_boxes=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw everything\n",
    "draw_box_model(modelo, boundaries_info, sections_info, frames_info, field_boxes_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To draw only field boxes:\n",
    "draw_box_model(modelo, field_boxes_info=field_boxes_info, draw_boundaries=False, draw_sections=False, draw_frames=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline reserva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo anterior do pipeline\n",
    "\n",
    "nf_data_servico = {}\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                nro_nota = 0\n",
    "                nr_nro_nf = 0\n",
    "                \n",
    "                #Definindo a pagina\n",
    "                # Carregar o arquivo PDF\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                # Página do PDF\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 4\n",
    "                x1 = 600\n",
    "                y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                if text:\n",
    "                    page_number = 0\n",
    "                else:\n",
    "                    page_number = 1\n",
    "                \n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                #pdf_document = fitz.open(file_path)\n",
    "                #page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho, nro_nota = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 530\n",
    "                x1 = 600\n",
    "                y1 = 540  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 545\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                nr_nro_nf = nro_nota\n",
    "                \n",
    "                nome_arquivo_json = os.path.basename(root) + \".json\"\n",
    "                \n",
    "                #json_file_path = os.path.join(target_directory, diretorio, \".json\")\n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[nr_nro_nf] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, nome_arquivo_json)\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamada das funçoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de consistencia de cnae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume extracted_cnae contains the extracted CNAE code or description from the document\n",
    "extracted_cnae = 'some_value'\n",
    "\n",
    "# Search the DataFrame for the extracted CNAE information (adjust the column name as needed)\n",
    "matching_row = cnae_df[cnae_df['cnae_column'] == extracted_cnae]\n",
    "\n",
    "# Use the values from the matching row\n",
    "if not matching_row.empty:\n",
    "    whole_value = matching_row.iloc[0] # Adjust to get the specific value you need\n",
    "    # Process the whole_value as needed\n",
    "else:\n",
    "    print('CNAE not found in repository')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mage_cnae_x_item_servico_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_servico_dict[7.02].upper()\n",
    "cnae_dict[4313400].upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template de funçao: frames_info -> sframe_fields_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields_frame(modelo, father_value, section):\n",
    "    \n",
    "\n",
    "    frame_label = father_value\n",
    "    print(section)\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_label) & (frames_info['model'] == modelo)]\n",
    "    \n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == father_value) & (sframe_fields_info['model'] == modelo)]\n",
    "    \n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        #extracted_text_box = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        \n",
    "        print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_frame['seq'], row_frame['model'], row_frame['father'], row_frame['label'], row_frame['reference'], row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'] ))\n",
    "        \n",
    "        # Divida o texto por nova linha e mantenha apenas a última parte (assume que o valor está sempre no final)\n",
    "        #value = extracted_text_box.split('\\n')[-1]\n",
    "        # Remova qualquer espaço em branco à esquerda ou à direita\n",
    "        #value = value.strip()\n",
    "        \n",
    "        for index_field, row_field in filtered_sframe_fields_info.iterrows():\n",
    "            \n",
    "            print(\"{:<5} {:<10} {:<30} {:<20} {:<20}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras possiveis chamadas de funcao mais inteligente\n",
    "\n",
    "- data_prestador\n",
    "\n",
    "- data_CNAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prestador\n",
    "data_prestador = {}\n",
    "father_value = \"2_frame_cnpj_prestador\"\n",
    "section = \"2. PRESTADOR DE SERVIÇO\"\n",
    "\n",
    "\n",
    "extract_fields_frame(modelo, father_value, section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_CNAE\n",
    "data_CNAE = {}\n",
    "father_value = \"4_frame_cnae_itens_servico\"\n",
    "section = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "\n",
    "extract_fields_frame(modelo, father_value, section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Informacoes dos DFSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaçao sobre os DF sendo utilizados\n",
    "\n",
    "\n",
    "sections_info\n",
    "\n",
    "frames_info.head()\n",
    "\n",
    "sframe_fields_info.head()\n",
    "\n",
    "field_boxes_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sframe_fields_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_boxes_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Filtrando o frames_info para buscar os dados de corte\n",
    "filtered_frames_info = frames_info[(frames_info['label'] == father_value) & (frames_info['model'] == modelo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == father_value) & (sframe_fields_info['model'] == modelo)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filtrando o field_boxes_info para buscar os dados de corte dos campos com BOX\n",
    "filtered_boxes_info = field_boxes_info[(field_boxes_info['father'] == father_value) & (field_boxes_info['model'] == modelo)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Operaçoes com arquivos e diretorios & Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> Config </mark>\n",
    "- root_pdf_path  (local inicial dos PDFs)\n",
    "\n",
    "- image_resized_path (local da imagem que foi convetida e resized)\n",
    "\n",
    "- nf_processada_path (local onde ficam os PDFs processados)\n",
    "\n",
    "\n",
    "<mark> Criados no processo </mark>\n",
    "\n",
    "- image_2work (arquivo de imagem resized criado)\n",
    "\n",
    "- name_image_2work (path e nome da imagem resized criada)\n",
    "\n",
    "- document_path (path e nome do PDF utilizado para tratamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_pdf_processed_ok(document_path):\n",
    "    \n",
    "    source_path = document_path\n",
    "    destination_path = os.path.join(f'{nf_processada_path}/{str(doc2convert)}')\n",
    "    shutil.move(source_path, destination_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mover PDF para diretorio de processados\n",
    "source_path = document_path\n",
    "destination_path = os.path.join(f'{nf_processada_path}/{str(doc2convert)}')\n",
    "shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***DELETAR**** o arquivo de imagem gerado\n",
    "image_path_to_delete = name_image_2work\n",
    "os.remove(image_path_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voltar (mover) PDF para diretorio para ser processado\n",
    "source_path = destination_path\n",
    "\n",
    "destination_path = document_path\n",
    "\n",
    "shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processo para iterar estrutura de arquivos, diretorios\n",
    "for roots, directories, documents in os.walk(image_resized_path):\n",
    "    print(f'\\n {documents} {name_image_2work}\\n\\n')\n",
    "    #if documents == :\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Buscar o primeiro documento do diretorio EXTERNO para processar\n",
    "source_directory = root_external_pdf_path\n",
    "destination_directory = root_pdf_path\n",
    "\n",
    "# Verifique se o diretório de destino está vazio\n",
    "if os.listdir(destination_directory):\n",
    "    raise Exception(\"O diretório de destino não está vazio!\")\n",
    "\n",
    "for roots, directories, documents in os.walk(source_directory):\n",
    "    # Filtre os documentos para incluir apenas aqueles com extensão .pdf\n",
    "    pdf_files = [doc for doc in documents if doc.lower().endswith('.pdf')]\n",
    "    \n",
    "    if pdf_files: # Verifique se há algum arquivo PDF no diretório\n",
    "        first_pdf_file = pdf_files[0] # Obtenha o primeiro arquivo PDF\n",
    "        source_path = os.path.join(roots, first_pdf_file) # Construa o caminho completo para o primeiro arquivo PDF\n",
    "        print(f\"Found the first PDF file: {source_path}\")\n",
    "        \n",
    "        # Mova o arquivo para o diretório de destino\n",
    "        shutil.move(source_path, destination_directory)\n",
    "        \n",
    "        break # Saia do loop após encontrar o primeiro arquivo PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOG - Single File vs. Separate Files\n",
    "\n",
    "1. Single File vs. Separate Files\n",
    "Single File: Suitable if the volume of logs is manageable and you want a consolidated view of all activities.\n",
    "Separate Files: Useful if you want to organize logs by day or by a specific module or process. This can help in troubleshooting specific issues and managing large volumes of logs.\n",
    "2. Concise vs. Detailed Logs\n",
    "You can create different log levels to handle concise and detailed logging:\n",
    "\n",
    "Concise Log: Use the INFO level to log only essential information, such as process start and end times, success messages, etc.\n",
    "Detailed Log: Use the DEBUG level to log detailed information, like variable values, intermediate steps, etc.\n",
    "Example with Python's logging Module\n",
    "Here's an example of how you might set up logging to handle both separate files and different log levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "log_file_path = 'novo_modelo/execucao_pipeline_extracao_pdf.log'\n",
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    filemode='a', # Append mode\n",
    "    level=logging.INFO, # Log level (e.g., INFO, WARNING, ERROR)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', # Log message format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S' # Date format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logger\n",
    "logger = logging.getLogger('my_logger')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create handlers\n",
    "info_handler = logging.FileHandler('info.log')\n",
    "info_handler.setLevel(logging.INFO)\n",
    "\n",
    "error_handler = logging.FileHandler('error.log')\n",
    "error_handler.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a formatter and set it for the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "info_handler.setFormatter(formatter)\n",
    "error_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handlers to the logger\n",
    "logger.addHandler(info_handler)\n",
    "logger.addHandler(error_handler)\n",
    "\n",
    "# Log messages\n",
    "logger.info('This is an info message.')\n",
    "logger.error('This is an error message.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example of concise log (INFO level)\n",
    "logging.info(\"Processo iniciado.\")\n",
    "\n",
    "# Example of detailed log (DEBUG level)\n",
    "logging.debug(\"Variable x value is 10.\")\n",
    "\n",
    "# ... rest of your code ...\n",
    "\n",
    "# Handle exceptions with logging\n",
    "try:\n",
    "    # Your code that might raise an exception\n",
    "    pass\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "log_file_path = 'novo_modelo/execucao_pipeline_extracao_pdf.log'\n",
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    filemode='a', # Append mode\n",
    "    level=logging.INFO, # Log level (e.g., INFO, WARNING, ERROR)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s', # Log message format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S' # Date format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Pipeline iniciado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the logger\n",
    "logging.info(\"Pipeline started.\")\n",
    "logging.info(\"Processing file: %s\", first_pdf_file_path)\n",
    "logging.warning(\"File has more than one page.\")\n",
    "logging.error(\"An error occurred while processing file: %s\", first_pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Pipeline iniciado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the logger\n",
    "logging.info(\"Pipeline started.\")\n",
    "logging.info(\"Processing file: %s\", first_pdf_file_path)\n",
    "logging.warning(\"File has more than one page.\")\n",
    "logging.error(\"An error occurred while processing file: %s\", first_pdf_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing the log level, you can control the verbosity of the logs. If you want separate log files for each day, the above code will create a new file every day based on the date.\n",
    "\n",
    "Remember, logging strategy should align with your application's needs, including debugging, auditing, and compliance requirements. Make sure to review and test your logging setup to ensure it meets your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import datetime\n",
    "\n",
    "# Get the current date for filename\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "log_filename = f\"log_{current_date}.txt\"\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename=log_filename,\n",
    "    level=logging.DEBUG,  # Log everything (change to INFO for concise logs)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "\n",
    "# Example of concise log (INFO level)\n",
    "logging.info(\"Processing started.\")\n",
    "\n",
    "# Example of detailed log (DEBUG level)\n",
    "logging.debug(\"Variable x value is 10.\")\n",
    "\n",
    "# ... rest of your code ...\n",
    "\n",
    "# Handle exceptions with logging\n",
    "try:\n",
    "    # Your code that might raise an exception\n",
    "    pass\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Teste e codigos para analisar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcoes de melhoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#Funçao de formatacao de numeros\n",
    "def format_number(number_str):\n",
    "    number_str = number_str.replace('R$', '').replace('.', '').replace(',', '.')\n",
    "    if '%' in number_str:\n",
    "        number_str = number_str.replace('%', '')\n",
    "        return float(number_str)  # multiplica por 100 para campos %\n",
    "    return float(number_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dados_cabecalho(modelo, frame_father, section):\n",
    "    \n",
    "    data_dados_complementares = {}\n",
    "    #frame_label = frame_father\n",
    "    \n",
    "    # 1. Filtrando o frames_info para buscar os dados de corte\n",
    "    filtered_frames_info = frames_info[(frames_info['label'] == frame_father) & (frames_info['model'] == modelo)]\n",
    "\n",
    "    # 2. Filtrando o sframe_fields_info para buscar os dados dos campos que estao nos frames\n",
    "    filtered_sframe_fields_info = sframe_fields_info[(sframe_fields_info['father'] == frame_father) & (sframe_fields_info['model'] == modelo)]\n",
    "\n",
    "    for index_frame, row_frame in filtered_frames_info.iterrows():\n",
    "        \n",
    "        x0, y0, x1, y1 = row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1']\n",
    "        extracted_text_frame = extract_text_from_frame(image_2work, (x0, y0, x1, y1), tessdata_dir_config)\n",
    "        values = extracted_text_frame.split('\\n')\n",
    "        print(\"{:<5} {:<10} {:<30} {:<20} {:<20} {:<7} {:<7} {:<7} {:<7}\".format(row_frame['seq'], row_frame['model'], row_frame['father'], row_frame['label'], row_frame['reference'], row_frame['x0'], row_frame['y0'], row_frame['x1'], row_frame['y1'] ))\n",
    "        for index_field, row_field in filtered_sframe_fields_info.iterrows():\n",
    "            print(\"{:<5} {:<10} {:<30} {:<20} {:<20}\".format(row_field['seq'], row_field['model'], row_field['father'], row_field['label'], row_field['reference']))\n",
    "            nf_data_cabecalho_prefeitura = {}\n",
    "            nf_data_cabecalho_prefeitura['secao'] = section\n",
    "            type_value = row_field['type']\n",
    "            label_value = row_field['label']\n",
    "            reference_value = row_field['reference']\n",
    "            for value in values:\n",
    "                result = process_line(value, reference_value, label_value)\n",
    "                if result:\n",
    "                    nf_data_cabecalho_prefeitura.update(result)\n",
    "            \n",
    "        return nf_data_cabecalho_prefeitura   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cabecalho\n",
    "f_father = \"1_frame_prefeitura_nf\"\n",
    "section = \"1 - CABECALHO\"\n",
    "\n",
    "#dict consolidador\n",
    "data_cabecalho = {}\n",
    "\n",
    "data_cabecalho = extract_dados_cabecalho(modelo, f_father, section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark> Testar esta configuraçao de Tesseract </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(cropped_frame, is_number = False):\n",
    "    if (is_number):\n",
    "        text = pytesseract.image_to_string(cropped_frame,\n",
    "                                           config ='-c tessedit_char_whitelist=0123456789 --psm 10 --oem 2')\n",
    "    else:\n",
    "        text = pytesseract.image_to_string(cropped_frame, config='--psm 10')        \n",
    "        \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Boxes with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Matplotlib library to draw boxes on an image is entirely feasible and provides more control over the appearance and customization of the drawings. Below, I'll provide an example of how you can draw boxes on an image using Matplotlib.\n",
    "\n",
    "First, make sure you have the necessary libraries installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def draw_boxes(image, boxes_info, color='r'):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(1)\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "\n",
    "    # Draw the boxes\n",
    "    for index, row in boxes_info.iterrows():\n",
    "        x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle((x0, y0), x1 - x0, y1 - y0, linewidth=1, edgecolor=color, facecolor='none')\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call this function with your image object and DataFrame containing the coordinates of the boxes to be drawn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_boxes(image, boundaries_info, color='r')\n",
    "draw_boxes(image, sections_info, color='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can customize the appearance of the boxes by changing the parameters of the patches.Rectangle function, such as line width, edge color, and face color.\n",
    "\n",
    "Using Matplotlib in this way allows you to have more control over the appearance of the plot, and you can easily combine it with other Matplotlib features to create complex visualizations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tecnicas de manitpulacao de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "\n",
    "def convert_pdf_to_string(file_path):\n",
    "\n",
    "\toutput_string = StringIO()\n",
    "\twith open(file_path, 'rb') as in_file:\n",
    "\t    parser = PDFParser(in_file)\n",
    "\t    doc = PDFDocument(parser)\n",
    "\t    rsrcmgr = PDFResourceManager()\n",
    "\t    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
    "\t    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\t    for page in PDFPage.create_pages(doc):\n",
    "\t        interpreter.process_page(page)\n",
    "\n",
    "\treturn(output_string.getvalue())\n",
    "\n",
    "\n",
    "2407-106 TERE SÃO PEDRO.pdf\n",
    "                \n",
    "def convert_title_to_filename(title):\n",
    "    filename = title.lower()\n",
    "    filename = filename.replace(' ', '_')\n",
    "    return filename\n",
    "\n",
    "\n",
    "def split_to_title_and_pagenum(table_of_contents_entry):\n",
    "    title_and_pagenum = table_of_contents_entry.strip()\n",
    "    \n",
    "    title = None\n",
    "    pagenum = None\n",
    "    \n",
    "    if len(title_and_pagenum) > 0:\n",
    "        if title_and_pagenum[-1].isdigit():\n",
    "            i = -2\n",
    "            while title_and_pagenum[i].isdigit():\n",
    "                i -= 1\n",
    "\n",
    "            title = title_and_pagenum[:i].strip()\n",
    "            pagenum = int(title_and_pagenum[i:].strip())\n",
    "        \n",
    "    return title, pagenum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import fitz\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "print(fitz.__doc__)\n",
    "\n",
    "if not tuple(map(int, fitz.version[0].split(\".\"))) >= (1, 18, 18):\n",
    "    raise SystemExit(\"require PyMuPDF v1.18.18+\")\n",
    "\n",
    "dimlimit = 0  # 100  # each image side must be greater than this\n",
    "relsize = 0  # 0.05  # image : image size ratio must be larger than this (5%)\n",
    "abssize = 0  # 2048  # absolute image size limit 2 KB: ignore if smaller\n",
    "imgdir = \"output\"  # found images are stored in this subfolder\n",
    "\n",
    "if not os.path.exists(imgdir):  # make subfolder if necessary\n",
    "    os.mkdir(imgdir)\n",
    "\n",
    "\n",
    "def recoverpix(doc, item):\n",
    "    xref = item[0]  # xref of PDF image\n",
    "    smask = item[1]  # xref of its /SMask\n",
    "\n",
    "    # special case: /SMask or /Mask exists\n",
    "    if smask > 0:\n",
    "        pix0 = fitz.Pixmap(doc.extract_image(xref)[\"image\"])\n",
    "        if pix0.alpha:  # catch irregular situation\n",
    "            pix0 = fitz.Pixmap(pix0, 0)  # remove alpha channel\n",
    "        mask = fitz.Pixmap(doc.extract_image(smask)[\"image\"])\n",
    "\n",
    "        try:\n",
    "            pix = fitz.Pixmap(pix0, mask)\n",
    "        except:  # fallback to original base image in case of problems\n",
    "            pix = fitz.Pixmap(doc.extract_image(xref)[\"image\"])\n",
    "\n",
    "        if pix0.n > 3:\n",
    "            ext = \"pam\"\n",
    "        else:\n",
    "            ext = \"png\"\n",
    "\n",
    "        return {  # create dictionary expected by caller\n",
    "            \"ext\": ext,\n",
    "            \"colorspace\": pix.colorspace.n,\n",
    "            \"image\": pix.tobytes(ext),\n",
    "        }\n",
    "\n",
    "    # special case: /ColorSpace definition exists\n",
    "    # to be sure, we convert these cases to RGB PNG images\n",
    "    if \"/ColorSpace\" in doc.xref_object(xref, compressed=True):\n",
    "        pix = fitz.Pixmap(doc, xref)\n",
    "        pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "        return {  # create dictionary expected by caller\n",
    "            \"ext\": \"png\",\n",
    "            \"colorspace\": 3,\n",
    "            \"image\": pix.tobytes(\"png\"),\n",
    "        }\n",
    "    return doc.extract_image(xref)\n",
    "\n",
    "\n",
    "fname = sys.argv[1] if len(sys.argv) == 2 else None\n",
    "if not fname:\n",
    "    fname = sg.PopupGetFile(\"Select file:\", title=\"PyMuPDF PDF Image Extraction\")\n",
    "if not fname:\n",
    "    raise SystemExit()\n",
    "\n",
    "t0 = time.time()\n",
    "doc = fitz.open(fname)\n",
    "\n",
    "page_count = doc.page_count  # number of pages\n",
    "\n",
    "xreflist = []\n",
    "imglist = []\n",
    "for pno in range(page_count):\n",
    "    sg.QuickMeter(\n",
    "        \"Extract Images\",  # show our progress\n",
    "        pno + 1,\n",
    "        page_count,\n",
    "        \"*** Scanning Pages ***\",\n",
    "    )\n",
    "\n",
    "    il = doc.get_page_images(pno)\n",
    "    imglist.extend([x[0] for x in il])\n",
    "    for img in il:\n",
    "        xref = img[0]\n",
    "        if xref in xreflist:\n",
    "            continue\n",
    "        width = img[2]\n",
    "        height = img[3]\n",
    "        if min(width, height) <= dimlimit:\n",
    "            continue\n",
    "        image = recoverpix(doc, img)\n",
    "        n = image[\"colorspace\"]\n",
    "        imgdata = image[\"image\"]\n",
    "\n",
    "        if len(imgdata) <= abssize:\n",
    "            continue\n",
    "        if len(imgdata) / (width * height * n) <= relsize:\n",
    "            continue\n",
    "\n",
    "        imgfile = os.path.join(imgdir, \"img%05i.%s\" % (xref, image[\"ext\"]))\n",
    "        fout = open(imgfile, \"wb\")\n",
    "        fout.write(imgdata)\n",
    "        fout.close()\n",
    "        xreflist.append(xref)\n",
    "\n",
    "t1 = time.time()\n",
    "imglist = list(set(imglist))\n",
    "print(len(set(imglist)), \"images in total\")\n",
    "print(len(xreflist), \"images extracted\")\n",
    "print(\"total time %g sec\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A basic text-to-PDF converter\n",
    "--------------------------------------------------------------------------------\n",
    "License: GNU GPL V3\n",
    "(c) 2018 Jorj X. McKie\n",
    "\n",
    "Usage\n",
    "-----\n",
    "python convert.py input.txt\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import fitz\n",
    "\n",
    "assert len(sys.argv) == 2, \"usage: python %s text.file\" % (sys.argv[0],)\n",
    "ifn = sys.argv[1]\n",
    "ofn = \"output1.pdf\"\n",
    "\n",
    "width, height = fitz.paper_size(\"a4\")\n",
    "fontsz = 10\n",
    "lineheight = fontsz * 1.2\n",
    "\n",
    "nlines = int((height - 108.0) / lineheight)\n",
    "\n",
    "sourcefile = open(ifn)\n",
    "line_ctr = 0  # page line counter\n",
    "total_ctr = 0  # total line counter\n",
    "out_ctr = 0  # count output lines\n",
    "out_buf = \"\"  # text of one page\n",
    "\n",
    "doc = fitz.open()\n",
    "\n",
    "\n",
    "def page_out(b):\n",
    "    page = doc.new_page(width=width, height=height)\n",
    "    return page.insert_text(\n",
    "        (50, 72),\n",
    "        text=b,\n",
    "        fontsize=fontsz,\n",
    "    )\n",
    "\n",
    "\n",
    "while True:\n",
    "    line = sourcefile.readline()\n",
    "    if line == \"\":\n",
    "        break\n",
    "    out_buf += line\n",
    "    line_ctr += 1\n",
    "    total_ctr += 1\n",
    "    if line_ctr == nlines:\n",
    "        out_ctr += page_out(out_buf)\n",
    "        out_buf = \"\"\n",
    "        line_ctr = 0\n",
    "\n",
    "if len(out_buf) > 0:\n",
    "    out_ctr += page_out(out_buf)\n",
    "\n",
    "print(\"PDF conversion results for file '%s':\" % (ifn,))\n",
    "print(out_ctr, \"lines read,\", total_ctr, \"lines written,\", nlines, \"lines per page.\")\n",
    "print(ofn, \"contains\", len(doc), \"pages.\")\n",
    "\n",
    "# Now add a header and footer to each page\n",
    "hdr_fontsz = 16\n",
    "ftr_fontsz = 8\n",
    "blue = fitz.pdfcolor[\"blue\"]\n",
    "pspace = 500\n",
    "\n",
    "for page in doc:\n",
    "    footer = \"%i (%i)\" % (page.number + 1, len(doc))  # footer text\n",
    "    plen_ftr = fitz.get_text_length(footer, fontname=\"Helvetica\", fontsize=ftr_fontsz)\n",
    "    page.insert_text(\n",
    "        (50, 50), ifn, color=blue, fontsize=hdr_fontsz  # header = input filename\n",
    "    )\n",
    "    page.draw_line(\n",
    "        fitz.Point(50, 60),\n",
    "        fitz.Point(50 + pspace, 60),  # line below hdr\n",
    "        color=blue,\n",
    "        width=0.5,\n",
    "    )\n",
    "    page.draw_line(\n",
    "        fitz.Point(50, height - 33),  # line above footer\n",
    "        fitz.Point(50 + pspace, height - 33),\n",
    "        color=blue,\n",
    "        width=0.5,\n",
    "    )\n",
    "    page.insert_text(\n",
    "        (50 + pspace - plen_ftr, height - 33 + ftr_fontsz * 1.2),  # insert footer\n",
    "        footer,\n",
    "        fontsize=ftr_fontsz,\n",
    "        color=blue,\n",
    "    )\n",
    "    page.clean_contents()\n",
    "\n",
    "doc.set_metadata(\n",
    "    {\n",
    "        \"creationDate\": fitz.get_pdf_now(),\n",
    "        \"modDate\": fitz.get_pdf_now(),\n",
    "        \"creator\": \"convert.py\",\n",
    "        \"producer\": \"PyMuPDF %s\" % fitz.VersionBind,\n",
    "        \"title\": \"Content of file \" + ifn,\n",
    "        \"subject\": \"Demonstrate methods new_page, insert_text and draw_line\",\n",
    "        \"author\": \"Jorj McKie\",\n",
    "    }\n",
    ")\n",
    "doc.subset_fonts()\n",
    "doc.ez_save(ofn, garbage=4, pretty=True)\n",
    "doc.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tables-detr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
