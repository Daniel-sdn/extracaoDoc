{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Novo modelo de extraçao de dados de NFs - NLP </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from pathlib import WindowsPath\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfReader, PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from io import BytesIO\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_pdf = r\".\\data\\272519EC-959B-4460-BBE6-D80D272B9ACD.PDF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputStream = open(doc_pdf, \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = PdfReader(inputStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = len(src.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = PdfWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_num in range(page_number):\n",
    "    output.add_page(src.pages[page_num])\n",
    "    output.remove_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o PDF final\n",
    "with open('seu_pdf_final_sem_imagens.pdf', 'wb') as output_pdf:\n",
    "    output.write(output_pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processamento PDF => Imagem => OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from pathlib import WindowsPath\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretório TESTE raiz para documentos PDF pesquisaveis\n",
    "root_directory = '.\\\\data\\data_teste'  # Diretório raiz TESTE\n",
    "\n",
    "\n",
    "#Diretório raiz para documentos geracao de JSON TESTE\n",
    "target_directory = '.\\\\data\\data_teste\\Gravacao_json_teste'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Usada para registar os numeros de paginas do PDF\n",
    "pdf_pages = r\".\\page_\"\n",
    "\n",
    "\n",
    "\n",
    "poppler_path = r'C:\\Users\\danie\\Downloads\\Release-23.07.0-0\\poppler-23.07.0\\Library\\bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Arquivos para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\".\\seu_pdf_final_sem_imagens.pdf\"  #Modelo de nf Mage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\".\\data\\272519EC-959B-4460-BBE6-D80D272B9ACD.PDF\"  #Modelo de MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\".\\data\\data_teste\\documentos_pdf_teste\\272519EC-959B-4460-BBE6-D80D272B9ACD.PDF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Conversao PDF => Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes!!!!!\n",
    "from pdf2image import convert_from_path\n",
    "pages = convert_from_path(file, 500,poppler_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "len(pages)\n",
    "\n",
    "image_counter = 1\n",
    "\n",
    "for page in pages:\n",
    "    filename = pdf_pages + str(image_counter) + \".jpg\"\n",
    "    page.save(filename, 'JPEG')\n",
    "    image_counter = image_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Executando o OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_file = filename\n",
    "\n",
    "factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\".\\data\\data_teste\\documentos_pdf_teste\\272519EC-959B-4460-BBE6-D80D272B9ACD.PDF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = r\".\\data\\data_image_test\\page_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = r\".\\data\\data_image_test\\nova_imagem.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using factor variable\n",
    "\n",
    "factor = 0.5\n",
    "\n",
    "file_path = image_file\n",
    "image = Image.open(file_path).convert(\"RGB\")\n",
    "width, height = image.size\n",
    "image.resize((int(width*factor), int(height*factor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import pytesseract\n",
    "\n",
    "# If you don't have tesseract executable in your PATH, include the following:\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "# Example tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of adding any additional options\n",
    "custom_oem_psm_config = r'--oem 1 --psm 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config='--psm 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portuguese text image to string\n",
    "text = pytesseract.image_to_string(image, lang='por', config=custom_oem_psm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_data(image, lang='por', config=custom_oem_psm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a imagem\n",
    "image = cv2.imread(image_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir região de interesse (parte de texto)\n",
    "roi = image[:, 300:]  # Isso depende das coordenadas da sua imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para escala de cinza\n",
    "gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar um limiar para segmentar o texto\n",
    "_, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar contornos na imagem\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma máscara para a região de texto\n",
    "mask = np.zeros_like(roi)\n",
    "cv2.drawContours(mask, contours, -1, (255, 255, 255), thickness=cv2.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolated_text = cv2.cvtColor(isolated_text, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(isolated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a máscara para isolar a região de texto\n",
    "isolated_text = cv2.bitwise_and(roi, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a imagem isolada para formato que pode ser exibido no notebook\n",
    "isolated_text = cv2.cvtColor(isolated_text, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Exibir a imagem\n",
    "display(isolated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a imagem isolada para formato que pode ser exibido no notebook\n",
    "isolated_text = cv2.cvtColor(isolated_text, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Salvar a imagem em um buffer\n",
    "image_buffer = io.BytesIO()\n",
    "Image.fromarray(isolated_text).save(image_buffer, format=\"PNG\")\n",
    "\n",
    "# Exibir a imagem\n",
    "display(Image(data=image_buffer.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar a imagem isolada (para verificar se a segmentação foi bem-sucedida)\n",
    "cv2.imshow('Isolated Text', isolated_text)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HOCR output\n",
    "hocr = pytesseract.image_to_pdf_or_hocr(image, lang='por', extension='hocr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_writer = PdfWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o PDF final\n",
    "# Salvar os dados HOCR em um arquivo\n",
    "with open('output.hocr', 'wb') as hocr_file:\n",
    "    hocr_file.write(hocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portuguese text image to string\n",
    "text = pytesseract.image_to_string(Image.open(image), lang='por', config='--psm 6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portuguese text image to string\n",
    "text = pytesseract.image_to_string(Image.open(image_file), lang='por', config=custom_oem_psm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_filename = 'words'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portuguese text image to string\n",
    "text = pytesseract.image_to_string(Image.open(image_file), lang='por', config=cfg_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract images/2col.png - --psm 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pytesseract.image_to_string(image, config=custom_oem_psm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_data(image, lang=None, config='', nice=0, output_type=Output.STRING, timeout=0, pandas_config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portuguese text image to string\n",
    "text = pytesseract.image_to_string(Image.open(Image_file), lang='por')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POC Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = r\".\\data\\data_image_test\\page_1.jpg\"  #imagem criada anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bounding box estimates\n",
    "print(pytesseract.image_to_boxes(Image.open(image_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get verbose data including boxes, confidences, line and page numbers\n",
    "print(pytesseract.image_to_data(Image.open(image_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about orientation and script detection\n",
    "print(pytesseract.image_to_osd(Image.open(image_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img_cv = cv2.imread(image_file)\n",
    "\n",
    "# By default OpenCV stores images in BGR format and since pytesseract assumes RGB format,\n",
    "# we need to convert from BGR to RGB format/mode:\n",
    "img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "print(pytesseract.image_to_string(img_rgb))\n",
    "# OR\n",
    "img_rgb = Image.frombytes('RGB', img_cv.shape[:2], img_cv, 'raw', 'BGR', 0, 0)\n",
    "print(pytesseract.image_to_string(img_rgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = r\".\\data\\data_image_test\\page_1.jpg\"  #imagem criada anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "from io import BytesIO\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageTemplate, Frame\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from PyPDF2 import PdfReader, PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a imagem em texto\n",
    "image = Image.open(image_file)\n",
    "text = pytesseract.image_to_string(image)\n",
    "\n",
    "# Criar o PDF do Tesseract\n",
    "buffer_tesseract = BytesIO()\n",
    "doc_tesseract = SimpleDocTemplate(buffer_tesseract, pagesize=letter)\n",
    "styles = getSampleStyleSheet()\n",
    "content_tesseract = [Paragraph(text, styles[\"Normal\"])]\n",
    "doc_tesseract.build(content_tesseract)\n",
    "\n",
    "# Criar o PDF com as informações de página\n",
    "buffer_page = BytesIO()\n",
    "doc_page = SimpleDocTemplate(buffer_page, pagesize=letter)\n",
    "def add_page_number(canvas, doc):\n",
    "    page_num = canvas.getPageNumber()\n",
    "    text = f\"Página {page_num}\"\n",
    "    canvas.drawRightString(200*doc.width/300, 10, text)\n",
    "doc_page.addPageTemplates([PageTemplate(id='AllPages', frames=[Frame(doc_page.leftMargin, doc_page.bottomMargin, doc_page.width, doc_page.height - 40, id='normal')], onPage=add_page_number)])\n",
    "content_page = [Paragraph(\"Texto de Página com Números\", styles[\"Normal\"])]  # Pode ser um texto qualquer\n",
    "doc_page.build(content_page)\n",
    "\n",
    "\n",
    "page_number = len(pdf_reader_page.pages)\n",
    "\n",
    "# Mesclar os PDFs\n",
    "pdf_reader_tesseract = PdfReader(buffer_tesseract)\n",
    "pdf_reader_page = PdfReader(buffer_page)\n",
    "pdf_writer = PdfWriter()\n",
    "\n",
    "\n",
    "for page_num in range(page_number):\n",
    "    page_tesseract = pdf_reader_tesseract.pages[page_num]\n",
    "    page_page = pdf_reader_page.pages[page_num]\n",
    "    page_tesseract.merge_page(page_page)\n",
    "    pdf_writer.add_page(page_tesseract)\n",
    "    \n",
    "# Salvar o PDF final\n",
    "with open('seu_pdf_final_com_paginas.pdf', 'wb') as output_pdf:\n",
    "    pdf_writer.write(output_pdf) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_writer = PdfWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = len(pdf_reader_page.pages)\n",
    "\n",
    "# Mesclar os PDFs\n",
    "pdf_reader_tesseract = PdfReader(buffer_tesseract)\n",
    "pdf_reader_page = PdfReader(buffer_page)\n",
    "pdf_writer = PdfWriter()\n",
    "\n",
    "\n",
    "for page_num in range(page_number):\n",
    "    page_tesseract = pdf_reader_tesseract.pages[page_num]\n",
    "    page_page = pdf_reader_page.pages[page_num]\n",
    "    page_tesseract.merge_page(page_page)\n",
    "    pdf_writer.add_page(page_tesseract)\n",
    "    \n",
    "# Salvar o PDF final\n",
    "with open('seu_pdf_final_com_paginas.pdf', 'wb') as output_pdf:\n",
    "    pdf_writer.write(output_pdf)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o PDF final\n",
    "with open('seu_pdf_final_com_paginas.pdf', 'wb') as output_pdf:\n",
    "    pdf_writer.write(output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converter a imagem em texto\n",
    "image = Image.open(image_file)\n",
    "text = pytesseract.image_to_string(image)\n",
    "\n",
    "# Criar o PDF\n",
    "buffer = BytesIO()\n",
    "doc = SimpleDocTemplate(buffer, pagesize=letter)\n",
    "\n",
    "# Estilo para o conteúdo do PDF\n",
    "styles = getSampleStyleSheet()\n",
    "style = styles[\"Normal\"]\n",
    "\n",
    "# Adicionar o texto extraído da imagem\n",
    "content = [Paragraph(text, style)]\n",
    "doc.build(content)\n",
    "\n",
    "# Adicionar informações da página\n",
    "page_info = \"Página 1 de 1\"  # Você pode personalizar isso conforme necessário\n",
    "\n",
    "# Abrir o PDF criado e adicionar informações da página\n",
    "buffer.seek(0)\n",
    "new_pdf = BytesIO()\n",
    "can = canvas.Canvas(new_pdf, pagesize=letter)\n",
    "page_width, page_height = letter\n",
    "can.drawString(page_width - 100, 10, page_info)\n",
    "can.save()\n",
    "\n",
    "# Combinar o conteúdo do PDF com as informações da página\n",
    "merger = PdfMerger()\n",
    "merger.append(BytesIO(buffer.getvalue()))\n",
    "merger.append(new_pdf)\n",
    "\n",
    "# Salvar o PDF final\n",
    "with open('seu_pdf_final.pdf', 'wb') as output_pdf:\n",
    "    merger.write(output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a searchable PDF\n",
    "pdf = pytesseract.image_to_pdf_or_hocr(image, extension='pdf')\n",
    "with open('test.pdf', 'w+b') as f:\n",
    "    f.write(pdf) # pdf type is bytes by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "import json\n",
    "import PyPDF2\n",
    "#from pdfminer.high_level import extract_pages\n",
    "#from pdfminer.layout import LTTextContainer, LTChar\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. spaCy NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import pandas as pd\n",
    "from spacy.tokens import Span\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processamento TEXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplode funçao Pre-processamento do texto\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remover quebras de página e espaços extras\n",
    "    text = re.sub(r'\\n+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remover caracteres especiais que não sejam letras, números ou espaços\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text = preprocess_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_new_document(pdf_text):\n",
    "    # Substituir quebras de página por espaços\n",
    "    pdf_text = re.sub(r'\\n+', ' ', pdf_text)\n",
    "    \n",
    "    # Encontrar padrões de campo e valor e separá-los em linhas distintas\n",
    "    new_lines = []\n",
    "    for match in re.finditer(r'([^:]+):\\s*(.+?)(?=\\s+[^\\s:]+:|$)', pdf_text):\n",
    "        field = match.group(1).strip()\n",
    "        value = match.group(2).strip()\n",
    "        new_lines.append(f\"{field}:\\n{value}\")\n",
    "    \n",
    "    # Compor o novo documento com os campos e valores em linhas distintas\n",
    "    new_document = '\\n'.join(new_lines)\n",
    "    \n",
    "    return new_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_document = compose_new_document(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import fitz\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_tomador = {}\n",
    "\n",
    "# Extrair Inscrição Municipal\n",
    "inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "if inscricao_municipal_match:\n",
    "    nf_data_tomador['Inscrição Municipal'] = inscricao_municipal_match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in nf_data_tomador.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover quebras de linha\n",
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Anterior - pesquisa por Regex in Boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modulos e paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "import json\n",
    "import PyPDF2\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Path - Documentos PDF para Extracao e geracao de JSONS - <mark>producao</mark></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Diretório raiz para documentos PDF pesquisaveis\n",
    "root_directory = '.\\\\data\\data_pdf\\NF_para_processamento'  # Diretório raiz \n",
    "\n",
    "\n",
    "#Diretório raiz para documentos geracao de JSON\n",
    "target_directory = '.\\\\data\\data_pdf\\Gravacao_json'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><mark>TESTE</mark> - Path - Documentos PDF para Extracao e geracao de JSONS - <mark>TESTE</mark></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretório TESTE raiz para documentos PDF pesquisaveis\n",
    "root_directory = '.\\\\data\\data_teste'  # Diretório raiz TESTE\n",
    "\n",
    "\n",
    "#Diretório raiz para documentos geracao de JSON TESTE\n",
    "target_directory = '.\\\\data\\data_teste\\Gravacao_json_teste'\n",
    "\n",
    "nro_nota_fiscal = 0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analise de arquivos e quantidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 2.1 Analise de PDF Pesquisavel </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "pdf_image_info = []  # Lista para armazenar informações sobre PDFs e imagens\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                pdf_image_info.append({\n",
    "                    \"subdiretorio\": os.path.relpath(root, root_directory),\n",
    "                    \"nome_arquivo\": file,\n",
    "                    \"tipo\": \"PDF\",\n",
    "                    \"status\": \"O PDF é pesquisável\"\n",
    "                })\n",
    "            else:\n",
    "                pdf_image_info.append({\n",
    "                    \"subdiretorio\": os.path.relpath(root, root_directory),\n",
    "                    \"nome_arquivo\": file,\n",
    "                    \"tipo\": \"PDF\",\n",
    "                    \"status\": \"O PDF não é pesquisável\"\n",
    "                })\n",
    "        elif any(file.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "            pdf_image_info.append({\n",
    "                \"subdiretorio\": os.path.relpath(root, root_directory),\n",
    "                \"nome_arquivo\": file,\n",
    "                \"tipo\": \"IMAGEM\"\n",
    "            })\n",
    "\n",
    "# Iterando e exibindo as informações coletadas\n",
    "for item in pdf_image_info:\n",
    "    print(f\"Subdiretório: {item['subdiretorio']} \\n\\nNome do arquivo: {item['nome_arquivo']}, Tipo: {item['tipo']}\")\n",
    "    if 'status' in item:\n",
    "        print(f\"\\nStatus: {item['status']}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> 2.2 Analise de Quantitativos </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analise de PDFs \n",
    "import os\n",
    "import fitz  # Módulo PyMuPDF\n",
    "\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "pdf_image_info = {}  # Dicionário para armazenar informações sobre PDFs e imagens\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    dir_name = os.path.basename(root)  # Nome do diretório no último nível\n",
    "    pdf_image_info[dir_name] = pdf_image_info.get(dir_name, {\"total\": 0})\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                status = \"O PDF é pesquisável\"\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"\n",
    "                \n",
    "            pdf_image_info[dir_name][\"total\"] += 1\n",
    "            pdf_image_info[dir_name].setdefault(\"pdf_pesquisavel\", 0)\n",
    "            pdf_image_info[dir_name].setdefault(\"pdf_nao_pesquisavel\", 0)\n",
    "            \n",
    "            if status == \"O PDF é pesquisável\":\n",
    "                pdf_image_info[dir_name][\"pdf_pesquisavel\"] += 1\n",
    "            else:\n",
    "                pdf_image_info[dir_name][\"pdf_nao_pesquisavel\"] += 1\n",
    "        elif any(file.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "            pdf_image_info[dir_name].setdefault(\"total\", 0)\n",
    "            pdf_image_info[dir_name].setdefault(\"imagens\", 0)\n",
    "            pdf_image_info[dir_name][\"total\"] += 1\n",
    "            pdf_image_info[dir_name].setdefault(\"imagens\", 0)\n",
    "            pdf_image_info[dir_name][\"imagens\"] += 1\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"pdf_image_info.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(pdf_image_info, json_file, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "#json_file_path = os.path.join(target_directory, f\"{os.path.splitext(file)[0]}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processo gravando um unico arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Leioute geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 1. CABECALHO\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['nome_prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['tipo_nota_fiscal'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nr_nro_nf = numero_nota_match.group(1)\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = numero_nota_match.group(1)\n",
    "    else:\n",
    "        nr_nro_nf = 0    \n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['codigo_verificacao'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho, nr_nro_nf\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "def extract_fields_prestador(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    nf_data_prestador = {}\n",
    "    \n",
    "    nf_data_prestador['secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['inscricao_estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador['telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['razao_social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['nome_fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['email'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['email'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_tomador(text):\n",
    "    nf_data_tomador = {}\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['rg'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['rg'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['inscricao_estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['razao_social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['email'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['email'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_impostos(text):\n",
    "    nf_data_valores = {}\n",
    "    nf_data_valores['secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_servicos'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['valor_servicos'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_deducao'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_deducao'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_incond'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_incond'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['base_calculo'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['base_calculo'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['aliquota'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['aliquota'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss_retido'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss_retido'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_cond'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_cond'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_pis'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_pis'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_cofins'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_cofins'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_ir'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_ir'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_inss'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_inss'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_csll'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_csll'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['outras_retencoes'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['outras_retencoes'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_liquido'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_liquido'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes\n",
    "\n",
    "\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho, nro_nota = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                # 6. CNAE\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['secao'] = \"6. CNAE\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                text = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_CNAE['cnae'] = text.strip()\n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 545  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 540\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[nr_nro_nf] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"MAGEfwdnotasfiscaiscarrier.json\")\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"pdf_info_novissimo.json\")\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Leioute Modernizacao Informatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_data_servico = {}\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "# 1. CABECALHO\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['nome_prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['tipo_nota_fiscal'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nr_nro_nf = numero_nota_match.group(1)\n",
    "        nf_data_cabecalho['numero_nota_fiscal'] = numero_nota_match.group(1)\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['competencia'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['dt_hr_emissao'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['codigo_verificacao'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "def extract_fields_prestador(text): # Função para extrair campos e valores dentro de um retângulo\n",
    "    nf_data_prestador = {}\n",
    "    \n",
    "    nf_data_prestador['secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['inscricao_estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    #telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-])', text)\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match: \n",
    "        telefone_str = telefone_match.group(1)\n",
    "        # Remover quebras de linha\n",
    "        telefone_str = telefone_str.replace('.', '')\n",
    "        telefone_str = telefone_str.replace('\\n', '')\n",
    "                \n",
    "        nf_data_prestador['telefone'] = telefone_str\n",
    "    else:\n",
    "        nf_data_prestador['telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['razao_social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['nome_fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['email'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['email'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_tomador(text):\n",
    "    nf_data_tomador = {}\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['cpf_cnpj_com_mascara'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['cpf_cnpj_sem_mascara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['rg'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['rg'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['inscricao_municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['inscricao_estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['inscricao_estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['razao_social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['endereco'] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['email'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['email'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_impostos(text):\n",
    "    nf_data_valores = {}\n",
    "    nf_data_valores['secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_servicos'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['valor_servicos'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_deducao'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_deducao'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_incond'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_incond'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['base_calculo'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['base_calculo'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['aliquota'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['aliquota'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_iss_retido'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_iss_retido'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['desc_cond'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['desc_cond'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_pis'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_pis'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_cofins'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_cofins'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_ir'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_ir'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_inss'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_inss'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_csll'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_csll'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['outras_retencoes'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['outras_retencoes'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['valor_liquido'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['valor_liquido'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_outras_info(text):\n",
    "    nf_data_outras_informacoes = {}\n",
    "    nf_data_outras_informacoes['secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['exigibilidade_iss'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['regime_tributacao'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['simples_nacional'] = simples_nacional_value\n",
    "        \n",
    "        \n",
    "    # Extrair ISSQN RETIDO:\n",
    "    local_prestacao_servico_match = re.search(r'ISSQN RETIDO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['issqn_retido'] = local_prestacao_servico_value        \n",
    "        \n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_prestacao_servico'] = local_prestacao_servico_value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['local_incidencia'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes\n",
    "\n",
    "\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 5\n",
    "                x1 = 600\n",
    "                y1 = 400\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                # 6. CNAE\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['secao'] = \"6. CNAE\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                text = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_CNAE['cnae'] = text.strip()\n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 545  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 540\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                nome_arquivo = file\n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"nome_arquivo\": nome_arquivo,\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"MAGEfwdnotasfiscaiscarrier.json\")\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diretório TESTE raiz para documentos PDF pesquisaveis\n",
    "root_directory = '.\\\\data\\data_teste'  # Diretório raiz TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"data\\data_teste\\documentos_pdf_teste\\Nota Fiscal Eletrônica 3.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\".\\data\\data_teste\\documentos_pdf_teste\\272519EC-959B-4460-BBE6-D80D272B9ACD.PDF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o arquivo PDF\n",
    "pdf_document = fitz.open(file)\n",
    "\n",
    "# Página do PDF\n",
    "page_number = 0  # Defina o número da página que deseja analisar\n",
    "page = pdf_document[page_number]\n",
    "\n",
    "# Definir retângulo de interesse\n",
    "x0 = 0\n",
    "y0 = 4\n",
    "x1 = 600\n",
    "y1 = 200  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "# Extrair texto dentro do retângulo\n",
    "text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ferramentas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PyPDF2.PdfReader(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processo gravando multiplos arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Funcoes de extracao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analise PDF + extracao + gravaÇao arquivos JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                \n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                \n",
    "                #pdf_info = {}  # Crie um novo dicionário para cada PDF\n",
    "                \n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha e rótulo\n",
    "                text = text.replace('\\n', ' ')\n",
    "                label = \"DISCRIMINAÇÃO DOS SERVIÇOS\"\n",
    "                if text.startswith(label):\n",
    "                    text = text[len(label):].strip()\n",
    "\n",
    "                # Atribuir texto ao dicionário\n",
    "                nf_data_servico['discriminacao_servicos'] = text\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['valor_total_nota'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                # 6. CNAE\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['secao'] = \"6. CNAE\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                text = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_CNAE['cnae'] = text.strip()\n",
    "                \n",
    "                \n",
    "                # 6. CNAE e Item da Lista de Serviços\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE e Item da Lista de Serviços\"\n",
    "\n",
    "                # Definir retângulo de interesse CNAE\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 545  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "\n",
    "                # Extrair CNAE\n",
    "                nf_data_CNAE_match = re.search(r'CNAE\\s+(.+)', text)\n",
    "                if nf_data_CNAE_match:\n",
    "                    # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                    nf_data_CNAE_str = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "                    # Remover quebras de linha\n",
    "                    nf_data_CNAE_str = nf_data_CNAE_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['cnae'] = nf_data_CNAE_str\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Item da Lista de Serviços    \n",
    "                # Definir retângulo de interesse - Item da Lista de Serviços\n",
    "                x0 = 0\n",
    "                y0 = 540\n",
    "                x1 = 600\n",
    "                y1 = 560  # Ajuste este valor para delimitar a região vertical    \n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))     \n",
    "                    \n",
    "                # Extrair Item da Lista de Serviços\n",
    "                nf_item_lista_servicos_match = re.search(r'Item da Lista de Serviços\\s+(.+)', text)\n",
    "                if nf_item_lista_servicos_match:\n",
    "                    nf_item_lista_servicos_str = re.sub(r'^Item da Lista de Serviços - ', '', text, count=1) \n",
    "                    # Remover quebras de linha\n",
    "                    #nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n \\n', '')\n",
    "                    nf_item_lista_servicos_str = nf_item_lista_servicos_str.replace('\\n', ' ')\n",
    "                    nf_data_CNAE['item_lista_servicos'] = nf_item_lista_servicos_str\n",
    "                      \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['dados_complementares'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['observacao'] = text.strip()\n",
    "                \n",
    "                \n",
    "                #nome_arquivo = pdf_info[file]\n",
    "                \n",
    "                \n",
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "                \n",
    "                \n",
    "                # Salvando as informações em um arquivo JSON\n",
    "                #json_file_path = os.path.join(root_directory, \"pdf_info4.json\")\n",
    "                #with open(target_directory, \"w\", encoding='utf-8') as json_file:\n",
    "                #    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "                #print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            \n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"      \n",
    "                \n",
    "                \n",
    "                \n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(target_directory, \"pdf_data_3.json\")\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json.dump(pdf_image_info, json_file, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")                \n",
    "          \n",
    "               \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                pdf_info[file] = {\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "# Salvando as informações em um arquivo JSON\n",
    "json_file_path = os.path.join(root_directory, \"pdf_info.json\")\n",
    "\n",
    "\n",
    "with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"As informações foram salvas em {json_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotina para salvar em varios arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Remover caracteres especiais e substituir espaços por underscores\n",
    "                cleaned_filename = unidecode(file)\n",
    "                cleaned_filename = re.sub(r'\\W+', '_', cleaned_filename)\n",
    "                cleaned_filename = cleaned_filename.replace(\"_\", \" \").strip()\n",
    "                cleaned_filename = \"_\".join(cleaned_filename.split())\n",
    "                \n",
    "                json_file_path = os.path.join(target_directory, f\"{os.path.splitext(cleaned_filename)[0]}.json\")\n",
    "                \n",
    "                with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "                    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "                \n",
    "                print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #pdf_info[\"diretorio\"] = os.path.basename(root)\n",
    "                pdf_info[file] = {\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    },\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funcoes de arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_json(pdf_path, text):\n",
    "    json_data = {\n",
    "        \"pdf_name\": os.path.basename(pdf_path),\n",
    "        \"text\": text\n",
    "    }\n",
    "    json_filename = pdf_path.with_suffix(\".json\")\n",
    "    with open(json_filename, \"w\") as json_file:\n",
    "        json.dump(json_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def process_pdfs_in_directory(directory_path):\n",
    "    pdf_paths = Path(directory_path).glob(\"*.pdf\")\n",
    "    for pdf_path in pdf_paths:\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        save_as_json(pdf_path, text)\n",
    "        print(f\"Created JSON for {pdf_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codigos anteriores (AVALIAR REDUNDANCIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # Módulo PyMuPDF\n",
    "import re\n",
    "import json\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextContainer, LTChar\n",
    "\n",
    "\n",
    "nf_data_servico = {}\n",
    "def is_pdf_searchable(pdf_path):\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        is_searchable = all(page.get_text(\"text\") != \"\" for page in pdf_document)\n",
    "        pdf_document.close()\n",
    "        return is_searchable\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao verificar o PDF: {e}\")\n",
    "        return False\n",
    "\n",
    "def extract_fields_cabecalho(text):\n",
    "    nf_data_cabecalho = {}\n",
    "    nf_data_cabecalho['Origem'] = \"reserrosistemaprefeituranf.zip\"\n",
    "    nf_data_cabecalho['Secao'] = \"1 - CABECALHO\"\n",
    "    \n",
    "    # Extrair Nome da Prefeitura\n",
    "    nome_prefeitura_match = re.search(r'PREFEITURA (.+)', text)\n",
    "    if nome_prefeitura_match:\n",
    "        nome_prefeitura = \"PREFEITURA \" + nome_prefeitura_match.group(1)\n",
    "        nf_data_cabecalho['Nome da Prefeitura'] = nome_prefeitura\n",
    "\n",
    "    # Extrair Tipo de NF\n",
    "    tipo_nf_match = re.search(r'NOTA FISCAL (.+)', text)\n",
    "    if tipo_nf_match:\n",
    "        tipo_nf = \"NOTA FISCAL \" + tipo_nf_match.group(1)\n",
    "        nf_data_cabecalho['Tipo de NF'] = tipo_nf\n",
    "    \n",
    "    # Extrair Número da Nota\n",
    "    numero_nota_match = re.search(r'Número da Nota:\\s+(\\d+)', text)\n",
    "    if numero_nota_match:\n",
    "        nf_data_cabecalho['Número da Nota'] = numero_nota_match.group(1)\n",
    "\n",
    "    # Extrair Competência\n",
    "    competencia_match = re.search(r'Competência:\\s+(.+)', text)\n",
    "    if competencia_match:\n",
    "        nf_data_cabecalho['Competência'] = competencia_match.group(1)\n",
    "\n",
    "    # Extrair Data e Hora de Emissão\n",
    "    data_emissao_match = re.search(r'Data e Hora da Emissão:\\s+(.+)', text)\n",
    "    if data_emissao_match:\n",
    "        nf_data_cabecalho['Data e Hora de Emissão'] = data_emissao_match.group(1)\n",
    "        \n",
    "    # Extrair Data e Hora de Emissão\n",
    "    codigo_verificacao_match = re.search(r'Código Verificação:\\s+(.+)', text)\n",
    "    if codigo_verificacao_match:\n",
    "        nf_data_cabecalho['Código Verificação'] = codigo_verificacao_match.group(1)    \n",
    "\n",
    "    return nf_data_cabecalho\n",
    "\n",
    "# 2. PRESTADOR DE SERVIÇO\n",
    "nf_data_prestador = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_prestador(text):\n",
    "    \n",
    "    nf_data_prestador['Secao'] = \"2. PRESTADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_prestador['CPF/CNPJ Formatado'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_prestador['CPF/CNPJ Sem Máscara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_prestador['Inscrição Municipal'] = inscricao_municipal_match.group(1)\n",
    "        \n",
    "               \n",
    "    # Extrair Inscrição Estadual\n",
    "    #if \"Inscrição Estadual:\" in text:\n",
    "    \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_prestador['Inscrição Estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_prestador['Inscrição Estadual'] = inscricao_estadual_match.group(1)       \n",
    "        \n",
    "                \n",
    "    \n",
    "\n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+([0-9.\\s-]+)', text)\n",
    "    if telefone_match:\n",
    "        nf_data_prestador['Telefone'] = telefone_match.group(1)\n",
    "    else:\n",
    "        nf_data_prestador['Telefone'] = \"NONE\"\n",
    "\n",
    "         \n",
    "                \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_prestador['Nome/Razão Social'] = razao_social_match.group(1)  \n",
    "                \n",
    "    # Nome de Fantasia:\n",
    "    nome_fantasia_match = re.search(r'Nome de Fantasia:\\s+(.+)', text)\n",
    "    if nome_fantasia_match:\n",
    "        nf_data_prestador['Nome de Fantasia'] = nome_fantasia_match.group(1)                                    \n",
    "                \n",
    "            \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_prestador['Endereço '] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_prestador['E-mail'] = email_match.group(1)  \n",
    "    else:\n",
    "        nf_data_prestador['E-mail'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "   \n",
    "        \n",
    "\n",
    "    return nf_data_prestador\n",
    "\n",
    "nf_data_tomador = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_tomador(text):\n",
    "    \n",
    "    \n",
    "    nf_data_tomador['Secao'] = \"3. TOMADOR DE SERVIÇO\"\n",
    "    \n",
    "    \n",
    "    # Extrair CPF/CNPJ com máscara 1\n",
    "    if \"CPF/CNPJ:\" in text:\n",
    "        cpf_cnpj_formatado_match = re.search(r'(\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2})', text)\n",
    "        if cpf_cnpj_formatado_match:\n",
    "                        nf_data_tomador['1-CPF/CNPJ Formatado'] = cpf_cnpj_formatado_match.group(1)\n",
    "                        nf_data_tomador['2-CPF/CNPJ Sem Máscara'] = re.sub(r'\\D', '', cpf_cnpj_formatado_match.group(1))\n",
    "\n",
    "        \n",
    "    # Extrair RG    \n",
    "    rg_match = re.search(r'RG:\\s+(.+)', text)   \n",
    "    if rg_match:\n",
    "        rg_str = rg_match.group(1)\n",
    "        if rg_str == 'Telefone:':\n",
    "            nf_data_tomador['RG'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['RG'] = rg_match.group(1)  \n",
    " \n",
    "        \n",
    "    # Extrair Telefone\n",
    "    telefone_match = re.search(r'Telefone:\\s+(.+)', text)\n",
    "    if telefone_match:\n",
    "        telefone_str = telefone_match.group(1)\n",
    "        if telefone_str == 'Inscrição Estadual:':\n",
    "            nf_data_tomador['Telefone'] = \"NONE\"  # Valor padrão quando não há correspondência\n",
    "        else:    \n",
    "            nf_data_tomador['Telefone'] = telefone_match.group(1)\n",
    "     \n",
    "\n",
    "    # Extrair Inscrição Municipal\n",
    "    inscricao_municipal_match = re.search(r'Inscrição Municipal:\\s+(.+)', text)\n",
    "    if inscricao_municipal_match:\n",
    "        nf_data_tomador['Inscrição Municipal'] = inscricao_municipal_match.group(1)\n",
    "                \n",
    "                \n",
    "                \n",
    "    # Extrair Inscrição Estadual\n",
    "    inscricao_estadual_match = re.search(r'Inscrição Estadual:\\s+(.+)', text)\n",
    "    if inscricao_estadual_match:\n",
    "        inscricao_estadual_str = inscricao_estadual_match.group(1)\n",
    "        if inscricao_estadual_str == 'Nome/Razão Social:':\n",
    "            nf_data_tomador['Inscrição Estadual'] = \"NONE\"\n",
    "        else:    \n",
    "            nf_data_tomador['Inscrição Estadual'] = inscricao_estadual_match.group(1)   \n",
    "                \n",
    "    \n",
    "    # Nome/Razão Social:\n",
    "    razao_social_match = re.search(r'Nome/Razão Social:\\s+(.+)', text)\n",
    "    if razao_social_match:\n",
    "        nf_data_tomador['Nome/Razão Social'] = razao_social_match.group(1)                                                \n",
    "                \n",
    "    # Endereço:\n",
    "    endereco_match = re.search(r'Endereço:\\s+(.+)', text)\n",
    "    if endereco_match:\n",
    "        nf_data_tomador['Endereço '] = endereco_match.group(1) \n",
    "    \n",
    "    # E-mail:\n",
    "    email_match = re.search(r'E-mail:\\s+(.+)', text)\n",
    "    if email_match:\n",
    "        nf_data_tomador['E-mail'] = email_match.group(1) \n",
    "    else:\n",
    "        nf_data_tomador['E-mail'] = \"NONE\"  # Valor padrão quando não há correspondência    \n",
    "\n",
    "    return nf_data_tomador\n",
    "\n",
    "# 7. VALORES E IMPOSTOS\n",
    "nf_data_valores = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_impostos(text):\n",
    "    \n",
    "    \n",
    "    nf_data_valores['Secao'] = \"7. VALORES E IMPOSTOS\"\n",
    "    \n",
    "    # Extrair VALOR SERVIÇOS:\n",
    "    valor_servicos_match = re.search(r'VALOR SERVIÇOS:\\s+(.+)', text)\n",
    "    if valor_servicos_match:\n",
    "        valor_servicos_str = valor_servicos_match.group(1)\n",
    "        valor_servicos_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_servicos_str)\n",
    "        if valor_servicos_sem_formato:\n",
    "            valor_servicos_sem_formatacao = valor_servicos_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR SERVIÇOS'] = float(valor_servicos_sem_formatacao)\n",
    "        else:\n",
    "            nf_data_valores['VALOR SERVIÇOS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "  \n",
    "  \n",
    "    # Extrair VALOR DEDUÇÃO:\n",
    "    valor_deducao_match = re.search(r'DEDUÇÃO:\\s+(.+)', text)\n",
    "    if valor_deducao_match:\n",
    "        valor_deducao_str = valor_deducao_match.group(1)\n",
    "        valor_deducao_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_deducao_str)\n",
    "        if valor_deducao_sem_formato:\n",
    "            valor_deducao_sem_formato = valor_deducao_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR DEDUÇÃO'] = float(valor_deducao_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR DEDUÇÃO'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "        \n",
    "    # Extrair DESC. INCOND:\n",
    "    valor_desc_match = re.search(r'DESC. INCOND:\\s+(.+)', text)\n",
    "    if valor_desc_match:\n",
    "        valor_desc_str = valor_desc_match.group(1)\n",
    "        valor_desc_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_str)\n",
    "        if valor_desc_sem_formato:\n",
    "            valor_desc_sem_formato = valor_desc_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['DESC. INCOND'] = float(valor_desc_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['DESC. INCOND'] = 0.0  # Valor não encontrado ou não está no formato esperado        \n",
    "        \n",
    "\n",
    "    # Extrair BASE DE CÁLCULO:\n",
    "    valor_calculo_match = re.search(r'CÁLCULO:\\s+(.+)', text)\n",
    "    if valor_calculo_match:\n",
    "        valor_calculo_str = valor_calculo_match.group(1)\n",
    "        valor_calculo_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_calculo_str)\n",
    "        if valor_calculo_sem_formato:\n",
    "            valor_calculo_sem_formato = valor_calculo_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['BASE DE CÁLCULO'] = float(valor_calculo_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['BASE DE CÁLCULO'] = 0.0  # Valor não encontrado ou não está no formato esperado    \n",
    "\n",
    "\n",
    "\n",
    "    # Extrair ALÍQUOTA:\n",
    "    valor_aliquota_match = re.search(r'ALÍQUOTA:\\s+(.+)', text)\n",
    "    if valor_aliquota_match:\n",
    "        valor_aliquota_str = valor_aliquota_match.group(1)\n",
    "        valor_aliquota_sem_formato = re.search(r'([\\d.,]+)%', valor_aliquota_str)  # Ajuste aqui\n",
    "        if valor_aliquota_sem_formato:\n",
    "            valor_aliquota_sem_formato = valor_aliquota_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['ALÍQUOTA'] = float(valor_aliquota_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['ALÍQUOTA'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "\n",
    "\n",
    "    # Extrair VALOR ISS:\n",
    "    valor_iss_match = re.search(r'VALOR ISS:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_str = valor_iss_match.group(1)\n",
    "        valor_iss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_str)\n",
    "        if valor_iss_sem_formato:\n",
    "            valor_iss_sem_formato = valor_iss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR ISS'] = float(valor_iss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR ISS'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR ISS RETIDO:\n",
    "    valor_iss_retido_match = re.search(r'RETIDO:\\s+(.+)', text)\n",
    "    if valor_iss_match:\n",
    "        valor_iss_retido_str = valor_iss_retido_match.group(1)\n",
    "        valor_iss_retido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_iss_retido_str)\n",
    "        if valor_iss_retido_sem_formato:\n",
    "            valor_iss_retido_sem_formato = valor_iss_retido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR ISS RETIDO'] = float(valor_iss_retido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR ISS RETIDO'] = 0.0  # Valor não encontrado ou não está no formato esperado \n",
    "\n",
    "    # Extrair VALOR DESC. COND:\n",
    "    valor_desc_cond_match = re.search(r'DESC. COND:\\s+(.+)', text)\n",
    "    if valor_desc_cond_match:\n",
    "        valor_desc_cond_str = valor_desc_cond_match.group(1)\n",
    "        valor_desc_cond_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_desc_cond_str)\n",
    "        if valor_desc_cond_sem_formato:\n",
    "            valor_desc_cond_sem_formato = valor_desc_cond_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['DESC. COND'] = float(valor_desc_cond_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['DESC. COND'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR PIS:\n",
    "    valor_pis_match = re.search(r'VALOR PIS:\\s+(.+)', text)\n",
    "    if valor_pis_match:\n",
    "        valor_pis_str = valor_pis_match.group(1)\n",
    "        valor_pis_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_pis_str)\n",
    "        if valor_pis_sem_formato:\n",
    "            valor_pis_sem_formato = valor_pis_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR PIS'] = float(valor_pis_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR PIS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair VALOR COFINS:\n",
    "    valor_cofins_match = re.search(r'VALOR COFINS:\\s+(.+)', text)\n",
    "    if valor_cofins_match:\n",
    "        valor_cofins_str = valor_cofins_match.group(1)\n",
    "        valor_cofins_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_cofins_str)\n",
    "        if valor_cofins_sem_formato:\n",
    "            valor_cofins_sem_formato = valor_cofins_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR COFINS'] = float(valor_cofins_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR COFINS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR IR:\n",
    "    valor_ir_match = re.search(r'VALOR IR:\\s+(.+)', text)\n",
    "    if valor_ir_match:\n",
    "        valor_ir_str = valor_ir_match.group(1)\n",
    "        valor_ir_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_ir_str)\n",
    "        if valor_ir_sem_formato:\n",
    "            valor_ir_sem_formato = valor_ir_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR IR'] = float(valor_ir_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR IR'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR INSS:\n",
    "    valor_inss_match = re.search(r'VALOR INSS:\\s+(.+)', text)\n",
    "    if valor_inss_match:\n",
    "        valor_inss_str = valor_inss_match.group(1)\n",
    "        valor_inss_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_inss_str)\n",
    "        if valor_inss_sem_formato:\n",
    "            valor_inss_sem_formato = valor_inss_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR INSS'] = float(valor_inss_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR INSS'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "            \n",
    "    # Extrair VALOR CSLL:\n",
    "    valor_csll_match = re.search(r'VALOR CSLL:\\s+(.+)', text)\n",
    "    if valor_csll_match:\n",
    "        valor_csll_str = valor_csll_match.group(1)\n",
    "        valor_csll_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_csll_str)\n",
    "        if valor_csll_sem_formato:\n",
    "            valor_csll_sem_formato = valor_csll_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR CSLL'] = float(valor_csll_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR CSLL'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    # Extrair OUTRAS RETENÇÕES:\n",
    "    outras_retencoes_match = re.search(r'OUTRAS RETENÇÕES:\\s+(.+)', text)\n",
    "    if outras_retencoes_match:\n",
    "        outras_retencoes_str = outras_retencoes_match.group(1)\n",
    "        outras_retencoes_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', outras_retencoes_str)\n",
    "        if outras_retencoes_sem_formato:\n",
    "            outras_retencoes_sem_formato = outras_retencoes_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['OUTRAS RETENÇÕES'] = float(outras_retencoes_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['OUTRAS RETENÇÕES'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "    \n",
    "    \n",
    "    # Extrair VALOR LÍQUIDO:\n",
    "    valor_liquido_match = re.search(r'VALOR LÍQUIDO:\\s+(.+)', text)\n",
    "    if valor_liquido_match:\n",
    "        valor_liquido_str = valor_liquido_match.group(1)\n",
    "        valor_liquido_sem_formato = re.search(r'R\\$\\s*([\\d.,]+)', valor_liquido_str)\n",
    "        if valor_liquido_sem_formato:\n",
    "            valor_liquido_sem_formato = valor_liquido_sem_formato.group(1).replace('.', '').replace(',', '.').strip()\n",
    "            nf_data_valores['VALOR LÍQUIDO'] = float(valor_liquido_sem_formato)\n",
    "        else:\n",
    "            nf_data_valores['VALOR LÍQUIDO'] = 0.0  # Valor não encontrado ou não está no formato esperado\n",
    "        \n",
    "\n",
    "    return nf_data_valores\n",
    "\n",
    "\n",
    "# 9. OUTRAS INFORMAÇOES / CRITICAS\n",
    "nf_data_outras_informacoes = {}\n",
    "# Função para extrair campos e valores dentro de um retângulo\n",
    "def extract_fields_outras_info(text):\n",
    "    \n",
    "    nf_data_outras_informacoes['Secao'] = \"9. OUTRAS INFORMAÇOES / CRITICAS\"\n",
    "    \n",
    "    # Extrair EXIGIBILIDADE ISS:\n",
    "    exigibilidade_iss_match = re.search(r'EXIGIBILIDADE ISS\\s+(.+)', text)\n",
    "    if exigibilidade_iss_match:\n",
    "        exigibilidade_iss_value = exigibilidade_iss_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['EXIGIBILIDADE ISS'] = exigibilidade_iss_value\n",
    "        \n",
    "    # Extrair REGIME TRIBUTAÇÃO:\n",
    "    regime_tributacao_match = re.search(r'REGIME TRIBUTAÇÃO\\s+(.+)', text)\n",
    "    if regime_tributacao_match:\n",
    "        regime_tributacao_value = regime_tributacao_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['REGIME TRIBUTAÇÃO'] = regime_tributacao_value\n",
    "    \n",
    "    # Extrair SIMPLES NACIONAL:\n",
    "    simples_nacional_match = re.search(r'SIMPLES NACIONAL\\s+(.+)', text)\n",
    "    if simples_nacional_match:\n",
    "        simples_nacional_value = simples_nacional_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['SIMPLES NACIONAL'] = simples_nacional_value\n",
    "    \n",
    "    # Extrair LOCAL PRESTAÇÃO SERVIÇO:\n",
    "    local_prestacao_servico_match = re.search(r'LOCAL\\. PRESTAÇÃO\\s+SERVIÇO\\s+(.+)', text)\n",
    "    if local_prestacao_servico_match:\n",
    "        local_prestacao_servico_value = local_prestacao_servico_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['LOCAL PRESTAÇÃO SERVIÇO'] = local_prestacao_servico_value\n",
    "    \n",
    "    # Extrair LOCAL INCIDÊNCIA:\n",
    "    local_incidencia_match = re.search(r'LOCAL INCIDÊNCIA\\s+(.+)', text)\n",
    "    if local_incidencia_match:\n",
    "        local_incidencia_value = local_incidencia_match.group(1).strip()\n",
    "        nf_data_outras_informacoes['LOCAL INCIDÊNCIA'] = local_incidencia_value\n",
    "   \n",
    "    \n",
    "    return nf_data_outras_informacoes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root_directory = '.\\\\Extracao_PDF_NF'  # Diretório raiz\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                # 1 - cabecalho\n",
    "                pdf_document = fitz.open(file_path)\n",
    "                page_number = 0  # Defina o número da página que deseja analisar\n",
    "                page = pdf_document[page_number]\n",
    "                x0 = 0\n",
    "                y0 = 0\n",
    "                x1 = 600\n",
    "                y1 = 110\n",
    "                \n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_cabecalho = extract_fields_cabecalho(text)\n",
    "                \n",
    "                \n",
    "                # 2. PRESTADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 100\n",
    "                x1 = 600\n",
    "                y1 = 236  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                \n",
    "                nf_data_prestador = extract_fields_prestador(text)\n",
    "                \n",
    "                # 3. TOMADOR DE SERVIÇO\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 210\n",
    "                x1 = 600\n",
    "                y1 = 340  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                nf_data_tomador = extract_fields_tomador(text)\n",
    "                \n",
    "                \n",
    "                # 4. DESCRIMINACAO DOS SERVIÇOS\n",
    "                nf_data_servico = {}\n",
    "                nf_data_servico['Secao'] = \"4. DESCRIMINACAO DOS SERVIÇOS\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 330\n",
    "                x1 = 600\n",
    "                y1 = 500  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_servico['DISCRIMINAÇÃO DOS SERVIÇOS'] = text.strip()\n",
    "                \n",
    "                \n",
    "                # 5. VALOR TOTAL\n",
    "                nf_data_valor_total = {}\n",
    "                nf_data_valor_total['Secao'] = \"5. VALOR TOTAL\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 500\n",
    "                x1 = 600\n",
    "                y1 = 535  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Usar expressão regular para extrair apenas os caracteres numéricos e pontos decimais\n",
    "                valor_total_match = re.search(r'R\\$ ([\\d,.]+)', text)\n",
    "                if valor_total_match:\n",
    "                    valor_total_sem_formatacao = valor_total_match.group(1).replace('.', '').replace(',', '.')\n",
    "                    nf_data_valor_total['VALOR TOTAL DA NOTA'] = float(valor_total_sem_formatacao)\n",
    "                    \n",
    "                    \n",
    "                # 6. CNAE\n",
    "                nf_data_CNAE = {}\n",
    "                nf_data_CNAE['Secao'] = \"6. CNAE\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 525\n",
    "                x1 = 600\n",
    "                y1 = 555  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"CNAE:\"\n",
    "                text = re.sub(r'^CNAE - ', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_CNAE['CNAE'] = text.strip()    \n",
    "                \n",
    "                \n",
    "                # 7. VALORES E IMPOSTOS\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 550\n",
    "                x1 = 600\n",
    "                y1 = 650  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_valores = extract_fields_impostos(text)\n",
    "                \n",
    "                # 8. DADOS COMPLEMENTARES\n",
    "                nf_data_dados_complementares = {}\n",
    "                nf_data_dados_complementares['Secao'] = \"8. DADOS COMPLEMENTARES\"\n",
    "\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 650\n",
    "                x1 = 600\n",
    "                y1 = 680  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^DADOS COMPLEMENTARES', '', text, count=1)\n",
    "                if text == \" \":\n",
    "                    text = \"NONE\"\n",
    "                    nf_data_dados_complementares['DADOS COMPLEMENTARES'] = text.strip()\n",
    "                else:    \n",
    "                    # Extrair texto dentro do retângulo\n",
    "                    nf_data_dados_complementares['DADOS COMPLEMENTARES'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                # 9. OUTRAS INFORMAÇOES / CRITICAS  \n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 680\n",
    "                x1 = 600\n",
    "                y1 = 725  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Extrair campos e valores\n",
    "                nf_data_outras_informacoes = extract_fields_outras_info(text)\n",
    "                \n",
    "                \n",
    "                # 10. OBSERVACOES\n",
    "                nf_data_observacao = {}\n",
    "                nf_data_observacao['Secao'] = \"10. OBSERVACOES\"\n",
    "                # Definir retângulo de interesse\n",
    "                x0 = 0\n",
    "                y0 = 725\n",
    "                x1 = 600\n",
    "                y1 = 760  # Ajuste este valor para delimitar a região vertical\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                text = page.get_text(\"text\", clip=(x0, y0, x1, y1))\n",
    "\n",
    "                # Remove a primeira ocorrência de \"Observação:\"\n",
    "                text = re.sub(r'^Observação:', '', text, count=1)\n",
    "\n",
    "                # Remover quebras de linha\n",
    "                text = text.replace('\\n', ' ')\n",
    "\n",
    "                # Extrair texto dentro do retângulo\n",
    "                nf_data_observacao['Observação'] = text.strip()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                pdf_info[file] = {\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        \"data_cabecalho\": nf_data_cabecalho,\n",
    "                        \"data_prestador\": nf_data_prestador,\n",
    "                        \"data_tomador\": nf_data_tomador,\n",
    "                        \"data_servico\": nf_data_servico,\n",
    "                        \"data_valor_total\": nf_data_valor_total,\n",
    "                        \"data_CNAE\": nf_data_CNAE,\n",
    "                        \"data_valores\": nf_data_valores,\n",
    "                        \"data_dados_complementares\": nf_data_dados_complementares,\n",
    "                        \"data_outras_informacoes\": nf_data_outras_informacoes,\n",
    "                        \"data_observacao\": nf_data_observacao,\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "                # Monta o caminho para o arquivo JSON com base no nome do arquivo da NF\n",
    "                json_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.json\")\n",
    "                \n",
    "                with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "                    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "                \n",
    "                print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root_directory = '.\\\\Extracao_PDF_NF'  # Diretório raiz\n",
    "\n",
    "pdf_info = {}  # Dicionário para armazenar informações sobre PDFs\n",
    "\n",
    "# Função para verificar se o PDF é pesquisável (você deve implementar isso)\n",
    "def is_pdf_searchable(file_path):\n",
    "    # Implemente a lógica para verificar se o PDF é pesquisável\n",
    "    # Retorne True se for pesquisável, False caso contrário\n",
    "    pass\n",
    "\n",
    "for root, dirs, files in os.walk(root_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        if file.lower().endswith('.pdf'):\n",
    "            if is_pdf_searchable(file_path):\n",
    "                status = \"O PDF é pesquisável\"\n",
    "                \n",
    "                # Aqui você pode continuar com o restante do seu código\n",
    "                # Preencha os dados que deseja extrair do PDF e armazene no dicionário pdf_info\n",
    "                \n",
    "                pdf_info[file] = {\n",
    "                    \"diretorio\": os.path.basename(root),\n",
    "                    \"dados_NF_PDF\": {\n",
    "                        # ... Preencha os dados da nota fiscal aqui ...\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                pdf_document.close()\n",
    "\n",
    "                # Monta o caminho para o arquivo JSON com base no nome do arquivo da NF\n",
    "                json_file_path = os.path.join(root, f\"{os.path.splitext(file)[0]}.json\")\n",
    "                \n",
    "                with open(json_file_path, \"w\", encoding='utf-8') as json_file:\n",
    "                    json.dump(pdf_info, json_file, ensure_ascii=False, indent=4)\n",
    "                \n",
    "                print(f\"As informações foram salvas em {json_file_path}\")\n",
    "            else:\n",
    "                status = \"O PDF não é pesquisável\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdftool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
